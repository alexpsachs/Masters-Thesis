{
    "zecarlos": "Why sometimes use php://input and sometimes using the $_FILES array?\n. in my case it works fine um Firefox, Chrome, Safari. Using IE8 after pick the file it always returns Failed.\nCant figure out whats wrong...\n. ",
    "SeanJA": "If you are still curious, take a look at my updated server side code: http://github.com/SeanJA/file-uploader/blob/master/server/php.php\n. In my example code, you would do it at line 239:\nif(!$result['success']){\n    //...\n}else { \n    // query here\n}\n. I played with it a bit, I could get it to do anything beyond passing everything in post variables (including the file, which would be bad as there is a max post size in php, whcih is usually quite low...). You could set it to do it's ajax call to '/uploader/' + file_name instead I guess?\n. the work I did... well... it didn't really work, sorry about that\n. If you want to know how, check here: http://codeigniter.com/user_guide/general/urls.html Not sure if you can do it on a per controller basis, it might actually be easier to rewrite part of the javascript instead (the part I mentioned above).\n. Also, this might be of use to you: http://codeigniter.com/forums/viewthread/99570/\n. There is also a bit of a hack that you can do, I detailed it here: http://blog.seanja.com/2011/01/using-valums-file-uploader-with-codeigniter/\n. Works fine in IE 8 for me, which version of it are you using? I have not actually touched the javascript, so from when I forked it it worked fine.\n. Granted, I am posting to a php file and not asp, but that shouldn't matter too much...?\n. FYI: The readme is off a bit, the original php.php file returned {\"success\": false, \"error\": \"error message\"} http://github.com/valums/file-uploader/blob/master/server/readme.txt#L12 (see: http://github.com/valums/file-uploader/blob/master/server/php.php#L53 )\n. s'not too hard: { if xhr has function send() } { elseif xhr has function sendAsBinary() }\n. @loganbest You might want to remove all the pdfs from that zip file (it is kind of big...)\n. Not that it solves your problem, but you could replace all of this stuff:\n$files1 = scandir($dir);\nforeach(array_diff(scandir($dir),array('.','..')) as $f)if(is_file($dir.'/'.$f))$l[]=$f;\nwith:\n$files = glob($dir.'/*.pdf');\nactually, this would have been more like what you had:\n$dir = 'forms/pdf/';\n    foreach(glob($dir.'*.pdf') as $pdf){\n        $files[] = str_replace($dir, '', $pdf);\n    }\n. How about something similar to what php does with the $_FILES array? \n1) upload to temp dir\n2) move the uploaded file\n3) delete the temp ( function destructor*() { [delete temp file] }\n- destructor is a placeholder for the language of choice... (in php: __destruct )\n. There is a rails:metal example... if that helps? http://github.com/JackDanger/file-uploader/commit/03ed9ba68d46805e22a0014ac0eee9ecbd5acd8d\n. So, is that actually a rails example, or do you need a plugin to use that one?\n. Why not fork it and add it to the /server folder? Or create a gist instead so things can be improved/fixed easier?\n. Takes 2 seconds: http://gist.github.com/557021\n. It might be better if you were to create a patch file out of your code:\nhttp://ariejan.net/2009/10/26/how-to-create-and-apply-a-patch-with-git/\n. This problem seems to have gone away in later releases (not sure why...?). This can be closed.\n. That is because firefox supports streaming the file straght to the server rather than using the multipart-form.\n. This plugin uses XHR for uploading multiple files with progress-bar in FF3.6+, Safari4+, Chrome and falls back to hidden iframe based upload in other browsers, providing good user experience everywhere.\n. The 404 page being an \"invalid characters in the uri\" page?\n. This might help you out: http://github.com/dhorrigan/codeigniter-query-string\nMake sure that you set the config stuff properly:\nuri_protocol should not be \"AUTO\" (see: http://github.com/dhorrigan/codeigniter-query-string/issues#issue/1 )\n. Sound like you might be uploading the file via xhr but looking for it in the regular fileupload variable. \n. To be honest, I am no asp expert (nor do I pretend to be...). You might want to look at this example? http://gist.github.com/576593 Or possibly ask the author of the gist how he does it if you cannot follow it in C#.\n. How would you use javascript to split a file into small chunks?\n. Well... it does use that if the browser supports it.\n. Side note... are you really letting people create random directories on your server? That is a terrible idea.\n. Which browsers have you tried it in? Perhaps it is a browser specific bug (or missing feature of some browsers and not others)?\n. It could also be an implementation specific problem? IE: .net/java/something doesn't like the content type being passed to it, but php/rails/whatever doesn't really care?\nWhat does the backend run?\n. Put four spaces in front of the code:\n<input id=\"fileupload\" name=\"fileupload\" type=\"hidden\" value=\"1\" />\n<input id=\"fileuploadname\" name=\"fileuploadname\" type=\"hidden\" value=\"test-upload.txt\" />\nand:\n<input id=\"fileupload\" name=\"fileupload\" type=\"hidden\" value=\"0\" />\n<input id=\"fileuploadname\" name=\"fileuploadname\" type=\"hidden\" value=\"\" />\nEither way I think this will work (I have just written it out, not tested it):\nfunction createUploader(){\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('file-uploader-demo1'),\n            action: 'do-nothing.htm',\n            params = {fileupload: $('#fileupload').val(), fileuploadname: $('#fileuploadname')}\n        });\n    }\nwhere the $('#').val() is document.getElementById().value (I am lazy...)\n. Sorry, there is a typo apparently, it should be this for the params field:\n...\n    params = {\n        fileupload: $('#fileupload').val(), \n        fileuploadname: $('#fileuploadname').val()\n    }\n});\nThe php would be this:\n<input id=\"fileuploadname\" name=\"fileuploadname\" type=\"hidden\" value=\"<$php echo $fileuploadname; ?>\" />\n[Also, prefix your html/code with 4 spaces to have it not get wiped out by the cleaner and make it show up nicer ;).]\n. Do you have a demo page / some dummy code in a gist that I can look at? It is probably easier to look at it and then explain rather than to just try and explain without a full understanding of what you have done so far.\n. Have you looked in the $_GET array? If memory serves me correctly, the params are passed as $_GET params when the upload is done using the xhr method, but when the upload is done using the hidden iframe they are passed using $_POST. You could also just use $_REQUEST if you wanted to, but I would suggest against that as $_REQUEST has other problems beyond the scope of the question\nHere are my findings from the current code:\n/////hidden iframe, note the post method, this would be the standard way that you would do file uploads if you were just writing the html onto the page\n```\n_createForm: function(iframe, params){\n    //[snip]\n    var form = qq.toElement('');\nvar queryString = qq.obj2url(params, this._options.action);\n\nform.setAttribute('action', queryString);\nform.setAttribute('target', iframe.name);\nform.style.display = 'none';\ndocument.body.appendChild(form);\n\nreturn form;\n\n}\n```\n/////xhr upload method, as you are pushing the file straight to the server in bytes, I don't think you can throw in any post data because that would be written to the file and mess everything up, you can however put the params into the query string (ie: /upload.php?param1=123&param2=234) and you will have no problems\n_upload: function(){\n    //[snip]\n    xhr.open(\"POST\", queryString, true);\n    xhr.setRequestHeader(\"X-Requested-With\", \"XMLHttpRequest\");\n    xhr.setRequestHeader(\"X-File-Name\", encodeURIComponent(name));\n    xhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\n    xhr.send(file);\n}\n. Hmmm... on second inspection, the $_POST array should never be filled out:\nvar queryString = qq.obj2url(params, this._options.action);\nform.setAttribute('action', queryString);\nPuts the target as blah.php?var1=123&var2=234.\n. Pretty sure this can be closed now @valums\n. I am curious why you wanted this feature...?\n. There are actually a few problems with .text() in jQuery that result in inconsitancies. New lines are left alone in firefox and chrome, but in IE they are removed. Also, this doesn't work as expected: \n$('<strong>test</strong> <br /><em>is</em> | <strong>not </strong> | wrong').text();\n. Do you have a patch?\n. You could just use a normal file field.\n. This is a dupe of #103\n. How does one drag files onto the browser on a tablet?\n. You should put that stuff in a gist instead, then it will be parsed right and you can break it into different files ;)\n. 1. Select multiple files where?\n2. sizeLimit should be validated on the server side of things (set on the server side) so not sure how that is an IE9 bug?\n3. You can upload as many files as your server has space for can't you? They each get uploaded separately by the script\n. el.innerTEXT doesn't exist in my version of firefox...\nNor does it seem to exist in the mozilla spec?\nThis one does though: https://developer.mozilla.org/En/DOM/Node.textContent\nWhat are you trying to fix?\n. Perhaps this helps? Unless that was you too... then probably not\nhttp://stackoverflow.com/questions/3664502/servercontent-length-returning-zero-when-uploading-a-file-unsing-xmlhttpreq\n. Yeop... leave it out, no reason for it to be there\n. Not too much would have to change:\nadd this function to the qqFileUploader class:\nfunction getFileName() {\n    return $this->file->getName();\n}\nand then for the uploading part:\n//handle the upload to qqfileuploader\n$uploader = new qqFileUploader($allowedExtensions, $sizeLimit);\n$result = $uploader->handleUpload('uploads/');\n//upload to dropbox\n$db_uploader = new DropboxUploader('email@address.com', 'password');\n$db_uploader->upload('uploads/'.$uploader->getFileName());\n//possibly delete the file from the server?\nunlink('uploads/'.$uploader->getFileName());\n. Is there something in the error log? A 500 error usually indicates something like that.\n. The problem is that your computer doesn't have the certificate installed, I think you will find the fix under the Trobleshooting header\nhttp://jaka.kubje.org/projects/dropbox-uploader/\n. That onload code won't work, you are overwriting it each time, which is why you end up with the last one only.\nTry this:\n```\nfunction createUploader(uploader_id, list_id, uploader_num){\nvar uploader = new qq.FileUploader({\nelement: document.getElementById(uploader_id),\nlistElement: document.getElementById(list_id),\n    action: 'fileuploader1.php?id='+uploader_num\n});\n\n}\nfunction init(){\n    createUploader('abc-uploader', 'separate-list', '1');\n    createUploader('wxy-uploader', 'separate-list1', '2');\n    createUploader('mno-uploader', 'separate-list2', '3');\n}\nwindow.onload = init;\n``\n. @bgrandgeorge Sincevar uploader` is a local variable, you don't actually need to change it at all, it gets redefined for each of the functions\nhttp://stackoverflow.com/questions/500431/javascript-variable-scope\n. ",
    "harshalone": "alright i had a look but now my question is i need to insert a record in the database also for the particular file to be retrieved later where should i add the code ? \ni tried to add it inside here in your old file :\n if(!move_uploaded_file($_FILES['qqfile']['tmp_name'], $path))\n        {\n            return false;\n        }\nelse\n      {\n         here my code to insert query // but it  wont worked for me\n      }\nPlease help ?\n. ",
    "valums": "Yes, it only works with divs to make keyboard access, and hover effect possible. Can't be fixed at the moment.\n. added jquery dialog to acceptance test, works fine in all tested browsers\n. will push today\n. this plugin is not backwards compatible with ajax-upload.js, you will need to change server-side anyway, so the name option is not worth adding\n. yes, and it doesn't send file the same way as normal form would, so it won't be in $_FILES array anyway\n. fixed in dev branch http://github.com/valums/file-uploader/tree/dev\n. it's not possible, because we send the file in the body due to browser limitations, it's easier to configure the codeigniter to accept querystring params\n. this works in IE, you just need to get the file on the server in a different way, please read http://github.com/valums/file-uploader/blob/master/server/readme.txt\n. The success false is not used anywhere, so I guess, I should remove it from readme.\n. Does the file.getAsBinary() works with large files (>100MB)? My guess is, that it will freeze the browser.\n. Thanks for the bug report, that's really a serious bug, I will make FF3.5 behave same way as IE8.\n. pushed new version which fixes this bug\n. @loganbest It can't be in IE, IE doesn't use XHR. Can you please tell me, how can I recreate it?\n. Yes, that's indeed a better way to handle upload. Issue fixed. http://github.com/valums/file-uploader/blob/3d8c3e69feae817a9a5c15766fa845a6f484f98f/server/php.php\n. Thanks, Sean.\n. ok, i will add ability to cancel upload in onSubmit event in the next version\n. fixed in dev branch http://github.com/valums/file-uploader/tree/dev\n. fixed in dev branch http://github.com/valums/file-uploader/tree/dev\n. Thanks! I added those changes to dev branch.\n. It's fixed in latest version of the script, I just haven't updated demo yet.\n. I checked in a version with fix 10 minutes ago, are you sure you are using it?\n. send me a screenshot how it looks on your pc to andrew (at) valums.com\n. fix added to current version, thanks for bug report\n. Hi,\nI checked on FF beta 4 and couldn't spot this issue. If you want me to investigate it further please make an online demo, which doesn't work for you and I will check it here again.\n. Good, thanks for letting me know.\n. Hi,\nThanks for the idea, I believe that it would be a great addition to the script. maxConnections option for fileUploader would work fine.\n. Closed by 16d20b4cccde5c92e01bf25571cd81bb2d369060\n. added in dev branch http://github.com/valums/file-uploader/tree/dev\n. Thanks! added fix in dev branch http://github.com/valums/file-uploader/tree/dev\n. Closed by 373cc29c6e6160f086862cd2923fbd55290830e5.\n. You can't use application/json, because json is returned inside an iframe in IE.\n. added in dev branch http://github.com/valums/file-uploader/tree/dev with a name multiple\n. Hi! Thanks for the patch! Although the bug with get params was fixed in a different way.  See the dev branch http://github.com/valums/file-uploader/tree/dev And sorry, I don't plan to add filename param,  because it makes code a little more confusing, and it's not very necessary.\n. it works for me with dev branch http://github.com/valums/file-uploader/tree/dev\n. Hi,\nThanks for the patch! minSizeLimit option added to dev branch. Check out the new qq.FileUploaderBasic class, it's more customizable, and maybe it will suit you more.\n. Hi,\nTry using the qq.FileUploaderBasic from dev branch, with multiple option set to false. And count the number of uploaded files in onSubmit and if it's more than 3 return false to cancel upload.\n. Hi,\nIt's not possible to use a standard html button with this uploader, and there is not way to fix this.\n. you can try updating the list of files with javascript after creating uploader. sorry, I can't help you with this issue, as it's too specific\n. Added by this commit http://github.com/valums/file-uploader/commit/40a5df342df62a3e2be99f6b446b1f096298d577\n. Hi,\nPlease try using the dev branch.\nI checked it in Chrome 6 and couldn't spot this issue. If you want me to investigate it further please make an online demo, which doesn't work for you and I will check it there again.\n. Closed by e3377a6b76d63842871ec5971c36380c6d9b0410\n. Thanks for the patch, but this was fixed a few days a go by this commit. http://github.com/valums/file-uploader/commit/e3377a6b76d63842871ec5971c36380c6d9b0410\n. Sorry, my fault, I replaced it with getInProgress method which returns number, instead of true, false, but forgot to update the readme.\n. It isn't meant to do so, if you wish to get a filename from the server, return it, and use responseJSON.fileName\n. Closed by 41113fa3a439f502970b7c01abbe864efe5344e9\n. That's Chrome's bug, if you can, please vote it up here http://code.google.com/p/chromium/issues/detail?id=44068\n. Closed by 461068d5b20c56aac873be8e3dfe84d90374773e\n. Thanks for bug report.\n. Return the name from the server script, and use response.fileName instead of fileName.\n. Looks good, thanks! Will apply later.\n. Thank you very much for the fix. It's really embarrassing to find a bug like this floating around for some time. \n. Fixed in a59bcc47ac6a74206110348f84071d1fb0ad95ef\n. Not applicable anymore.\n. Yes, unfortunately you are correct. I do not have the time to maintain the project anymore. I will contact other contributors this week to see if anyone is interested in taking over this small project.\nOn Apr 20, 2012, at 10:05 PM, Mike O'Brien wrote:\n\n40 open pull requests and 117 open issues with no commits or comments from the author in almost a year. Can we assume the author is no longer maintaining this project?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/269\n. Fixed in fc06431efaf1a3b3b37d4c481ea94c31c3027414\n. \n",
    "guybrush": "http://github.com/guybrush/file-uploader/commit/fabb53376143bb1bca83a9cc735984971436b7fd\nfontSize: '460px' -> fontSize: '46px'\nguess this was a typing error?\n. I don't quite understand your problem, what is defaulting to {multiple: true, name: 'file'}?\nBut there is a minor bug in the the current xhr-implementation-example in server/php.php. $_GET['name'] musst be $_GET['qqfile'].\nhttp://github.com/guybrush/file-uploader/commit/cace25116fb2c068189e62fcc9c146f15516eb03\n. http://github.com/valums/file-uploader/pull/34\n. guybrush/file-uploader@6a5560ce015ad2177dc6b47307f316b3b0b7cdf7 fixes valums/file-uploader#16 partly, added some tests\n. this pull-request is not valid anymore, since onProgress() is already available in valums/file-uploader@3e2c0ddd41ad22322dc1be7f353e91fbd699b781 (dev-branch)\n. ",
    "budda": "I'm attempting to set the form name to:\n       name: 'files[upload]',\nAs the format is required for use with the Drupal CMS form system.\n. are you saying that its not possible to specify an input field name using the new plugin?\n. ",
    "extolabs": "can you please post the sample work you have done on this..\nThanks,\nAnil\n. no worries :) atleast we tried\n. Thankyou verymuch guys\n. ",
    "bobbob10": "I'm using the latest JavaScript.\nYou're right, it shouldn't matter since it hasn't hit the server code yet...just the querystring is messed up. Do you have HTTPWatch or Fiddler?\n. FYI, my content-type is being sent as \"multipart/form-data; boundary=---------------------------7daa3d740284\" too.\n. ",
    "sandyarmstrong": "FF 3.5 does have send(), but it does not properly handle File objects as an argument. See https://developer.mozilla.org/en/XMLHttpRequest#send() for details.\n. ",
    "loganbest": "the XHR.send bug is still there for FF3.5 and IE\n. http://gageincorporated.com/clients/pdf-upload.zip\nI zipped up my project for you to test on. I'm using FF 3.5.13 and FF 3.0.7.\nWhat is a solution for IE users?\n. well the whole point of that dropdown box is to populate with PDF's.... at least I left it at 14mb instead of the original 200mb....\nI'll do that code change.... on the other hand, what about the FF and IE issue?\n. Hello? anything??\n. ",
    "fstrube": "I guess for the test, you can look for FileReader which is only supported in FF 3.6+, then you will know if passing a File obj to send() is possible.  Try wrapping it all in a try-catch in the qq.UploadHandlerXhr.prototype's upload function:\n```\n    // Fix for Firefox 3.5, which doesn't like passing a File object to xhr.send()\n    try{\n        new FileReader();\n    }catch(err){\n        file = file.getAsText('');\n    }\n// Send the xhr\nxhr.open(\"POST\", this._options.action + queryString, true);\nxhr.send(file);\n\n```\nI used getAsText because my app works specifically with CSV files, but getAsBinary may be more appropriate depending on your scenario.\n. ",
    "jinleileiking": "3x\n. ",
    "imnotquitejack": "Thanks SeanJA, that was helpful!\n@image.uploaded_data = env['rack.input']\n. ",
    "vohtaski": "Another rails example (Rails 2.3.5 with has_attachment):\nhttp://github.com/vohtaski/fileuploader_and_rails\n. Do you have a longer error message ?\n. ",
    "chatgris": "Hello,\nI'm getting the following error with both example :\nEncoding::UndefinedConversionError (\"\\xFF\" from ASCII-8BIT to UTF-8)\nAny clue ?\n. It breaks on\n    file.print request.raw_post\nBut only with ruby 1.9.2, works fine with 1.8.7 ree\nEdit :\nFix for 1.9.2 :\n    file.print request.raw_post.force_encoding(\"UTF-8\")\n. ",
    "jamsi": "This works in 1.9.2 using the latest version of valums fileuploader.js\nhttp://www.jigsawboys.com/2010/10/06/ruby-on-rails-ajax-file-upload-with-valum/\n. Just to confirm; @steliyan-georgiev - that works perfectly.\nThe issue seems to only occur in IE though.\n```\n            \n\n\n        var lol = new qq.FileUploaderBasic({\n            button: document.getElementById('lolskates'),\n            action: '/jobs/upload',\n            allowedExtensions: ['jpg', 'png', 'jpeg', 'gif', 'pdf'],\n            debug: true\n          });\n\n```\n. This doesn't seem to support IE though, which uses the iframe method? As the request header is only set for XHR transfers.\nRefer to commit https://github.com/valums/file-uploader/commit/a7eeccad4ff0944793d05f154ddb98726f6f5416\n. ",
    "trafnar": "Here is a rough sample using the paperclip gem\nit's my controller's \"create\" action. My model is called Screen and the file attachment is called \"image\"\nhttps://gist.github.com/26082d2b56b00bd54dad\n. Not sure if this is the same as yours but...\nI had the same problem, I realized it was a CSS issue. The \"failed\" message is put into the dom regardless of success or failure and the tag that wraps it has a class like \"success\" or \"failure\" you can use that class to hide the failure notice as appropriate.\n. Well, it seems this patch breaks uploads beyond the max connections amount. I'll keep at it.\n. Sean - I'm creating a Rails app and following RESTful design patterns. Updates of resources are supposed to use PUT.\nI realized my fix was a bit silly, I spent a lot of time last night reading the code and learned a lot about JS in the process. I made a more sensible fix but it I didn't attempt to make it work for older browsers yet.\nhttps://github.com/trafnar/file-uploader/blob/60defc10e5f6d08900c5460d43051c0ee5aa7030/client/fileuploader.js\n. ",
    "rnicholus": "Since SimonEast's repo was merged into master a month or so ago, we should have this.\n. I take it this is no longer an issue.  If it is, please open a new issue with reproduction instructions.  Thanks.\n. @reinink In IE, the button element receives the click event, instead of the child input element.\n. @sepehr Note that the content-type should actually be plain/text, not text/html.\n. Which version of the uploader?\nOn Jan 25, 2013 5:43 PM, \"saulberardo\" notifications@github.com wrote:\n\nFor me it just worked also with \"text/html\". No other option worked.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/47#issuecomment-12726381.\n. Then there is something else going on in your environment that is causing the issue.  text/plain is the correct response content-type.  Without more specific information about your setup and the problem you are having, I can't say what is causing the issue.\n. Please provide the output from the Javascript console with the debug option\nset to true.  Also describe what specific problem you are experiencing.\nOn Jan 25, 2013 7:44 PM, \"saulberardo\" notifications@github.com wrote:\nWindows 7, IE-9 in IE-7 mode (observe I didn't actually tested on IE-7) ,\nPHP 5.1.53, Apache 2.2.17. If you want to know something else, just ask.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/47#issuecomment-12728956.\n. What specific response text are you attempting to return?  Your case is\nunusual.  I have yet to come across a case where text/plain was\nlegitimately causing a problem.  So, I'd like to get to the bottom of this.\n\nOn Fri, Jan 25, 2013 at 9:25 PM, saulberardo notifications@github.comwrote:\n\nRemember, with \"header(\"Content-Type: text/html\");\" it works like a charm.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/47#issuecomment-12730304.\n. I'm afraid I'm not familiar w/ NetBeans.  I'm a former Eclipse user now\nutilizing IntelliJ.\n\nHave you looked at the raw response in IE?  I'd be curious to see what it\nlooks like.\nOn Fri, Jan 25, 2013 at 10:30 PM, saulberardo notifications@github.comwrote:\n\nThe problem occurs when I use this simple php script to process the\nrequest:\n<?php\n$result = array('success'=> true);\n// or with $result = array('error'=> false);\nheader(\"Content-Type: plain/text\");\necho json_encode($result);\nIf you want I can send you the entire NetBeans project so you check if\nthere is something else going.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/47#issuecomment-12730902.\n. Sure, I'll take a look.\n\nOn Fri, Jan 25, 2013 at 10:47 PM, saulberardo notifications@github.comwrote:\n\nYes I did, and they were exact what they were supposed to be (i.e. the\nexact content-type I had sent as header). The project doesn't have any\nNetBeans specific stuff. Indeed, it's just a project to test the uploader\nwithout anything else added. You should be able to inspect it even with\nnotepad.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/47#issuecomment-12731040.\n. @Ptcc Please do not comment on closed cases that are 3 years old.  Instead, open up a new case.  Please be sure to read and follow the guidelines described at the top of the new issue form as well. \n. @mrvanes If this solves your problem, please open up a pull request with the changes so it may be evaluated for inclusion into the master branch.\n. I've referenced this case in a newer case.\n. Agree with the comment by @dresende.  Regarding the initial request.  This can be a consideration for 3.0.\n. I will make this localizable by allowing users to override the default text, but I will not replace the default units with KiB, MiB, etc. \n. Addressed in 3.2-IP.\n. No chance I can merge this after so much time.  Please re-open a new PR if there is still missing functionality.\n. Will look into this in 2.2.\n. Moving to 3.0.\n. Not seeing any issues in recent versions of FF.  Please re-open if you are still seeing this.\n. Will look into this more in 2.2.\n. This should have been fixed in 2.1.  I verified in case #399.\n. Have a look at the demo and the documentation.  It is now possible to customize the button text & error messages.\n. Note that I will be fixing this for good, hopefully, in 3.1.  I have identified this as a priority 1.\n. Will research this in 3.0.\n. I found an issue that prevented the response from being parsed in somewhat older Android versions.  For example, in Android 2.3.6, xhr uploading is not supported, so Fine Uploader falls back to form submission.  The stock Android browser (at least) adds the response as a child text node of <pre style=\"word-wrap: break-word; white-space: pre-wrap;\">.  I noticed this in the javascript console of my Galaxy S2, which is running 2.3.6.  IE 7-9 will add the response as a child text node of a <pre></pre>, but without any attributes.  The existing code that rips the response out of the <pre> element didn't take into account the 2.3.6 case, so I modified it and all appears to work well now.  \n\nNote that I realize this is not the Android issue described in the headlining message of this case, but since the case is title \"Doesn't work on Android\", I thought I'd throw this fix in here.  \nI'm still. looking into the 0-size issue.\n. I'm having some trouble reproducing the 0-size file issue.  I've attempted on both Android 2.3.6 and Android 4.0.4 (stock browsers on both).  I uploaded several files, and while the file sizes were incorrect for files that were not locally stored, I was still able to upload.  If someone is still seeing this issue, please re-open this case, report your version of Android, your browser, and the specifics of the file used to reproduce this.  I'd hate to remove the 0-size check unless it is completely necessary.  I suppose I could only disable this check if the UA string contains \"Android\", but I'd like some current reports from users that are experiencing this problem before I do so.\n. 2.3.6, and presumably 2.3.3 as well, does not support the file api, so this\nis expected and unavoidable.\nOn Nov 14, 2012 5:39 AM, \"tellibus\" notifications@github.com wrote:\n\nI tested with 2.3.6, same issue (I can upload files bigger than the\nsizeLimit). Other than that, everything seems to run ok.\nDisclaimer: tested the Android versions only on the 2.1.2 and\nto-be-released 3.0 demo pages.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/82#issuecomment-10363235.\n. Is this still needed?  Is this not yet accounted for?  Will close if no response in 2 days.\n. Not really necessary since users can simply check the value of getInProgress() in their onComplete handler.\n. This was never implemented in file-uploader.  I guess can see why 201 may be acceptable, but I'm not so sure about 202 and 204.  It doesn't seem like either of the HTTP response status codes would ever be reasonable responses in this context.\n. A success message is still required.  Can you elaborate on your last comment a bit?\n. Oh, I see what you mean.  If the request is not successful, a success message is not required.  However, it is generally a bad idea to return, for example, a 4xx response code to indicate failure due to the way IE handles small non-2xx responses.  This is why I always recommend you return a 200 response.  Have a look at the IE limitations section of the readme for more info.  Note that the absence of a success message will always indicate failure.\n. Alrighty.  Please base your changes off of an In Progress branch (in this case, 3.1-IP).\n. Also, please elaborate on why you return a 202, and under what conditions you actually return this response.\n. No activity for a while.  Feel free to re-open later if desired.\n. Will be re-writing this using jQuery in 3.0.  See #306.  I don't plan on going the wrapper route.  Thanks for your contribution, though.\n. Already part of master (2.1-SNAPSHOT)\n. I'm not a Ruby on Rails guy, so I'm not sure which of these solutions is best.  I can say that the one contributed by @msolovyov doesn't seem appropriate, since the topic of this request is the iframe uploader, which does not use XHR.  So, the two candidates are:\n- the one contributed by @xaviershay\n- the one noted in the post by @msaffitz\n\nPreferences?\n. Closing this due to lack of responses.\n. jQuery is not used internally by Fine Uploader.  Also, couldn't you just set the header via the customHeaders option?\n. jQuery is not used internally by Fine Uploader.  Also, couldn't you just set the header via the customHeaders option?\n. Why would I do that?  Fine Uploader already has code internally for setting\nrequest headerrs.\nOn Wed, Jan 30, 2013 at 8:34 AM, dei79 notifications@github.com wrote:\n\nBut it's simple to steal the implementation from jquery?\n// Caches the header\n                setRequestHeader: function( name, value ) {\n                    if ( !state ) {\n                        var lname = name.toLowerCase();\n                        name = requestHeadersNames[ lname ] = requestHeadersNames[ lname ] || name;\n                        requestHeaders[ name ] = value;\n                    }\n                    return this;\n                },\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/104#issuecomment-12891932.\n. Are you saying the token will ALWAYS be located in the csrf-token meta tag?\n\nOn Wed, Jan 30, 2013 at 8:38 AM, dei79 notifications@github.com wrote:\n\njust makes the live easier for all system which are using CSRF for\nauthorization. The system would work out of the box.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/104#issuecomment-12892140.\n. Where in this document does it say that the CSRF token should be placed in\na csrf-token meta tag?\n\nOn Wed, Jan 30, 2013 at 8:43 AM, dei79 notifications@github.com wrote:\n\nYes right:\nhttp://guides.rubyonrails.org/security.html#cross-site-request-forgery-csrf\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/104#issuecomment-12892392.\n. If that is true for all cases, then I suppose it could be added to the\ncode, but I'm not sure it's worth the effort.  All you have to do, as an\nintegrator that relies on CSRF tokens, is specify a custom header, like so:\n....\nrequest: {\n   ...\n   customHeaders: {\n      X-CSRF-Token: $('meta[name=\"crsf-token\"]'.attr('content');\n   }\n}\n\nOn Wed, Jan 30, 2013 at 8:47 AM, dei79 notifications@github.com wrote:\n\nIt's how RoR is doing this and the UJS support for rails in handling this\nas well:\n// Make sure that every Ajax request sends the CSRF token\n    CSRFProtection: function(xhr) {\n```\n  var token = $('meta[name=\"csrf-token\"]').attr('content');\n  if (token) xhr.setRequestHeader('X-CSRF-Token', token);\n},\n```\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/104#issuecomment-12892593.\n. If you are sure you are not dealing with a cross domain request, then your server is returning a non-200 response. See the 4th entry in the FAQ for more details.\n. The only other possibility, as far as I can tell, is that you are indeed\nattempting a cross-domain request.  Please post the contents of the request\nand response.\n\nOn Fri, Apr 5, 2013 at 4:07 PM, Adam Alboyadjian\nnotifications@github.comwrote:\n\nNope, it's returning a 200:\nKey Value\nResponse HTTP/1.1 200 OK\nConnection close\nDate Fri, 05 Apr 2013 21:05:38 GMT\nContent-Length 91\nCache-Control private, max-age=0, must-revalidate\nX-Runtime 103\nETag \"2de3ec7217039bd839e8f207de77e93a\"\nContent-Type text/plain; charset=utf-8\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/pull/104#issuecomment-15980838\n.\n. and the request endpoint is...?\n\nOn Fri, Apr 5, 2013 at 4:11 PM, Adam Alboyadjian\nnotifications@github.comwrote:\n\nRequest headers:\nKey Value\nRequest POST /composition_attachments HTTP/1.1\nAccept  text/html, application/xhtml+xml, /\nAccept-Language en-us\nUser-Agent  Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0)\nContent-Type    multipart/form-data; boundary=---------------------------7dd2d725110646\nUA-CPU  AMD64\nAccept-Encoding gzip, deflate\nHost    adam.dev.maindomain.com:3001\nContent-Length  113590\nConnection  Keep-Alive\nCache-Control   no-cache\nResponse body:\n{\"download_url\":\"/composition_attachments/26\",\"attachment_id\":26,\"success\":true}\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/pull/104#issuecomment-15981021\n.\n. I'll look into this in 3.0.\n. @akre54 I will look into the initial request in 3.2 (hopefully).  You are correct, though.  The initial pull request here is not suitable due to the use of map.  At this point, IE7 and up are supported.  Support for IE7 may be dropped in the future, but there are no plans at this point.  IE8 will likely be supported for the forseeable future.\n. Fixed in 3.2-IP using regexp.\n. Why is it useful to send a second request with the parameters?  The parameters are already sent with the upload request.\n. Why is it useful to send a second request with the parameters?  The parameters are already sent with the upload request.\n. @jpoehls Andrew Valums is no longer working on this project.  I have taken over.  \n\nIf you want the parameters to be present in the request instead of the query string, the request must be multipart encoded.  Currently, you can force the XHR upload request to use this encoding (see the forceMultipart option), but all parameters are part of the query string.  It would not be hard to simply add all parameters to the FormData object if an XHR upload request is possible.  As far as uploads in browsers that do not support the File API, such as IE, we would need to dynamically build input elements in the associated form for each parameter.  \nIf this functionality is added, it would need to be tied to an option, and would default to the current behavior (params in the query string).\n. I've scheduled this as an enhancement for the 3.3 milestone.  If I receive a bunch of comments from current users who would like to see this sooner, I can move it to an earlier milestone.\n. Scheduled for 3.3 at this point.\n. @blakie The beauty of github lies in the ability to submit proposed changes to a project's code in the form of a pull request.  Feel free to contribute this yourself if you'd like it completed sooner.  Otherwise, i'll have to do my best and fit it in to the 1.5 hours off free time i have every night or so.  If a bunch of people comment on this issue after my post, i can certainly consider moving it into an earlier release as well...\n. Does this patch address the xhr AND the form uploader?\nOn Nov 23, 2012 3:58 AM, \"Paolo Lunazzi\" notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus I just wrote a quick and dirty\npatch. In the next days I will submit the pul request.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/113#issuecomment-10654722.\n. The xhr fix is quite easy.  Form uploader is another story.  Also, sending\nparameters in the body of the request will need to be controlled by an\noption, and by default, this option must be off, since fine uploader has\nalways sent params in the query string.\nOn Nov 23, 2012 7:45 AM, \"Paolo Lunazzi\" notifications@github.com wrote:\nquick and dirty meant that it fixed only my urgency (read: form uploader).\nI will work on it to fix even xhr uploader.\nOn Fri, Nov 23, 2012 at 2:39 PM, Ray Nicholus notifications@github.comwrote:\n\nDoes this patch address the xhr AND the form uploader?\nOn Nov 23, 2012 3:58 AM, \"Paolo Lunazzi\" notifications@github.com\nwrote:\n\n@rnicholus https://github.com/rnicholus I just wrote a quick and\ndirty\npatch. In the next days I will submit the pul request.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/113#issuecomment-10654722>.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/113#issuecomment-10659732>.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/113#issuecomment-10659857.\n. Since this is becoming a popular request.  I'll make this my next feature to tackle after adding the ability to upload directories (#380).\n. This much-request feature has now been implemented in the 3.1 branch.  See the associated blog post for more details.\n. SimonEast's repo was merged into master some time ago, so we should have this.\n. Still seeing issues w/ 2.0 or 2.1-SNAPSHOT?  This should be fixed. \n. @applezqp You are either returning a response code that is not 200, or you are using javascript to invoke the select files dialog initially.\n. Still having an issue?  Will close if no response in 2 days.\n. jQuery re-write planned for 3.0.  See #306\n. I think most of this has already been accounted for.\n. Not sure I understand the request here.  If someone else does, please either re-open or file a new issue/PR.  Thanks!\n. See the inputName option.\n. Still having an issue?  Will close if no response in 2 days.\n. Still an issue?  If no response in 2 days, I'll close this case.\n. I will mark this as a 2.2 task then.  Thanks for the heads-up!\n. This is on hold until #347 is addressed.\n. removing from milestone until #347 is addressed and a PR is received\n. Any of the PHP contributors want to look into this?\n. I originally asked a \"php\" person to take this on as i don't have an essy\nway to test any changes to the php examples.  If that breaks, I'll be\nswimming in support requests, so if someone with more php experience than\nmyself doesn't open up a pull request and test it, I won't be merging it in.\nOn Dec 8, 2012 4:57 AM, \"Jonathan\" notifications@github.com wrote:\n@rnicholus https://github.com/rnicholus it looks like #347https://github.com/valums/file-uploader/issues/347is closed?\n@tellibus https://github.com/tellibus you could do the following:\n$uploader = new qqFileUploader();\n$result = $uploader->handleUpload('uploads/');\n$result['filename'] = $uploader->getUploadName();\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\notherwise your method seems to work also.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/155#issuecomment-11157484.\n. I really can't keep track of all of the chaos surrounding the PHP example.  I have asked for one person to reliably maintain this example, and I haven't had anyone step up for more than a short period of time.  If you see any issues with the PHP example that need to be fixed, I would say go ahead and open up pull requests, assuming you have tested cross-browser.  I'm less inclined to merge PHP changes in that are not bugfixes. \n. Relying on a Flash or Java solution, especially for uploading, is almost always a headache, especially when you have a large and diverse user base.  Fine Uploader will remain a javascript library that does not depend on Flash or Java.\n. I'm not so sure about the onSubmit change, but the cancel function for FUB can be a 3.0 feature.  I'll add it to the 3.0 spreadsheet (see the readme for a link).\n. Still an issue?  Will close if no response in 2 days.\n. Still having an issue?  Will close if no response in 2 days.\n. Please see issue #32.  Otherwise, this may be added in 3.0.\n. @igorcomputacao  This issue has gone off on a tangent.  Several different issues are discussed here.  Which one are you referring to?\n. @igorcomputacao Are you attempting to open your file dialog with javascript?  That was the original issue reported here.\n. @igorcomputacao Again, are you attempting to open your file dialog with javascript?  If you are, this is the source of your problem.  Based on the error message and the browser, I'm fairly certain that you are.  If you are, you cannot do this.  It is not allowed in IE.  Specifically, IE does not allow opening the file dialog via javascript if you intend to also submit the form via javascript (which fine uploader does).\n. Which plug-ins specifically are you referring to?  I'm not aware of a way\nto make your specific scenario reliably work.\n\nOn Thu, Aug 30, 2012 at 8:46 AM, igorcomputacao notifications@github.comwrote:\n\nOk, you win.\nYour answer:\nYes, I click at image (X - Not Loaded) and a javascript open the window\nfor select the file.\nOk, I understand that It's not possible, but exists any way to do this on\nIE?\nI see this \"feature\" works on IE, using other plugins.\nThanks.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/162#issuecomment-8159792.\n. Use the button that comes with file uploader, and allow the user to click on it to trigger the file dialog.  In short, don't write any javascript that clicks the input element programmatically.\n. This issue is closed and now 1.5 years old.  Please stop posting here.  If you have an issue post in the support forum.\n. 1. Because its closed.\n2. Because this is all documented in the readme, FAQ, and numerous other issues.\n3.  Because this issue isn't a container for random thoughts related to\n   security errors in ie over the course of 2 years.\n4. Because there is a support forum if you still don't understand how to deal with this situation.\n\nGot it?\nAny further comments in this thread will be deleted.\nOn Feb 17, 2013 4:06 AM, \"Radek Suski\" notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus What's you problem? No one is\nreporting it as bug but apparently still some people amy not have realised\nthat the main problem is the virtual click on the \"select\" button.\nIf people would comment it here I would probably be never ale to find the\ncause of the issue.\nWhy it bothers you if someone is posting in a closed bug report or not?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/162#issuecomment-13683622.\n. No ajax requests in IE.  IE uses multipart form requests.\n. duplicate of #82\n. I will look into this in 2.2.  Not sure if this is still an issue.\n. Moving into 3.0.\n. Tested 3.0 with Opera 12.10 in OS X (Mountain Lion).  Multi-select & drag & drop worked fine.  Opera apparently posts an annoying \"do you want to upload your files to %s\" modal whenever you drop files, though.  It isn't clear how to turn this off.\n. Note that I have recently removed support for Opera.  Drag and drop was only recently introduced in Opera (12), and this appears to be broken in 12.11.  By most accounts, Opera has less than 2% market share worldwide.  It is not worthwhile to spend time supporting such a browser when there are many better options available.\n. Still looking for a PHP example maintainer, who can hopefully address and test this.\n. removing from milestone until a PR is received\n. I'm sorry, but it is not possible to merge this into master after so much time.  If you are interested, you can have a look at the current code and contribute any features that are still missing.  Note that the current version allows you to manually trigger uploads.  Thanks.\n. An increase in memory usage is not necessarily an indication of a memory leak.  If you have more information, please re-open this case.\n. An increase in memory usage is not necessarily an indication of a memory leak.  If you have more information, please re-open this case.\n. Please have a look at my plans for Fine Uploader 3.0\n. Please have a look at my plans for Fine Uploader 3.0\n. I'm going to merge this in now, but I cannot vouch for its correctness.\n. I'm going to merge this in now, but I cannot vouch for its correctness.\n. Thank you for your contribution.\n. Thank you for your contribution.\n. Still an issue?  If not, I will close in 2 days.\n. Not an issue anymore\n. If this information is useful, this belongs in a wiki page or in the examples directory.  Can someone here contribute something along these lines?\n. Use FileUploaderBasic.\n. works for me w/ mountain lion\n. @emartini86 Correct!\n. This is expected.  IE9 and earlier does not support the file api, so there\nis no way to determine the file size client-side.\nOn Nov 15, 2012 6:58 AM, \"Infrag\" notifications@github.com wrote:\nConcerning point number 2 - sizeLimit is not validated.\nIf I try to upload oversize file with Chrome, Error is thrown that file\nexceeds limit. If I do the same in IE nothing happens.\nSo I thing it really is an IE9 bug.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/181#issuecomment-10407628.\n. exists in current version\n. Please have a look at the current version, where you can manually trigger uploads.\n. Still an issue?\n. Still an issue?\n. I am not, so the issue likely lies in your server configuration.\n\nOn Tue, Oct 30, 2012 at 3:41 PM, imitchell notifications@github.com wrote:\n\nI am seeing the same issue on Chrome - Version 22.0.1229.94 m\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/187#issuecomment-9921947.\n. I've never seen this issue, nor has anyone reported this since the last post here (3 months ago).  If anyone is still seeing this, please post specific steps required to reproduce.\n. @bgrandgeorge Correct!\n. Still an issue?\n. I dont plan on supporting safari for windows, for the reason you mentioned,\nand due to the fact that safari for windows is a completely unnecessary\nproduct since chrome is an option.  Safari for windows was introduced to\nbring a webkit browser to windows.  Now that chrome exists, the substandard\nsafari for windows is obsolete.\nOn Oct 7, 2012 3:56 PM, \"TimNZ\" notifications@github.com wrote:\nYes, still an issue with Safari for Windows, but really how much of an\nissue in the real world with Safari Windows numbers and given Apple no\nlonger release Windows version.\nBut still...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/190#issuecomment-9212386.\n. Really not possible to merge this anymore. Please open a new PR is this is desired functionality.\n. Really not possible to merge this anymore.  Please open a new PR is this is desired functionality.\n. PHP specific, not Fine Uploader-related.\n. No, this is not possible in IE9 or earlier due to the fact that files are\nuploaded in these browsers by submitting a form inside a hidden iframe.\n The W3C spec states that a form element's method attribute only has two\nvalid values: POST and GET.\n\nOn Fri, Jan 11, 2013 at 6:28 PM, Gabe Odess notifications@github.comwrote:\n\nI also would like to ability to send a PUT request, however, my reasons\nare to follow development standards not for memory issues. Is this possible?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/197#issuecomment-12170169.\n. Files are sent via form submission in IE9 and earlier.  This results in a\nmultipart encoded request.  The file data is contained inside of one of the\nmultipart boundaries in the request.  POST is a very appropriate method\nchoice for such a request anyway.\n\nOn Fri, Jan 11, 2013 at 6:42 PM, Gabe Odess notifications@github.comwrote:\n\nAh I see. It appears that the Rails framework gets around this by sending\na _method:'put' parameter in the post params. I tried sending this in the\nquerystring as a workaround, but that doesn't seem to work. Am I correct to\nunderstand that the image data is occupying the post parameter space, thus\nmaking it impossible to send _method:'put' as a POST parameter?\n\ncitysprout\nConnecting you to local farms.\nGabriel Odess-Gillett\nLead Developer & Co-founder\n413.248.4223 mobile\ncitysprout.com\nOn Jan 11, 2013, at 7:36 PM, Ray Nicholus wrote:\n\nNo, this is not possible in IE9 or earlier due to the fact that files\nare\nuploaded in these browsers by submitting a form inside a hidden iframe.\nThe W3C spec states that a form element's method attribute only has two\nvalid values: POST and GET.\nOn Fri, Jan 11, 2013 at 6:28 PM, Gabe Odess notifications@github.comwrote:\n\nI also would like to ability to send a PUT request, however, my\nreasons\nare to follow development standards not for memory issues. Is this\npossible?\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/197#issuecomment-12170169>.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/197#issuecomment-12170509.\n. Browsers don't compress data, servers do.  I'm not aware of a way to compress a file on the client side without resorting to something like flash or java.\n. There will definitely not be any such library integrated into Fine Uploader as part of the core library. Zip compression is not appropriate for many files, such as images and videos (to name a few). But of course you are free to compress files however you see fit and then submit them to Fine Uploader.\n. That repo was merged into master a little while ago.\n. The progress indicator doesn't appear since IE does not support the File API.  For browsers that do support the File API, the progress event is handled to update the status of the upload during the xhr upload.  There is no way to determine upload progress with the form uploader.\n\nIt is not advisable to \"force\" IE to use the XHR uploader, since IE does not support xhr.upload().\n. duplicate (#225)\n. Not working in IE9?  Closing.  Please re-open with IE9 adjustment.\n. Since this info is already present in an X-header (if the request is not MPE) or the Content-Type header of the file's multipart boundary, I'm not sure anything needs to be done here.\n. This is quite old/out-of-date.  If this is still desired, please open up a new pull request based on the current master.  Thanks!\n. Doable, but not in the 2.x branch.  This will likely be part of 3.x..\n. @cdvrooman Please show your code.  If you are simply using the \"thumbnail\" demo as-is, you can see, looking at the code, that this is not capable of showing the thumbnail of an actual dropped/uploaded image.  The demo is meant to simply highlight the possibility.  You will need to write your own code to display the thumbnail of a dropped/selected image file.  The File API along with the createObjectURL function are both a necessity to make this happen.\n. Ah yes, if you know the path of the uploaded file, you can display a thumbnail in the browser by following the advice from @tellibus.  My comment discussed how you can display a thumbnail before the file has even been uploaded.  The latter is something I plan on adding to FU in the near future.  The former could be a fallback, for browsers that don't support the File API.\n. Closed as this has now been split up into 3 separate cases.\n. Lack of XHR is not a problem.  IE certainly supports XHR.  It does not, however, fully support the File API and FormData.\n. @peterldowns There is no way to determine upload progress in browsers that do not support the File API, such as IE9 and older.\n. @peterldowns Please see case #506 for information about a possible way to obtain upload progress in non-File API browsers.  I hope to look into this feature at some point in the future, but, unfortunately, resources are still very limited on Fine Uploader so it may be a while before I get to this.\n. Already merged into master via ae2ee3bcc8c1d88fc09e4db85d076a5efbedd2ab.\n. That certainly will not speed up the upload.  If anything, it will slow it down.  But, chunking of uploads is something I may consider.  See case #323.\n. I am able to reproduce and will look into this for 3.2.  Thanks for your report.\n. Fixed in 3.1.\n. See case #316.\n. I can look into this further for 2.2, but may make it into 2.1 if someone contributes the code and a test case.\n. 3.1 at earliest\n. @NTICompass Sweet!  Please do so in the 3.0 branch though.  The 2.x branches (and master) are closed for non-example pull requests.  In the future, all pull requests will need to be matched up with branches that end in \"WIP\" (work in progress).  I didn't rename the 3.0 branch to 3.0-WIP since I have linked to it in many places and didn't want to break that link. \n. This will be a task that the new hire assigned to Fine Uploader can tackle when he starts.  Moving to 3.7, but will likely be pushed further back.\n. This will be a task that the new hire assigned to Fine Uploader can tackle when he starts.  Moving to 3.7, but will likely be pushed further back.\n. This is becoming less important as the years go on and older versions of IE die off.\n. Not sure I understand the request.  There is already such a button.  Can you clarify?\n. Still seeing this issue? Will close in 2 days if no response.\n. Fixed in master.\n. Are you still having this issue?  There is now an option to hide the cancel link for form uploads.  I've found that it doesn't appear to be possible to reliably cancel a multipart form upload.\n. merged into master from @SimonEast & @bencolon \n. Will need to investigate further for 2.1.\n. The current recommendation is to set your response type to text/plain.  This seems to work fine with the current codebase in all browsers I have tested (Chrome, FF, IE7-9).  Please see case #346 for details.  If there is something else to be discussed, please re-open this.  Thanks!\n. There is no way to limit the number of files a user can select in a file input dialog. \n. I'm afraid we won't be introducing jQuery until 3.0.  The 2.x branch will be \"native javascript\".  Check out the 3.x branch  (once development begins) and open an appropriate issue if you would like something like this included.  Thanks. \n. Seems to work for me.  Still seeing this issue? Will close in 2 days if no response.\n. Still seeing this issue? Will close in 2 days if no response.\n. merged into master from @SimonEast \n. I need to examine this a bit more before closing.  Perhaps we should be doing this in Fine Uploader?\n. I believe this problem can be fixed by simply setting the content-type of your response to text/html, although text/plain appears to be a more safe content-type, especially if you intend to return HTML in your JSON response.  See case #346 for more details.  Please re-open if this does not solve your issue.\n. Still seeing this issue? Will close in 2 days if no response.\n. This portion of the code has changed since filing this issue.  Are you still seeing this problem?  If there is no response within 2 days, I'll consider this matter resolved.  Thanks.\n. Still seeing this issue? Will close in 2 days if no response.\n. The issue is your fault.  My guess is that you have opted to combine the\nJavascript files yourself instead of downloading one of the precombined\nfiles.  Either they or toy have done something else strange with the\nJavascript files.  Without any details other than \"come on\", i can only\nguess.  Good luck.\nOn Jan 9, 2013 3:16 AM, \"Bai,Yilin\" notifications@github.com wrote:\n\nsame issue here, come on!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/250#issuecomment-12036685.\n. jQuery UI may be used in Fine Uploader 3.0.  See issue #326.  Unfortunately, I will not be able to merge in your pull request at this time.  Thanks for the effort anyway.\n. fixed in #255\n. merged into master from @SimonEast \n. The cancel link should now disappear after the last byte of the file has been received server-side. \n. see the autoUpload option in the latest code\n. merged into master from @SimonEast \n. Agreed.  I plan on addressing this in the next release.\n. I think I've covered this in #296.\n. I think I've covered this in #296.\n. @kankamik I've merged changes to complete #296 into master.  Before 2.1 releases, can you let me know if my changes address your situation?\n. Still seeing this issue?  Will close in 2 days if no response.\n. Still seeing this issue?  Will close in 2 days if no response.\n. Still seeing this issue?  Will close in 2 days if no response.\n. merged into this repo, from @SimonEast\n. Project has been handed over.\n. Still seeing this issue?  Will close in 2 days if no response.\n. Still seeing this issue?  Will close in 2 days if no response.\n. Are you able to reproduce this with the latest code?\n. See the autoUpload option and associated functions in the newest code.\n. Are you still seeing this with the new code?  If no response within 2 days, I will consider this closed.\n. See #316\n. Looking for contributors w/ PHP experience to look into this.\n. Is this still an issue?  If no comment w/in 2 additional days, this will be closed.  Thanks.\n. @kenny-chiang Which browser?  IE, by any chance?   Also, what do you mean by \"not working\"?  Note that, while the cancel button historically is present in IE, it doesn't seem to work at all, or at least reliably.  That is, it doesn't seem to actually stop the upload.  Also, there are some edge cases where clicking \"cancel\" will not actually stop the upload, because the file has already been sent and the server has yet to respond to the request.  The current version in master should have two improvements:\n1. The cancel link is removed after the last byte has been sent in this commit.\n2. You can hide the cancel link when the form uploader is used.  I've found that clicking cancel in that case does not seem to actually stop the client from sending bytes to the server.  That was introduced in this commit.\n. This is a bit out of sync with the current code.  If this is still an issue, please open a new issue with a clear description of the problem.  Thanks.\n. will not merge\n. Hello!  \n\nI agree with your suggestions.  Let me go comment and point out a few things...\nMilestones\nWe should set some milestones, however, it is not yet clear what those milestones are.  My initial goal (in progress) is to deal with any defects created by the recent merges.  At the same time, I'm building a new demo page in the gh-pages branch of this project.  As you may know, Github serves web content by convention out of this branch, so this is an ideal place to maintain a demo page.  So, the first milestone is to tackle the obvious bugs caused by the merge, get some working demos, and sort though the issues and pull requests.  Once that is done and I'm fairly confident in the code, I will create a 2.0 stable branch.  The master branch will be for continuing development.  \nCoding Rules\nI'm a believer in JSLint.  I'm sure Douglas Crockford would agree with me ;-)  Such rules can eventually go into the readme under a Contributors section.  Perhaps the code could use some more comments, but I'd be careful to over-comment the code, as comments have a tendency to stay frozen in time as the code changes (i.e. become stale).\nOutstanding Pull Requests and Issues\nMany of the pull requests are probably not applicable or a pain to merge in at this point.  It seems possible though, that there are outstanding issues (even old ones) that still apply.  So, I do plan on going thought them.\nBetter Documentation\nCompletely agree here.  I plan on, for one, documenting the options fully in the README.  The demo, once complete, should also serve as a form of documentation.  Ideally, the fileuploader code in the demo would be synced with master.  \nMiscellaneous\nI've created a Google Group a couple days ago for file-uploader where discussions like this one can take place.  Ideally, I'd like to have more members so ideas for improvements can be discussed.  See the top of the README for a link.\n. I now have a working, albeit simple, demo.  The demo simply serves as an example for users of Fine Uploader.  Nothing fancy so far, but it can be improved.  The demo code is stored in the gh-pages branch, so feel free to open up a pull request if you have any ideas.  Otherwise, I'll make improvements/additions over time.  \nI'll be sure to go through the code next, make it jslint compliant, and add comments where appropriate.  I would also like to, as I mentioned in my original comment, expand upon the README on the project page.  As you suggested, I plan on fully documenting all options.  The README will ultimately contain a section for contributors.   I will likely start on these items in the next day or two and open up issues to track these efforts.  Feel free to open up issues that correspond to items you would like to see accomplished as well.\nI did plan on going though some of the forked versions, at some point, to see if there are any useful new features out there.  BTW, we are technically on 2.0 now, according to the README.  I suppose I could consider future minor milestones point releases, and radical changes would be part of a 3.0.  \nWhile the Issues section is nice for feature requests and bug reports, I don't think it's the best place for random comments, project direction discussion, and questions from users.  IMHO, that's what mailing lists are for.  \nWhile I do have a day job that does not usually involve Fine Uploader, I do plan on keeping this project relatively active, as time allows.  As always, assistance in any way is always appreciated.\n. I'm hesitant to refactor the code (to make it jslint compliant) until we've established a stable version of the code.  2.1\n. Not going to do this in 2.x.  I'll be sure to be JSLint compliant in 3.x.\n. Not going to do this in 2.x.  I'll be sure to be JSLint compliant in 3.x.\n. Progress being made in the enhance-readme branch.\nSee the start of the options documentation rewrite.\n. README has been enhanced.\n. Wow, I'm an idiot.  I'm going to blame late-night coding for this bug.  Thanks for the patch!\n. I might be seeing something similar in IE8/9:\n1. Select a file.\n2. Before the server responds to the first request, select a second\n   file.\nThe first file will \"complete\" but the second file has the spinner\nicon next to it forever, even though the upload has completed.\nIs this what you are seeing?\nOn Tue, Aug 28, 2012 at 9:55 AM, Rik4444 notifications@github.com wrote:\n\nJust upgraded from version 1.0 of the uploader to the latest version on\nthis site and have been doing a lot of testing. I've found 1 bug in IE and\na few strange behaviours across all browsers.\n*Note: maxConnections is set to 3\nWhen i test in IE8 i cannot get the queue to work properly. When i queue\nmore than 3 files only the first three files get uploaded and fire an\nonComplete event. If i queue more than 3 files the excess files are\nuploaded succesfully but do not have their onComplete events fired. I've\nchecked with fiddler, the server is sending a correct response after each\nupload just like it did for the first 3 files. So the request and the\nresponse are good, but the onComplete event is not being fired.\nI've tested this with the current fileuploader.js \"out of the box\" and the\nfollowing js:\nfunction createUploader() { var uploader = new qq.FileUploader({ element:\ndocument.getElementById('file-uploader'), action: '/AJAX/FileUpload',\nparams: { param1: 'I want to see this string in the QueryString when\ndebugging serverside' } }); } window.onload = createUploader;\n*I use jquery-1.5.1 with this.\nTested with a .net 4.0 MVC2 website on IIS7 (remote) and Cassini (local\ntestserver).\nThanks for all the work you guys are putting in!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/295.\n. I have maxConnections set to 3 as well.\n\nAs far as the additional behavior you are seeing, after we submit the form,\nit's up to the user agent to build and send the multipart form request.\nOn Tue, Aug 28, 2012 at 10:24 AM, Rik4444 notifications@github.com wrote:\n\n... file has the spinner icon next to it forever, even though the upload\nhas completed.\nThat\u00b4s exactly what I\u00b4m seeing, but it only ever happens on the fourth\nfile, I suspect because maxConnections is set to 3. I\u00b4ll test it with\nanother setting and post the results in a minute.\nAnother thing I\u00b4ve noticed is that uploads seem to be competing for a\nserver response. When i upload 3 files, 2 large and 1 small (and in that\nexact order), file 1 (large) gets uploaded, when it completes file 3\n(small) immedeately starts uploading. After that one of the following\nthings happens, either the upload for file 3 completes and file 2 starts\nuploading OR file 3 pauses uploading halfway, file 2 starts uploading and\nfile 3 resumes only when file 2's upload is complete. Strange?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/295#issuecomment-8095394.\n. Looks like, in some cases, the iframe onload event handler isn't being called.  Looking into it...\n. @Rik4444 Are you seeing this only with the post-merge post-handover version, or can you reproduce with earlier versions as well?\n. This one looks old enough...\n. Looking closer, I believe the version I pointed you at will not have this problem.  I believe this issue was introduced in this commit.  \n\nTake two files, for example.  Add the first file, then add the second before the first one completes.  Note that there is one _detach_event variable that contains a function used to detach the onload event handler for the iframe.  When the first file begins uploading, _detach_event is set with a function that will detach the onload handler for the first iframe.  When the 2nd file begin uploading, _detach_event now points at the function that will detach the onload handler for the 2nd iframe.  So, when the 1st file finishes, the onload event handler is removed for the 2nd iframe.  This is why onComplete is never called for the 2nd file, since this is part of the callback associated with handling an iframe onload event.\n. I'll probably fix it today or tomorrow at the latest.\nOn Aug 28, 2012 11:59 AM, \"Rik4444\" notifications@github.com wrote:\n\nYup, that must be it.\nNow I could use the older version, but I'll bet that commit is useful\n(improvement in garbage collection?). Let's see if we can't fix this bugger\n:).\nIn any case, thanks for the help and the quick reply!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/295#issuecomment-8098933.\n. @Rik4444 Can you check out my proposed fix in the eternal-spinner-ie branch and confirm that it fixes the issue for you?\n. I'm going to consider this issue resolved and merge the changes into master at around 10am CST unless I hear otherwise.\n. Sounds good.  Would you like me to hold off merging until you are done verifying on your end?\n. I don't plan on supporting IE 5.5, nor do I plan on supporting IE6, since\nMicrosoft has effectively ended support for both of those.\n\nLooks good to me.\nOn Thu, Aug 30, 2012 at 10:41 AM, Rik4444 notifications@github.com wrote:\n\nIE 5.5, my whole site crashes and the uploader doesn't work either (no big\nsurprise)\nIE 6, a few small visual things are off but it seems to work! I am getting\na \"failed\" response from the server, but the uploader itself seems to be\nworking. I could dig into this further if you think its necessary.\nIE 7, working fine.\nCan't test any newer versions with IEtester unfortunately, so that'll have\nto be it for now.\n- I am using some custom css with this so I can't judge the styles at\n  the moment, but style is not what we're testing here (right?). I'm actually\n  working on some improvements for the standard css at the moment, will do\n  some more testing on that before I submit it.\n\u2014\n  Reply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/295#issuecomment-8163658.\n. @Rik4444 Thanks much for your report and your help testing this.\n. Please list which browser(s) you have reproduced this issue with, share you\njs & PHP code, and list let us know how current your copy of\nfileuploader.js is.\n\nOn Wed, Aug 29, 2012 at 11:31 AM, fabienthomas notifications@github.comwrote:\n\nHello all,\nI'm running into an issue with fileuploader, i can upload small files\n(videos in my case) but every file bigger than +/- 60mb just return an\nerror while my php script handles the upload.\nin my qqUploadedFileXhr class, $_SERVER['CONTENT_LENGTH'] is undefined and\ncause an exception that of course abort the upload.\nI really don't know if its a server setting issue, brower issue or if i've\ndone something wrong with my code.\nAny help will be really appreciated ;)\nThanks\nF.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/297.\n. Have you always had an issue with files of this size?  If not, what changed before the problem began?  When reproducing this, are you attempting to upload the files on the same machine or network as your server endpoint?  If not, can you reproduce this issue when running your application locally?\n. Could be a number of issues, but I'd be a bit surprised in the fine uploader js code was the culprit.  Perhaps you have some maximum POST request limitation set around 60 MB on your webserver?\n\nAll i can recommend is to use something like Charles to inspect the request after it is sent.  That may shine some more light on the underlying problem.\n. The best course of action at this point is to inspect the post request\nafter it leaves the user agent and then again on the sever.\nOn Aug 30, 2012 3:22 AM, \"fabienthomas\" notifications@github.com wrote:\n\n@Gildus https://github.com/Gildus i've tried, several times, but the\nresult is the same every time :/\nThanks\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/297#issuecomment-8152522.\n. How old is your version of file uploader?  The current version will use FormData for XHR requests if you specify \"multipart\" for the (currently undocumented) encoding option.  That is certainly a better solution than modifying fileuplooader.js.  \n\nvar uploader = new qq.FileUploader({\n    element: document.getElementById('file-uploader'),\n    action: '/server/upload'\n    encoding: 'multipart',\n...\n});\nI'm not sure why this option is somewhat hidden in the code.  I'll probably fix this.\n. If your version has an encoding option read somewhere in the code, you can do what I described above.  This is a much better solution than modifying the code.  Modifying the code will likely cause you pain later if you need to upgrade.\n. Also consider switching POST to PUT for some weird PHP issue described in #61.\n. Come to think of it, I'm apprehensive about switching the request type unless I receive a multitude of responses that this is the proper solution to resolve \"out of memory\" issues in PHP.  I'm finding it a little hard to believe that the request type would cause this sort of issue.\n. merged into master\n. Waiting for verification from others before merging this into master.\n. No response from reporters.  Fix merged w/ master.\n. There is some information in this stackoverflow question.\n. I think the problem is that the function references this._options.listElement, which may be null.  I think the correct fix is not to do a null check.  Rather, reference this._listElement instead, which is never null in FileUploader.\n. There were a couple problems, after closer inspection.\n1. The call to _options.listElement should never happen, since this can be undefined.  Instead, _listElement should be referenced.\n2. The code that clears the contents of listElement should have never been placed in FileUploaderBasic code, since FUB does not have a listElement property.  I created an implementation of clearStoredFiles in FileUploader that, after calling the FUB clearStoredFiles (which simply empties the storedFiles array), clears the contents of listElement.  \nThis should fix this issue.\n. Note that this partially, but does not completely solve #299.  There are other similar issues in 299 that need to be addressed.\n. Messed up the merge.  I meant to take my commit only.  Looks like it merged in your instead.  Oops.  Fixed now.\n. I'm hesitant to merge this right away.  Currently, I'm just trying to get Fine Uploader stable.  I will look at this for 2.1 though.  I'm thinking sometime mid-september.\n. @Rik4444 Do you think you could rebase your master branch from this one, resolve merge conflicts, and then commit the changes?  Then I can evaluate your contribution and we can go from there.\n. Hey @Rik4444, are you still around? If not, I'll push this into 2.2 and attempt to resolve conflicts before testing myself.\n. @Rik4444 It's going to take a little work to merge this in manually due to the age of this pull request.  Unless you're still around to resolve the conflicts, I'll have to push this into 2.2.  But, honestly, this may end up being pushed into 3.0 as I don't want to make too many big changes while I'm working on 3.0 to make syncing my work in 3.0 w/ changes in 2.x less nightmarish.  \nI took a peek at your changes.  The css changes look simple enough, but some of the js-related changes may need to be eliminated/updated.  For example, the I made some changes to the progress-bar in case #327.  Also, modifying the template option using regex seems like something we shouldn't be doing.\n. I'll take another peek at your code hopefully tonight and get back to you.\n. Actually, if you could just resolve the merge conflicts and include all of your changes, including the js/regex stuff, I'll give it a spin.  Thanks!\n. We're getting too close to the release date for 2.1 and I'd like to finish up the other feature/enhancement and then spend the rest of the time in this release cycle working on 3.0 and letting 2.1 \"simmer\" in case I missed any bugs in my testing.\nAt the very least, this will need to be moved to 2.2.\n. removing from milestone until merge conflicts are resolved.\n. I'm not sure if this PR is dead or not.  If not, please re-open and note that this will have to be part of 3.0 now, so the changes will need to be against the 3.0 branch.\n. I don't like the fact that a private variable, _storedFiles is being passed into the user's params function.  Why pass anything?\nAlso, why is onSubmit too early to set params?\n. Can you offer a pull request?  I would be careful to make any drastic changes, especially anytime soon.  My place, in the future, is to rewrite Fine Uploader using jQuery.  I will likely consider any such suggestions when that happens.  That will likely be Fine Uploader 3.0.\n. If it's easier for you, a detailed list of desired improvements/modifications to the templating portion of the code might be helpful once i get around to 3.0.\n. This is probably going to be covered, or at least more closely examined in #517 \n. The click event should bubble up to the anchor.  Are you saying that is not happening?  Can you provide a functional example that demonstrates the issue you are seeing?\n. Can you post any code at all?  Code that you used to reproduce this?  Click\nevents will most definitely bubble unless an event handler on an element\ndoes something specific (such as calling stopPropagation()) to stop the\nbubbling process.\nOn Mon, Sep 3, 2012 at 7:30 PM, Jacob Thomason notifications@github.comwrote:\n\nUnfortunately at the moment I don't have a functional example... The event\nwasn't bubbling though. :/\nOn Sep 3, 2012, at 8:28 PM, Ray Nicholus wrote:\n\nThe click event should bubble up to the anchor. Are you saying that is\nnot happening? Can you provide a functional example that demonstrates the\nissue you are seeing?\n\u2014\nReply to this email directly or view it on GitHub.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/305#issuecomment-8249675.\n. I have no way to verify this, so I'll take your word for it.\n. Your message is a little confusing.  I think you meant to quote this:\n\ngetName: function(id){\n        var file = this._files[id];\n        // fix missing name in Safari 4\n        //NOTE: fixed missing name firefox 11.0a2 file.fileName is actually undefined\n        return (file.fileName !== null && file.fileName !== undefined) ? file.fileName : file.name;\n    }\nSeems like setting the element in the files array to null would also cause an exception on getSize.  I'll get to this at some point.\n. Correct.  That is what I was referring to.  Have another look at your initial post (\"where this is in the code...\").  Also, the array is not set to null, rather an element in the array is null.  \nI've classified this as a bug and I'll get to fixing it at some point in the near future.  Thanks for the report.\n. I believe setting that element in the array to null is the bug.  If you look at the code, you will see that the array is used in several places to reference the underlying File object.\n. There is nothing in the code that prevents form submission.  There is, however, a warning that appears if the user attempts to navigate away from the page if the uploader thinks uploads are still pending.  Have a look at the _preventLeaveInProgress function.  The files array does not directly factor into this.  I don't think another callback is necessary here.  I'll take a close look in the next few days.\n. In progress...\n. In progress...\n. Fixed in master, see 06de1f3 for code specifics.\n. Instead of opening up a new issue, can you please move your comments to the existing issue you opened to deal with this request (#304)?\n. ...also made all indentation consistent\n. Note that I did not use the original suggestion in the report to fix this.  Instead, I decided to properly account for stored files.\n. Code please\nOn Sep 4, 2012 4:49 AM, \"umeshk\" notifications@github.com wrote:\n\nHi,\nFor some reason I have to keep the input type file is hidden & when user\nclicks the Upload photo I am triggering the file click. But that is working\nfor firefox and chrome but not for IE. When I remove the visibility for IE\nits working but not for hidden visibility.\nThanks\nUmesh Kulkarni\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/311.\n. If you are triggering the file selection dialog via Javascript, this will\nnever work properly in ie.  You need to change your approach as this is not\nallowed in ie.  Please spend some time looking over similar issues.\nOn Sep 4, 2012 8:09 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nCode please\nOn Sep 4, 2012 4:49 AM, \"umeshk\" notifications@github.com wrote:\n\nHi,\nFor some reason I have to keep the input type file is hidden & when user\nclicks the Upload photo I am triggering the file click. But that is working\nfor firefox and chrome but not for IE. When I remove the visibility for IE\nits working but not for hidden visibility.\nThanks\nUmesh Kulkarni\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/311.\n. Not able to reproduce w/ FF 15 on OS X.  I used the last uploader on the demo page, which sets multiple to false.\n. Perhaps there is some other option you have set that is causing this.  Please post your code.\n. Can you also provide the full stack trace?  The line in your error message is called in many, many situations.\n. I am able to reproduce now.  Are you certain there is only one POST request sent (for the first file only)?\n. That's what I figured.  Ok, I'll look into this further.  Thanks for the report.  Should work fine when using the file selection dialog though.\n. I'm inclined to simply prevent the upload from happening at all if the user attempts to stop multiple files.  The behavior would be the same if the user drops a file that is too large, or a restricted file type.  Any problem with this?\n. Not possible.  IE 9 and older does not support the file API.\nOn Sep 5, 2012 6:23 AM, \"CharlesLioe\" notifications@github.com wrote:\n\nDrag and Drop does not work in IE9, is it possible to make it work somehow?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/313.\n. I'm not a node guy, so I'll go ahead an merge this in after a short bit of research/confirmation.  Thank you for your contribution.\n. Thanks for your contribution.\n. This isn't working for me.  Exception on JSON.parse when attempting to parse, for example, \"{success: true}\".\n'{\"success\": true}' works though.  I'm concerned that some people might be returning \"{success: true}\",\n. I would tend to agree with you.  Some of the examples, unfortunately, use \"{success: true}\" though.  Those will also need to be fixed.  I'm not sure it is a good idea to merge this in now, though.  Perhaps after the current milestone.\n. Thanks for your contribution!\n. Made the following changes:\n- No longer call showMessage if a non-200 response is detected when handling an XHR upload.  It seemed silly to do this in this specific case only, as far as upload failures are concerned.\n- Changed the last parameter of the onError callback from xhr to reason.  This was important to allow onError callbacks for upload errors of both types (XHR & iframe).  See the callbacks section in the readme for more info.\n-  The onError callback is now called whenever any exceptional condition occurs, whether it is during an upload or during file selection.\n- Removed the support for a \"reason\" property in the JSON response from the server.  The \"error\" property seems to be the standard, based on the available examples in the server folder.  So, the \"error\" property now takes over the role filled by the old \"reason\" property.  In other words, your \"error\" value will appear if you hover over a failed file, and it will be included in the reason property whenever your onError callback is called.\n. Thanks for your contribution.  I'll need to do the same for the java example, now that I think of it.\n. Thanks for your contribution.\n. Setting params in onUpload is not effective.  If you want to set parameters after selecting files, you must do so in your onSubmit handler.\n. Why is onSubmit not suitable?  If you want to modify these parameters after a file is selected, onSubmit is the appropriate place.  What exactly are you trying to validate, and when?\n. Please show your code\nOn Oct 29, 2012 6:53 AM, \"sacher74\" notifications@github.com wrote:\nHave the same problem here.\nI have a dropdown list which value I need to pass to the server. If user\nchanges selection in the dropdown after selecting files, the first file in\nthe queue doesn't take the correct parameter value like other files do.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/320#issuecomment-9863684.\n. Once the file has been submitted to the uploader, you cannot change the parameters sent with the associated request.  For this reason, the onSubmit callback is the appropriate place to use this function call.\n\nIn your case, autoUpload is set to false.  You have apparently left out the portion of your code where you call uploadStoredFiles.  The appropriate place to change all parameters after creating the uploader, in this case, is to do so before you call uploadStoredFiles, not in your onUpload handler.  Once your onUpload handler is called, it is too late to change the parameters for that file.\n. https://groups.google.com/forum/#!topic/fineuploader/JatcTKV8hRA\n. +1\nOn Sep 11, 2012 9:05 PM, \"Tower He\" notifications@github.com wrote:\n\nonComplete: function() {\n   // uploader is an instance of qq.FileUploader\n   if(uploader.getInProgress() == 0) {\n     // Do Something\n   }}\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/321#issuecomment-8478952.\n. Why do we need this check again?  If _storedFileIds is empty, indexOf will return -1, which is already accounted for.\n. This is due to a bug I just fixed for IE8 and earlier.  See case #324.  Update your code to the latest code from master.\n. I assume you are referring to the slice function in the File API.  This is something I may consider for 2.1, but, more likely, this will be included in the jQuery re-write, which will be 3.0.\n. There will be 2 versions: 2.0 would continue to be the \"library-agnostic\" version.  A 3.0 version would be a re-write using jQuery.  Eventually the 2.0 branch would be considered \"legacy\" code, and would only receive bug fixes.  Switching to jQuery (3.0 branch) will make cross-browser support much easier.\n. Please show your code to aid me in reproducing this.\n. Unbelievable.  IE 8 and older do not support indexOf on arrays.  I guess I never noticed this.  Could IE possibly be a worse browser?  Never ran into this when testing though, strangely enough.\n. ...looks like running IE9 in ie7/8 mode is not a great test.\n. should be fixed in master now\n. Duplicate of issue #324.  Fixed in master.\n. To be honest, this sounds like more of a maintenance nightmare than my initial proposal, and it doesn't solve any of the problems that would be solved by moving entirely to jQuery.  My plan is to eventually phase out the \"native js\" Fine Uploader.  Why? Because it is much easier and faster to evolve the product using a library like jQuery, along with all of the available plug-ins (including jQuery-UI).  The existing \"native js\" Fine Uploader will remain, but will not evolve after a point in the near future.  I will continue to fix critical bugs in this version, but new feature development will eventually happen in the jQuery version.  I realize that not everyone will be happy with this, but I expect most users will appreciate the move to jQuery.  I know I will.  If someone, for whatever reason, does not want to depend on jQuery, they will be able to use the non-jQuery version.  It's not going away, it just won't evolve.  \n\nI noticed you referenced Prototype.  I have used Prototype in the past, and have no plans to write anything using Prototype by choice in the future.  Prototype's decision to extend the DOM was a poor one.  jQuery's choice to wrap the DOM, instead, was a good one.  Putting that aside, jQuery has a huge amount of plug-ins, and many more users by comparison. \n. Well, there will be two versions.  However, the 2.x version will be considered a \"legacy\" version of Fine Uploader.  I'll maintain it, at least for a while, by patching it with critical bugfixes.  The 3.x version will be the jQuery re-write version, and will be considered the main version where new features will be added.  It's going to take a little while to get the 3.x (jQuery) version into a usable state since I haven't started on it yet and I will be doing this in my free time.  Initially, 3.x will be in a beta phase until all major issues have been worked out.  Once it is \"released\", the 2.x version will go into a legacy-sustaining mode, and new feature development/evolution will only occur in 3.x.  \nOnce 3.x is out of beta, users can continue to choose the 2.x version, but feature requests will not be honored.  At some point, the 2.x version may be EOLed altogether.  \nDoes this make sense?\n. I would expect most users to be more concerned with features, support,\nreliability, and ease-of-use over the uniqueness of the codebase.\nOn Sep 19, 2012 5:18 AM, \"Emmanuel\" notifications@github.com wrote:\n\nthere are numerous jQuery uploaderes available\nwhile...\nyour pure-cs is the only one! Keep the good work and uniqueness of your\nsolution!!!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/326#issuecomment-8686593.\n. @reinink I'm not sure FileUploaderBasic will exist in 3.0 as you know it now.  However, my goal is to make 3.0 as flexible as possible, so that users can use their own upload button, their own file list, their own css, or choose to omit one or more of these items and simply rely on callbacks.  Please see the google doc referenced in the readme on master if you would like to specify features/considerations for me to take into account when developing 3.0. \n. I can certainly put that into my TODO list when developing 3.0 (which has\nalready started, though i haven't done much at all yet).  Could you please\ncodify this request and any others in this spreadsheet, if possible?\nhttps://docs.google.com/spreadsheet/ccc?key=0AnQh9-ZBDuh_dEJGZFY1dEl2SDlGUGZNLUVfanZKeXc#gid=0\n\nOn Wed, Sep 19, 2012 at 1:11 PM, reinink notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus I'm not opposed to one plugin,\nas long as we have the control available now. I get the need for some of\nthis functionality to be built in\u2014as long as it doesn't get too big or too\ncomplicated to remove all that stuff.\nPut differently, I'd love version three to not require any assets (CSS,\nimages)\u2014just the JavaScript file.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/326#issuecomment-8700698.\n. @reinink I should add that the main reason I would move to jQuery is not to increase its popularity, but to make it easier to maintain and add features.  Relying on a library like jQuery allows me to remove a lot of noise from the code, that is, functions that jQuery already provides.  The help that jQuery provides in terms of cross-browser support and helper functions, to name a couple, make it very compelling to move in that direction.\n. @emanwebdev Just because the uploader is written in jQuery, does not mean that it must be a clone of some other uploader also written in jQuery.  To put it simply, as I've stated in this case many times already, the product will be more difficult to evolve if we do not add a crutch, such as jQuery, to the codebase.  Code that does not evolve eventually dies.  Also, as I have already noted in this case, the non-jquery version will still exist, but it will eventually be in a bugfix-only mode.  \n\nI don't plan on cloning anything.  The 3.0 version will be a port of the existing features found in Fine Uploader 2.0 to a jQuery plug-in, along with a host of other features, some of which are listed in the google doc referenced in the readme.  \nWhy are you opposed to including jQuery in your source code?  The minified version is 93 KB and this file can be cached more easily if we rely on a CDN. \n. I've created a poll to see what interested users think.\n. @david-proweb Unless I am misunderstanding, you are suggesting that the core code will not be written in jQuery, which defeats the purpose of using jQuery at all, IMHO.  I'm not fond of adding more complexity to the project by creating these types of wrappers.  \n. @david-proweb If I am going to re-write the app using jQuery, the most benefit is received from rewriting core using jQuery.  If the majority of users vote to not go the jQuery route in the poll, I may consider your idea, but, even without a wrapper, it is trivial for non-jQuery users to integrate Fine Uploader into their application.  I am actually doing this now with several of the projects I am working on.  I'm just not sure it's worth the trouble to write wrappers.\n. @walterdavis As I've said, if I go ahead w/ 3.0, the non jQuery-version will still be available, and serious bugs will be patched in this branch after 3.0 is released, but there are compelling reasons to not re-invent the wheel in the codebase and let a library like jQuery make evolution of the product easier.  \nI'll look at the results of the poll after a few days and see what users as a whole think before I spend more time on a 3.0/jQuery version of Fine Uploader.\n. Quite a lively conversation here.  Never thought this would be so controversial. :smirk:\n. @h3 It really doesn't make much sense to me to re-write fine uploader in native javascript.  I imagine I'd end up writing pretty much the same code we have now.  To say that the benefits end at easing maintenance and evolution of the product along with reducing noise in the code is like saying the benefits of bypass surgery end at the years of life the procedure adds to a patient's life.  If you think about it, that is a very apt analogy.  \nAs far as the cost of using a framework such as jQuery, the API really has not changed very much at all since its inception.  Sure, functions have been added, and others have been deprecated, but very few breaking changes have occurred in quite some time.  You mention that native JS is not going away anytime soon, but you haven't really defined native JS.  What is native JS exactly?  ECMAScript has undergone several revisions.  Will the newest planned revision, Harmony, be fully backwards compatible, syntax-wise?  Who knows.  This is, perhaps an argument for using a framework like jQuery.  Perhaps the layer of abstraction jQuery provides will shield javascript developers from any breaking changes once Harmony becomes a reality.\n. Hmm, i don't recall saying i was going to use jquery ui.\nOn Sep 23, 2012 1:08 PM, \"Jacob Lee\" notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus I think you are missing the\npoint about keeping the upload library as stand alone product. My problem\nis having this code base tied to some other code base, that your project\nhas no control over. Also, I HATE jQuery UI, it is a bloated pile of crap,\nwhich is sad since jQuery itself is amazing. But that's all fine, if you\ndecide to screw this project royally I can just fork it for myself.\nGood luck.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/326#issuecomment-8800977.\n. @cleer73 No problem, but I should say that I don't really appreciate your original comment, that you have since removed.  Please keep in mind that this is not a commercial product, I am not paid to do this.  I maintain and evolve this in my spare time since I use and like this library.  I also want to make the best decision for Fine Uploader to ensure that it is useful and appreciated for as long as possible.  I don't intend to take the project in a direction that most users object to.  This is why I have kept this discussion open and have created a poll.  My mind is not made up yet regarding the future of Fine Uploader.  I'd like to make a decision that everyone will like, but that is usually not possible.  I also want to ensure that maintenance and development of this product does not consume more time than I have.  I see introducing jQuery as a way to streamline future development and maintenance of this library. \n. @cleer73 Looks like I may have referenced jQuery I in a couple places.  Such as here and here, but rest assured I really would like to avoid introducing any dependencies other than jQuery.  While jQuery UI has a couple plug-ins that would be useful, such as DnD and sortable, I think it would be easy enough to support these behaviors w/out introducing another dependency.\n. @cleer73 Yes, using sizzle would certainly give me an advantage as far as element selection is concerned.  You're right, BTW: Sizzle was developed by Resig and is now the selector engine for jQuery.  Strangely enough, Prototype uses sizzle as well (1.7+).  \n\nAs I mentioned, using sizzle would aid in element selection, but I don't gain any of the other advantages that jQuery offers, such as events, DOM manipulation, DOM traversal, ajax support, effects, and other utilities (such as data(), each(), extend(), etc).  I tend to think that some of these elements of jQuery will be useful to me.\n. Another option is to use jQuery inside of Fine Uploader code, but not implement it as a jQuery plug-in.  jQuery would still be a required dependency, though.  Users who do not want to write any jQuery code would not have to.  Also, the use of jQuery would be completely internal and transparent to users of Fine Uploader.  \nPerhaps a jQuery plug-in could also exist that wraps Fine Uploader (again, Fine Uploader core would be written using jQuery).  This wrapper would allow those who choose to use it the ability to register for events, pass in jQuery objects as arguments for certain options, etc.\nThoughts on this approach?\n. I certainly could allow more devs to get involved.  Unfortunately, I don't have admin access to this repo yet.  I'd have to talk to Andrew about that.  \nWhy do you think I'm not accepting a lot of pull requests?  I have closed a bunch of really old pull requests, but I personally went through all 130 or so issues/PRs over the last month and marked the ones I see as interesting/potentially useful.  The rest I closed.  As far as new PRs, if the PRs are javascript-related, I tend to be a bit picky, no argument there. If I see a PR with a concept that seems truly useful, I will \"massage\" it a bit before merging it into master.  \"Massaging\" the PR code is prudent if I see something has been left out, if it does not pass some quick tests I run, or if the design of the new code goes against some existing architectural decisions already in place in Fine Uploader.  One example of this would be including an option and/or code for a feature in FileUploaderBasic when it only applies to FileUploader.  I've also massaged or outright rejected PRs with code that seems redundant to me or, in my opinion, adds \"noise\" to the codebase when there are other, existing methods to achieve the same goal.  I'm also hesitant to add adjustments for really old browsers (although I don't recall seeing any such PRs recently).  I don't plan on supporting IE6 or older, for example.\n. ...I would like to add that my suggestion to write the code code in jQuery and create a jQuery plug-in wrapper as an optional add-on would only be a useful avenue to pursue if those who voted \"nay\" on the jQuery proposal have a problem with cluttering up their code base by writing the own jQuery to interface with the plug-in.  Perhaps these people have an otherwise jQuery-free project (speaking of their own handwritten code) or are using some other library such as Prototype or some other similar library.  If the naysayers simply object to including jQuery as a dependency, this idea is not a useful one, though.\nI would like to know, specifically, why some object to simply including jQuery as a dependency.  If this is your specific objection, perhaps you could elaborate.\n. I didnt really take your assertion as a criticism.  I'm happy to hear\nconstructive criticism or suggestions for improvement, along with ideas.\nSo, don't feel that you need to back down.\nI'll need to give some more thought to 3.0 over the next few days or so.\nI'll post my conclusion when i reach one.\nI'll probably close the poll in the next hour or so.\nFor those who voted for jquery, care to share what you would think/do if\nthe decision did not go in your favor? That is, what if i decided not to\nrewrite in jquery? What if i consider the suggestion to write an (optional)\njquery plugin wrapper? This may result in slower progress as far as\nfeatures and bugfixes are concerned, and may rule out some planned\nfeatures.  I guess I'm trying to figure out if anyone is as pro-jquery\nplug-in as some of the commenters that are anti-jquery plug-in.\nTo put it even simpler: Some people are clearly pissed off with my plan to re-write Fine Uploader using jQuery.  Would anyone be pissed off if I decided to keep the core library in plain 'ole naked js?  Again, I might write an optional jQuery plug-in wrapper if I went this route.  Note that, if I went this route, there may be some notable refactoring of the existing code.\nOn Sep 23, 2012 7:14 PM, \"Jacob Lee\" notifications@github.com wrote:\n\nSo far as the management goes, those are your choices, it was not ment as\na criticism. It was just my impression of your stance on the management, I\nam sorry I offended you. As I seem to have made a total jack ass of myself\non this thread I will drop all other points, and respond to your very last\nstatement:\nFor my work, I actually use jQuery, so it's not so much that I would have\nto include jQuery in my projects to continue using your uploader. It's that\nif I ever decided to move on from jQuery, for whatever reason in the\nfuture, I would have to drop your codebase and find another, with\ncomparable features. It just gives me more flexibility in future projects,\nand I think it gives you a broader audience base in the long run.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/326#issuecomment-8804529.\n. Final vote:\n\nFor jQuery: 40 (78%)\nAgainst: 11 (22%)\nI'd like to hear more discussion here from both sides.  Please see my post above this one.\n. First I heard about MicroJS.  Pretty cool indeed.\n. Headjs is interesting, but I envisioned using a tool to combine all\n3rd--party js files into one file for each release.  In the master branch,\nthey would be split out into separate files, with instructions for those\nwho want to combine them.  I also would consider splitting up\nfileuploader.js into separate files to aid in future development and\nbugfixes.  Again, they would be combined in all releases.\nOn Mon, Sep 24, 2012 at 2:15 PM, Emmanuel notifications@github.com wrote:\n\nIt is so unique and rare to see a refined uploader like yours that\ndoesn't rely on a framework\n+1\nP.S.\nMicroJS.com\nFantastic! THANKS!!!\n- see http://headjs.com/\n\u2014\n  Reply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/326#issuecomment-8830897.\n. I've come to a conclusion.  \n\nWhile I don't necessarily agree with the arguments presented by the very vocal group of users against re-writing the library using jQuery, I respect their concerns.  Perhaps I can make everyone happy here.\nThe plan:\n\nI will not make jQuery a dependency.  \nThere may, however, be a lot of refactoring in 3.0.  \nThere will most definitely be some breaking changes as well.  When this happens, I'll do my best to document the breaking changes to those upgrading can do so as painlessly as possible.  (Off-topic note: Some of the 2.x releases may have minor breaking changes as well, but, again, they will be well documented for those upgrading.)\nI will likely create an optional jQuery plug-in wrapper that will give jQuery users all of the benefits of a jQuery plug-in.\nNot sure what 3rd party-libraries I will use in 3.0 or if I will use any 3rd-party code at all.  MicroJS is something to consider.  Please see this comment regarding use of 3rd-party libraries and code organization. \nPlease see the google doc in the readme if you want to add suggestions for 3.0 features.\n. Check out the 3.0 branch from time to time if you are interested in my progress.\n. in progress...\n. I added css and a bit more javascript to support a visible, moving progress bar for browsers that support the file API (non-IE browsers, for the most part).  It's a blue-gradient bar, and it appears when the upload starts, moves as the upload progresses, and then disappears when the upload completes.  If you do not want the progress bar to appear, you can hide it with css.  \n\nPlease see 1ccecf0 for code specifics.\n. This has already been reported in #324 and fixed.\n. 2.0 is frozen now, so this can go into 2.1.  Thanks for your contribution.\n. Merge is no longer non-trivial and I don't immediately have a way to test this PHP code.  So, could you rebase with master, and adjust your commit by resolving the merge conflicts?  Thanks.\n. @Kedyr Could you merge master into your patch-1 branch, resolve merge conflicts, and commit the changes?  After that, I will be able to merge this pull request into my master branch.  Thanks!\n. Closing this as I haven't received a response.  I'm not setup to test PHP changes so I'd rather not make these myself.  This can be re-opened if someone fixes the merge conflicts and verifies that the fix works.  Also, I'm not keen on making anything other than bug fix changes to the PHP examples as these seem to break often.\n. Please use the latest code from master.  This issue was fixed yesterday in #324.\n. I suppose adding this wouldn't hurt, but it really is not necessary at all.  The filename is included in the request.  Is there some reason it needs to be a parameter as well?\n. Well, I can certainly add this if it will make people's lives easier.  It shouldn't be a big deal.  I'll look into it for 2.1.\n. Merged into master, now part of 2.1-SNAPSHOT.\n. Probably going to revert this change as it may cause issues for users with a version of the PHP example that takes the absence of the \"qqfile\" parameter in the query string as an indication that the request is a multipart one.  While this is bad logic, I don't want to cause issues for users relying on this example.  I'll be sure and have the PHP example logic patched to use a more reasonable algorithm as well.\n. reverted in master in d01a38231011ee0424fa396f126cc60900ce19b2.  If you are having problems pulling the filename out of multipart form requests, please see the PHP example in the server folder.\n. The fact that these classes are defined options on both FileUploaderBasic and FileUploader is not sitting right with me.  We really shouldn't be doing that.  I'll need to give this some thought, and I think some additional changes will be needed to make this right. \n. There shouldn't be any css options in FUB.  I think if users want more control over the appearance of the button, they can either override the qq-upload-button css classes, or contribute their own button via the button option.\n. Thank you for your contribution.\n. After another look, I think the readme is fine as one file for now.  I added some more sections & moved things around a bit.\n. And this happens when you upload, when the page loads, or...?\nOn Sep 16, 2012 3:34 AM, \"Beate\" notifications@github.com wrote:\n\nI tested http://fineuploader.com in my IE7 in VirtualBox with XP, but it\ndoesn't work.\nError:\nZeile: 164\nZeichen: 5\nCode: 0\nFehlermeldung: Unspecified error.\nURL: http://fineuploader.com/\n(it doesn't work in my Site, either, so i tested if i did something\nwrong..)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/335.\n. Okie dokie.  I'll take a peek.  Do you know if this is a new issue, our one\nthat has existed for a while?\nOn Sep 16, 2012 4:02 AM, \"Beate\" notifications@github.com wrote:\nSorry :) It happens on Upload.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/335#issuecomment-8593261.\n. I just fired up an XP machine, and ran in IE7 browser mode.  No problem on the demo page, other than the text on the buttons is not visible, which I can probably look into.  If you are seeing an issue, you'll have to provide more specific information.\n. Yes, and this is part of 3.0.  See #460.\n. There are a couple problems with this code. \n1. Why is the formatProgress option declared in FileUploaderBasic when it is only usable in FileUploader?\n2. I'm not sure why you made the change to the template option.  listElement will always be undefined when the template property is evaluated since this._options only contains the options defined in FileUploaderBasic at that time.  Furthermore, There is already code in place to use the listElement in place of the qq-upload-list ul in the template, if a listElement is defined.  See this line near the end of the FileUploader function:\n\nthis._listElement = this._options.listElement || this._find(this._element, 'list');\n. Ah yes, looking again, i was mistaken about # 2.  \nYou will also need to move the formatProgress option from FileUploaderBasic into FileUploader.\n. ...regarding the request to move the formatProgress message into FileUploader, I have already done something like this for the multipleFileDropNotAllowedMessage.  After extending the FileUploaderBasic options with the FileUploader options, I add this property to the messages object.  Perhaps, now that we will have two messages specific to FileUploader, there should be an additionalMessages (or something similar) object on FileUploader that contains these messages.  We could then do the following:\nqq.extend(this._options.messages, this._options.additionalMessages);\n. You will have to provide more information.\n. Please see rules regarding issue filing.  https://github.com/valums/file-uploader#issue-tracker\n. I'm not seeing this at all.  Again, you'll have to provide more information.  Such as: browser, version of Fine Uploader, etc.  Are you testing locally (that is, are the server and the client on the same machine)?\n. Fine Uploader reports progress based on the XHR upload progress\nnotifications.  The notification provides the total file size and the # of\nbytes sent.  We use these two numbers to arrive at the percentage.  If this\nnumber is wrong, that would indicate a bug in Firefox, which seems highly\nunlikely.  You will need to provide a test case for verification, and I am\nnot seeing a problem myself, using Firefox.  In fact, I uploaded a 2 GB\nfile, and everything worked as expected.  It seems more likely that the\nfile has indeed arrived when it hits 100%, but your server-side code is\ndoing something with the file, such as copying it to another location, that\nis adding additional time to the process.\nOn Tue, Sep 18, 2012 at 9:04 AM, crirus notifications@github.com wrote:\n\nBrowser is Firefox, the pluing is latest and I am testing on client/server\nnot locally\nThe server is pretty fast in BW 2Gbit line.\nWhat I see as far as progress, it's a very fast processing on client then\nserver need way more time to receive all file data and respond.\nIt appears as if the browser send the file fast and report as done, then\nfile travels 30 minutes to get to server.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/337#issuecomment-8655798.\n. I just started a 197 MB file upload.  It's uploading pretty slowly.\n Nothing seems odd so far.\n\nLooks like you're using a minified Fine Uploader, and your javascript is\ninside a script tag.  Both of these conditions make debugging difficult.\n Can you use a non-minified version of fine uploader and move your\njavascript into a js file on your staging site?\nOn Tue, Sep 18, 2012 at 10:20 AM, crirus notifications@github.com wrote:\n\nit's not server side, I look at the file as it's uploaded on server tmp\nfolder, it takes over 30 minutes which is normal, while the 100% appears in\nlike 20 seconds, here is a temporary test server\nhttp://staging.magnovideo.com/\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/337#issuecomment-8658448.\n. Also, you said you attempted to upload a 1.5 GB file, but you have a 1 GB\nrestriction, it appears.  Update: I'm guessing you were logged in as a pro user.  \n\nMy file is still uploading, 11%.\nOn Tue, Sep 18, 2012 at 10:34 AM, Ray Nicholus ray@garstasio.com wrote:\n\nI just started a 197 MB file upload.  It's uploading pretty slowly.\n Nothing seems odd so far.\nLooks like you're using a minified Fine Uploader, and your javascript is\ninside a script tag.  Both of these conditions make debugging difficult.\n Can you use a non-minified version of fine uploader and move your\njavascript into a js file on your staging site?\nOn Tue, Sep 18, 2012 at 10:20 AM, crirus notifications@github.com wrote:\n\nit's not server side, I look at the file as it's uploaded on server tmp\nfolder, it takes over 30 minutes which is normal, while the 100% appears in\nlike 20 seconds, here is a temporary test server\nhttp://staging.magnovideo.com/\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/337#issuecomment-8658448.\n. ...switched from Chrome to FF 15 on OS X, same 197 MB file, uploading\nslowly, appears normal.\n\n\nOn Tue, Sep 18, 2012 at 10:40 AM, Ray Nicholus ray@garstasio.com wrote:\n\nAlso, you said you attempted to upload a 1.5 GB file, but you have a 1 GB\nrestriction, it appears.\nMy file is still uploading, 11%.\nOn Tue, Sep 18, 2012 at 10:34 AM, Ray Nicholus ray@garstasio.com wrote:\n\nI just started a 197 MB file upload.  It's uploading pretty slowly.\n Nothing seems odd so far.\nLooks like you're using a minified Fine Uploader, and your javascript is\ninside a script tag.  Both of these conditions make debugging difficult.\n Can you use a non-minified version of fine uploader and move your\njavascript into a js file on your staging site?\nOn Tue, Sep 18, 2012 at 10:20 AM, crirus notifications@github.comwrote:\n\nit's not server side, I look at the file as it's uploaded on server tmp\nfolder, it takes over 30 minutes which is normal, while the 100% appears in\nlike 20 seconds, here is a temporary test server\nhttp://staging.magnovideo.com/\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/337#issuecomment-8658448.\n. I'm going to cancel my upload as it has been running for 40 minutes and is only at 61%.  Nothing abnormal as far as I can see.  I'm not able to reproduce this.\n. Will close for now.  If you come up with more info, you are welcome to re-open this case.\n. Thanks for your contribution!\n. I'm confused, what is the bug in fileuploader.js?  Query parameters are not specific to GET requests.\n. You'll notice that user-specified parameters are also sent in the query string.  This has always been the behavior of the uploader, as far as I know.  The filename in the query string is redundant, but was added by request in #331.  This really shouldn't cause you any problems, since, again, user-specified parameters are also included in the query string.\n. You're going to have to help me understand why, when using PHP server-side,\na query string containing the filename causes a problem, but a query string\ncontaining user-supplied parameters does not. In other words, how is this a\nproblem:\n\n\n\nhttp://foo.com/upload/receiver?qqfile=0162320SBY.pdf\nbut this is not:\nhttp://foo.com/upload/receiver?param1=123&param2=456\nThe former is the url of a multipart form request with just the filename\nsent in the query string, the latter is the url of a multipart form request\nwith user-defined parameters (see the params property in FileUploaderBasic).\nOn Thu, Sep 20, 2012 at 5:00 PM, Denominator notifications@github.comwrote:\n\nI understand now.\nFirst of all please remember that I'm only trying to help here!\nSo, I will quote you :)\n\"I suppose adding this wouldn't hurt, but it really is not necessary at\nall. The filename is included in the request. Is there some reason it needs\nto be a parameter as well?\"\nThe next thing is that this suggestion was clearly from a rather\nunexperienced developer who added this because she/he didn't know how to\nget filename parameter from POST. I don't know if it is the reason to\nmodify not trivial (and very helpful) library (especially by such developer\n- nothing personal!).\nThird, most important thing is that in release 2.1 uploader is not working\nwith PHP because of that modification. I've spent more than hour trying to\nfind out what's going on.\nFrom perspective of someone writing server-side code for uploader I think\nit is reasonable to treat filename in GET parameters as property exclusive\nfor ajax upload. I think this way only because in my opinion it can be more\nreliable than to rely on PHP ways of testing whether it is standard form\nupload or not.\nI don't know - what do you think?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/339#issuecomment-8747210.\n. Looking at the PHP code again, I see what you mean.  But, it seems silly that the the existence of an item in the query string is used to determine what type of request we are dealing with.  It seems like this is a bug in the PHP example.  Shouldn't you be using the content-type to make this determination instead?  That is, if the content-type starts with multipart/form-data, it's a MPF request.\n. I would recommend making this change to the php example.  That is, use the content-type to determine if we are dealing with a multipart form request, instead of checking for an item in the query string or checking to see if $_FILES is empty.  Using the content-type seems like the correct way to make this determination.\n. I'm not familiar w/ PHP, so I just looked it up.  $_SERVER[\"CONTENT_TYPE\"] should retrieve value of the content-typ header field.  I'm not sure how string manipulation works in PHP, but you'll need to check if this value starts with \"multipart/form-data\" to determine if it's a MPF request.  If you could, please make this change to the php example in master and open up a pull request.  I would, but you are in a better position to verify/test this as you use PHP and I do not.  \n\nAlso, I agree, as I mentioned in the cited case, that the filename in the query string for MPF requests is not necessary.  While this should not cause problems on a properly coded server, I am willing to revert this change.\nAlso, please note that 2.1 is not released.  If you want a released version, you will need to use 2.0.\n. A few comments:\n- I'm not aware of a specific case where a multipart form upload would have an odd content type in IE.  It is a common and accepted practice to determine if a request is a multipart form request based on the content-type header starting with \"multipart/\".\n- I would be surprised if it would be hard to use the content-type header to determine if this is a MPFR in PHP.  It should be as simple as determining if the value of $_SERVER[\"CONTENT_TYPE\"] starts with \"multipart/\".\n- If multiple files are uploaded, they will each be sent as separate requests.  So, the length of the url is not really a concern here.  \nIf you'd like, I can research fixing the PHP code tonight, and you can tell me if it works based on your tests.  I'll create a new branch.  \nI may also consider reverting the change made in #331 since this is not needed and the PHP example clearly shows how to retrieve the filename in a MPFR.\n. The filename in the query string for MPFR has been reverted in d01a38231011ee0424fa396f126cc60900ce19b2.  \nAs far as the PHP example file, I believe this:\nif (isset($_GET['qqfile'])) {\n        $this->file = new qqUploadedFileXhr();\n    } elseif (isset($_FILES['qqfile'])) {\n        $this->file = new qqUploadedFileForm();\n    } else {\n        $this->file = false; \n    }\nshould probably be changed to something like this (not tested & note that I have never written a line of PHP in my life before):\nif (strpos(strtolower($_SERVER[\"CONTENT_TYPE\"]), 'multipart/') === 0) {\n        $this->file = new qqUploadedFileForm();\n    } else {\n        $this->file = new qqUploadedFileXhr();\n    }\nCan you please test this and open up a pull request with the corrected code?  Opening up a pull request is a snap, just follow the github documentation.  Note that you will need to fork this repo first.\n. Cool.  Thanks.\n. I have used text/html with IE9 and IE8 without any issues in my java\nservlets.  In fact, I just tried it now.  I don't know a whole lot about\nPHP, but it seems strange that this content type causes problems with PHP.\n Are you sure there is not some other issue here with your script?  What is\nthe exact response you are attempting to send.\nOn Sat, Sep 22, 2012 at 11:07 AM, Denominator notifications@github.comwrote:\n\nUpdate.\nGenerally it is continued explanation why this plugin didn't work for me\nwith ie9 and PHP (using script provided with plugin) and how to make it\nwork.\nFirst of all I return html in json response after upload - shouldn't make\nany difference, but just saying.\nAs a side note, using suggestion (from included in plugin php server-side\nscript):\n// to pass data through iframe you will need to encode all html tags\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\nwas not very helpful in this case. So I didn't use it - just used:\necho json_encode(..);\nSecond of all I consider here ie9 working in \"Browser Mode: IE9\" and\n\"Document Mode: IE9 standard\" (press F12 to start developer tools and look\nat the top right corner of it to check your mode).\nI don't even have time to read about all this stupid compatibility and\nquirks modes mambo jambo from Microsoft. Just gave it up!\nI use html5 doctype: \"<!DOCTYPE html>\" which puts IE9 in desired modes (at\nleast in my case).\nNow you have to watch out!\nIe9 has some stupid setting turned on by default that show sites from\nintranet in compatibility mode (whatever that is).\nIt is in menu called \"compatibility modes settings\" or something like that\n- I'm using non-english version.\n  Have a look here:\n  http://www.sevenforums.com/tutorials/1196-internet-explorer-compatibility-view-turn-off.html.\n  It is worth to read it and check out menu of those settings in your\n  particular ie9. Please give a second to the setting turning on\n  compatibility mode for all intranet sites(!) but also skim through others\n  just to be safe.\nThis setting impacts developers greatly as a lot of us develop using some\nserver in LAN (don't sure if it impacts local development). Anyway I turned\nit off everywhere in this menu.\nNow back to our ajax upload plugin:\nIe9 is scenario with Iframe (not XHR).\nYou upload a file and you get json response.\nJson is stored in Iframe (innerHTML).\nThen json is parsed (using eval()).\nIn ie9 parsing of this json failed for me. Parse exception was thrown,\nthen catched and json {success: false} was returned instead of my json.\nThe reason for failure during parsing json is content-type header of\nresponse from PHP script.\nI use example PHP (php.php) script where there is no setting of\ncontent-type header. As a result in my situation text/html was returned\n(default? content-type of page that is owner of Iframe?).\nNow I'm pretty sure eveything worked ok in the past, but Microsoft made\nsome updates to mime types hanlding by ie.\nResults?\nWhen ie got response which was json with content-type text/html and put it\ninto Iframe as innerHTML, this innerHTML didn't look like the content\n(json) I responded from PHP.\nSome modifications were made by ie9 (closed json object earlier etc. -\nstrange things). Anyway this modifications introduced by ie9 made syntax\nerrors in json which resulted in parse exception later.\nGenerally ie9 destroyed my json in my opinion.\nContent-type text/html with json as content was no-no for me.\nSo I changed content-type to application/json. But (after some time of\ncourse..) I realized ie9 doesn't know application/json content-type(!).\nHave a look here\nhttp://msdn.microsoft.com/en-us/library/ms775147(v=vs.85).aspx#Known_MimeTypes.\nAs ie9 doesn't know application/json content-type it prompted to open/save\nresponse from PHP as a separated file(!).\nI tried content-type text/plain and it worked.\nI think this content-type prevents ie9 from trying to open/save response\nas file or doing some kind of black magic over the response (destroying it\nin my case).\nAlso content-type text/plain didn't broke anything in firefox or chrome\n(latest versions).\nPlease notice that you should include proper charset in all your\ncontent-type headers as I've read that it can open a whole cave of demons\nin ie if it is not there or is somehow invalid.\nExample content-type I use: \"text/plain; charset=UTF-8\"\nAlso please notice that I've seen some idea that if ie doesn't know\nprovided content-type (like application/json) it can also try to use file\nextension (from url as far as I understand) but it was not my case and I\ndon't think people use URLs like http:/....../upload.json to upload a file\nso I didn't care about it.\nSummary:\n-\nI used text/plain content-type for json response because it worked for\n   me. Should it be a standard for this plugin and should it be commited - I\n   have no idea. It makes ajax upload in ie9, and chrome and firefox work.\n    -\nIf above content-type is ok, setting of header should be included in\n   php server-side script provided with this plugin\nI know it is long and complicated but I think it is because the problem is.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/339#issuecomment-8790191.\n. ...also, do you happen to have a pull request to fix the multipart request detection logic in the PHP script?  I'm guessing the code I posted will work but I'll need someone to confirm.\n. No, I'm not.  I'm sending text in my json response.  application/json causes issues with IE9 in some cases.  I don't recall the specifics, but with this content-type, in some cases, IE9 wraps the response in tags.  If the response is text/html, or text/plain IE leaves the response alone.  I guess text/plain is in fact a better alternative than text/html.  I guess I never anticipated anyone returning HTML in their response.  What is the use case for returning HTML in your response?\n. Ah, I see.  I'm going to open up a case to change content-type recommendations for responses to text/plain.\n. This case is getting a bit long in the tooth.  Opening up another case for the correction to the PHP example.\n. I'm guessing this one was by mistake.  I'll close this and use #341 instead.\n. Sounds like a reasonable request/behavior.  Let me give this some thought.  Thanks for opening up this pull request.\n. @tellibus It looks like a PHP-related change has made it into this pull request.  Was that your intent?  It is usually best to create a branch specifically for one pull request and make other, non-related changes in other branches only.  If your intent was not to have the PHP commit merged into master, can you possibly create a branch with your validated-files change only?\n\nSide note: Do you think you could tackle & test the PHP change I discussed at the end of #339?\n. No problem, don't worry about #339.  If you could sort the commits in this pull request out, that would be helpful though.  You'll probably need to close this pull request, create a new branch with your js-specific changes, and then open up a new PR with that branch.    Thanks!\n. Not sure I have time in the 2.1 schedule for this.  Pushing to 2.2.\n. I'd like to fit this into 2.2, but if it's closed, I won't see it when I plan the release.  I'm going to keep this open, and if the merge is no longer trivial by the time I get to it, I can manually merge and resolve the conflicts.  I'm not simply merging this as is since I believe there is more work to be done here, such as adjusting the error/alert message to inform the user that some files have been rejected, along with adding specifics to the documentation.  It is also possible that I will notice additional prudent changes when I review this pull request.  I also test each pull request before it is merged.  All this adds up to time that I may not have this release.\nI appreciate the pull request, and I will certainly plan on getting to this enhancement request in 2.2.\n. You will need to either open a new PR or add a commit with your js\nchanges.  If you look at the files changes section at the top, you'll\nnotice that there are no longer any changes to be merged in at all.  Might\njust be easier to close this and open up new pr's.\nOn Sep 23, 2012 4:42 AM, \"tellibus\" notifications@github.com wrote:\n\nRay, I closed it to open a new PR, as you explained above in\nvalums/file-uploader#341https://github.com/valums/file-uploader/issues/341#issuecomment-8776917\nAlso, maybe we just need an option \"stopOnFirstInvalidFile\" with true as\ndefault value to preserve existing behavior and bc.\nSo should I open a new PR? I didn't want from the beginning to mix JS with\nPHP.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/341#issuecomment-8796877.\n. Can you open up a pull request with this changes?  I'm currently only setup with a java backend.\n. @tellibus Are you willing/able to open up a pull request with these changes?  I'm not in a position to make changes to PHP examples as I'm not setup to test them at this time.\n. It would be nice to sanitize filenames client-side, but it's not possible in all cases.  If the XHR uploader is used, the filename is set as a query parameter and the file is streamed, so, we could use regex  client-side to sanitize the name.  In the case of the form uploader (used mostly for IE), the filename is included by the user-agent in the body of the request (more specifically, in the section of the body that contains the uploaded file data).  We have no control over the filename in this case.  I suppose we could also specify the cleaned-up filename as a query parameter, but that would simply be a non-standard convention that users would have to be aware and I'm not sure we should do that.  I believe it is acceptable to expect the server-side code to sanitize the filename,\n. Thanks much!\n. Sorry, the Java example is incomplete.  I'll use this case as a reminder to improve that example.\n\nIn the meantime, please have a look at my hastily thrown-together java servlet code in the test branch (UploaderReceiver.java).  Please note that I wrote this quickly and it is NOT ready for production, but it is a good starting point for handling multipart form requests and XHR upload requests.\n. There, I've contributed an improved java example.  I tested in briefly in Chrome and IE9.  Any problems with it, please let me know.\n. There is no such header sent with a multipart encoded request.  Have a look\nat the servlet example in the server/java\nfolderhttps://github.com/valums/file-uploader/tree/master/server/javaif\nyour server-side language is java, which appears to be the case.\nOn Mon, Sep 24, 2012 at 9:16 AM, anitakfitz notifications@github.comwrote:\n\nOk, i followed your link in the message above, but I do not see any\ndifference between this example and the version I have ? the problem I have\nis that in IE9, the following line returns null for filename:\nString filename= request.getHeader(\"X-File-Name\");\nmy jsp code is as follows:\nvar uploader = new qq.FileUploader({\n// pass the dom node (ex. $(selector)[0] for jQuery users)\nelement: document.getElementById('fileToUpload'),\n// path to server-side upload script\naction: streamUrl,\ndebug: true,\nmultiple: false,\n```\n                    // additional data to send, name-value pairs\n                    params: {\n                        lineId:\"1\"\n                    },\n                    // events\n                    // you can return false to abort submit\n                    onSubmit: function(id, fileName){\n                        //  alert(\"last file: \" + lastFile);\n                        if (lastFile != \"\") {\n                            // we could call something server side here to delete\n                            // the last file, but probably easier to delete on submit ...\n                        }\n                        $('.qq-upload-list').empty()\n                        // $('.qq-upload-list > li').remove();\n                        // disable submit button\n                            / //  $(\"#sData\").attr(\"disabled\", \"true\");\n                        $(\"#sData\").addClass(\"ui-state-disabled\");\n                    },\n                    onProgress: function(id, fileName, loaded, total){},\n                    onComplete: function(id, fileName, responseJSON){\n                        lastFile=fileName;\n                        // need to handle failure from server here\n                        //   alert(responseJSON.success);\n                        if (responseJSON.success == \"true\")\n                            $(\"#sData\").removeClass(\"ui-state-disabled\");\n                        // else\n                        //   alert(\"There was an error in accessing your file, please reselect the file and try again\");\n                    },\n                    onCancel: function(id, fileName){},\n                    messages: {\n                        // typeError: \"{file} has invalid extension. Only {extensions} are allowed.\",\n                        sizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\n                        minSizeError: \"{file} is too small, minimum file size is {minSizeLimit}.\",\n                        emptyError: \"{file} is empty, please select files again without it.\",\n                        onLeave: \"The files are being uploaded, if you leave now the upload will be cancelled.\"\n                    },\n                    showMessage: function(message){\n                        alert(message);\n                    }\n            });\n\n```\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820099.\n. Correct.  Do not use this.  I removed it from master.  The octet stream\nreader is just that, an octet stream reader.  You are trying to read a\nmultipart encoded request.  I have an example that parses such a request in\nthe java folder.\n\nAlso, there is no need to modify the code to include file size in the\nheader.  File size should be included by the user agent in the\nContent-Length header field.\nOn Mon, Sep 24, 2012 at 10:48 AM, anitakfitz notifications@github.comwrote:\n\nI am not sure I understand \u2026 I am using your octet stream reader class as\nmy \u2018servlet\u2019 url being called from the jsp/html calling the file uploader,\nthis works fine in firefox and chrome, but not in IE. I have actually even\nmodified your js to also include file size in the header, because I want to\nrevalidate that the entire file has been saved. Are you saying that this\noctet stream reader is NOT what I should be using to handle the url from\nthe file uploader ?\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 10:28 AM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header\n(#343)\nThere is no such header sent with a multipart encoded request. Have a look\nat the servlet example in the server/java\nfolderhttps://github.com/valums/file-uploader/tree/master/server/javaif\nyour server-side language is java, which appears to be the case.\nOn Mon, Sep 24, 2012 at 9:16 AM, anitakfitz notifications@github.com\n<mailto:notifications@github.com>wrote:\n\nOk, i followed your link in the message above, but I do not see any\ndifference between this example and the version I have ? the problem I\nhave\nis that in IE9, the following line returns null for filename:\nString filename= request.getHeader(\"X-File-Name\");\nmy jsp code is as follows:\nvar uploader = new qq.FileUploader({\n// pass the dom node (ex. $(selector)[0] for jQuery users)\nelement: document.getElementById('fileToUpload'),\n// path to server-side upload script\naction: streamUrl,\ndebug: true,\nmultiple: false,\n// additional data to send, name-value pairs\nparams: {\nlineId:\"1\"\n},\n// events\n// you can return false to abort submit\nonSubmit: function(id, fileName){\n// alert(\"last file: \" + lastFile);\nif (lastFile != \"\") {\n// we could call something server side here to delete\n// the last file, but probably easier to delete on submit ...\n}\n$('.qq-upload-list').empty()\n// $('.qq-upload-list > li').remove();\n// disable submit button\n/ // $(\"#sData\").attr(\"disabled\", \"true\");\n$(\"#sData\").addClass(\"ui-state-disabled\");\n},\nonProgress: function(id, fileName, loaded, total){},\nonComplete: function(id, fileName, responseJSON){\nlastFile=fileName;\n// need to handle failure from server here\n// alert(responseJSON.success);\nif (responseJSON.success == \"true\")\n$(\"#sData\").removeClass(\"ui-state-disabled\");\n// else\n// alert(\"There was an error in accessing your file, please reselect the\nfile and try again\");\n},\nonCancel: function(id, fileName){},\nmessages: {\n// typeError: \"{file} has invalid extension. Only {extensions} are\nallowed.\",\nsizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\nminSizeError: \"{file} is too small, minimum file size is\n{minSizeLimit}.\",\nemptyError: \"{file} is empty, please select files again without it.\",\nonLeave: \"The files are being uploaded, if you leave now the upload will\nbe cancelled.\"\n},\nshowMessage: function(message){\nalert(message);\n}\n});\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820099>.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820530>.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8823543.\n. ...please note that the Content-Length is only really useful for XHR\nuploads.  For multipart encoded requests, Content-Length indicates the size\nof, not just the file, but the size of all fields in the request.  In the\ncase of multipart encoded requests, you can check the file size using the\napache commons fileupload library in the example I provided.\n\nOn Mon, Sep 24, 2012 at 11:07 AM, Ray Nicholus ray@garstasio.com wrote:\n\nCorrect.  Do not use this.  I removed it from master.  The octet stream\nreader is just that, an octet stream reader.  You are trying to read a\nmultipart encoded request.  I have an example that parses such a request in\nthe java folder.\nAlso, there is no need to modify the code to include file size in the\nheader.  File size should be included by the user agent in the\nContent-Length header field.\nOn Mon, Sep 24, 2012 at 10:48 AM, anitakfitz notifications@github.comwrote:\n\nI am not sure I understand \u2026 I am using your octet stream reader class as\nmy \u2018servlet\u2019 url being called from the jsp/html calling the file uploader,\nthis works fine in firefox and chrome, but not in IE. I have actually even\nmodified your js to also include file size in the header, because I want to\nrevalidate that the entire file has been saved. Are you saying that this\noctet stream reader is NOT what I should be using to handle the url from\nthe file uploader ?\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 10:28 AM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header\n(#343)\nThere is no such header sent with a multipart encoded request. Have a\nlook\nat the servlet example in the server/java\nfolderhttps://github.com/valums/file-uploader/tree/master/server/javaif\nyour server-side language is java, which appears to be the case.\nOn Mon, Sep 24, 2012 at 9:16 AM, anitakfitz notifications@github.com\n<mailto:notifications@github.com>wrote:\n\nOk, i followed your link in the message above, but I do not see any\ndifference between this example and the version I have ? the problem I\nhave\nis that in IE9, the following line returns null for filename:\nString filename= request.getHeader(\"X-File-Name\");\nmy jsp code is as follows:\nvar uploader = new qq.FileUploader({\n// pass the dom node (ex. $(selector)[0] for jQuery users)\nelement: document.getElementById('fileToUpload'),\n// path to server-side upload script\naction: streamUrl,\ndebug: true,\nmultiple: false,\n// additional data to send, name-value pairs\nparams: {\nlineId:\"1\"\n},\n// events\n// you can return false to abort submit\nonSubmit: function(id, fileName){\n// alert(\"last file: \" + lastFile);\nif (lastFile != \"\") {\n// we could call something server side here to delete\n// the last file, but probably easier to delete on submit ...\n}\n$('.qq-upload-list').empty()\n// $('.qq-upload-list > li').remove();\n// disable submit button\n/ // $(\"#sData\").attr(\"disabled\", \"true\");\n$(\"#sData\").addClass(\"ui-state-disabled\");\n},\nonProgress: function(id, fileName, loaded, total){},\nonComplete: function(id, fileName, responseJSON){\nlastFile=fileName;\n// need to handle failure from server here\n// alert(responseJSON.success);\nif (responseJSON.success == \"true\")\n$(\"#sData\").removeClass(\"ui-state-disabled\");\n// else\n// alert(\"There was an error in accessing your file, please reselect\nthe file and try again\");\n},\nonCancel: function(id, fileName){},\nmessages: {\n// typeError: \"{file} has invalid extension. Only {extensions} are\nallowed.\",\nsizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\nminSizeError: \"{file} is too small, minimum file size is\n{minSizeLimit}.\",\nemptyError: \"{file} is empty, please select files again without it.\",\nonLeave: \"The files are being uploaded, if you leave now the upload\nwill be cancelled.\"\n},\nshowMessage: function(message){\nalert(message);\n}\n});\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820099>.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820530>.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8823543.\n. For multipart: You can check the size of the FileItem object and compare it with the size of your locally saved file.\n. This is what I have done in my projects since IE tends to do this in some\ncases.  If you have the \"include local directory path\" setting enabled in\nyour IE security settings, the full path will be sent.  Also, if the site\nyour are uploading to is marked as a \"trusted site\" you will also see the\nfull path.\n\n\nOn Mon, Sep 24, 2012 at 1:53 PM, anitakfitz notifications@github.comwrote:\n\nSo, it looks like in request parser, when I get the filename, it gets the\nfull client side filename, including local path, so then in upload\nreceiver, I need to separate out the filename only (from the full path) to\ncreate the new server side file path\nJust want to confirm \u263a\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 2:50 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header\n(#343)\nFor multipart: You can check the size of the FileItem object and compare\nit with the size of your locally saved file.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8829999>.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8830119.\n. Agreed.  You will have to plan on handling the filename with the full path.\n\nOn Mon, Sep 24, 2012 at 2:32 PM, anitakfitz notifications@github.comwrote:\n\nHmm, ok, I think I have a workaround, I wont be able to depend on ie\nsecurity settings, since this will be whatever the clients have\nI think I do have it working somewhat, however, I am getting the file\nuploaded (on my local server, still have to test on the real server)\nI have noticed, however, that when the upload completes, I do get the json\nresponse (success) for ie and other browsers, but the other browsers are\ndisplaying file size where IE is not ?\nThanks so much for your help !!\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 3:14 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header\n(#343)\nThis is what I have done in my projects since IE tends to do this in some\ncases. If you have the \"include local directory path\" setting enabled in\nyour IE security settings, the full path will be sent. Also, if the site\nyour are uploading to is marked as a \"trusted site\" you will also see the\nfull path.\nOn Mon, Sep 24, 2012 at 1:53 PM, anitakfitz notifications@github.com\n<mailto:notifications@github.com>wrote:\n\nSo, it looks like in request parser, when I get the filename, it gets\nthe\nfull client side filename, including local path, so then in upload\nreceiver, I need to separate out the filename only (from the full path)\nto\ncreate the new server side file path\nJust want to confirm \u263a\nFrom: Ray Nicholus [mailto:notifications@github.com][mailto:\nnotifications@github.com]\nSent: Monday, September 24, 2012 2:50 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header\n(#343)\nFor multipart: You can check the size of the FileItem object and compare\nit with the size of your locally saved file.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8829999>.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8830119>.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8830840>.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8831478.\n. My initial plan is to, in some instances, replace the failUploadText with the first however-many characters of the \"reason\" or \"error\" text in the response.  To see the entire message, the user could click on or hover over the failure message.  I think I need to figure out case #317 first though.\n. Please see the readme for details.\n. I'm not seeing any access denied issues.  What version of fine-uploader are you using?  How are you reproducing this?\n. I'm not seeing these at all.  If you find a recipe to reproduce, please let me know.\n. Win 7, sp1\n\nIE 9.0.8112.16421\n. Mine is W7 pro.  Well, like I said, if you find a pattern, please share.  Otherwise, I've not run into this issue in my testing or in my use of Fine Uploader in 2 applications I maintain/develop.\n. Always standards.  Compatibility mode is a huge PITA.  I would not\nrecommend using that, or \"quirks mode\".\nOn Sat, Sep 22, 2012 at 12:29 PM, Denominator notifications@github.comwrote:\n\nDoes your ie operate in standards or compatibility mode?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/345#issuecomment-8790904.\n. Any update on this?  Can it be closed?\n. alrighty.  if you or anyone else can reproduce this, please re-open.\n. Did I miss anything?\n. Fixed in #424\n. Looking at the PHP code, it looks like move_uploaded_file in qqUploadedFileForm is returning false, ostensibly due to an error moving/copying the uploaded file.  What does your client-side code look like?\n. BTW, I can attempt to help you here, but I don't have any PHP experience.  Server-side, my forte is Java/Groovy.  You may get more help if you post this question in the Fine Uploader forums.\n. Please see case #352.\n. The tests in the tests dir 2+ years old.  It's not clear how many of them are still relevant.  The ones that are would require some effort to make them work with the current codebase.  Also, the server-side end of these tests is written in PHP.  I'm using java servlets for my testing.  \n\nI already have some QUnit tests written in the 3.0 branch.  I plan on expanding these tests over time.  This is discussed in case #391.\n. I may be able to get this in to 2.1...\n. This is already scheduled for 2.1, so, barring some crisis, it should make it into 2.1.  I try to take some time to ponder changes proposed in pull requests in case additional adjustments to the code are prudent before merging with master.  I just haven't taken the time to look into this one yet.  Possibly tonight.\n. I should say that I'm glad you are taking the time to follow-up, and I appreciate your help on this.\n. I took a peek at this and would like to make a change.  \nThe default implementation of showMessage uses the alert function.  This means that the user will see an alert message for each offending file, and the file will not be uploaded until the user dismisses the alert dialog.  Perhaps we should, instead, defect calling showMessage until we exit the loop in _uploadFileList, and then call showMessage.  \nThe tough part is determining what we would pass to showMessage after the loop exits.  If there is one error type with several offending files, we could perhaps intelligently construct one error message listing all files.  If there are several different types of error conditions encountered, the message dialog may be a bit large and wordy.  I definitely have a problem with alert being used at all, but I don't plan on replacing that with something less annoying until 3.x.  [off-topic] Another thing I don't like: a default implementation for showAlert in FileUploaderBasic.  Again, that will likely change in 3.x. [/off-topic]  \nAnother option would be to just say: if you don't like an alert dialog after each offending file is encountered, either set stopOnFirstInvalidFile to true, or override showMessage with something less annoying.  [off-topic]  If you are lucky enough to be using Twitter-Bootstrap as a user of Fine Uploader, the alert plugin would be a nice replacement.  I think I will use something with a similar behavior in 3.x when I remove alert. [/off-topic]  \nThoughts?\n. I, too, like the idea of grouping them, but I'm worried about how this will look in an alert dialog.  It will likely look pretty ugly.  Lots of text in one dialog box is never a good thing.  I'm trying to decide which is a better temporary situation until i replace the default implementation of showMessage: an alert dialog with potentially a lot of text, or an alert dialog after each failed file that much be dismissed for the uploader to continue.  The user can override showMessage if they don't like either situation though.  Thoughts on how we should proceed?  I'm liking the \"potentially too long alert dialog\" a bit more, but I could go either way I guess.\n[off topic] I decided not to introduce jQuery as a mandatory dependency.  That is, the library will not be re-written in jQuery.  I go into some detail about my plan for 3.0 here.  Even if we were using jQuery, I agree that depending on TB just for the alerts plugin wouldn't be a good idea.  I'm guessing I can find something on microjs.com.  [/off-topic]\n. ...just thought of a reason to not wait until the end of _uploadFileList to call showMessage with one long string of error messages.\nIf the user has decided to override showMessage with something that, for example, displays a TB alert, they might not appreciate receiving one long string with all error messages for all invalid files.  Instead, they might want to display, say, an alert for each file that fades away after a few seconds.  \nI think this is a big reason to just keep it the way you coded it and still plan to replace user of alert in the default showMessage with something nicer in 3.0.\n. I accidentally referenced case 355 in some other related commit messages.  Oops.  Just an FYI. \n. We haven't moved any validation server-side in this commit.\n. That's correct, but that is up to the user.  If they aren't interested in some enforcement of these rules client-side, then that's their prerogative.  That's not really related to this case, unless I'm missing something.\nThese rules are really not super-useful anyway, and are easily fooled.  The 2 size-related rules are not enforceable at all in IE.  allowedExtensions simply checks the extension of the filename, which doesn't guarantee that the file is what it claims to be (based on the extension).  The only true way to ensure a file's identity is to run some magic byte tests on the files server-side.  Even the type attribute of a file (provided by the File API, which most browsers other than IE implement) only appears to be a filename extension check (at least in Chrome).\n. Just to be sure we are on the same page, to add to my last message: showMessage, in my opinion, is only appropriate when submitting files (if there is a problem with the submission).  After the upload has started, the server needs to deal with any problems that aren't caught by the client (for whatever reason).  For example, if the server identifies a file, and it isn't an acceptable type, it can return an error property in the JSON response, and if the faildUploadTextDisplay mode is set to \"custom\", they will see that error next to the failed file.  I wouldn't think we would want showMessage to be called in this case, due to the default implementation.  onError IS called though, with the error message.\n. nice catch!\n. As far as I'm concerned, neither of these is correct.  Please see my post on this issue.  I don't currently have an environment set up to test using PHP, so it would be quite helpful if you could test my code in the referenced post and let me know if it works.  If it doesn't perhaps we can make it work, as I don't believe the current method for determining the request type in the PHP example is reasonable.\n. I really hope I'm not the only one who thinks it's a bad idea to determine the request's encoding type based on the presence of a specific query parameter (a query parameter name that is also not constant since it is tied to the inputName option).\n. @rjha I'm not sure what you are referring to.  My problem is that the current PHP code uses the presence of a specific item in the query string to determine the type of request.  Have a look at the first \"else\" in the \"updated\" example above.\n. The issue is either in your code, or in your server configuration.  Give the latest php example a shot first.  If that doesn't work, you will need to take a close look at your application server.\n. The master branch, starting with version 2.1.2, is also the latest released\nversion of Fine Uploader, which means you can download the js/css/imgs on\nthe releases page.  I am hesitant to include anything other than js in the\nreleased zip.  If you are interested in downloading examples (or any other\nfiles) associated with a specific version, simply go to the branch you are\ninterested in and click on the \"zip\" button.\nOn Wed, Oct 31, 2012 at 2:16 PM, Max Felker notifications@github.comwrote:\n\nOkay, I can confirm that this fix from @weberhoferhttps://github.com/weberhoferis working. Looks like it was merged into master, so maybe the zips in the\nreleases (which where the btn on the project page links to) needs to be\nupdated.\nBetter yet, display a link for the master zip?\nEveryone, really appreciate the help. This is pretty awesome!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/352#issuecomment-9958178.\n. I am hesitant to put examples into the released zips as I have no way to\ntest all of them, nor do I have the time.  The items in the releases zip\nshould be tested.  Maintained examples can remain in the source, but those\nwithout maintainers will be removed at some point.  If the maintainers are\nwilling to test in all browsers before each release, I can possibly include\nthose tested server-side examples.\n\nOn Wed, Oct 31, 2012 at 3:39 PM, Max Felker notifications@github.comwrote:\n\nHey Dude,\nThanks for the reply. The reason why I was bringing this up is because if\nyou go to http://fineuploader.com/, it says that it works for IE7+. This\nis true except for the server side PHP controller that included in the\n2.1.2 release. I would say that this is going to be confusing for people.\nAs a relatively good developer, it took me about 30 minutes to get it\nworking with every browser (sans IE) and 2 days to get it to work with IE\ndue to the fact that I had to debug everything from file permissions,\nserver vars, and all the other fun stuff.\nI guess my question is this: Why are you hesitant to put something into\nthe release besides html/css/js? This fix is the only way that the PHP\ncontroller will work with IE so why wouldn't that be included? It's about 3\nlines of change that have been tested, confirmed, and then merged. I know,\neveryone hates IE (including me) but people need cross browser support.\nAt the very least, why put a note on the release page about the PHP\ncontroller update for IE?\nNeither of these option would hurt too much and would have saved me many\nhours lol. Just food for thought.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/352#issuecomment-9961108.\n. @NTICompass has offered to be the maintainer for the PHP code, but, the more the merrier!  Looks like we have a lot of PHP users, so I'd love to see multiple contributors for that example code.\n\nCan you monitor the google groups forum and the github project issues for PHP questions?\n. group: https://groups.google.com/forum/#!forum/fineuploader.  You may want\nto browse the 3.0 readme as well to get an idea of the changes planned for\n3.0 (releasing Nov 19).\nOn Thu, Nov 1, 2012 at 9:06 AM, Max Felker notifications@github.com wrote:\n\nSure thing man. Got a link to that Google Group?\nI'm going to fork, make a few updates and keep my out for other PHP peeps.\nThanks guys!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/352#issuecomment-9981145.\n. Excellent.  I'm pleased that you are willing ti lend a hand.\n\nOn Thu, Nov 1, 2012 at 9:14 AM, Max Felker notifications@github.com wrote:\n\nAwesome, thanks for the link dude. Yeah, I'm always hacking around and get\nsome free time here at work every so often to work on the open source\nstuff. I just used this for a project and got really familiar with it so\nI'm excited to contribute.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/352#issuecomment-9981387.\n. Sounds good Rocket.  Will this involve javascript changes as well?\n\nOn Thu, Nov 1, 2012 at 9:10 AM, Rocket notifications@github.com wrote:\n\n@maxatbrs https://github.com/maxatbrs:\nhttps://groups.google.com/forum/#!forum/fineuploader\nI'd love to have others help with the PHP code as I may not always have\nfree time. I was actually working last night on adding PHP 5.4 Session\nUpload Progress, but I don't know when I'll be ready to push that.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/352#issuecomment-9981286.\n. Ah ok.  Those will need to be based off of the 3.0 branch then.\n\nOn Thu, Nov 1, 2012 at 9:23 AM, Rocket notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus: Yeah. To get the status, you\nneed to make AJAX calls to ask PHP 5.4 for the progress.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/352#issuecomment-9981664.\n. Thanks for the PR.  I'll take a closer look at this sometime today or tomorrow, hopefully.\n. I think we are making assumptions about foreign languages that may not be true in all cases.  I'm hard-pressed to think of a case where one would localize is/are.  In many cases, the is/are placeholder simply wouldn't be appropriate.  \n\nI've thought about this, and I'd much rather simply have the following changed made:\ntypeError: \"{file} has an invalid extension. Valid extension(s): {extensions}\"\nThis results in less changes to the code.  I'm not sure we need anything more.\nWhat do you think?\n. Yep, for some languages it certainly would have been useful, but not so much for others.  Any chance you will make this change in your branch and commit it?  If so, I could merge that it right away, most likely.\n. Thanks for your help!\n. Forgot that bind is not supported in older browsers, such as pre-IE9.  I'll have to use the version of bind on MDN for those browsers.\n. Not going to do this.  I'll let developers utilizing FU create their own tooltip, if the default one is not good enough.\n. Not going to do this.  I'll let developers utilizing FU create their own tooltip, if the default one is not good enough.\n. Thanks for your contribution!\n. You will need to handle an xhr (post) upload request for all browsers other than IE.  For IE, you will need to handle a multipart form request.  If you want to make it easier (with the loss of some features) you can set the forceMultipart option to true and handle all requests from all browsers as multipart form requests.  I personally don't recommend this though.  \nIf you are not familiar with how this works in Ruby, you will need to do some research.  There is probably a gem that takes care of most of this for you.\n. What version of the js library are you using?\n. There is no error.\nYou are using the readme in the master branch (2.1-SNAPSHOT) with the 2.0 client.  If you want to use the 2.0 released client, reference the 2.0 branch readme.  If you want to use the 2.1-SNAPSHOT (unreleased) version, use the readme in the same (currently master) branch.\nNote that I added a link in the 2.0 download section to the 2.0 readme, but this is simply a link to the readme in the corresponding 2.0 branch.\n. No problem.  It's a common practice to have unreleased, work-in-progress code in the master branch.  This can be referred to as the snapshot version.  Not everyone does this though.  For example, if you use GitHub Flow, the master branch actually contains the latest \"released\" code.  However, I'm sticking to the more traditional approach.  Master = work in progress.  Other branches = released unless otherwise specified.  I'll be sure to link to the proper readme in the downloads section in the future, though.\n. See it here\n. Please see the onError callback documentation.  Note that this callback has\nchanged/improved in the 2.1-SNAPSHOT version (master branch).\nOn Thu, Sep 27, 2012 at 11:07 AM, djuric notifications@github.com wrote:\n\nI want to validate if file is uploaded on clients side but I don't see a\nway to check for this ( unless I edit core class)\nWhats the best way for this that you guys can recommend?\nHelp much appreciated :)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/361.\n. Thanks for this.  I was wondering if you could look at #347.  I'm interested in getting that tested and merged into master as well.\n. Thanks for catching this!\n. I think in most cases, users would want the dragenter event tied to the document.  But I I think your request is reasonable.  Perhaps some do not want this behavior.  I can look into making the elements attached to the dragenter and dragleave events configurable. Do you have any preferences?  \n\nNote: I'm not sure what release this will be in.  Maybe 2.1, but more likely not until 2.2 or later.  Receiving a solid pull request may speed that up though.\n. It is already possible to have multiple file uploaders on the same page.\nI'm doing this on the demo page.\nOn Sep 30, 2012 2:49 AM, \"Andrew Nugged\" notifications@github.com wrote:\n\nMore of that: if we can attach file-uploader to only part of the page - we\ncan attach two different uploader instances on same page so we can for\nexample create few indepentent dropzones for quick fileuploading per\nitem (for example in different folders, i.e. with different \"action\" and\n\"params\" parameters for each dropzone).\n(maybe for future to decrease JS cpu load/memory footprint uploader must\nbe created in one-main-code for any instances on one page... anyway)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/364#issuecomment-9011633.\n. It shouldn't be too hard to allow the user to specify the drag event\ntargets, but i can take a look at that if you're not comfortable making\nthose changes.\nOn Sep 30, 2012 5:30 AM, \"Andrew Nugged\" notifications@github.com wrote:\nSo they already divided by focus places with different action/prarms?\nGreat - so only to detach uploader from whole page will be great. Okay, so\n- does it complex and need deep code structure knowledge? Can I involve if\n  not-so-complex?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/364#issuecomment-9012454.\n. I'm going to leave this for 2.2, but I'll make it one of the first cases I work on.\n. You can already do this, without modifying any fine uploader code.  Simply return whatever text or html you want in your response and read it client-side in your onComplete handler.\n. I've thought about this some more and realized that I'm still not sure specifically what the requirement is here.  The dragenter event is already tied to the individual drop zones.\n. Ongoing. I achieved more of this with the drag & drop refactor, and I indent to continue this effort.\n. Ongoing.  I achieved more of this with the drag & drop refactor, and I indent to continue this effort.\n. Should have covered this in #327\n. Must have been a late night when I updated the readme.  Thanks for catching this issues as well.\n. It's pretty difficult to determine what you've actually changed due to the spacing issues.  Could you fix this first?  Also, I'm a bit hesitant to accept any \"improvements\" to the php example, or any examples for that matter, unless they are bugfixes.  I'm finding that too much of my time is spent on support of the examples, when I really should be focusing almost entirely on the javascript code.  Furthermore, there is an outstanding issue, as I see it, with the encoding type detection in the php example which I consider to be most important at this point.  This is issue #347.\n. Should have covered this in #317.\n. TODO: documentation\n. plug-in and documentation should be complete\n. This is now part of the 3.0 branch.\n. Work on this is being staged in the failed-upload-retry branch.\n\nI'm about 1/2 done, and still have the following items to complete:\n- public retry function for FUB users\n- manual retry button (for FU)\n. Should be 100% functional in the failed-upload-retry branch.  Still TODO:    \n- respect maxConnections when attempting to retry\n- more testing\n- update readme\n. Just need to update the readme & then merge into 3.0.\n. This should be the true.  I'll update the readme to reflect this.\n. It should be pretty easy to add a \"public\" cancel function to 3.0.  I just created a case to ensure I don't forget.\n. In the 3.0 branch.\n. This is not the appropriate place to discuss a defect.  Please open a new\ncase, provide your code, and some more specifics required to reproduce.\nOn Dec 8, 2012 10:21 AM, \"cob4lt\" notifications@github.com wrote:\n\nI am using FUB and I dont understand why I am getting this error when\ncalling cancel method\nAfter line this\napp_obj.Stupovi.fineUploader.cancel(app_obj.Stupovi.fineUploader._storedFileIds[0]);\nand the console log\n[FineUploader] Sending upload request for 0\njquery.fineuploader-3.0.min.js:56\n[FineUploader] Cancelling undefined jquery.fineuploader-3.0.min.js:56\nUncaught TypeError: Cannot read property 'fileName' of undefined\nThank you\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/376#issuecomment-11160179.\n. Moving into 3.0.\n. Thinking that I will support the following:\n\nB\nSI\nkB = 1000 B\nMB = 1000 KB\nGB = 1000 MB\nIEC 60027\nKiB = 2^10 B\nMiB = 2^20 B\nGiB = 2^30 B\n. All computers do use those labels, but they don't all define them the same\nway.  For example, os x defines a MB as 10^6 bytes (using the SI values),\nbut windows defines it as 2^20 (using the binary value).  I wanted to\nprovide the ability for developers to choose either to define the min and\nmax file size limits used by the file validator.  Note that this, for the\nmost part, only applies to the two validation options.\nAfter some thought last night, honestly though, I'm probably going to close\nthis case as \"won't implement\" since there is likely going to be confusion\namong those who don't understand these units.\nOn Nov 14, 2012 2:42 AM, \"tellibus\" notifications@github.com wrote:\n\nAm I wrong supposing that most developers and users would use binary\nprefixes? Afaik, all computers use kB, MB and GB in their binary\ndefinition.\nMy point is that someone would want to upload a 50 KiB file (that shows as\n50 kB in the file system) and that won't work with a sizeLimit of SI 50\nkB...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/378#issuecomment-10358767.\n. @tellibus Thoughts?\n. I concur.\n. In 3.0 now.\n. This is likely NOT going to make it into 3.0 due to the complexity this will add to the code (and we are relatively close to the release date).  \n\nA couple things to be aware of here:\n- Regarding selection of folders in the dialog, there is no way to allow users to select both files and folders in the same dialog, it's either one or the other.  This makes sense, but means we will either need two input elements, or perhaps radio buttons that, when clicked, would modify the input element to allow either folder or file selection.  Of course, there would need to be instance functions behind the radio buttons as well (for FUB users).\n- In order to support DnD of folders in Chrome, we first need to grab an array of Entry objects from the dataTransfer object attached to the event.  To do this, we must parse the array of items associated with the DTO and call a proprietary function on each item to obtain the Entry.  If the Entry is a DirectoryEntry, we must create a DirectoryReader to read any Entry objects associated with this directory.  Eventually, we wind up with an array of files.  Note that the function that allows us to read entries inside a directory takes callbacks as parameters.\n. I decided to allow uploading directories only via drag-and-drop.  \nIf I were to allow selection of directories via the \"select files\" dialog, I would need to provide either two input elements/buttons or provide some way to modify the one input element to toggle between selecting files and selecting directories.  There is, unfortunately, no way to allow users to select both files and directories in the same \"select files\" dialog.  So, I'm just going to leave this behavior out as it isn't very impressive or useful, in my opinion.  \nThis is now part of 3.1.\n. No idea what this means anymore.  If I identify specific improvements that need to be made, I'll create cases and schedule them.\n. Andrew Collins started off this feature with a pull request (see above).  Here are some comments I made in response to the PR:\n- [x] There should be an option to control whether this feature is enabled or not.\n- [x] Fine Uploader, IMHO should send the DELETE request itself, and the server should respond in a format similar to the accepted upload response.  If the request contains a \"success\" property w/ a value of \"true\" the UI would be updated (by removing the associated  in FU mode).  Other properties could be passed for the benefit of the onDeleteComplete callback (see number 5 below).\n- [x] There should be a way for developers to force users to confirm the deletion.  There is already a showMessage function \"option\" that can be overriden.  The default impl uses alert.  There could also be a default showConfirm(...) w/ a default implementation that uses window.confirm(...).  Developers could override this, with, for example, a Bootstrap modal.\n- [x] There should be a function added to the API for FIneUploaderBasic users.\n- [x] The onDelete callback would be called before the request is sent.  Perhaps a return value of false would prevent the request.  This would occur before the confirm is launched, which would also affect the outcome of the delete request (depending on which button the user clicks in the dialog).  There would also need to be a onDeleteComplete callback that functions similar to onComplete  This way, a developer could structure their code to display a success or error message when appropriate.  \nJust some thoughts.  I fully planned on adding the details above myself, so don't feel obligated to spend more time on this.  Your code is a good start.  Some comments/input from you would be helpful though.  It's always nice to get some input from a fellow developer.\nThis feature is currently being staged in the delete-button branch.\n. The request, at this time, will be a DELETE request.  Also, following the spec outlined in HTTP 1.1 RFC 2616, sect 9.7, the UUID of the file (resource) to be deleted will be passed as part of the request URI.  I also intend to follow the spec as far as acceptable response codes.  I think I'll allow the server to return whatever it wants in the response body, and include the XmlHttpRequest object instance in the onDeleteComplete callback along with a determination on Fine Uploader's part of the success.  A client could return JSON, XML, or whatever it wants since Fine Uploader will use the response code to determine success.\n. Hello again Andrew.  I have thought about allowing the UUID to be part of the URI (path) OR the query string.  This could be toggled via a new restful property in the deleteFile option.  \nAs far as smarter server-side code is concerned, developers are going to have to either construct their own ajax call to delete the file, or we can do it for them, removing much of the client-side complexity from their code into Fine Uploader's code.  Either way, they will need to handle the request server side and return some sort of response.  It should be trivial to determine the request method server-side.  If developers don't want to adjust their server-side code, they can leave the delete feature disabled, as it will be by default.\nI thought about sending the request as a POST, but that does not seem like the correct approach.  DELETE is most appropriate here. All DELETE requests will be sent the same way, on all user agents.  That is, I plan on using XmlHttpRequest to send the DELETE request.  This should work, in theory, on all supported browsers.  IE7 was the first version of IE to support XHR, and that is the oldest version of IE supported by Fine Uploader.  \nRegarding your comment on allowing PUT requests for uploads, it simply cannot be done in an intuitive cross-browser fashion that follows any published standard.  I received a similar request earlier (#554).  For upload requests, Fine Uploader resorts to form submission in a hidden iframe for browsers that do not support the File API.  The method attribute of  only accepts POST and GET as valid values, per the  W3C spec.  I've found that this is enforced by IE, as expected.  I would not be in favor of sending PUT upload requests for XHR uploads, and POST requests for non-XHR uploads.  I think the method should be the same, regardless of the methods used on the client-side to send the request.  \nAs far as parameters for upload request are concerned, I plan on continuing to allow parameters to be part of the query string, but, by default, they will be included in the request payload in 3.3.  As I mentioned earlier, DELETE requests could contain the UUID in the URI path, or in the query string (configurable, but defaulting to URI path, perhaps).  \nAs far as providing an option to add parameters for upload requests to the URI path to support RESTful workflows, I suppose could do this as well, but I haven't received a specific feature request for this yet.  Doing this would complicate the feature that allows users to specific custom parameters a bit.  Passing parameters in the URI path or the query string are both valid in RESTful workflows anyway.  I think custom parameters, specified by users via the param option object, or via the setParams API function are best left in either the query string or the request payload.  Developers who want to construct an alternate endpoint for each file with specific parameters in the URI path can easily do so via the relatively new setEndpoint API function.  \nAlso, I'm not fond of X headers.  Note that we have no control over the request headers for requests sent using form submission (IE9 and earlier, along with Android 2.3.x and earlier)  \n. In 3.3-IP.  Please see the readme & the associated blog post for more details.\n. TODO:\n- [ ] pull in pdf.js as an optional dep\n- [ ] augment preview code to handle PDFs via pdf.js API\n- [ ] modify identify.js to identify PDFs (25 50 44 46)\n- [ ] documentation\nWe'll probably just preview the first page by default, and then modify if users have more specific (reasonable) requirements.\n. This is a bit out of scope for an upload library.\n. After some thought, I'm not quite sure how I should implement this exactly.  There are so many different paths I can take.  I realize that this will need to be highly customizable to ensure that most FineUploader mode users who want such a feature can easily make use of this and customize it to fit their needs without writing their own.  I think, at the very least, I need to spend another release thinking about this.  However, I would really appreciate some input from Fine Uploader users.  I'd like to hear some UX-related ideas.  I'll solicit users via Twitter, the groups support forum, and perhaps Geekli.st for input.\nIf I don't receive any input at all, or any +1's/^5s, I may just kill this feature.  I'll let the users tell me what they want for this one...\n. Need to discuss this with the graphic designers at Widen before I proceed.  Moving to 3.7, but likely will be pushed farther back.\n. The plan is to provide an onTotalProgress callback, along with support for an optional aggregate progress bar in Fine Uploader UI.\n- [x] onTotalProgress callback with two params: totalUploaded, totalSize.  Both integers.\n- [x] callback will be invoked whenever an individual file's progress changes (increase in totalUploaded value)\n- [x] ...whenever a file is added (increase in totalSize value)\n- [x] ...whenever a file is canceled (reduction in totalUploaded & totalSize values)\n- [x] Total progress bar in UI will be hidden once it reaches 100% or once there are no files in progress.\n- [x] Total progress represents only the current \"batch\" of files. Once there are no more files in progress & all files have uploaded successfully or the failed ones have been canceled, the progress bar will be reset internally.\n. This can easily be accomplished with an onValidate callback.\n. Duplicate of #518.\n. May bump this into a later release as I'm not sure how useful/important this really is.\n. Not sure this makes sense, after some though.  May be closed.\n. I think this already works in Android, though some testing will be required.  A bit of work may be required to make this function properly in IOS6.  The primary use case here is for mobile devices.  \nI'm not sure I plan on making this work for desktop machines with USB-connected or built-in laptop cameras.  This will require a bit more work and UI considerations.  Essentially, I will need to provide a \"snap picture\" button for non-mobile devices along with a window to display the video from the camera if I want to support desktop/laptop cameras as well.  It's not clear that this would be worth the effort, as I'm not sure many people (if anyone) would find this feature useful on a non-mobile device.  \nIs anyone interested in uploading pictures from non-mobile devices?\n. Works fine without any changes on the stock browser in Android 4.0.4.  I remember this also working in Android 2.3.6, but I'll need to confirm.  Some adjustments may be needed for IOS6 (to allow access to the camera).  Still need to test on the Surface tablet.  If IOS6 only needs a specific value for the input element's accept attribute, I'll probably just document that.\n. Surface tablet photos work as is.\nIOS6 has a strange restriction here.  The multiple attribute of the input element MUST be false or not present, along with a value of \"image/;capture=camera\" on the input's accept attribute.  This means that users can either upload a picture via the camera, or select multiple files at once, and not both.  This essentially requires the integrator to make a difficult decision if uploading via the camera on IOS6 is a desired feature.  I'll need to give this some thought.  Ideally, I'd like to make it possible to either switch between the two modes in IOS6 (camera access vs multiple file selection) or simply work some magic to make both possible simultaneously.\n. So, there are a few ways I can deal with the IOS6 restriction (see my comment above this one).\n- Do nothing, and simply instruct integrators who want to allow users to upload pictures taken directly from the camera in IOS6 to set the multiple option to false and ensure this value is included in the acceptFiles option: \"image/_;capture=camera\".  _Pro:** No changes/complexity added to the code. Con: Users will not be able to select multiple files at once if these two options are set.\n- Provide a new option, allowCameraAccess, that, when set to true, will set the options described in the previous bullet-point automatically.  Pro: Easier for integrators.  Con: Same as previous bullet-point.\n- Provide a new API function, setCameraAccess, that, when set, sets or unsets the options described in the first bullet-point.  Pro: Allows integrator to switch between multiple file selection and camera access without re-instantiating Fine Uploader.  Cons: Adds more complexity to the code.  Will need to consider designing some sort of optional toggle-switch for FineUploader mode's default UI.\nI could probably combine the last two bullet points as well.  \nThoughts?\n. If I don't receive any feedback on my last comment within the next few days, I'm going to bump this to 3.6.  \n@heralight Since you +1'd this, do you have any thoughts, by any chance?\n. Bumping this to 3.6, or until I get some feedback.\n. @Sydney-o9 Can you please comment on my last message in this thread?\nNote that this already works without any code adjustments for all Android devices, as well as the surface tablet.  The tricky part involves iOS devices.  Please read my last two long messages in this issue for more details.\n. Hi @mikemaccana!  I thought, briefly, about a second button, but this would only serve a purpose for iOS6 devices.  Android and even the Surface Tablet (and presumably Windows Mobile devices) are capable of ingesting from the camera and the filesystem (multiple files) with the same button.  Plus, requiring a second button certainly adds complexity to the library.  I'm not sure that complexity is justifiable in this case.\nI'm thinking that it may be sufficient to have iOS users choose between camera access and multiple file selection.  Integrators can always create their own second file input element, properly configured, that can be used exclusively for camera access, if they wish.  They can submit the <input> or the File (after the picture has been snapped) to the addFiles API method, and Fine Uploader will take it from there.  \nYour suggestion did make me think about multiple file input elements, though.  As I mentioned, it is fairly easy for integrators to create multiple file input elements and then pass them off to Fine Uploader on the associated onChange handler, but styling it is a bit less trivial without Fine Uploader's help.  So, I created case #819.  Let me know what you think.\n. @JasonBoland That's the direction I'm leaning.\n. I think two buttons would only be useful or make sense for iOS users, since the 2nd button is unnecessary for other mobile OS users.  You certainly could have a 2nd button that only appears for iOS users, but maybe it isn't that important for iOS users (or any mobile users) to select multiple files and upload via the camera anyway.  I'm still leaning towards an iOS-specific option that would disable the multiple option and set the correct accept attribute on the associated file input.  In the future, I may make use of getUserMedia to allow uploads via a desktop camera (#829), and this may require a second button.\n. I think this has sat long enough.  I'll proceed in 3.6 as described in my last few posts.\n. Working on this for 3.6...\n. I've completed this feature for 3.6 (currently in the develop branch).  You can read about all the gory details in my blog post on this feature.\n. this is a duplicate of #63, which is currently scheduled for 3.0 (but may be pushed to a later release as 3.x release planning is still a little hazy)\n. Well, I've certainly \"started\" writing unit tests.  I've adopted QUnit and have covered all of the utility functions with tests.  More tests need to be written for other portions of the code, but this can happen over time.  I also need to integrate with a CI system to automatically run these tests, but that is another story.\n. No, it doesn't, and it isn't supposed to.  The option is cancelButtonText, not cancelButtonHtml or cancelButtonElement or even cancelButton.  You are supposed to use it to alter the button text.  \nHave a look at the _bindCancelEvent function and you will see why it is critical that the click event target must be the  qq-upload-cancel anchor element (using the default fileTemplate).  If you want to, say, use an img as your cancel button, you will need to appropriately override the fileTemplate option.   If you alter fileTemplate, be sure your cancel element's class matches the cancel classes option, and be mindful of the logic in _bindCancelEvent.  In the simplest scenario, the parent of your cancel element would have to be the file template's list item element.\n. Hello.  I'm not very familiar with any of the CLR languages, other than C#, so I'm not sure if your code handles both XHR upload requests and multipart/data requests.  Does it?\n. Did you test with internet explorer? It will not send an xhr/ajax request.\nA multipart form request must be handled in this case.\nOn Oct 5, 2012 4:02 AM, \"Ch\u00e9 Letton\" notifications@github.com wrote:\n\nAs long as the coder users Ajax.BeginForm the XHR headers will be there.\nI have tested the code with all kinds of different files and all work.\nAn example of a header from Firefox Web Console for an Excel spread sheet\nis shown below:\nX-Requested-With:XMLHttpRequest\nX-File-Name:456.xls\nUser-Agent:Mozilla/5.0 (Windows NT 5.1; rv:15.0) Gecko/20100101\nFirefox/15.0\nReferer:http://localhost:6648/\nPragma:no-cache\nHost:localhost:6648\nContent-Type:application/octet-stream\nContent-Length:5336576\nConnection:keep-alive\nCache-Control:no-cache\nAccept-Language:en-us,en;q=0.5\nAccept-Encoding:gzip, deflate\nAccept:text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nThe Response info:\nX-AspNetMvc-Version:4.0\n-AspNet-Version:4.0.30319\nServer:ASP.NET Development Server/10.0.0.0\nDate:Fri, 05 Oct 2012 09:00:12 GMT\nContent-Type:text/html; charset=utf-8\nContent-Length:16\nConnection:Close\nCache-Control:private\nHope this answers the question.\nChe\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/393#issuecomment-9169492.\n. Can you confirm that you have tested this with IE?  It doesn't look like multipart data requests are accounted for.\n. This pull request is connected to your master branch, so you don't need to submit a new pull request.  Once you commit the fix to your master branch, it will automatically become part of this pull request.\n. The problem is in your server side code.  Please share that as well and\nmention what version of fine uploader you are using.\nOn Oct 5, 2012 6:43 PM, \"IronTurtle\" notifications@github.com wrote:\nWhen trying to upload the file and rerouting it to another folder using\nsettings.uploadpath, we noticed that each file was being corrupted. We also\nnoticed the size of the file is smaller than the original file we wanted to\nupload.\nI am using Chrome on a Mac, but my partner is also using Chrome on WIndows\n7.\nfunction createUploader() {\nvar uploader = new qq.FileUploader({\nelement: document.getElementById('uploader'),\nuploadButtonText: \"Select File\",\naction: '/upload',\ndebug: true,\nmultiple: false,\nautoUpload: true,\nonSubmit: function(id, fileName){\nconsole.log(\"Submitted id: \" + id);\nconsole.log(\"Submitted Filename: \" + fileName);\n},\nonProgress: function(id, fileName, loaded, total){\nconsole.log('Progress ' + loaded + \"/\" + total);\n},\nonComplete: function(id, fileName, responseJSON){\nconsole.log(\"Completed upload!!!!\");\nconsole.log(responseJSON);\n}\n});\n}\nNone of our files were uploaded fully.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/394.\n. It's also possible that a proxy server is causing a problem, but i don't\nknow much about your situation.  Did you check the content length header\nfield?\nOn Oct 5, 2012 7:02 PM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nThe problem is in your server side code.  Please share that as well and\nmention what version of fine uploader you are using.\nOn Oct 5, 2012 6:43 PM, \"IronTurtle\" notifications@github.com wrote:\n\nWhen trying to upload the file and rerouting it to another folder using\nsettings.uploadpath, we noticed that each file was being corrupted. We also\nnoticed the size of the file is smaller than the original file we wanted to\nupload.\nI am using Chrome on a Mac, but my partner is also using Chrome on\nWIndows 7.\nfunction createUploader() {\nvar uploader = new qq.FileUploader({\nelement: document.getElementById('uploader'),\nuploadButtonText: \"Select File\",\naction: '/upload',\ndebug: true,\nmultiple: false,\nautoUpload: true,\nonSubmit: function(id, fileName){\nconsole.log(\"Submitted id: \" + id);\nconsole.log(\"Submitted Filename: \" + fileName);\n},\nonProgress: function(id, fileName, loaded, total){\nconsole.log('Progress ' + loaded + \"/\" + total);\n},\nonComplete: function(id, fileName, responseJSON){\nconsole.log(\"Completed upload!!!!\");\nconsole.log(responseJSON);\n}\n});\n}\nNone of our files were uploaded fully.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/394.\n. I'm not very familiar with node myself.  The client side code is pretty\nsimple.  In your case (using chrome) the user agent simply sends a post\nrequest with the streamed contents of the file.  The content-length header\nfield is filled in by the user agent.  When the request first comes in,\ndoes the content-length value match the expected file size? The problem is\neither in your server side code, or perhaps a proxy is messing with the\nrequest.  Just looking briefly at your code, i see some things that are\nobviously wrong, or at least not advisable, such as setting the response\ntype to 404 if there is a problem processing the request, but that\nparticular choice is not the cause of your problem.\n\n\nI realize you are using one of the example scripts, which i did not write,\nnor can i maintain.  I am seriously considering removing some of the\nexamples as I've noticed that many of them are either poorly written, or\njust plain wrong, and i don't want to spend time learning all of the\nvarious server side languages to maintain these since it takes time away\nfrom maintaining and evolving the actual Javascript app.  You may want to\neither email the author of the example, and/or read up on how to handle xhr\npost requests and multipart form requests in node.  Stackoverflow may be a\ngood resource.\nOn Oct 5, 2012 7:34 PM, \"IronTurtle\" notifications@github.com wrote:\n\nWe used your latest code for a same run. I believe this is all the code we\nused for our server-side for file uploader:\n// Settings\nvar settings = {\nnode_port: process.argv[2] || 3000,\nuploadpath: __dirname + '/images/profile-pics/'\n};\napp.post('/upload', function(req, res) {\nuploadFile(req, settings.uploadpath, function(data) {\n    if(data.success){\n        res.send(JSON.stringify(data), {'Content-Type': 'text/plain'}, 200);\n}\nelse\n    res.send(JSON.stringify(data), {'Content-Type': 'text/plain'}, 404);\n});\n});\n// Mainfunction to recieve and process the file upload data asynchronously\nvar uploadFile = function(req, targetdir, callback) {\n// Moves the uploaded file from temp directory to it's destination\n// and calls the callback with the JSON-data that could be returned.\nvar moveToDestination = function(sourcefile, targetfile) {\n    moveFile(sourcefile, targetfile, function(err) {\n        if(!err)\n            callback({success: true});\n        else\n            callback({success: false, error: err});\n    });\n};\n// Direct async xhr stream data upload, yeah baby.\nif(req.xhr) {\n    var fname = req.header('x-file-name')/req.user.username + \".jpg\"/;\n```\n// Be sure you can write to '/tmp/'\nvar tmpfile = '/tmp/'+uuid.v1();\n// Open a temporary writestream\nvar ws = fs.createWriteStream(tmpfile);\nws.on('error', function(err) {\n    console.log(\"uploadFile() - req.xhr - could not open writestream.\");\n    callback({success: false, error: \"Sorry, could not open writestream.\"});\n});\nws.on('close', function(err) {\n    moveToDestination(tmpfile, targetdir+fname);\n});\n// Writing filedata into writestream\nreq.on('data', function(data) {\n    ws.write(data);\n});\nreq.on('end', function() {\n    ws.end();\n});\n```\n}\n// Old form-based upload\nelse {\n    moveToDestination(req.files.qqfile.path, targetdir+req.files.qqfile.name);\n}\n};\n// Moves a file asynchronously over partition borders\nvar moveFile = function(source, dest, callback) {\nvar is = fs.createReadStream(source)\nis.on('error', function(err) {\n    console.log('moveFile() - Could not open readstream.');\n    callback('Sorry, could not open readstream.')\n});\nis.on('end', function() {\n    fs.unlinkSync(source);\n    callback();\n});\nvar os = fs.createWriteStream(dest);\nos.on('error', function(err) {\n    console.log('moveFile() - Could not open writestream.');\n    callback('Sorry, could not open writestream.');\n});\nis.pipe(os);\n};\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/394#issuecomment-9193601.\n. Any update?  Have you located a showstopper issue in the node example, or is there some other issue on your end?\n. Please re-open if you have new info.\n. I'm hoping we can make use of twitter bootstrap to make a re-design a bit easier, even for us non-graphic designers.  When I was researching unit testing frameworks for the core javascript, I noticed QUnit's home page.  I'd like to turn fineuploader.com into something like that.  Perhaps there can be a link to a page with more (and more detailed) examples on the fineuploader index page, assuming the index page just has one trivial example w/ code.  I guess I'd like to abstract some key stuff from the readme and prominently display it on fineuploader.com.  Currently, users have to visit the github readme to get to most places and get most important info.  I'm assuming that fineuploader.com will be the entry point for many users, and I'd like to not only make it nice looking, but useful for those who have no interest in navigating to the github project page.\n. @tellibus Any help is appreciated.  See my note above.  If you aren't familiar with TB, you may want to take a peek at their demo/docs.\n. Also, the demo would still, ideally, work in the gh-pages branch using\n\"Github Pages\".  There are some limitations to this approach though, such\nas the lack of support for POST requests, which is why I introduced the\nundocumented demoMode option.\n\nOn Tue, Oct 9, 2012 at 12:26 PM, tellibus notifications@github.com wrote:\n\nI'm not sure I'm more skilled in graphic design, but I'd like to help.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/395#issuecomment-9270454.\n. Have a look at the head element in index.html.  I'm pulling it (the css\nfile) in via a cdn.  You can either do that or download it and reference it\nlocally.\nOn Oct 12, 2012 4:51 AM, \"tellibus\" notifications@github.com wrote:\nI'm nearly setup with the design (very basic TB actually). I'm looking at\nthe gh-pages branch and I don't see boostrap there. Should I include it in\nthe PR?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/395#issuecomment-9371501.\n. Wow!  It looks really nice.  Certainly much better than the awful demo page\nI made.\n\nMy concern is that is looks very similar to the Twitter Bootstrap library's\nhomepage.  I'm not sure if that is a valid concern or not.  Probably not.\n What are your thoughts?\nThis looks like a starting page for the Fine Uploader library.  We would\nstill need a styled page to hold some demo code and live examples.\n Something to replace the current awful-looking demo page at\nhttp://fineuploader.com.  Ideally we would have most if not all of the\nexisting demos on that page, but the code would be styled and visible on\nthe actual page as well.  I assume the main page would link to the demo\npage, and the styling would be consistent.\nI really appreciate your effort on this.\nThoughts?\nOn Fri, Oct 12, 2012 at 7:17 AM, tellibus notifications@github.com wrote:\n\nOk, it's still WIP but you can see what it can be at\nhttps://github.com/tellibus/file-uploader/blob/site-demo(gh-pages)/\n(no js included for the moment)\nSince it seems impossible to preview on gh: you can see it here:\nhttp://tellibus.com/fineuploader/\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/395#issuecomment-9374627.\n. Agreed.  You can make use of the code tags, which TB styles for you.\n\nOn Fri, Oct 12, 2012 at 9:21 AM, tellibus notifications@github.com wrote:\n\nI should also include the most simplest demo on the index page. And for\neach demo, provide the underlying js code.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/395#issuecomment-9378078.\n. Cool.  Thanks for the update and thanks for your work on this.  I'm may\nping the TB people to make sure they are ok with us lifting the design of\ntheir homepage.  I don't want to piss anyone off.\n\nOn Fri, Oct 12, 2012 at 9:13 AM, tellibus notifications@github.com wrote:\n\nFor the looks, normal. It's using the standard Css classes with really\nminor changes.\nFor the demos, yes it's in progress. I plan to have two separate pages for\nFUB and FU as you can see from the menu.\nWill keep you updated.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/395#issuecomment-9377836.\n. @xpleria 2.2 development starts today (since I just finished releasing 2.1).  I'm going to determine a release date for 2.2 shortly and update the master readme with the date.  \n\nNote that the 2.2 release will likely be a small one, but the 3.0 release (which will likely be the next release after 2.2) has been in progress for a while now.  Lots of big stuff planned for 3.0.  If you are interested in looking at the 3.0 progress, have a peek at the 3.0 branch.  There is a 3.0 milestone issue tracker that also lists all planned features for 3.0.  A couple features (in the closed tab) have already been completed.  Once on the issue tracker page, if you examine the milestone drop-down on the left of the page, you'll see that I have features planned out for 3.1, 3.2, and 3.3 as well.\n. @xpleria We will continue this discussion offline via email.  Currently, the demo page re-design is in-progress.  A contributor, @tellibus, is working on it as we speak.  He has produced an \"intro\" page and is working on a demo page.  You can see examples in the case I referenced earlier.\n. @tellibus Can you email me?  I'd like you and @xpleria to coordinate on the web page redeisgn since you both have offered to help.  I'll share xpleria's email address once you message me.  Two heads are better than one!  \nThanks.\n. We can continue here, or via email.  xpleria asked me to ask you to email him, so I obliged.  \n@xpleria Can the two of you discuss further in this thread?  The benefit of doing this is that it provides some transparency and allows others to jump in with suggestions/questions as well.\n. I'll take a peek and put together some comments/suggestions/request either tonight or tomorrow.  As always, thanks for helping out!\n. @tellibus I really like it.  It looks quite nice!  There are a few modifications I'd like to make though, such as providing a link to releases page, a link to the master readme, and perhaps a heavily abridged version of the master readme.  Also, more demos will need to be added, but that shouldn't be too hard.  \nI like the idea of one long page with \"sections\" and I think the additional demos should be placed on the same page.  Perhaps everything can be easily reached using the affix component as well. \n. I would agree - I don't think it is absolutely necessary to provide a FUB demo, but perhaps we should since I'm not sure how else we can refer to FUB (and I don't want to leave it out of the home/demo page).\nI would keep the one bootstrap demo, but the rest should be \"barebones\" in my humble opinion (for the reason you mentioned).  \nLet's not use affix then.  I like the nav bar at the top of the demo page you linked to.  We don't need tons of demos, but there should be a handful, covering different use cases.  I do think that we should leave out demos that manipulate the classes, option and possibly the template option as well.  Pre-3.x versions require you re-define all sub-options, even if you only want to modify one.  This is an especially big headache if you only want to only override one of the classes sub-options.  I've addressed this in 3.0, where you can simply define the classes (or any other sub-options you want to override) you want to change, and leave out the ones you don't.  Also, overriding classes is a pretty straightforward concept, and templates are for more advanced users. \nOnce 3.0 is released, I'll need to add at least one section to the site about use of the new jQuery plug-in. \n. Starting my morning commute.  I'll take a peek and reply to your comments\nI'm the next hour or two.\nOn Oct 17, 2012 7:18 AM, \"tellibus\" notifications@github.com wrote:\n\nFUB demo done (bootstrapped this time). I think I should PR now, what do\nyou think @rnicholus https://github.com/rnicholus?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/395#issuecomment-9525060.\n. @tellibus Very nice indeed.  I really appreciate your work on this.  You certainly have put in a lot of time.  \n\nThere are a couple nitpicky things, and the abridged readme (both things I can address). The one thing I'd like added is a link to the releases wiki page.  I really do want to encourage people to use the snapshot/work-in-progress branch, but in case there is a blocking defect, or if they are not comfortable using a snapshot version, I want them to be able to easily find released versions.  The link to the releases page should be understated (not prominent).\n. Yep, I did miss it.  Excellent.  Guess it's time for a PR!\n. New home/demo page(s) are in place.  Sweet!\nI'll keep this open for a couple more days in case anyone wants to see any adjustments or additions.\n. A quick TODO list for me:\n- screencast so users can see progress bars (that don't appear in the demo since the uploads are instant due to the dummy endpoint).\n- 3.0 update (as 3.0 work progresses)\n- perhaps some more details from the readme?\n- override showMessage in FUB demo (and possibly others as well) to use something like TB alerts instead of the default window.alert function.\n. Can elaborate on your assertion that the photo is being \"cached\"?  What\nhave you observed that leads you to believe this?\nI have yet to do any IOS6 testing.  Since I don't have an iPhone 5, I'll\nneed to upgrade xcode on my mac and test using the iphone simulator.  Can\nyou please file an issue and respond to my questions above in the issue so\nwe can track this further?\nOn Mon, Oct 8, 2012 at 4:22 PM, naamakat notifications@github.com wrote:\n\nWe're using the file-uploader and it works really great on all platforms,\nexcept ios6.\nWhile trying to upload images on iPhone (Safari ios6), I can upload photo\nonly once, but after that the photo is being cached and I can't upload any\nother photos unless I clear all cookies+data. Why is that happening?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/396.\n. Oops, I guess you did file an issue.  I sometimes get confused between emails coming from the mailing list and emails coming from the github project.\n. I was able to reproduce this.  It looks like Safari in IOS 6 caches the result of ajax calls in some cases.  No idea why Apple thought this was a reasonable behavior.  \n\nAnyway, it looks like I can turn off this insane caching by adding a \"Cache-Control\" header with a value of \"no-cache\".\n. Should be fixed in the 2.1 snapshot (master) branch.  Please re-open if this does not address the issue, but I was able to upload files in the ios6 simulator.\n. I'm going to go ahead and close this as I'm not sure this is really needed anymore.\n. This seems like a low-risk fix, so I don't plan on holding up the 2.1 release.\n. Please see the debugging section in the readme, follow the instructions, then report back.\n. Also, I see nothing in your PHP file that suggests you are handling any kind of response whatsoever.  Please show your complete server-side code.\n. Since you've enabled debug mode, what log messages do you see in your javascript console?\n. What browser are you using?\n. The problem is either in your server-side code, our your action path is incorrect.  Your server is returning a 500 response.\n. Now I'm seeing this:\n[uploader] xhr - server response received fileuploader.js:1201\n[uploader] responseText = {'error':'increase post_max_size and upload_max_filesize to 20M'} fileuploader.js:1201\n[uploader] 'error' is not a valid property on the server response. fileuploader.js:333\nThe response text indicates that there is an error server-side, but you are also not formatting your response correctly.  Please see the documentation that explains proper JSON response format.\n. I'm not exactly sure what die does with the text passed to it.  Apparently, using this does not output a proper JSON response.  Your underlying problem is not the response though.  It is the message contained in the error that you should pay attention to.\n. @walterdavis Can you tell me why die is not returning proper JSON, while the array function apparently is?  I'm not very familiar with PHP.\n. @xpleria What needs to be clarified?  The documentation for all callbacks, including onError is described here.\n. @xpleria Ah ok, well, that is an issue that should be adressed in the PHP example I guess.  All responses should be valid JSON.\nRegarding your onError question, I'm not sure what you are asking, specifically.  Simply write whatever code you desire in your onError callback function, and it will be executed whenever an upload error is detected.\n. Using your above code, you would want to do this instead:\nvar uploader = new qq.FileUploader({\n            element: document.getElementById('file-uploader'),\n            multiple: true,\n            action: 'ajax.php',\n            debug: true,\n            onComplete: function(id, filename, responseJson) {\n               /* do something here */\n            }\n            });\n. Also, there are examples on the demo site at http://fineuploader.com.  Near the bottom of the page, you'll see a link to example the example code.  \nThe demo page is a bit ugly (I'm really not a graphic designer, at all), but it is currently being re-designed by@tellibus.\n. @xpleria I completely agree.  The code should be displayed near each example.  The current demo page is, admittedly, very utilitarian and basic.  The re-designed demo page, when it is finished, will do a better job of displaying example code near each example.  \nPlease have a look at the demo page redesign case - #395, if you are interested.  It is scheduled for the next release (2.2). \n. It would be tough for me to look into this further as I am not setup to test using PHP.  My primary server-side language is Java, and I don't plan on spending too much of my scarce Fine Uploader time on the server-side.  \nThe recommended content-type for response is text/plain.  Fine Uploader should handle those response just fine, assuming the response is valid JSON.  text/html is also somewhat acceptable, but if you are using IE and your JSON response happens to contain some HTML, you will run into problems.\n. And how does fine uploader fit into this equation exactly?\nOn Oct 15, 2012 2:18 AM, \"sdeshmukh1983\" notifications@github.com wrote:\n\n1 down vote favorite\nI have an extjs form. When I submit that form, I get empty $_POST value.\nI am also getting empty php://input value.\nThese tweaks have made no difference:\nincreasing post_max_size to 16M\nadding nokeepalive to htaccess\nsetting content-type in code (if not set)\nSometimes form gets posted successfully,sometimes not.\nMy form is like this:\nvar form = new Ext.FormPanel({});\non 'click': { fn: function(evt, btn){ submitForm(form); } }\ni have submitForm() where i am doing some stuff bfore submitting form like\nadd some hidden variables value etc, and inside submitForm() i have written\nform.getForm().submit({})\nPlease help....\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/401.\n. Are you posting in the correct github project?  Your post references some extjs code, and a form, but no mention of the actual uploader at all, not even sample code you are using to create the uploader.  \n\nI'm not sure why your form has anything to do with the uploader.  Fine Uploader is not a form element.\n. The code, as is, works fine for me outside of ie.  You'll need to provide\nspecifics surrounding your issue.\nOn Oct 15, 2012 6:55 AM, \"edmundjohnson\" notifications@github.com wrote:\n\nVersion 2.1: In fileuploader.js, function _controlFailureTextDisplay\nthe following line:\nthis._find(item, 'failText').innerText = shortFailureReason ||\nfailureReason;\nneeds to be:\nqq.setText(this._find(item, 'failText'), shortFailureReason ||\nfailureReason);\nso that .textContent is set as well as .innerText\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/402.\n. Ah, I'm guessing you are using Firefox.  I usually use Chrome, where this works fine.  It does not work fine, apparently, in FF though.  \n\nGood catch!\n. I'll probably fix this and release a 2.1.1 version.\n. Should be fixed in the 2.1.1 release (today) and in master and the 3.0 WIP branch.\n. You cannot change this option after creation of the uploader instance.  Can you provide a use-case?\n. It's not clear if you simply want to pass different parameters for each\nfile, or if you need a completely different endpoint for each file.  If the\nformer is true, you can control this via the setParams function.  Please\nadvise.\nOn Nov 15, 2012 4:28 AM, \"Jonas Olmstead\" notifications@github.com wrote:\n\nI am using a rest API that defines the target location in the url string\nlike destination/action/object\nFor example: /api/v1/folder1/upload/file?name=myname\nTo use this file-uploader I would need to destroy it and recreate it each\ntime the user selects a different folder unless I am not understanding\nsomething.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/403#issuecomment-10403954.\n. You will need to create a new uploader instance for each endpoint.\nOn Nov 15, 2012 6:57 AM, \"Jonas Olmstead\" notifications@github.com wrote:\nI need a completely different endpoint for each file. So for instance if I\nwant to upload one file to \"folder1\" and one file to \"folder2\" the two API\ncalls would be:\nhttp://myco.com/api/v1/folder1/upload/file?qqfile=filename1\nhttp://myco.com/api/v1/folder2/upload/file?qqfile=filename2\nApparently this is becoming more common in REST-style APIs to use dynamic\nURLS and filter them on the server side. Query parameters are used for more\nspecific information.\nSo, the ability to change the \"action\" parameter of the uploader after\ninitialization is pretty important for my case.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/403#issuecomment-10407620.\n. Allowing the ability to alter the endpoint of an uploader instance would add complexity to the code.  Please provide a detailed account of your workflow along with reasons why it is not reasonable to simply create a new uploader instance.\n. It is certainly possible to modify the uploader to allow the user to\nspecify a new endpoint, perhaps by adding a setAction (or setEndpoint for\n3.0) function.  That would add some complexity to the uploader, and it's\nnot clear to me why simply specifying the folder in the query string is a\nless effective approach.  The simplest solution here ostensibly is to use a\nparameter to pass the folder name.\n\nOn Thu, Nov 15, 2012 at 7:32 AM, Jonas Olmstead notifications@github.comwrote:\n\nSure okay. My UI includes of a tree structure of folders. When a user\nselects a folder, information about that folder is displayed along with\nthis excellent uploader. Using the uploader results in files uploaded to\nthe selected folder through a REST API.\nCurrently I need to destroy and recreate the uploader each time a folder\nis selected:\n$('#fileUploader').empty();\nmyUploader = new qq.FileUploader({element:\ndocument.getElementById('fileUploader')...\nThis is an administrative application and so the UI is quite long-lived.\nThe above code could potentially be run 100s or even 1000s of times without\nrefreshing the window. I am unsure what the memory implications of this are.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/403#issuecomment-10408479.\n. @sp-niemand Please see the setEndpoint API function in the API documentation along with the case where this function was added, #509.\n. This case would only involve changes to FU.  Users of FUB should be able to come up with their own UI using the exact algorithm you've specified.  \n\nFirst I'm looking to include some sort of a status message next to the file.  For, example, if the file has finished uploading, but we are still waiting for a reply from the server, a specially formatted \"Processing...\" message would appear next to the file.  Second, when this happens, the progress bar that comes standard with FU would turn into, perhaps, a barber pole... \n.  \nThere are other cases that would benefit from a mechanism to display temporary status information next to a file in FU, such as the auto/manual failed upload retry feature.  In that case, during a retry, we would want to display \"Retrying 2/3\" next to the file, for example.\n. Simply added common status message element to the FU template that, in this case, by default, says \"Processing...\" next to the file (with the spinner remaining and the progress bar hidden) when we have sent the last byte but are still waiting for a server response.  \nI also created what I'm calling a qQuery function in the utils section of the code.  See the documentation for more details.\nPlenty of refactoring in this case, with matching QUnit tests.\n. I noticed that Firefox doesn't fire its last progress event until it receives the response from the server, which is a bit of a bummer.  There is a Firefox issue filed to track this \"issue\".  \nIt sounds like Firefox might actually be following the letter of the XHR V2 spec, while Chrome is adhering to the \"spirit\" of the spec.  Chrome's implementation, which results in the last progress event fired after the last byte has been \"sent\" is what most may expect, but this may just be a violation of the spec.  Not sure what IE10 does yet as I haven't looked into that yet.  A FF developer has opened a thread on w3.org, asking for some clarification.  \nA Chromium dev believes the \"expected\" behavior is actually a webkit detail, and not specific to Chrome.  This suggests that Safari and Chrome exhibit the same behavior, which I have verified.  It sounds like there is a push to adjust the spec to allow webkit's behavior to be the expected behavior (according to the letter of the spec).\nNote that I am not using the \"loadend\" event to determine when the browser has finished sending the last byte.  I'm simply comparing the \"loaded\" value with the \"total\" value when handling \"progress\" event notifications.  If these two values are equal, I'm declaring the file \"completely sent\".  According to the spec, I should be able to do this (I think) since the \"loadend\" event is simply fired after the last \"progress\" event.  See the spec regarding the ProgressEvent for more details.\n. I'm sorry, but I don't provide any server-side examples, other than the java example.  The other examples are provided by contributors other than myself.  If the response text is empty, you are not returning a proper JSON response.  If you are not seeing any response log message at all, and the debug option is set to true (and you are not using IE), then your endpoint (action option) is not correct.\n. Yes, you are not returning the correct response in your server code.  have\na look at the readme\nOn Oct 17, 2012 4:11 AM, \"GitOffice\" notifications@github.com wrote:\n\nWhen I set debug=true ,I found something as below in firebug console. \"\n[uploader] xhr - server response received [uploader] responseText = \" ,and\npost option is the content uploaded file in firebug console\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/405#issuecomment-9520701.\n. What is the exact custom header name and value you want to pass along with the upload request?\n. ?\n. I'll take a closer look for you in 4 or 5 hours.\n. If you are having a problem with a library that crops your images, I won't\nbe able to help with that.\n\nLooking quickly at your code, you are making calls to at least one\n\"private\" property (_filesInProgress).  Properties that start with an\nunderscore are, by convention, private.  You should be using the\ngetInProgress function instead.\nI realize that simply using a convention to \"enforce\" property access is\nnot the best approach, but it will be a big task indeed to modify the code\nto prevent access to private properties.\nOn Wed, Oct 17, 2012 at 4:19 PM, andrewvmail notifications@github.comwrote:\n\nCrazy that was fast reply. Cheers.\nOn Wed, Oct 17, 2012 at 2:16 PM, Ray Nicholus notifications@github.comwrote:\n\nI'll take a closer look for you in 4 or 5 hours.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/407#issuecomment-9544283>.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/407#issuecomment-9544384.\n. Thanks for your work.  I will merge this later this evening (CST)\n. Awesome job.  I just made a few small changes and moved the navbar and footer into common html files.  I'll probably make more small changes and additions over time.  \n\nI'll need to modify and add to the demos when 3.0 is ready to be released.  3.0 will have some breaking changes and new big features.  3.1, 3.2, and 3.3 are scheduled to have some cool new features as well.  Perhaps I'll start building the 3.0 version of the demo page shortly, and not link to it until 3.0 has been released.  You are, of course, more than welcome to take this on as well, but you've been a big help so far, so no need to worry about it if your plate is full.\n. Don't mind that last commit - i used the wrong case number in the commit message\n. Doh!  Should have read that before I made my last change.  One moment.\n. There we go.  I had to ensure your scrollspy code was not simply placed \"after\" my include js code, but rather in the callback of my GET request (after adding the navbar to the DOM).  I didn't notice the scrollspy issue last night.  Guess it was late.\nAs far as the \"active\" class on the menu item is concerned, I removed that.  Sure, we can make that work again with a little javascript, but I'm not sure how useful this is with a 2-item sub-menu anyway.    When using GH Pages, everything must be client-side.  There is no way to add server-side code.  \nAs far as the common HTML files I created: Code duplication is always a bad thing.  It is easy to copy and paste initially, but maintenance becomes a headache when you have to always remember to make the same change in 3 different files.  I think anything we can do to make it easy to maintain this code would be good.  I'm likely going to move the javascript into separate files as well to remove some of the clutter from the HTML files.\n. Yep, the onready is not needed.  No harm, but I'll probably remove it\n(if I remember later).  Thanks again for your contribution here.  It's\nalways nice to see people who say they will help out, and then actually\ndo help out.\nOn Thu, Oct 18, 2012 at 8:52 AM, tellibus notifications@github.com wrote:\n\nYes I noticed the callback as I checked your commit, not sure the\n$(document).ready() is necessary inside the callback though?\nFor DRY, I agree. I just guessed no PHP on gh-pages, and I've never\nthought about the includes via Ajax like you did.\nFeel free to re-organize! It's just a canvas after all.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/408#issuecomment-9565015.\n. Seems reasonable, but I'll think about this some more before merging.  \n\nAlso, please split this into two lines.  A loop contained entirely on one line is impossible to debug using breakpoints.\nSo, it should read:\njavascript\nwhile(item.qqFileId == undefined) { \n    item = target = target.parentNode; \n}\n. Seems reasonable to me.  Thanks for your contribution!\n. also merged into 3.0 branch\n. It looks like the user/developer would have to contribute a modified fileTemplate in order for this to work, since the {fileId} string that this addition depends on is not part of the default fileTemplate option.  This is, unfortunately, not very intuitive.  I could see, perhaps modifying the default fileTemplate option to include a place for the fileId.  However, I'm not sure how useful this is.  File ids can be easily obtains via the callbacks.  What is the use case here?\n. Also, something strange happened when you made your modifications.  Github shows 3277 changes.\n. Brandon - you are not the first to request that I make it easier for developers to allow users to delete previously uploaded files.  This feature is scheduled to 3.1.  Have a look at case #382.\n. ...feel free to add comments to the case I referenced.  I'm currently trying to avoid adding any unscheduled and non-vital features until 3.0 is released, since I have to hand-merge all changes from the 2.x branches into 3.0 due to the significant changes that I have made to the 3.0 code structure.\n. Fine Uploader does not resize images for you.\n. This is, as far as I know, just the way IOS6 works.  As you stated, if you want access to the camera, set the multiple attribute to false.\n. See #389 also.\n. Can explain what you mean by \"breaks this feature\"?  The acceptFiles option expects a comma delimited string of MIME types AND/OR \"audio/\", \"video/\", or \"image/*\".  These values are then simply passed along to the input element via the accept attribute.  Note that IE, Safari, and Opera do not support this attribute, so Chrome and Firefox are the only browsers that can make use of this.  If you are seeing issues in these browsers, then this is an issue with the browser.\n. If you want to essentially write your own UI, you should be using FileUploaderBasic, not FileUploader.\n. FUB includes no UI elements.  It is meant for those who wish to create\ntheir own ui.\nOn Oct 22, 2012 7:45 PM, \"CodeBuddy\" notifications@github.com wrote:\n\nGreat,\ndoes FileUploaderBasic have drag and drop methods too?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/415#issuecomment-9686268.\n. This isn't something i plan on doing.  If be happy to look at a pull\nrequest though.\nOn Oct 22, 2012 1:36 AM, \"johanosventer\" notifications@github.com wrote:\nimprovement. Would be nice to get updates from nuget.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/416.\n. ...or perhaps a pull request isn't needed? You're going to have to provide\nspecifics since i have no experience with nuget nor do i understand how\nthis can be added to nuget.\nOn Oct 22, 2012 3:04 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nThis isn't something i plan on doing.  If be happy to look at a pull\nrequest though.\nOn Oct 22, 2012 1:36 AM, \"johanosventer\" notifications@github.com wrote:\n\nimprovement. Would be nice to get updates from nuget.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/416.\n. It looks like simply contributing to the nuget repo requires a windows machine.  My main machine is a mac and I plan on using a unix-based CI server in the near future as well.  I can understand how this may be helpful to you, but I don't plan on adding this to the schedule.  Sorry.\n. That would be helpful, thanks!\n\n\nOn Tue, Jun 17, 2014 at 10:38 AM, Chris Hynes notifications@github.com\nwrote:\n\nLooks like you can run nuget on Mac/Linux via Mono:\nhttp://blog.lextudio.com/2013/01/how-to-use-nuget-on-mono-part-i/\nNuget is huge for the .NET crowd. If you're interested, I can send over\nsome build scripts I use for generating and uploading packages on other\nprojects.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/416#issuecomment-46324306.\n. discussion will take place in the PR\n. I'm assuming by \"data\" you mean the query string.  I'll have to look at your changes a bit more closely as this code has existed as-is for quite a long time as far as I can tell.  Can you provide an actual example, complete with your client-side code that produces a problematic URL, and then describe why this URL presents a problem?\n. Sigh.  I should have read #417 a bit closer.  Yep, you do appear to be correct.  No pluses in the path allowed, it appears.  I'll look over your PR a bit closer tonight and, if all looks good, I'll merge it in for 2.2.  Thanks for the PR and associated issue.\n. Guess I should have created a QUnit test for this.  I'll make sure one is added to 3.0 after I merge this in.\n. Carry-over from #395.  Also consider creating a screencast.\n. You can check out all of the planned and completed features for 3.0 in the\nissue tracker.  i have defined 3.0, 3.1, 3.2, & 3.3 milestones and dropped\nplanned features into each.  However, i haven't set a release date for any\nof these milestones yet.  i generally only determine a release date for the\ncurrent milestone.  2.2 (which will likely be changed to 2.1.2 due to the\nminor changes involved) will be the last planned 2.x release.  3.0 will be\nthe next planned release after 2.2/2.1.2.\nOn Oct 23, 2012 3:22 AM, \"tellibus\" notifications@github.com wrote:\nRay, except for the screencast, you can count me in if you want me to\ndelegate some / all of the tasks.\nBtw, when is 3.0 expected? I haven't seen the milestone for it.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/419#issuecomment-9694084.\n. Thanks for offering your help.  I'll spend some more time detailing\nspecific demo changes required for 3.0.\nOn Oct 23, 2012 6:50 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nYou can check out all of the planned and completed features for 3.0 in the\nissue tracker.  i have defined 3.0, 3.1, 3.2, & 3.3 milestones and dropped\nplanned features into each.  However, i haven't set a release date for any\nof these milestones yet.  i generally only determine a release date for the\ncurrent milestone.  2.2 (which will likely be changed to 2.1.2 due to the\nminor changes involved) will be the last planned 2.x release.  3.0 will be\nthe next planned release after 2.2/2.1.2.\nOn Oct 23, 2012 3:22 AM, \"tellibus\" notifications@github.com wrote:\n\nRay, except for the screencast, you can count me in if you want me to\ndelegate some / all of the tasks.\nBtw, when is 3.0 expected? I haven't seen the milestone for it.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/419#issuecomment-9694084.\n. Actually, I would also like to move all of the content in the readme to the homepage in 3.0.  The readme is kind of ugly and hard to follow.  I think we could make it look a lot better if we had more than markdown to work with.  I'm not sure exactly what I would like it to look like, yet, but the documentation page for raphael was a bit of an inspiration.  The tricky part may be properly documenting (without confusing users) \"sub-options\" such as those that belong to the classes and request options (among others).\n. Here's what I'm hoping to accomplish with the demo page for 3.0:\n- modify example/demo code to reflect all changes in 3.0\n- add jQuery plug-in example\n- create screencast\n- convert most if not all the markdown readme to HTML (on the gh-pages site)\n. @tellibus Any chance you'll be able to tackle some of these items?\n. @tellibus sounds good to me.  Thanks for helping out again.\n. @tellibus We should create a branch based on gh-pages and do all 3.0 work there.  I don't want to merge 3.0 changes with gh-pages until the release date for 3.0.  I'll create a gh-pages-3.0 branch that we can both work in tonight.\n. ...I'd also like to have an HTML5 logo prominently displayed on the demo/home page, now that I think of it.  We are making use of HTML5 (where supported).\n. I'll go ahead and mark this \"in progress\".\n. :thumbsup:\n. The source tree will not contain the combined js files, but the zipped\nreleases will always contain combined files.  If you want to combine files\nin a snapshot branch, such as this one, you make use of the handy gradle\nscript included in the 3.0 branch.  This script will allow you to easily\ncreate your own combined and/or minified and/or gzipped javascript files\nyourself.  Have a look at this\nsection of\nthe 3.0 readme for details: https://github.com/valums/file-uploader/tree/3.0#building-and-using-the-snapshot-version\n\n\nOn Wed, Nov 7, 2012 at 11:09 AM, tellibus notifications@github.com wrote:\n\nI may have missed the answer to this question, but do you plan to combine\nall the js in one file? I can't find a combined file on the 3.0 branch, so\nI'm combining them for the sake of the demo.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/419#issuecomment-10156247.\n. Wow, looking nice!\n\nOne thing, though.  I don't actually want to provide a link to the 2.x\nbranches/releases or provide 2.x demos or even mention 2.x.  3.x will\nreplace 2.x.  If users have issues with 3.x, I'd like to deal with them in\nthe forums and get those issues ironed out.  3.0 will not be the complete\nre-write that I originally planned.  It is the start of a lot of new big\nfeatures, such as the jQuery plug-in wrapper, auto& manual failed upload\nretry, etc, and re-organization of options along with a lot of code\nrefactoring, but I don't anticipate the need to highlight the existence of\nthe 2.x code.  Once 3.0 is released, that will be the new path for Fine\nUploader.\nOn Wed, Nov 7, 2012 at 2:30 PM, tellibus notifications@github.com wrote:\n\nWork in progress: http://tellibus.com/fineuploader/ that's all for\ntoday...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/419#issuecomment-10163759.\n. Excellent work, as always.\n\nOn Thu, Nov 8, 2012 at 11:42 AM, tellibus notifications@github.com wrote:\n\nStill WIP. Will continue and hopefully finish tomorrow.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/419#issuecomment-10197365.\n. Looking good.  I especially like the logo.\nOn Nov 9, 2012 6:16 AM, \"tellibus\" notifications@github.com wrote:\nStill WIP. Finished homepage and Fine Uploader demo page. Todo: jQuery\nwrapper (will simply convert FU page), and FUB demos (adapt to 3.0).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/419#issuecomment-10224374.\n. Cool!  I'll take a peek and probably make any necessary adjustments.\n Thanks again!\n\nOn Fri, Nov 9, 2012 at 10:52 AM, tellibus notifications@github.com wrote:\n\nDone with PR valums/file-uploader#459https://github.com/valums/file-uploader/issues/459\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/419#issuecomment-10236132.\n. I made a few adjustments to the 3.0 demo page code:\n\nAdded docs link\nAfter some thought, I decided that it made sense to prominently display a link directly to the readme.  This will suffice until I move the API documentation into the homepage.  That may happen this release, may not.  I'll create a new story for that.\nAll buttons now plural\nThe (formerly 2, now 3) buttons near the top of the index page are now all plural, for consistency.\nUsed raw js files (not combined)\nI removed the combined fineuploader.js file and, instead, reference each of the component js files.  This means that the demo uses the same client directory that will exist in master, and nothing more. By doing this, I can easily update the fine uploader source for the demo in a few lines:\nbash\ngit checkout master -- client;\ngit commit -a -m \"sync with master\";\ngit push origin gh-pages;\nI also removed all of the <script src= tags to the top of each page.  I just prefer to have them all in once place.\nRemoved trailing commas\nIE7 (and earlier) has an issue with trailing commas.  A big issue.  In fact, any trailing comma in the source will cause strange, hard-to-track-down issues.\nMentioned support for IE10\n3.0 now supports IE10, so I updated the text accordingly.\n. I've given the screencast and the idea of moving the documentation to the home page a lot of thought over the past couple weeks.  I've decided not to do either.  \nIt's not clear what a screencast would give users that the existing documentation does not.  The current Fine Uploader home page is really nice, and I think it does a more than sufficient job of informing potential users.  A screencast would allow me to show the progress bar in action, but I could just as easily do this with a screenshot.  Perhaps I'll include this screenshot and any other similar ones on the homepage.  \nAs far as the documentation is concerned, it certainly would look a bit nicer on the homepage, since we would be able to better style it with CSS.  However, I kind of like having the documentation versioned along with the source.  This allows users to easily peer at documentation from earlier (and in-progress) versions. \nI'll close this case, but if there is something I missed, it can certainly be re-opened.\n. Yep.  Your sever-side code is returning an error response.\nOn Oct 23, 2012 6:01 AM, \"wmds\" notifications@github.com wrote:\n\n[uploader] iframe loaded\n[uploader] converting iframe's innerHTML to JSON\n[uploader] innerHTML = {\"error\":\"An error has occured\"}\nObject {error=\"An error has occured\"}\nusing 2.2 version\nany idea?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/420.\n. Thanks!\n. I'm not able to assit with any Coldfusion issues.  Perhaps some other Fine Uploader user who also uses CF will be able to offer some insight.\n. You may have more luck in the support forums.  I'm closing this as it does not appear to be a Fine Uploader specific issue.\n. Thanks much for removing the copied fileupload.js and .css files.  Having copies of these in the server directory was not a great idea to begin with as this is not updated when the associated .js and .css files in the root of the repo are changed.\n. Hi there.  Thanks for this, but I am currently not merging in any changes to the PHP example until case #347 is addressed.  If you would like to include that fix in your PR, that would be awesome.\n. My point in the referenced case is that determining the type of request based on an item in the query string is not sound logic.  Have a look at this post.\n. This logic currently works, but will fail if the inputName option is\nchanged.  The correct way to\ndistinguish between an xhr and a multipart request is to look at the\ncontent-type header.\nOn Oct 25, 2012 5:05 AM, \"Johannes Weberhofer\" notifications@github.com\nwrote:\nCurrently the system guesses to receive an async upload when the\n$_GET['qqfile'] is set. But this variable is also set when a form upload\nhappens. So the script starts falsely to handle a async upload instead of\nan file-upload.\nThe working solution is to determine whether the $_FILES['qqfile'] file\nupload variable is set - this one is never set in a async upload, the\ndetection which upload should be handled is correct.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/424#issuecomment-9772160.\n. I hope it's obvious at this point why it is ill-advised to determine the\nencoding type of the request by looking at the query string.  This is why\nthe content-type header exists.\nOn Oct 25, 2012 6:35 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nThis logic currently works, but will fail if the inputName option is\nchanged or if the uploader ifs modified to send parameters in the request\nbody (a likely optional behavior in the future).  The correct way to\ndistinguish between an xhr and a multipart request is to look at the\ncontent-type header.\nOn Oct 25, 2012 5:05 AM, \"Johannes Weberhofer\" notifications@github.com\nwrote:\n\nCurrently the system guesses to receive an async upload when the\n$_GET['qqfile'] is set. But this variable is also set when a form upload\nhappens. So the script starts falsely to handle a async upload instead of\nan file-upload.\nThe working solution is to determine whether the $_FILES['qqfile'] file\nupload variable is set - this one is never set in a async upload, the\ndetection which upload should be handled is correct.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/424#issuecomment-9772160.\n. Thanks! \n. Just tested with 16.0.1 on Mountain Lion & Win 7 SP1, no issue on either of\nthose (tested using the \"out-of-the-box demo\").  Are you seeing the issue\nwith earlier versions of FF on Ubuntu as well?\n\n\nOn Wed, Oct 24, 2012 at 8:26 PM, Mike Decker notifications@github.comwrote:\n\nI'm using Firefox 16.0.1 on Ubuntu 12.04. Dragging files onto a dropzone\nspawns an alert, \"No files to upload.\" This occurs with my own code and\nwith fineuploader.com demos. I have no problems using an up-to-date\nChrome. Is this a known issue?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/425.\n. I'm installing an Ubuntu VM now on my mac.  This is perhaps a known issue though.\n. Works with FF 14.0.1.  Struggling to get 16.0.1 installed.\n. That comment appears to be related to FF 11 though.  At any rate, I'm not having any luck upgrading FF to 16.0.1 on Ubuntu.  When I I attempt to install the .deb, the software center complains \"breaks existing package 'firefox-globalmenu'...\"\n. It seems pretty clear that there is some issue here outside of Fine Uploader.  The error message you're seeing only appears when the FileList on the DataTransfer object is empty.  This mirrors the initial post in the bug report we are both looking at.  Are you seeing any js errors?\n. Did some more reading.  Seems like this is a long-standing issue.  Maybe it will never be fixed.  If the drop event result in an empty FileList on the DT object, there is really nothing simple that can be done here.  One option would be to add an exception to your code that disables the DnD feature when running FF running on Ubuntu.  You'd have to, of course, parse the useragent string, and this would mean that Nautilus users also could not DnD.  On the plus side, you'd still have multiple file selection via the dialog, and all the other benefits of the File API would be available (assuming there aren't additional issues).\n. First, your jQuery selector is incorrect.  If you want to select a file input element given the context of an element with an ID of \"uploader-box\", your selector would be $('input[type=\"file\"]', '#uploader-box').  Second, you should not trigger the file selection dialog via javascript.  This will never work in some browsers, such as IE, which will prevent the actual upload from happening.\n. Hmm, apparently both 'input[type=file]' and 'input[type=\"file\"]' will work.  Alrighty.  Regardless, you should not trigger the file selection dialog for the reason I stated in my previous post.\n. A feature case, #384, already exists to add an aggregate progress bar.  It is scheduled for 3.1.  I will create a case (3.3) to include a cancel all button/function as well.\n. The cancel all feature is #428.\n. I'm just going to expose this as an API function.  If I get some requests to add a button to FineUploader mode, I'll do so if I get a consensus regarding placement & default styling of this button (or if I get one really good suggestion).\n. Added to 3.3-IP.\n. I do plan on adding an option to support deleting files from the uploader in a later release.  See case #382.  \n\nYour modification is reasonable and likely helpful.  You would also, of course, need to modify the default fileTemplate to include a space for the id, which would simply be an additional css class or attribute on the file list item.  Perhaps a case is in order to add these changes, and perhaps provide a public \"getFileElement\" function to FileUploader that would return the file list item given an ID.\n. Actually, now that I think of it, perhaps I could simply make the currently private _getItemByFileId function public and that would allow you to obtain the associated list item without any other changes to the code.  Note that access to functions is only tied to a convention (starts with underscore = private).  You can access any of the \"private\" functions at any time if you choose to do so.  Normally, I would not recommend doing that as it is easy to shoot yourself in the foot this way.  In this case, you can give that a shot until I make the _getItemByFileId function \"public\".\nI am toying with the idea of enforcing access to functions in case #366.\n. Glad to hear it.  I'll associate this case with a milestone so I remember\nto make it easier to obtain the associated HTMLElement in a future release.\nOn Fri, Oct 26, 2012 at 3:04 PM, Geoff Mayes notifications@github.comwrote:\n\nAwesome: _getItemByFileId worked. Thanks! Now I can upgrade to\nfile-uploader 2.1.2 and not worry about carrying my hacks forward.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/429#issuecomment-9825270.\n. Think I can fit this into 3.0.\n. This is now in 3.0.\n. Please provide some more detail about your problem, such as your client\nside code.\nOn Oct 26, 2012 8:46 PM, \"Nghia\" notifications@github.com wrote:\nI'm experiencing the exact same problem as outlined in issue #295https://github.com/valums/file-uploader/issues/295but with Fine Uploader 2.1.2\nI've set maxConnections to 1 and tried uploading more than one file. Only\nthe first file gets an onComplete, and it waits on the last file with the\nspinning icon. If I cancel the file and try to upload another, it'll show\nthe spinning icon again.\nI also get the following javascript error:\nTypeError: element is undefined\nfileuploader.js (line 185)\nif (element.querySelectorAll){\nThat error gets fired twice.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/430.\n. Also have you tested with earlier versions of fine uploader in the same\nenvironment?\nOn Oct 26, 2012 9:02 PM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nPlease provide some more detail about your problem, such as your client\nside code.\nOn Oct 26, 2012 8:46 PM, \"Nghia\" notifications@github.com wrote:\n\nI'm experiencing the exact same problem as outlined in issue #295https://github.com/valums/file-uploader/issues/295but with Fine Uploader 2.1.2\nI've set maxConnections to 1 and tried uploading more than one file. Only\nthe first file gets an onComplete, and it waits on the last file with the\nspinning icon. If I cancel the file and try to upload another, it'll show\nthe spinning icon again.\nI also get the following javascript error:\nTypeError: element is undefined\nfileuploader.js (line 185)\nif (element.querySelectorAll){\nThat error gets fired twice.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/430.\n. There are several issues with the php example.  This is one.  I'm going to merge in a temp fix.  Hopefully someone else will address the other issues I have noted in the issues section.  Thanks!\n. Looks like the php example was completely fixed in #424.\nOn Oct 28, 2012 7:05 AM, \"mbartosinski\" notifications@github.com wrote:\n\nhi,\ni think there is a logical error in example file php.php:\nin __construct of qqFileUploader class is code:\nif (isset($_GET['qqfile'])) {\n    $this->file = new qqUploadedFileXhr();\n} elseif (isset($_FILES['qqfile'])) {\n    $this->file = new qqUploadedFileForm();\n} else {\n    $this->file = false;\n}\nit's wrong, because $_GET['qqfile'] is always set.\neven if upload is via regular form... (i checked the fileuploader.js)\ni changed the code to:\nif (isset($_FILES['qqfile'])) {\n    $this->file = new qqUploadedFileForm();\n} elseif (isset($_GET['qqfile'])) {\n    $this->file = new qqUploadedFileXhr();\n} else {\n    $this->file = false;\n}\nand it works much better...\ncorrect me if i'm wrong!\nregards,\nmichael from poland :)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/431.\n. I would not recommend extending fine uploader.  Also, it is generally a bad idea to access \"private\" functions (those that begin with an underscore).  Any private function can change at any time, and these changes will not be documented.  Also, in the near future, the accessibility of these private functions may be better enforced.  \n\nThe best approach here is to count the number of times your onSubmit callback executes.  That will equal the number of stored files before uploading begins.\n. It's unlikely that the request is not being made.  You can verify with a\ntool like Charles.  The more likely scenario is that your server side code\nis not handling multipart encoded requests.\nOn Oct 30, 2012 7:04 AM, \"Peter Tellgren\" notifications@github.com wrote:\n\nI'm using the basic plugin to allow for a single file upload. Works fine\nin Chrome, FF but not in IE (8 tested as for now).\nmy implementation (coffeescript)\nhttps://gist.github.com/3979802\nMy backend is a Rails 3.2 app.\njs log in IE reports that iframe is loaded\nfile dialog shows up and I can select image.\nonSubmit is triggered as my template is loaded.\nNo request is received on server side\nafter some time I get an error message with no content.\nany suggestions?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/433.\n. What are you setting the content-type of your response to?\n. Your content-type should be \"text/plain\", especially if you are returning\nHTML in your JSON response.\n\nOn Wed, Oct 31, 2012 at 8:55 AM, Borut Toma\u017ein notifications@github.comwrote:\n\nheader('Content-type: application/json'); in php script. But it's the same\nwithout this line. Does this defaults to json?\nI tink there is no problem with json returned. It is properly formatted.\nJust the html inside json is scrambled - encoded.\n$('#'+target).append(responseJSON.html).text();\nAbove code properly formats html but is not compiled against DOM - in\nbrowser I see html code instead of new element.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/434#issuecomment-9945372.\n. You will need to set the debug option to true and include the log messages\nin this case.\n\nOn Wed, Oct 31, 2012 at 9:01 AM, Ray Nicholus ray@garstasio.com wrote:\n\nYour content-type should be \"text/plain\", especially if you are returning\nHTML in your JSON response.\nOn Wed, Oct 31, 2012 at 8:55 AM, Borut Toma\u017ein notifications@github.comwrote:\n\nheader('Content-type: application/json'); in php script. But it's the\nsame without this line. Does this defaults to json?\nI tink there is no problem with json returned. It is properly formatted.\nJust the html inside json is scrambled - encoded.\n$('#'+target).append(responseJSON.html).text();\nAbove code properly formats html but is not compiled against DOM - in\nbrowser I see html code instead of new element.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/434#issuecomment-9945372.\n. So, what is wrong with the response, exactly?\n. I'm a little confused.  The response from your javascript console looks fine to me.  But, you provided a screenshot of unknown origin with escaped special characters.\n. I just tested again (with the 3.0 branch, which should, in this case, work\nexactly like the 2.1.2 version).  In my response, I returned a div with a\ntext node child.  The response client-side was as expected.  So, I can only\nassume that something in your server-side code is escaping these characters.\n\n\nOn Wed, Oct 31, 2012 at 7:31 AM, Borut Toma\u017ein notifications@github.comwrote:\n\nI was using AjaxUpload till now. I just love this nice file uploader. It's\nso simple to integrate into website.\nBut it has one strange flaw. When PHP encodes special characters to\nentities (cos of iFrame limitations) javascript can not decode this\nresponse properly.\nHere is simple case...\nIn PHP:\necho htmlspecialchars(json_encode(array(\"success\" => true, \"msg\" => \"\nthis works\n\")), ENT_NOQUOTES);\nIn javascript:\n$('#'+target).append(responseJSON.msg); => browser output: this\nworks<\\/div>\nI send different html code for different file upload types. So html needs\nto be perfect. How can I decode this html entities back in javascript or is\nthere another way of doing that?\nThanks!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/434.\n. So you are suggesting the example php be modified accordingly? \n. You're using htmlspecialchars in this example, which I thought was a problem.  I'm a bit confused again.  I tested returning HTML in my JSON response  in IE8 w/out any issues.  Didn't you say that simply using json_encode solves the html escaping issue?\n\nI'm also using java on the backend.  I didn't write the PHP example and am finding this example to be a continuous source of headaches.\n. It sounds like you should be using json_encode by itself?  \nI can't say for sure since I don't really use PHP.  There is a good chance I will be removing the PHP example in 3.0 since no one has stepped up to maintain it and I'm spending entirely too much time supporting it.\n. @NTICompass ...and I would love to have you maintain the PHP example!  Will you be able to handlie support requests via the github project and the forums?\n. I personally don't think it's a problem to include all required response\ndata in the upload response.  Adding another call would complicate things\nconsiderably.  As far as security is concerned, Fine Uploader is using\nJSON.parse for all browsers that support the JSON object.  For other\nbrowsers (IE7 and older, I think), a naked eval is used.  I suppose 3.x\ncould use a polyfill such as Douglas Crockford's JSON2 for older browsers.\nOn Wed, Oct 31, 2012 at 11:22 AM, Borut Toma\u017ein notifications@github.comwrote:\n\n@rnicholus https://github.com/rnicholus @NTICompasshttps://github.com/NTICompass\n:\nI am thinking if it wouldn't be better to generate html code after upload\ncompletion with extra ajax request. In that case json will stay simple and\nmore secure. What do you think?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/434#issuecomment-9951323.\n. I guess I'm not too sure why the htmlescapechars must be used.  All we want it to return the exact text from the JSON response.  Using json_encode by itself seems to work in all cases, unless I'm missing something.\n. I created a 3.0 case to introduce the JSON2 polyfill.  FineUploader does support IE7. but nothing older. \n\nSee case #436.\n. No rush.  Most of my work on this project occurs after 9pm since I don't really have time to write code for this project during working hours, you know, with work and all :smirk:\n. Please show your code\n. I've changed my mind on this one, since it only is applicable to IE7.  I'm not sure I want to introduce more code just to make IE7 a bit safer.  In the near future, I'd like to entertain the idea of dropping IE7 support altogether.\n. Care to provide a reason?\nOn Nov 3, 2012 3:19 AM, \"Borut Toma\u017ein\" notifications@github.com wrote:\n\nThere is no need to support IE7 anymore...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/436#issuecomment-10037315.\n. Well, I'll provide my reason.  While the number of ie7 users is relatively\nsmall, and i think it is important for the Web community to encourage use\nof modern browsers by refusing to support outdated browsers, there are\nenough companies still stuck on this version.  For example, my employer\nsupports some customers who rely on ie7 to this day.  I will certainly not\nremove support for ie7 until my employer has done the same.  Believe me,\nthough, i would like nothing more than to remove support for ie7 today.\nFret not, that day will come.\nOn Nov 3, 2012 6:52 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nCare to provide a reason?\nOn Nov 3, 2012 3:19 AM, \"Borut Toma\u017ein\" notifications@github.com wrote:\n\nThere is no need to support IE7 anymore...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/436#issuecomment-10037315.\n. Yes, that may be a decision some make.  I bet if your ie7 users accounted\nfor a good chunk of your income, you might be singing a different tune\nthough.  :-)\n\n\nAnyway, there really isn't much i need to do in order to ensure the app\nworks in ie7 anyway.  This has not accounted for hardly any of my time so\nfar.  I'll likely continue support until it becomes a hassle.\nOn Nov 3, 2012 1:27 PM, \"Borut Toma\u017ein\" notifications@github.com wrote:\n\nI see your point but I am willing to risk to loose a few percent of users\nthat use IE7 or bellow.\nOne great example is Google which is dropping support for IE8:\nhttp://www.computerworld.com/s/article/9231316/Google_to_drop_support_for_IE8_on_Nov._15\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/436#issuecomment-10042468.\n. In 3.0\n. In 3.0.\n. I'm punting on this one.  Initially, I thought this would be fairly straightforward to implement, but after some thought, it is not.  There are a bunch of edge cases and behaviors to consider.  For example, what if the user drops 3 files, using all maximum connections, and then drops another file, and then another?  In what order should the files upload?  There are a couple possibilities here, and I'm not sure which one is preferable.  Another issue: should dropped or multi-selected files upload/appear in the order they are presented in the drag event/input element, or should they upload/appear in reverse order?  Add the ability to cancel queued and uploading files, and this becomes even more complicated.\n\nNo one actually requested this behavior, other than myself, and I'm not so sure I'm sure how I want such a feature to behave in all cases myself.  So, if I receive some requests to implement this, and there can be agreed-upon behaviors, I can revisit this in the future.  Until then, I'm not sure this is worth the effort or the additional complexity this will add to the code.\n. I'm not sure what you are showing me here.  Please show all of your code,\nboth your HTML and your javascript.\nOn Thu, Nov 1, 2012 at 3:06 PM, mike-aungsan notifications@github.comwrote:\n\nHow do we show upload list in different div ?\nFor example,\nThe following does not work.\n\n\n\n\n\n\n\n\n\n\n\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/440.\n. - You can create alternate drop zones and hide the default one if you'd like.  Have a look at the extraDropzones, hideDropzones, and disableDefaultDropzone options.\n- You can create your own upload file list (pass this element as a value to the listElement option).  Understand that contributing your own list element requires a bit of work on your part.  You will need to represent all of the classes that are present in the default fileTemplate option.  If you use different class names, you will need ti contribute the appropriate values via the classes option as well.\n\nGenerally FileUploader is useful if you like the default design and only plan on making minimal changes to the structure.  In your case, you should use FileUploaderBasic and write your own UI.\n. - You can create alternate drop zones and hide the default one if you'd like.  Have a look at the extraDropzones, hideDropzones, and disableDefaultDropzone options.\n- You can create your own upload file list (pass this element as a value to the listElement option).  Understand that contributing your own list element requires a bit of work on your part.  You will need to represent all of the classes that are present in the default fileTemplate option.  If you use different class names, you will need ti contribute the appropriate values via the classes option as well.\nGenerally FileUploader is useful if you like the default design and only plan on making minimal changes to the structure.  In your case, you should use FileUploaderBasic and write your own UI.\n. Fine Uploader now requires your response be a valid JSON response.  Yours is not.  In your response, if you remove the comma after the object literal, you should be back in business.\n. Update: I meant to say remove the comma after the (inner) object literal, not after the the array literal.  I've updated my response.\n. Update: I meant to say remove the comma after the (inner) object literal, not after the the array literal.  I've updated my response.\n. For future use or for anyone reading this thread,\nJSONLinthttp://jsonlint.com/is a nice tool for validating your JSON.\nOn Thu, Nov 1, 2012 at 4:05 PM, ymmark0 notifications@github.com wrote:\n\nExcellent, thanks, that did it.\nOn Nov 1, 2012, at 9:48 PM, Ray Nicholus wrote:\n\nUpdate: I meant to say remove the comma after the (inner) object\nliteral, not after the the array literal. I've updated my response.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/441#issuecomment-9995908.\n. Why is this check needed?\n. I will try to reproduce this, but if i cannot (i have never seen this\nhappen before) i will need some information from you.  First, what is the\ncontent type of your response?\nOn Nov 2, 2012 6:30 AM, \"rajaboini525\" notifications@github.com wrote:\nHi IPmen,\nI am also having same problem.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/443#issuecomment-10011559.\n. It looks like you didn't read the fine uploader manual/readme.  Your\nproblem is the response's content-type.  Set the content-type of your\nresponse to \"text/plain\" and you should be fine.\n\nOn Fri, Nov 2, 2012 at 6:59 AM, IPmen notifications@github.com wrote:\n\nIt's MVC project C#.net\njs code\nonComplete: function(id, fileName, responseJSON){\nif (responseJSON) {\nServer code\n[HttpPost]\n    public ActionResult StepTwo(HttpPostedFileBase file_)\n    {\n        var sample = Session[\"createSample\"] as Sample;\nreturn Json(ConvertToSamplePageModel(sample));\n}\nContent-Type application/json; charset=utf-8\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/443#issuecomment-10012160.\n. As i said, you are not setting the content type of your response correctly.\n. Can you describe the \"errors\" a bit, along with your environment?  I've never had any issues with \"text/plain\" myself.\n. @owenmead I looked at the case you referred to, and it doesn't contain any specifics regarding the problem you observed.  I am looking for some detail about the errors you experienced.\n. Setting debug to true and pasting the contents of your javascript console\nafter reproducing the problem is advised here.\n\nYou are correct, your content-type must not be \"application/json\".  IE does\nnot support this content-type in responses.\nOn Thu, Nov 15, 2012 at 10:36 AM, owenmead notifications@github.com wrote:\n\nI'll have a deeper look at it today. The onComplete callback was not\ngetting a responseJSON.success with \"text/plain\", yet it was with\n\"text/html\". Today I'll see if I can figure out why.\nRegardless if it is \"text/plain\" or \"text/html\" using \"application/json\"\nwill defiantly break things in IE since it doesn't know to handle it in the\nbrowser, then prompts to download.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/443#issuecomment-10415020.\n. The  will not throw off the parser.  If you look at the code, you will see that it is accounted for.  I still do not see what errors you have encountered.  Everything looks completely normal and expected based on what you have posted.  Please show all of your javascript code.\n\nAlso, i adjusted your comment as you did not escape the html tags, causing them to not appear.\n. Also please provide the version of the uploader you are using.  I'm also\nstill trying to figure out what exact \"error\" you are seeing.  Nothing you\nhave provided suggests that a problem exists.\nOn Nov 15, 2012 5:29 PM, \"owenmead\" notifications@github.com wrote:\n\n--- This is using text/plain ------\nLooking at IE's network log:\nResponse headers:\nContent-Type text/plain; charset=utf-8\nResponse body:\n{\"path\": \"/media/cache/69/27/69278d2dfed114b767ac4f19532de5a2.jpg\",\n\"success\": true, \"filename\": \"Tulips5.jpg\"}\nFrom the JS Console with debug:\nLOG: [uploader] iframe loaded\nLOG: [uploader] converting iframe's innerHTML to JSON\nLOG: [uploader] innerHTML =\n{\"path\": \"/media/cache/69/27/69278d2dfed114b767ac4f19532de5a2.jpg\", \"success\": true, \"filename\": \"Tulips5.jpg\"}\nLOG: [object Object]\n--- This is using text/html ------\nLooking at IE's network log:\nResponse headers:\nContent-Type text/html; charset=utf-8\nResponse body:\n{\"path\": \"/media/cache/64/2d/642d0f910d9e0b524a1cb85fec63c98c.jpg\",\n\"success\": true, \"filename\": \"Penguins17.jpg\"}\nFrom the JS Console with debug:\nLOG: [uploader] iframe loaded\nLOG: [uploader] converting iframe's innerHTML to JSON\nLOG: [uploader] innerHTML = {\"path\":\n\"/media/cache/64/2d/642d0f910d9e0b524a1cb85fec63c98c.jpg\", \"success\": true,\n\"filename\": \"Penguins17.jpg\"}\nLOG: [object Object]\nSeems that when using \"text/plain\" the response in the debug log is\nsurrounded with a\nwhich would throw off the JSON parser. Putting a breakpoint in my onComplete verifies that I'm essentially getting nothing back via the responseJSON parameter.\nServer seems to be sending back the proper response body.\nI know you mentioned in your notes not to use text/html esp if returning HTML in your response, but I can't find another way around it.\nUsing : IE 9.0  under  Window 7\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/443#issuecomment-10430520.\n. Ah yes.  The code to handle the pre tags in a response was added in 2.0 (august).  7 months is incredibly old.  Unfortunately, there are a bunch of third-party wrappers for Fine Uploader out there, and all of the ones I've encountered have not been good about updating to recent versions.  I generally discourage use of these wrappers.\n. Hello Steven.  I'd be happy to use a common system that would signal all\nthird-party maintainers when a new version is released.  Do you have any\npreferences/suggestions?\n\nCurrently, I announce new releases via the twitter feed.\nOn Tue, Nov 20, 2012 at 11:27 PM, Steven Skoczen\nnotifications@github.comwrote:\n\nHey there,\nI'm the maintainer of the aforementioned third-party wrapper, so it's my\nfault. :)\nI generally don't have enough time to keep up the projects I'm maintainer\non, let alone keep tabs on the libs they use - I try to use package\nmanagers to mitigate this wherever possible. Is there any system for\nnotification on new releases such as this one that I could subscribe to to\nkeep things current?\nThanks for the help, and for writing a great library.\n-Steven\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/443#issuecomment-10586022.\n. Is this happening on the actual demo site or with your own code? If it is\nwith your own code, you will need to show your code.\nOn Nov 2, 2012 3:52 AM, \"prashant7july\" notifications@github.com wrote:\nelement not found spinner\nthrow new Error('element not found ' + type);\nwhy I am getting this Issues during the \"Manually Trigger Uploads\"\nhttp://fineuploader.com/fine-uploader-demo.html\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/444.\n. I'm not sure what you are asking.  I am also not able to reproduce this issue.  I tested w/ autoUpload set to false in FF 16 - no issues.\n. It looks like part of your message is missing\n. I followed what I believe are your specific steps to reproduce, on the demo site, with FF, and I was unable to reproduce.  You can re-open this case if you have more specifics about the problem you are experiencing. \n. You can send any data you'd like to the server along with the upload request via the params option.\n. In 3.0.\n. Thanks to a contributor for getting a jump start on this before I even had a Win8 copy.  I'll let this person post here in case they wish to remain anonymous.\n. Thanks! \n. I can see why you may find this useful, but I would not like to send the original text response to the onComplete callback if parsing fails.  The documentation states that the responseJSON parameter of the onComplete handler is a simple object containing the response data, and this is what the user/developer is expecting.  The original responseText is already logged, and I feel that this is the correct approach.\n. There is nothing that can be done on the Fine Uploader side as far as I can tell.  It seems like generating a preview is outside of the scope of the uploader, and doing so in user time has some potential problems.  If the user refreshes the browser window, what happens after the file has been uploaded?  \n\nAfter the file has been uploaded, and any upload-related tasks have been performed (such as copying the file to a central location and adding an entry to a DB), additional work should take place outside of user time on a separate thread.  Your onComplete handler can trigger some function that reveals a DIV with some sort of a spinner or a \"please wait, processing\" background.  This div can then be filled in via ajax when the file preview has been generated.\n. Hi!  All pull requests must be against an in-progress branch.  Currently, 3.0 is in progress.  The 2.1.2 version has been released, and as a result, is not open to pull requests.\nFurthermore, if we are to alert the user with a message, this message must be configurable, which means we must contribute an additional text option.  In addition to this, you are forcing the use of the alert function.   You should be delegating to the showMessage function, which can be overriden to provide an alternate way to display messages to users.\n. This now does fit the contract, but I'm still not sure what problem you are trying to solve here.  If fine uploader is unable to parse the response, surely the onComplete handler will not be able to do anything with it either.  Either your server-side code generates a valid JSON response, or it does not.  If the latter is true, your code needs to be fixed.\nFurthermore, pull requests must be against an in-progress branch, which, in this case, would be 3.0.  2.1.2 has been released and as a result, is closed to pull requests.\n. Not currently.  This would require some non-trivial changes to the fine uploader code, and I'm not sure if it is worth the effort as the benefit is not clear to me.\n. You can pass the product id as a parameter, which will be sent with each\nrequest.  See the params option and the setParams function.\nOn Nov 5, 2012 7:12 AM, \"koichirose\" notifications@github.com wrote:\n\nThe main benefit is managing all the files with a single server request.\nExample: I create a new product, with 3 images.\nIf I have 3 different request I'd have no way to know which product they\nrefer to, since it's a new product and I don't have the ID. I should save\nthe product, return the id and then save each image for that product (and\nit would require some non trivial changes on my code).\nIs that planned in the future?\nThanks\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/453#issuecomment-10069838.\n. If you don't have a product I'd anyway, i guess I'm not seeing how a single\nrequest benefits you over multiple requests.  In each case, you wind up\nwith the same collection of files server side, regardless of the number of\nrequests.\nOn Nov 5, 2012 7:25 AM, \"koichirose\" notifications@github.com wrote:\nYes, but since I don't have a product id yet, I'd have to change all my\ncode to allow a two-step form submission (submit form first, get the\nproduct id, submit images).\nNot feasible for us right now.\nThank you anyway for the very quick responses.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/453#issuecomment-10070198.\n. I added some tests, but automating the testing of much of this library continues to be difficult.  I think I'll ned to investigate automated browser-based tests using webdriver, but that will be a great deal of work.  Perhaps for a later release.\n. Anything is possible with css.  Why do you want to do this, though?\nOn Nov 7, 2012 5:13 AM, \"Mattia\" notifications@github.com wrote:\nIs it possible to hide the items list?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/456.\n. You can hide elements using css.  It would be redundant to provide such an\noption.\n\nOn Wed, Nov 7, 2012 at 8:08 AM, Mattia notifications@github.com wrote:\n\nI was wondering if there was a specific option from file-uploader plugin.\nI don't wanna show that list in some cases.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/456#issuecomment-10149194.\n. There is no element with this css class in Fine Uploader.\n. Have a look at issue #214.\n. It'll be easier if I just merge this into the gh-pages-3.0 branch and then make adjustments.  \n\nThanks for this work!\n. Apparently a 0-width, 0-height, transparent input element covers the text node in the button element in IE7.  I fixed this by wrapping the button text in its own DIV.\n. In 3.0.  See the onValidate callback documentation.\n. Your 2nd attempt at calling setParams is correct, but you don't need a \"param\" prefix added to your property. Please show me all of your code.  I can't tell if you are overriding the onSubmit callback properly without seeing all of your code, but I suspect that is one problem.\nJust out of curiosity, why are you converting a boolean to a bit?\n. I'm afraid I can't help you with this.  You'll need to talk to whoever\nwrote this widget.  My guess is that the widget is using an older version\nof Fine Uploader.  Older versions of Fine Uploader did not correctly set\nthe context when invoking callbacks.  It's possible that there is some\nissue with the widget itself as well.\nOn Mon, Nov 12, 2012 at 2:57 PM, lubosdz notifications@github.com wrote:\n\nThank you very much for fast response.\nThe problem is, that second example throw javascript error \"TypeError:\nthis.setParams is not a function\".\nCheckbox boolean - JSON converts into string \"true\" or \"false\" which in\nPHP test empty($value) always evaluates to true.\nHere is full code - it is actually widget - not sure if this helps you:\n$this->widget('ext.EAjaxUpload.EAjaxUpload', array('id'=>'uploadAjaxPdf','postParams'=>array(\n    \"someStaticValue\" => '$(\"#ofield-compile-pdf\").is(\":checked\") ? 1 : 0',),'config'=>array(\n       'action'=>Yii::app()->createUrl('ipdf/formular/upload', array(\n            'uploadType'=>'pdf-template',\n        )),\n       'allowedExtensions'=>array(\"pdf\"), // case insensitive\n       'sizeLimit'=>IpdfResource::MAX_FILE_SIZE, // in bytes\n       'minSizeLimit'=>IpdfResource::MIN_FILE_SIZE,\n```\n   'onComplete'=>'js:function(id, fileName, responseJSON){ document.location.href=\"/some/Url\" }',\n'onSubmit'=>'js:function(file, ext){            var comp=$(\"#ofield-compile-pdf\").is(\":checked\") ? 1 : 0;            var del=$(\"#ofield-delete-previous-pdf\").is(\":checked\") ? 1 : 0;            //alert(\"compile:\"+comp+\", delete:\"+del);             this.setParams({\"compile\" : comp, \"delete\" : del});       }',\n```\n)));\nThank you very much.\nLubos\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/462#issuecomment-10303964.\n. I'm going to close this issue.  Feel free to re-open if you find an issue specific to Fine Uploader that needs to be discussed.\n. Please have a look at the building and using the snapshot version section in the 3.0 readme.\n. What does CBA stand for?  \n\nYou don't need to install gradle.  Just clone the repo, and run gradlew along with the appropriate task on the command-line.\n. Your server-side code must be able to parse multipart encoded requests, which are sent for all browsers that do not support the File API.  This includes IE9 and earlier, along with Android 2.3 (and earlier) and very old versions of other browsers.\n. I'm not sure what your question is.\n. That is definitely not the correct solution.  IE is not the old browser that may result in Fine Uploader sending a multipart encoded request.  You need to check the content-type of the request to be sure how you should proceed with parsing.  Your \"fix\" will cause you problems in IE10 as well as other browsers that do not support the File API.\n. Yes, that line of code is probably not correct, but neither is your solution.  I can assure you, your solution will not work in IE10, Android 2.3.x, or very old versions of Opera, FF, and Chrome.  Using the user agent string to determine how to parse the request is not a reliable method.\n. Please post your support request in the google groups forum.  One of the PHP contributors should be able to help you fix your server-side code.\n. responseJSON is the result of parsing the server response.  The parameter\nis a simple object since your server response is always json.  Why would\nyou want this to be text?\nOn Nov 15, 2012 4:17 AM, \"Martijn Lafeber\" notifications@github.com wrote:\n\nSo there's no way to have it return anything but json?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/466#issuecomment-10403618.\n. This is not a bug and the question had been answered so I'm closing this case.  Thanks to everyone who participated! \n. It's really very simple, the parameter reflects whatever your sever\nreturns, which must be valid json.  You can include whatever you like in\nthis json.\nOn Nov 15, 2012 7:01 AM, \"Martijn Lafeber\" notifications@github.com wrote:\nIt's normal in Rails 3 to render a .js.erb partial after an xhr request.\nYou can have javascript in the partial which is executed. The controller\npasses objects which you can also use in that partial. Example:\n$('#pictures').append('<%=escape_javascript render(:partial => 'picture', :locals => {:picture => @picture}) %>')\nThe 'picture' partial already exists because it's used to render the\npicture html.\nSo basically, I want my response to be html. I understand I can also use\nthe resulting json to somehow build the html I need in the onComplete\nfunction, but it's going to be uglier than my one line .js.erb partial!\nIt's not a bug as @rnicholus https://github.com/rnicholus mentions, but\nit's an issue for everyone who uses the file-uploader in combination with\nRails.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/466#issuecomment-10407708.\n. The JSON requirement is important as it allows Fine Uploader to easily\nparse the response and determine if an error has occurred, as well as\ndetermine what the error may be.  There are other possible properties of\nthe response that can be used to instruct Fine Uploader.  For example, in\n3.0, the server may include a directive to prevent any further retries for\na particular file (since 3.0 support auto and manual retries for a failed\nupload).\n\nPlease let me know if you have any further questions.  May the file be with\nyou!\nOn Thu, Nov 15, 2012 at 7:28 AM, Martijn Lafeber\nnotifications@github.comwrote:\n\nYes. The fact that the server response has to be valid json is slightly\nannoying for Rails programmers. Thank you for your quick response though,\nI'll include the entire rails partial in a json object as @borut-thttps://github.com/borut-tsuggested, then use that in the onComplete function!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/466#issuecomment-10408400.\n. First off, please show your code & mention which version of Fine Uploader you are using.\n. No response from the poster after 2 days.  If you have a support request, please post in the support forum.\n. Please provide a title and a detailed description of the change along with\nthe reason why you made this change. \nOn Nov 16, 2012 4:33 AM, \"OpenCate\" notifications@github.com wrote:\n\nYou can merge this Pull Request by running:\ngit pull https://github.com/OpenCate/file-uploader patch-1\nOr view, comment on, or merge it at:\nhttps://github.com/valums/file-uploader/pull/468\nCommit Summary\n- initial 3.0 cleanup\n- initial 3.0 segmentation of uploader roles/components\n- stub for build file which will, among other things, combine and\n  optio\u2026\n- start of build file to combine, minify, and gzip js files\n- add gradlew to build\n- add gradlew to build\n- this is currently a snapshot build\n- sync fileuploader.js with master\n- breakup js file, create temporary test environment to aid\n  development\u2026\n- #355 https://github.com/valums/file-uploader/issues/355 - update\n  3.0 branch\n- update readme from master\n- #360 https://github.com/valums/file-uploader/issues/360 - update\n  3.0 branch (WIP)\n- #363 https://github.com/valums/file-uploader/issues/363 - sync\n  readme fix from master to 3.0 branch\n- group options\n- #354 https://github.com/valums/file-uploader/issues/354 - allow\n  users to only override sub-properties that should devia\u2026\n- #354 https://github.com/valums/file-uploader/issues/354 - more\n  adjustments to allow users to only override sub-properti\u2026\n- fix demo js based on refactoring of fine uploader js\n- fix demo html file for form uploads\n- #354 https://github.com/valums/file-uploader/issues/354 - object\n  detection in all browsers\n- #354 https://github.com/valums/file-uploader/issues/354 - object\n  detection in all browsers\n- allow FU to add to subproperties of a FUB option\n- allow FU to add to subproperties of a FUB option\n- #370 https://github.com/valums/file-uploader/issues/370 & #367https://github.com/valums/file-uploader/issues/367- merge fixes into 3.0 WIP\n- #371 https://github.com/valums/file-uploader/issues/371 - 3.0\n  branch - invoke onError callback in FUB too\n- #296 https://github.com/valums/file-uploader/issues/296 - 3.0\n  branch - display all dropzones and exclude default dropzo\u2026\n- #296 https://github.com/valums/file-uploader/issues/296 - 3.0\n  branch - display all dropzones and exclude default dropzo\u2026\n- fix nested object extension & object detection function\n- update readme to match current state of 3.0 codebase\n- update readme to match current state of 3.0 codebase\n- add version tag\n- add version tag\n- #391 https://github.com/valums/file-uploader/issues/391 started\n  writing QUnit tests for Fine Uploader 3.0 js code; alre\u2026\n- #391 https://github.com/valums/file-uploader/issues/391 more util\n  tests\n- #391 https://github.com/valums/file-uploader/issues/391 fix unit\n  test\n- #396 https://github.com/valums/file-uploader/issues/396 - 3.0\n  branch - prevent Safari on IOS 6 from caching the result \u2026\n- #396 https://github.com/valums/file-uploader/issues/396 - 3.0\n  branch - prevent Safari on IOS 6 from caching the result \u2026\n- #391 https://github.com/valums/file-uploader/issues/391 move files\n  to make it easier to run tests on multiple browsers\n- #391 https://github.com/valums/file-uploader/issues/391 all\n  utility functions now have unti tests\n- more reorganization of options\n- update readme after reorganization of options\n- reflect new name (Fine Uploader) in internal \"classes\" and functions\n- missed some items in the readme during rename to Fine Uploader\n- #372 https://github.com/valums/file-uploader/issues/372 - start of\n  jQuery plug-in wrapper work\n- #372 https://github.com/valums/file-uploader/issues/372 - minor\n  adjustments\n- #372 https://github.com/valums/file-uploader/issues/372 - demo\n  page for jquery plugin\n- #372 https://github.com/valums/file-uploader/issues/372 - comment\n  adjustment\n- #372 https://github.com/valums/file-uploader/issues/372 - fix some\n  issues with the plug-in, and add support for calling\u2026\n- #372 https://github.com/valums/file-uploader/issues/372 - remove\n  some temporary testing code\n- #399 https://github.com/valums/file-uploader/issues/399 - 3.0\n  branch - fix callback context\n- #372 https://github.com/valums/file-uploader/issues/372 - finished\n  code for jQuery plug-in wrapper\n- #372 https://github.com/valums/file-uploader/issues/372 convert\n  jQuery objects in 1D arrays to HTMLElements when transf\u2026\n- #372 https://github.com/valums/file-uploader/issues/372 convert\n  jQuery objects in 1D arrays to HTMLElements when transf\u2026\n- #372 https://github.com/valums/file-uploader/issues/372 remove\n  trailing comma for the sake of IE\n- #372 https://github.com/valums/file-uploader/issues/372 start of\n  jQuery plug-in addition to readme\n- #372 https://github.com/valums/file-uploader/issues/372 start of\n  jQuery plug-in addition to readme - fix link & formatting\n- #372 https://github.com/valums/file-uploader/issues/372 no need to\n  send element option if uploaderType = 'basic'\n- #372 https://github.com/valums/file-uploader/issues/372 minor fix\n  to plugin\n- #372 https://github.com/valums/file-uploader/issues/372 fix\n  callback to event code - issue with reference to plugin ele\u2026\n- #372 https://github.com/valums/file-uploader/issues/372 updated\n  readme to include documentation and examples for users \u2026\n- #372 https://github.com/valums/file-uploader/issues/372 fixed\n  event handler function signatures\n- #372 https://github.com/valums/file-uploader/issues/372 fixed call\n  to setParams in plug-in example\n- #402 https://github.com/valums/file-uploader/issues/402 - 3.0\n  branch - fix custom failed upload text display for Firefox\n- make it easier to update 3.0 branch\n- organize test files\n- update readme after re-org\n- more re-org, allow jquery plug-in builds\n- update readme after addition of jQuery plug-in builder to gradle\n- #372 https://github.com/valums/file-uploader/issues/372 - don't\n  die if use calls plug-in without any args (for adding e\u2026\n- grammar fix\n- grammar fix\n- #409 https://github.com/valums/file-uploader/issues/409 - sync fix\n  with test branch\n- auto-retry working for XHR and form uploaders, many additional items\n  \u2026\n- auto-retry working for XHR and form uploaders, many additional items\n  \u2026\n- cleaned up error reporting/detection, TODO: should we always use the\n  \u2026\n- cleanup handler autoRetry\n- auto retry note\n- public retry function (FUB)\n- retry \"button\" for FU\n- fix unit tests\n- #418 https://github.com/valums/file-uploader/issues/418 -\n  hand-merge fix into 3.0 branch\n- auto-retry working for XHR and form uploaders, many additional items\n  \u2026\n- auto-retry working for XHR and form uploaders, many additional items\n  \u2026\n- cleaned up error reporting/detection, TODO: should we always use the\n  \u2026\n- cleanup handler autoRetry\n- auto retry note\n- public retry function (FUB)\n- retry \"button\" for FU\n- Merge remote-tracking branch 'origin/failed-upload-retry' into\n  failed\u2026\n- respect maxConnections, other cleanup\n- option name change\n- add ability to prevent retry via server response & fix callback\n  wrapp\u2026\n- rename a retry option\n- update readme\n- edit readme instance method text\n- #373 https://github.com/valums/file-uploader/issues/373 - auto and\n  manual retrying of failed upload\n- remove version stamp from css\n- fix one of the retry options in readme\n- fix cancel button color & failure text message if non-200 response &\n  \u2026\n- Fix retry hang in IE, account for lack of cancel button if turned\n  off\u2026\n- #375 https://github.com/valums/file-uploader/issues/375 update\n  dependency section of readme\n- update readme\n- fix spacing issue in readme\n- remove downloading section from readme\n- fix title\n- remove 3.0 link\n- start of \"upgrading from 2.x\" section\n- fix link in readme\n- update \"upgrading from 2.1.2\" section of the readme\n- update \"upgrading from 2.1.2\" section of the readme\n- issue #404 https://github.com/valums/file-uploader/issues/404 -\n  processing status message, common status message element\u2026\n- 3.0 release date\n- #376 https://github.com/valums/file-uploader/issues/376 - expose\n  public cancel function for FUB users\n- sync server folder w/ master\n- #429 https://github.com/valums/file-uploader/issues/429 - expose\n  public function to obtain element associated with a file\n- fix jquery tester\n- move showMessage option to FU from FUB\n- #379 https://github.com/valums/file-uploader/issues/379 - add\n  public reset function\n- #437 https://github.com/valums/file-uploader/issues/437 - cleanup\n  progress bar & _onProgress function\n- ie fixes\n- #447 https://github.com/valums/file-uploader/issues/447 - add\n  support for IE10\n- #447 https://github.com/valums/file-uploader/issues/447 - add\n  reference to qq.ie10()\n- #447 https://github.com/valums/file-uploader/issues/447 - add\n  reference to qq.ie10()\n- #438 https://github.com/valums/file-uploader/issues/438 - improve\n  logging, provide public simple (but safe) logging fun\u2026\n- #438 https://github.com/valums/file-uploader/issues/438 - fix\n  qq.log entry in readme\n- spelling issues in readme\n- re-organize test sources\n- #455 https://github.com/valums/file-uploader/issues/455 -\n  qq.UploadButton QUnit tests\n- #460 https://github.com/valums/file-uploader/issues/460 - ie7\n  button fix\n- add onValidate callback check to \"test\" js file\n- #461 https://github.com/valums/file-uploader/issues/461 - add\n  batch and single file onValidate callback\n- #461 https://github.com/valums/file-uploader/issues/461 - readme\n  update\n- #461 https://github.com/valums/file-uploader/issues/461 - add to\n  feature list\n- update readme with breaking changes\n- #166 https://github.com/valums/file-uploader/issues/166 - added\n  Opera support to readme\n- removed redundant feature\n- #461 https://github.com/valums/file-uploader/issues/461 - simplify\n  new onValidate callback, fix callback wrappers\n- #373 https://github.com/valums/file-uploader/issues/373 - add\n  onManualRetry callback\n- #82 https://github.com/valums/file-uploader/issues/82 - fixed\n  response parsing issue found in Android 2.3.6, also logg\u2026\n- added mention of Android support\n- update issue tracker guidelines link\n- update server dir from master\n- Merge branch '3.0' of github.com:valums/file-uploader into 3.0\n- Merge branch 'master' into 3.0\n- Merge branch '3.0' of github.com:valums/file-uploader into 3.0\n- remove example/server files that contains references to fine\n  uploader\u2026\n- update readme with new 3.0 features\n- update server-side readme\n- \"reference\" to examples dir in main readme\n- link to server-side requirements doc\n- adjust callback error reporting\n- remove util = require('util')\nFile Changes\n- M .gitignore (4)\n- A WEB-INF/web.xml (19)\n- A build.gradle (59)\n- D client/demo.htm (41)\n- D client/do-nothing.htm (1)\n- D client/fileuploader.js (1642)\n- R client/fineuploader.css (19)\n- A client/js/button.js (102)\n- A client/js/handler.base.js (120)\n- A client/js/handler.form.js (197)\n- A client/js/handler.xhr.js (168)\n- A client/js/header.js (12)\n- A client/js/jquery-plugin.js (148)\n- A client/js/uploader.basic.js (483)\n- A client/js/uploader.js (575)\n- A client/js/util.js (319)\n- A gradle/wrapper/gradle-wrapper.jar (0)\n- A gradle/wrapper/gradle-wrapper.properties (6)\n- A gradlew (164)\n- A gradlew.bat (90)\n- M license.txt (5)\n- M readme.md (685)\n- D server/ASP.Net_VB/Index.vbhtml (57)\n- D server/coldfusion/upload-page.cfm (45)\n- M server/nodejs.js (1)\n- A server/python_django/file_uploader/init.pyc (0)\n- A server/python_django/file_uploader/manage.pyc (0)\n- A server/python_django/file_uploader/settings.pyc (0)\n- A server/python_django/file_uploader/urls.pyc (0)\n- A server/python_django/file_uploader/view.py (23)\n- A server/python_django/file_uploader/view.pyc (0)\n- D server/python_django/templates/demo.htm (38)\n- A server/readme.md (26)\n- D server/readme.txt (23)\n- D server/uploads/.gitignore (2)\n- A test/css/styles.css (53)\n- A test/fineuploader/MultipartUploadParser.java (136)\n- A test/fineuploader/RequestParser.java (54)\n- A test/fineuploader/Runner.java (47)\n- A test/fineuploader/UploadReceiver.java (113)\n- A test/index.html (74)\n- A test/jquery.html (76)\n- A test/js/uploader-demo-jquery.js (84)\n- A test/js/uploader-demo.js (82)\n- A test/testbuild.gradle (84)\n- A test/unitTest/index.html (25)\n- A test/unitTest/purl.js (271)\n- A test/unitTest/upload-button-test.js (20)\n- A test/unitTest/util-test.js (176)\nPatch Links\n- https://github.com/valums/file-uploader/pull/468.patch\n- https://github.com/valums/file-uploader/pull/468.diff\n\u2014\n  Reply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/468.\n. Your branch is apparently based off of 3.0, but you are initiating a pull request with a target of master.  That is not going to work here.  Please open a new pull request, target the 3.0 branch, and kindly provide a title and a description of your changes.  Thanks!\n. Can you please explain what the \"message zone\" is?  \n\nAs far as the error message, Fine Uploader will always display the \"default\" error message next to a failed file, unless you set the mode property of the failedUploadTextDisplay option to 'custom'.  The default for this value is 'default', which results in display of the value stored in the failUpload property of the text option next to the failed file.  \nPlease see the documentation in the readme for the failedUploadTextDisplay option for more details.\n. I considered this for 3.0, but decided against it.  Splitting the elements in the template into individual options/properties introduces a whole new problem.  What if a developer wants to change the order in which these elements appear in the DOM?  Some other option/mechanism would also have to be introduced to allow this.  This would certainly add complexity to the project, and likely confusion as well.    \nNormally, classes are associated with styles.  If you need to change the styling of the template elements, it is reasonable to simply override FU's style attributes on these elements in your own CSS files.\n. I guess I'd need to see your code to understand better, but you should just be able to reference the default Fine Uploader classes in your selectors.\n. In your case, it is perhaps overkill, but I'm not sure it justifies splitting the elements in the template into individual options, primarily for the reason I mentioned in my initial post.  \nIt sounds like you are dealing with some 3rd-party code, or perhaps some \"untouchable\" in-house code that adds this click handler.  I would expect that this code delegates the handler to the document, expecting the click to bubble up before it is finally handled.  If that is true (and I would be surprised if it isn't, given what you have told me), you should be able to stop the click event from bubbling past whatever container element houses your uploader instance.\n. This is not a fine uploader issue.  Fine uploader only sends requests when a file is uploaded.  If you would like to, you may post in the support forums, but you are probably better off posting your question in a forum specific to Javascript questions.  perhaps stackoverflow.\n. You need to specify a button element (via the button option) when using\nfub.  This requirement doesn't change when you use the jquery plugin\nwrapper.  Also, your params option is not valid.\nOn Nov 18, 2012 1:38 PM, \"tellibus\" notifications@github.com wrote:\n\nHave you tried to actually put some text in you dom \u00e9l\u00e9ment (div)? See the\ndemo webpage for FUB. It doesn't use the jQuery wrapper but you get what I\nmean I guess.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/472#issuecomment-10490301.\n. ...and you are not using the callbacks properly.  If you are going to use\nthe jquery plugin, you should use it as you would any other jquery plugin.\nThink of the callbacks as events.  Have a thorough read of the jquery\nplugin section of the readme.\nOn Nov 18, 2012 1:45 PM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nYou need to specify a button element (via the button option) when using\nfub.  This requirement doesn't change when you use the jquery plugin\nwrapper.  Also, your params option is not valid.\nOn Nov 18, 2012 1:38 PM, \"tellibus\" notifications@github.com wrote:\n\nHave you tried to actually put some text in you dom \u00e9l\u00e9ment (div)? See\nthe\ndemo webpage for FUB. It doesn't use the jQuery wrapper but you get what\nI\nmean I guess.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/472#issuecomment-10490301.\n. I said the button option, not the element option.  You must specify a\nbutton element if you use fub.\nOn Nov 18, 2012 1:50 PM, \"Borut Toma\u017ein\" notifications@github.com wrote:\n\nDocs says different:\nThere is no need to specify the element option. It will be ignored if you\npass it in. The plug-in will pass the element option for you, using the\nelement you associated with the plug-in (the element with an id of\nfineUploaderElementId in the above example).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/472#issuecomment-10490464.\n. Regarding your error message, this is actually referring to your \"error\" event handler.  You are referencing an errorReason variable that has not been defined anywhere.  The error message itself is misleading.  It should reference the 'onError' callback in the message.  It's a benign issue, so I'll list this as a known issue and fix it in 3.1.\n\nYou have to specify a button so Fine Uploader knows where to hide the input element.  FU adds a \"hidden\" input as the sole child of your button element.  If you are using FU (as opposed to FUB), a button is created for you, but you can override this.  FUB users must define a button element.  The element associated with the plug-in instance should be a container element for all HTML associated with that plug-in.  This is a common and accepted meaning for jQuery plug-in instance elements.  So, you should change the element associated with your plug-in instance to a proper container element.  \nI am an avid jQuery user, and have developed the plug-in/wrapper such that it embraces all standards and conventions that jQuery users have come to appreciate.  I'm not sure what your experience level is with jQuery and jQuery plug-ins.  If you are not particularly experienced in this area, you probably won't benefit much from using the plug-in.  Instead, working directly with the \"naked\" Fine Uploader library may make most sense.  The jQuery plug-in intentionally does not offer any features above and beyond those offered by the \"naked\" library.  It simply provides a way of using Fine Uploader that is likely very familiar and comfortable for those who are accustomed to using jQuery plug-ins in their apps.  \nAlso, you should remove the trailing comma after your endpoint value.  IE7 has big problems with trailing commas.  If any of your users utilize IE7, the app will fail in mysterious ways due to IE7s inability to parse javascript with trailing commas.\n. You just need an element specifically to function as the select files\nbutton.  it really doesn't make sense for it to be the same element as the one\nthat you have tied your plugin instance to.\nOn Nov 19, 2012 1:07 AM, \"Borut Toma\u017ein\" notifications@github.com wrote:\n\nIf I understand you right that I need to wrap uploadButton inside parent\ncontainer? Please take a look a the updated example above if I've done it\nright?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/472#issuecomment-10503022.\n. Also, you can remove theisBatch parameter from your validate callback.  I forgot to remove that param from the readme after i simplified the validation contribution code.\n. Did you read my explanation on why this is needed?  Again, the element tied\nto a plugin instance is a container element for the entire plugin.  A\nbutton doesn't fit this description.  Assuming the element tied to the\nplugin instance is also the select files button adds more confusion than\nanything else.  What if the plugin user doesn't want this? How would we\nhandle the button option if the plugin is not in basic mode? Now element tied to the plugin instance\nhas a different meaning depending on how the plugin is used.\n\nI would expect those familiar with jquery plugin conventions to not be\nconfused by the current setup.\nOn Nov 19, 2012 2:55 AM, \"Borut Toma\u017ein\" notifications@github.com wrote:\n\nSo different element for plugin instance and for button. Ok, I understand\nbut don't see the need for this...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/472#issuecomment-10505453.\n. Borut, if you build a real application, your advice regarding inference of the button element when in FUB mode starts to break down.  As it stands, the code you have presented above is not usable.  It provides no feedback to users at all.  \n\nLet's say we continue to build upon your example above, and provide some very rudimentary feedback for users after they select a file.  Let's also go with your suggestion that the plug-in instance is also the button element.  \njavascript\n...\n.on('submit', function(event, if, filename) {\n   var $selectedFile = $('<div></div>');\n   $selectedFile.text(filename);\n   $(this).append($selectedFile);\n}\nAny jQuery plug-in user would want to simply append the div element containing the file info to the plug-in container.  The convention is to append it to \"this\".  In your case, \"this\" is, by default, a button.  We certainly don't want to append this element to the button.  So, now instead of using the accepted convention of appending content to \"this\", we have to append it to some other element not at all associated with the plug-in instance.  \nWhat I'm saying is, it is generally not a good idea to invent your own convention when one already exists.\n. Can you let me know where you read this?  I'd like to add a correction to that article or thread.  \nYou can change parameters for each file in your onSubmit handler by using the setParams method.\n. You dont have to use the jQuery wrapper to accomplish anything with Fine Uploader.  The wrapper is simply a convenience for those accustomed to using jQuery plug-ins in their apps. \nIf you are using the \"naked\" version of Fine Uploader, without the jQuery plug-in wrapper, simply define an onSubmit callback.  The function you specify will be invoked once for each file before it is submitted to the uploader.  You can then call this.setParams({ ... }); inside your function and pass whatever parameters, specific to that file, you want sent along with the request.\n. @snyper3xs it is not clear from your comment what issue you are struggling with.  If you require some assistance, please post in the support forum.  See http://fineuploader.com/support for more info.\n. Fixed in 3.1-IP.\n. I'm assuming you see this message in your onError callback.  Without seeing your code and the debug logs, I can only guess.  There are several possibilities.\n. Can you explain what the problem was in another way?  I'm not sure I understand what the problem was exactly.\n. I need javascript console output with the debug option set to true before I can provide any assistance.\n. Ok, most likely you are returning a response with a response code other than 200, which will prevent IE from parsing the response.  Please post the raw response data here as well.  I am looking for the response headers and the response data.  You can easily grab this information in the network tab of IE's F12 developer tools.\n. The network tab in f12 developer tools.\nOn Tue, Nov 20, 2012 at 1:25 PM, wiredmonkey notifications@github.comwrote:\n\nWhat's the easiest way to do this in IE8? Does the firebug lite provide\nthis?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/476#issuecomment-10568879.\n. Nope.  I'm a Java guy.  It would be great if you could post the response\nheaders and body so we can confirm.  Most likely, the error message you are\nseeing is not the cause of your problem.  It is simply Fine Uploader noting\nthat it knows the response is an error response, but it is unable to parse\nthe response body.  This usually happens when your server returns a non-200\nresponse and the \"show friendly HTTP error messages\" setting in IE options\nis checked.  In this case, IE ignores the response body and inserts its own\n\"friendly\" error message in the iframe if the response body is small\nenough.  When we attempt to parse this response, we end up with an \"access\ndenied\" error since IE swaps out the iframe content with an error message\npage from the local filesystem.  Accessing properties on the iframe, at\nthis point, results in an \"access denied\" error due to cross-site scripting\nrestrictions.\n\nMoral: you should only return 200 in your responses if you want to ensure\nthat an error message is parsed correctly in IE.  Another option is to turn\noff the \"show friendly HTTP error messages\" setting, but that's hardly\nreasonable since you'd have to instruct all of your users to do this.\n Unfortunately, this setting is turned on by default in all versions of IE.\nOn Tue, Nov 20, 2012 at 1:31 PM, wiredmonkey notifications@github.comwrote:\n\nIt's looking like a ColdFusion issue, I tested the upload/resize directly\nwith a simple file upload and found that it on some files cause Internet\nExplorer to display an 'Internet Explorer cannot display the webpage error\nwhich would make sense about the wrong response code. This only seems to\nhave when the imageresize functionality is run, you don't happen to use CF\ndo you? ;)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/476#issuecomment-10569134.\n. Closed as I'm not sure what else is needed here.\n. You'll have to be more specific about the \"issues\" you are seeing and the\nresponse your server is returning.\nOn Jan 9, 2013 1:37 AM, \"applezqp\" notifications@github.com wrote:\nI am sure my server returns a 200 response and the \"show friendly HTTP\nerror messages\" setting is unchecked, but I encountered issues for all IE\nversions. Why?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/476#issuecomment-12034469.\n. Also, don't add your comment to another, old case that has very little in common with your situation.  Post support requests in the support forum, and include actual details surrounding your problem so i have some place to start.\n. Duplicate of #392.\n. Why are you returning a value in your compete callback handler?\n\nThere is really no good reason to allow developers to customize the format\nof the response.  You are already able to return any additional custom\nproperties, including properties that contain HTML values, in your response\nas well, provided the response is valid JSON.\nOn Nov 21, 2012 6:14 AM, \"pbauerochse\" notifications@github.com wrote:\n\nI think it would be nice to enable a custom server response. Instead of\nreturning the fixed structure with\n{success: false, error: \"My error message\"}\nI'd like to return a different structure with a different success\nidentifier. I guess a nice way to override this could be to return a\nboolean in the onComplete handler. There one could react to the server\nresponse and manually determine whether the response indicates a success or\nerror.\nExample:\n[..]\n   .on('complete', function(event, id, fileName, responseJSON) {\n        // custom validation of responseJSON here\nreturn responseJSON.myCustomSuccessIdentifier;\n});\nBest Regards\nPatrick\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/478.\n. Are you saying the server side code is part of your framework and you have\nno control over the actual response it sends? Which framework is this?\nOn Nov 21, 2012 6:50 AM, \"pbauerochse\" notifications@github.com wrote:\nIn my case I'm writing an application which is using an internally\ndeveloped framework, which already has some basic classes for\nUploadResponses. But that class unfortunately is not compatible with the\nstructure fineuploader needs.\nTo be concrete:\nUploadResponse does not have the boolean property \"success\" but instead\nhas a \"status\" enumeration which determines whether the upload was a\nsuccess. In my case it would be nice to evaluate the server response from\nwithin the onComplete handler and let that handler return whether the\nupload was a success or not.\nI would then implement the onComplete handler like so\n.on('complete', function(event, id, fileName, responseJSON) {\n         // custom validation of responseJSON here\n         return responseJSON.status === 'SUCCESS';\n});\nRight now I would have to create a custom Object which introduces the\nboolean success property and a string error message property. This is not a\nbig deal actually but kind of unpleasant since I'm duplicating a property\nwhich my framework already provides.\nWhat do you think?\nCheers\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/478#issuecomment-10595628.\n. Allowing status of the upload to be determined in the complete callback\nwould break at least a couple features.  I don't plan adding the ability to\ndo this as I think your case is an unusual exception.  You would probably\nbe better off forking the project and making a small change in the XHR and\nform uploader classes.  When the JSON response is parsed, you can simply\nadd a \"success\" property to the result object based on the response from\nyour server.  It should be a 1 or 2 line adjustment in both classes, I\nwould imagine.\n\nOn Wed, Nov 21, 2012 at 7:24 AM, pbauerochse notifications@github.comwrote:\n\nKind of, yes. Of course I can extend the frameworks classes to alter the\nresponse but I would then duplicate an existing property (status) which is\nalready indicating a success/error. It's a custom framework which is\nmaintained by another department in my company.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/478#issuecomment-10596619.\n. Your post is unreadable and you have provided no information about your problem at all.  feel free to reopen when you are ready to provide specifics about the problems you are having.  Also please read the documentation before opening up a support request.  I spent a great deal of time reworking the documentation to help out users of this library.\n. The official example does reflect the latest version, as do the docs.  What\nspecific improvements would you like to see in the readme.\nOn Nov 22, 2012 6:51 AM, \"pinkopalla\" notifications@github.com wrote:\nWell, this is my first day with this plugin. I think that when one comes\non the official page (apart from the novelties introduced by the last\nversion), I would expect that the official example reflects the latest\nofficial distribution.\nThis plugin seems to be better than the blueimp's jquery file uploader,\nbut the docs are a lot confused.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/480#issuecomment-10633452.\n. You are downloading 2.1.2, which is not the latest version.  Please read\nthe documentation on the  master branch.\nOn Nov 22, 2012 3:40 AM, \"prashant7july\" notifications@github.com wrote:\nWhen I am download the zip file from -\nhttps://github.com/downloads/valums/file-uploader/2.1.2.zip\nThe list of file is different and when I am checking the \"\nhttp://fineuploader.com/\"\nIn http://fineuploader.com/\n\n\n\n\n\nhttp://code.jquery.com/jquery-latest.js\"</a>\nhttp://platform.twitter.com/widgets.js\"</a>\nhttp://code.jquery.com/jquery-latest.js\"</a>\n\nhttp://code.jquery.com/jquery-latest.js\"</a>\nhttp://platform.twitter.com/widgets.js\"</a>\nhttp://code.jquery.com/jquery-latest.js\"</a>\n\nhttp://fineuploader.com/js/prettify.js\"</a>\nhttp://fineuploader.com/client/js/header.js\"</a>\nhttp://fineuploader.com/client/js/util.js\"</a>\nhttp://fineuploader.com/client/js/button.js\"</a>\nhttp://fineuploader.com/client/js/handler.base.js\"</a>\nhttp://fineuploader.com/client/js/handler.form.js\"</a>\nhttp://fineuploader.com/client/js/handler.xhr.js\"</a>\nhttp://fineuploader.com/client/js/uploader.basic.js\"</a>\nhttp://fineuploader.com/client/js/uploader.js\"</a>\nwhen DOWNLOAD zip file then there is fileupload.js only js file Why?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/480.\n. Also nothing is gained, other than confusion, by inspecting the source code\nof the demo page.  Why exactly are you doing this?  Simply follow the\nexamples, read the docs, and you will be fine.\nOn Nov 22, 2012 3:40 AM, \"prashant7july\" notifications@github.com wrote:\nWhen I am download the zip file from -\nhttps://github.com/downloads/valums/file-uploader/2.1.2.zip\nThe list of file is different and when I am checking the \"\nhttp://fineuploader.com/\"\nIn http://fineuploader.com/\n\n\n\n\n\nhttp://code.jquery.com/jquery-latest.js\"</a>\nhttp://platform.twitter.com/widgets.js\"</a>\nhttp://code.jquery.com/jquery-latest.js\"</a>\n\nhttp://code.jquery.com/jquery-latest.js\"</a>\nhttp://platform.twitter.com/widgets.js\"</a>\nhttp://code.jquery.com/jquery-latest.js\"</a>\n\nhttp://fineuploader.com/js/prettify.js\"</a>\nhttp://fineuploader.com/client/js/header.js\"</a>\nhttp://fineuploader.com/client/js/util.js\"</a>\nhttp://fineuploader.com/client/js/button.js\"</a>\nhttp://fineuploader.com/client/js/handler.base.js\"</a>\nhttp://fineuploader.com/client/js/handler.form.js\"</a>\nhttp://fineuploader.com/client/js/handler.xhr.js\"</a>\nhttp://fineuploader.com/client/js/uploader.basic.js\"</a>\nhttp://fineuploader.com/client/js/uploader.js\"</a>\nwhen DOWNLOAD zip file then there is fileupload.js only js file Why?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/480.\n. Have a look at the java example i created, in the server directory.  If you\nare not familiar with the work required to handle multipart encoded\nrequests, simply follow my example code and you will be fine.\nOn Nov 22, 2012 9:36 AM, \"zibibbalibbo\" notifications@github.com wrote:\nHi all, we are trying to use fine uploader to create an upload button on\nour web application. But we have a problem, the post is sent to the server\nbut we can't find the way to read the file server-side. Those are part our\nsources:\nthe script (the file is sent to the server):\nvar uploader = new qq.FineUploaderBasic({\nbutton: $fub[0],\ndebug: true,\nrequest: {\nendpoint: '/private/club.do?task=uploadDocument&code='+code,\nforceMultipart: true\n}\n});\nthe servlet:\nboolean isMultipart = ServletFileUpload.isMultipartContent(request);\n```\nif (isMultipart) {\nDiskFileItemFactory fif = new DiskFileItemFactory(DEFAULT_SIZE_THRESHOLD, new File(getTempPath(request)));\n\nServletFileUpload upload = new ServletFileUpload(fif);\nupload.setHeaderEncoding(request.getCharacterEncoding());\nupload.setSizeMax(DEFAULT_SIZE_MAX);\n\nFMUser fmUser = getFMUserByLoggedUser(loggedUser);\n\nString destDir = \"/Club/2012\";\n\n// Temp dir e la ripulisco\nFMFile tmpDir = rm.getTempDir(fmUser, repo, false);\n\nList<FileItem> items = upload.parseRequest(request);\n\n```\nat this point we have that our List items is empty.. And we are stopped\nhere.\nCan anyone help us?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/481.\n. I'm not very familiar with struts, but I don't see why you wouldn't be\nable to use a DispatchAction.  Looks like it gives you access to\nHttpServletRequest.\n\nOn Thu, Nov 22, 2012 at 10:26 AM, zibibbalibbo notifications@github.comwrote:\n\nWith your example all is running, but we wanted to use struts and to\nreceive the uploaded file through a DispatchAction reading our object from\nthe request. Is it possible? Or the fineUpdater can only be used with a\nservlet?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/481#issuecomment-10639313.\n. I'm going to close this since I think everything has been addresses, but feel free to let me know if you have any further questions.\n. This sounds like a good set of options to provide.  Seems like you would only need to add buttonHover and buttonFocus properties to the classes option.\n\nIdeally, I would like to do away with these classes entirely and simply make use of CSS pseudo-classes, but :focus is only supported in IE8 and up, so that is not possible until I drop support for IE7.  Until then, we will have to continue to listen for appropriate DOM events.\n. You can create a classes option in FUB and define these two new properties.  FU will inherit those properties in its classes option by default.\n. sounds good\nOn Fri, Nov 23, 2012 at 10:43 AM, obiwanus notifications@github.com wrote:\n\nYes, this sounds good. I could provide a pull request tomorrow if you\ndon't mind.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/482#issuecomment-10664561.\n. Merged into 3.1-IP via PR #485\n. Re #482\n. All pull requests must be based off of an IP branch, as stated in the readme.  Please open a new pull request based off of 3.1-IP.  Otherwise, it looks good.\n. \"qqfile\" is the default value for the inputName property.  If you deviate from this default value, you will need to change the example accordingly.  \n\nThe implementation does not assume a GET request.  $_GET is simply used in PHP to grab parameters passed via the query string.  The $_GET and $_POST global names do not necessarily reflect the request method.  \nThere is a pending feature request to allow parameters to be sent only in the request body.  Once this is completed, you will be able to switch this behavior on by setting an option.  Please see #113 for more details.\n. Thanks for your contribution!\n. AFAIK, this is only possible with images.  Can you provide a use case?  I'm trying to figure out why this would be preferable than simply dragging and dropping files, which is already supported.\n. Ah ok.  Well, this is the first request I have received.  Unless I receive a pull request or other express interest in this, I'll have to put this off until all other currently scheduled work has been completed.\n. If you are asking if a way exists for you to pass a file or blob to the\nuploader via a function call, the answer is currently \"no\".  It would be\neasy to allow this, though.  Yours is the first such request I've received,\nthough.  Do you have more than one use case in mind?\nOn Nov 30, 2012 6:46 PM, \"Gerardo Curiel\" notifications@github.com wrote:\n\nThis would be very useful as an additional method for uploading files.\nHere's the pasteboard implementationhttps://github.com/JoelBesada/pasteboard/blob/master/assets/js/modules/copyandpaste.coffee(in coffeescript).\nBut anyway, is there any way right now of uploading a file, given a Blobhttps://developer.mozilla.org/en-US/docs/DOM/Blobor\nFile https://developer.mozilla.org/en-US/docs/DOM/File object?.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/487#issuecomment-10910084.\n. Fine Uploader already uses the File API internally, where supported.  I can\ncertainly allow a file to be passed in as well.  Please open up a feature\nrequest and I'll schedule it.\n\nOn Fri, Nov 30, 2012 at 9:25 PM, Gerardo Curiel notifications@github.comwrote:\n\nIt would be useful to pass a blob or file object to file-uploaded if the\nmethod for receiving such file is external to this plugin, like the\n\"clipboardData\" approach from pasteboard. Also, it seems like that's the\nstandard way offered by the File API.\nAnother use case: I would like to pre-process an image before uploading,\nmaybe resize it using something like load-imagehttps://github.com/blueimp/JavaScript-Load-Image.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/487#issuecomment-10912407.\n. Note that I just delivered a new API function: addFiles.  See the readme in the 3.1 branch for more details.\n. moving into 3.3...\n. Beginning work on this for 3.4.  I already have an API function that accepts Blob objects, so it seems like this should be as easy tying into the clipboard API.  Per my understanding, the Clipboard API is only properly supported in Firefox 4+ and Chrome 21+.  I confirmed the presence of an onpaste property on the document in both of those browsers.  Safari 6 also has this property, which may mean that File API support exists in this browser as well.  However, IE10 does not pass this test.  I expect to be able to support pasting images from the web.  I may be able to support pasting any items from the filesystem, though I haven't looked into this and this seems like a silly way to upload files since DnD is supported.\n. It still may be useful to add the ability to paste images into the upload\narea, though.\nOn Feb 27, 2013 7:08 PM, \"\u5c0f\u677e\" notifications@github.com wrote:\naddBlobs is enough,tks!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/487#issuecomment-14210806\n.\n. Actually, though, it might be difficult to determine, for the user, when it\nis possible to paste an image with the default uploader ui.  I might have\nto think about this some more.  Maybe I'll simply add this feature and\nleave it up to integrators to set (our possibly override the default)\ntarget element for the paste event.\nOn Feb 27, 2013 7:31 PM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nIt still may be useful to add the ability to paste images into the upload\narea, though.\nOn Feb 27, 2013 7:08 PM, \"\u5c0f\u677e\" notifications@github.com wrote:\n\naddBlobs is enough,tks!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/487#issuecomment-14210806\n.\n. Looks like Chrome may be the only browser that actually implements the Clipboard API.  Once again, Chrome is on the bleeding edge while other browsers are playing catch-up.  To support image pasting in FF, and possibly other non-Chrome browsers, I guess I'll have to toy with the idea of creating a hidden content-editable DIV inside the \"paste target element\".  This will receive the pasted image.  I will then need to draw the image onto a  which will then need to be converted to a Blob.  This will require a bit more code, and may be a bit tricky, unfortunately.\n. After some more investigation, I realized that, in order to make this work in browsers that don't support the Clipboard API, in addition to the steps posted above, I'll also need to proxy all cross-domain images.  I'll have to decide if I provide the ability to paste images outside of Clipboard API browsers in this release.  If I do, integrators will need to provide an endpoint address (via a new option) that will proxy external images.\n. After some thought and discussion, I'll probably only support browsers that completely implement the Clipboard API.  This means only Chrome 13-ish and up.  It looks like the Clipboard API was implemented in Chrome sometime between v13 and v14.  I'm inclined to wait until other browsers catch up and support the Clipboard API before I add paste image support for these browsers as well.  Supporting pasting of images without the Clipboard API is potentially complex and would require integrators to support a GET request that proxies cross-domain images in some cases (possibly many cases).  I'm not sure the demand for this feature is high enough to merit the added complexity to the library (and to the integrator's sever-side code) at this time.\n\n\nI'm interested in hearing opinions on this.  Otherwise, my plan is to support image pasting for browsers that support the Clipboard API, which currently only includes Chrome.  I anticipate to code this in such a way that pasting images will work immediately in other browsers, after they add support for the Clipboard API, provided vendor-specific prefixes are not part of the implementation.\n. I'm currently working on this feature in the paste-images branch.\n. This feature is now part of 3.4-IP.\n. You can paste an image present in your clipboard just as you would paste any other item.  You must define a paste target though.  There is a blog entry that covers this feature at  http://blog.fineuploader.com/2013/03/04/upload-an-image-via-paste-in-3-4/. There is also a section on the docs site.  If you have a specific question regarding use of this or any other feature, please see the support page on the home page for instructions on opening up a support thread.\n. Yes\nOn Friday, September 27, 2013, relipse wrote:\n\nOh now i see, looking great. Btw, does anything work besides a textarea or\n<input text element for pasting?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/487#issuecomment-25224384\n.\n. All of my testing occurs with multiple uploaders on the same page.  If\nthere is a specific issue in 2.1, it will only be fixed in the 3.x branch.\nPlease upgrade to 3.0, and attempt to reproduce again.  If you are still\nable to reproduce, please provide your html and javascript code so i can\nlook into this further.\nOn Nov 26, 2012 12:18 AM, \"Adam Krebs\" notifications@github.com wrote:\nI need two different uploaders on a single page tied to two different\nelements (two different templates, on- callbacks, the whole nine) using\nFU2.1. Both have multiple set to false. I am running into an issue\nwhere the first uploader correctly triggers its callbacks on the initial\nupload, but fails silently (no callbacks) when attempting a new upload.\nCommenting out the qq initializer for the second uploader fixes the problem.\nAny ideas?\nI haven't yet tried with version 3.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/488.\n. I'm not aware of this issue and I have tested extensively on Android 4.0.4.\n Please show your code or provide a live example that I can use for\nreproduction.  Perhaps there is something in your code/environment that is\ncausing this to happen?  What version of Fine Uploader are you using?\n\nOn Mon, Nov 26, 2012 at 9:08 AM, Magnus notifications@github.com wrote:\n\nHi,\nI have encountered a problem with Android browsers when selecting a file.\nSometimes it reloads/(submits?) the page from where I'm selecting a\nfile, and sometimes it works and does not reload the page.\nIt seems to occur randomly and in both Chrome for Android and the stock\nbrowser. Is this a known issue, or am I the only one?\nHTC Sensation, Android Z710e with Sense 3.6, Android 4.0.3.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/489.\n. Using your website, I took 6 pictures, resulting in 6 uploads via Chrome,\nand did the same with the stock browser.  No problems noted (no page\nreloads, etc), other than the fact that the upload failed, which was\nexpected based on your comment.  I am using Android 4.0.4.\n\nOn Tue, Nov 27, 2012 at 4:14 AM, Magnus notifications@github.com wrote:\n\nThanks for your reply.\nIt seems to happen very often when taking a picture with the camera.\nHere is an isolated example of when it often fails (uploads now fails\nbecause of a server limit I've set, the problem is before the actual\nupload).\nhttp://mfjohansson.nu/test/fileupload/\n/Magnus\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/489#issuecomment-10752336.\n. My tests on the 4.x branch of Android were also on the GT 10.1.  Thanks for the update.\n. Any update?  Are we ok with closing this as a 3rd-party-bug?\n. No problem.  I've labelled this case accordingly.\n. You are correct, the input does extend past the container div, but adjusting the z-index is not the proper fix here.  Instead, you should set the width and height css properties of the input to \"100%\".  I can include this as a fix in 3.1.\n. You must set the height AND width to 100%.  Based on your comment, you have only set the width, which explains the lack of a pointer cursor.\n. Which browser, and do you have a live site I can examine?\n. Hmm, looks like setting the width & height to 100% causes this issue with the cursor.  The accepted fix is to style the input as fine uploader already does.  \n\nGoing back to your initial concern, even if the hidden input expands past the container (div), this should not cause problems with other, nearby buttons, as far as I can tell.  In fact, I added another button next to the \"select files\" button in my test app and did not run into any issues in Safari, Chrome, FF, or IE.\nPerhaps something in your code is causing the original issue.  Perhaps you could share all of your code?\n. Ah yes.  You will most definitely need to use the 2nd one.  Can we call this closed?\n. Please read the callbacks documentation.\n. There are no current plans to support this, but you are right, the plug-in wrapper does not handle the \"container\" selector/jQuery object in a manner that is consistent with other jQuery plug-ins.  This should probably be fixed.  I'll schedule this for 3.1.  Essentially, the plug-in wrapper should create a FU instance for each HTMLElement represented by the associated jQuery object.\nThe jQuery plug-in wrapper is new as of 3.0, so I suppose there was bound to be something I overlooked.  \nP.S. I'd like to point out that the plugin function is fineUploader(...) and not fileUploader(...).\n. I'm going to re-open this issue, as it is now a feature request, scheduled to be part of the 3.1 milestone.  \nThanks for reporting this.\n. @akre54 This change/fix has been implemented in the 3.1 branch.  Let me know if you have any issues.\n. Fixed in 3.1.\n. No need to modify the source code.  Please read the documentation first  You will notice that a params option and setParams function exist.\n. I'm guessing you have no control over this silly security rule.  Well, there is currently no way to ensure the filename will not be the last parameter in the query string.  You do have the option of removing the filename from the query string entirely, though.  You can ensure this behavior by setting the forceMultipart option to true.  Note that all requests will be multipart encoded if you do this, but it should address your very specific issue. \n. Oops, sorry.  Looks like, while the XHR uploader will indeed send the filename in the request body, it will still append the file name to the query string.  Not sure if this is still going to result in a problem for you.  If it is, then I guess you will be forced to modify the source code, if you are not able to control this restriction on your end.\n. I guess you will have to modify the source then.  It seems like your situation is unusual.  Am I correct?\n. Once feature request #113 is completed, there will be an option to ensure\nall parameters are in the request body, as opposed to the query string.\n This should solve your problem a bit more cleanly.\nOn Tue, Nov 27, 2012 at 9:32 AM, Ole Kallehave notifications@github.comwrote:\n\nIf there's no available options to avoid the filename being appended, then\nI guess modifying the source is the only option yes. I don't know if the\nsituation is unusual, I'm not really that much into mod security, that I\nknow if it's a common rule or not.\nAnyways, thanks for a great uploader :)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/494#issuecomment-10762097.\n. What specific problem are we trying to solve here?\n. This will not solve the issue you referred to.  You have added the accept header to the XHR request.  A file is not uploaded in IE9 and earlier using XHR.  Instead, a multipart encoded POST request is sent by submitting a form in a hidden iframe.  \n\nFine Uploader documentation suggests that all of your server responses use a content type of \"text/plain\" due to the issues present in IE.  Please see the \"internet explorer limitations\" section in the readme for more details.\n. Can you provide a concrete/specific example of this problem?\n. I'm assuming this happens for all POST requests, including those coming from the form uploader?  Is this only an issue with Firefox, or potentially other browsers?\n. I suppose we could modify the default accept header for the xhr uploader to include \"text/plain\".  However, you can specify this in your own app, without modifying any source, by simply passing the appropriate property via the customHeaders option.  Note that there is no way for us to modify headers associated with requests sent by the form uploader.\n. Any update here?  Does my suggestion address your issue?\n. If you use the entire java example (all three classes) along with the associated dependencies, uploads from all browsers will be parsed correctly. \n. I'm sorry, but this is not an uploader question.  You will ned to spend\nsome time learning/reading up on java and the servlet api and, apparently, spring.\nOn Nov 28, 2012 7:45 PM, \"zlczhou\" notifications@github.com wrote:\n\nHi,the problem has not solved .\nI used springmvc,but in controller which POJO set a Controller annotion !\nI can not get the ServletContext, allways it's a null.\nAt 2012-11-28 09:30:40,\"Ray Nicholus\" notifications@github.com wrote:\nIf you use the entire java example (all three classes) along with the\nassociated dependencies, uploads from all browsers will be parsed correctly.\n\u00a1\u00aa\nReply to this email directly or view it on GitHub.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/497#issuecomment-10831768.\n. in 3.1.\n. Simply keep a copy of the param object you originally specified, modify it appropriately,  and then pass it back to FU via setParams(myParams).\n. Just tested in FF 17.0, Windows 7 and I didn't have any problems.  I even tested the same example pictured in your screenshot.  Perhaps an add-on is causing you grief.\n. I've found firebug to be, ironically, quite buggy.  The fact that FF still\nrequires you install an add-on to allow developers to debug javascript is\nastonishing, but that's for another discussion.\n\nI would recommend upgrading to a 1.10.x release of firebug.  I'm not sure\nwhy 1.9.1 is causing an issue for you.  I could look into it, but I don't\nreally have time to chase down issues caused by firebug if simply upgrading\naddresses the issue.  If you happen to figure out why this version of\nfirebug is causing problems, feel free to post that informat here.\n Otherwise, upgrading seems to be a reasonable solution.\nOn Wed, Nov 28, 2012 at 8:27 AM, marcelpanse notifications@github.comwrote:\n\nYou are right, as soon as i disabled all my plugins it started working.\nWhat surprised me is that the plugin causing grief was Firebug 1.9.1.\nAlso tested with Firebug 1.10 on OSX and that working fine.\nAny idea's on how this can break the uploader? (since it is a really\npopular plugin).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/500#issuecomment-10804216.\n. You're right, it is overkill in your case.  That is why FineUploaderBasic\nexists.\n\nOn Wed, Nov 28, 2012 at 10:45 AM, Adam Krebs notifications@github.comwrote:\n\nWe're using FineUploader in a number of places on our site that have\nvastly different requirements. In some places we're using all the features\n(drop zones, file lists, loading indicators), but in one area we only need\nvery basic functionality (a link that triggers an upload dialog, then\ninserts the result into a TinyMCE editor.). It seems like overkill to set\nup an extra template, especially when the upload list isn't needed.\nHere's what we are currently using:\nvar this = this;$('.editor-image-uploader').fineUploader({\n    multiple: false,\n    request: {\n        endpoint: '/upload',\n        inputName: 'Project[workspace_image]',\n        forceMultipart: true,\n        params: {\n            type: 'Project',\n            class_id: _this.classModel.id\n        },\n    },\n    validation: {\n        allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],\n        acceptFiles: 'image/*',\n        sizeLimit: 2097152,\n    },\n    dragAndDrop: {\n        disableDefaultDropzone: true,\n    },\n    text: {\n        uploadButton: 'Upload Photo',\n    },\n    template: .template(editorImageUploaderTemplate)(),\n    showMessage: function(message) {\n        $(this.element).parent().siblings('.errorMessage').text(message).show();\n    }}).on('complete', function(event, id, filename, response) {\n    // insert response file into editor});\nand in the editorImageTemplate:\n{uploadButtonText}\nIdeally we'd like to just call\n$('.editor-image-uploader').fineUploader({....}); on the link without\npassing an extra template. Is there an easy way to do this?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/501.\n. In your code, you are setting the inputName option correctly, so it should\nchange the property in the request to reflect this value.  Perhaps you\ndon't understand exactly what this property means.  If so, have a look at\nthe documentation for the inputName option.\n\nThere is a FineUploaderBasic example on the homepage (look in the \"more\ndemos\" dropdown, or see the buttons at the bottom of the index page).  Yes,\nyou have to contribute your own button element when using FUB.  You are not\ncontributing a \"separate\" \"button\" element, since FUB expects you to\nprovide one.  Using FUB via the jQuery plug-in wrapper.  Have a look at the\n2nd dot-point in the jQuery plug-in documentation section of the readme.\nOn Wed, Nov 28, 2012 at 12:01 PM, Adam Krebs notifications@github.comwrote:\n\nI couldn't see a way to change the inputName in FineUploaderBasic.\nHere's my markup:\n\n\nand js:\n$('.editor-image-uploader').fineUploader({\n    uploaderType: 'basic',\n    button: $('.editor-image-uploader-btn'),\n```\nmultiple: false,\nrequest: {\n    endpoint: '/upload',\n    inputName: 'Project[workspace_image]',\n    forceMultipart: true,\n    params: {\n        type: 'Project',\n    class_id: this.classModel.id\n\n},\n\n},\nvalidation: {\n    allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],\n    acceptFiles: 'image/*',\nsizeLimit: 2097152, // 2 MB\n\n}}).on('complete', function(event, id, filename, response) {\nconsole.log('on(complete) event')\nvar editor = tinymce.get('Project_workspace');\nvar new_p = editor.getDoc().createElement('p');\nvar new_img = editor.getDoc().createElement('img');\nnew_img.src = response.fileLocations;\n$(new_p).append(new_img);\neditor.execCommand('mceInsertContent', false, new_p.innerHTML);});\n```\nDo I need the separate button element? I'm finding my element isn't\ngetting correctly attached without giving it a separate button element,\nand even then I still can't select it. Do you have an example of how the\nbasic uploader would be used with jQuery? (or even a qq.fineUploaderBasic\nexample that I can use).\nThanks for your fast responses.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/501#issuecomment-10813384.\n. First, no need to stop using the jQuery plug-in if you intend to use FUB.\n It's just as easy to use FUB w/ the plug-in.\n\nSecond, the input element is not visible.  I'm not sure why you are worried\nabout the font-size properties on this element.  Style your supplied button\nelement that wraps this input however you want.\nOn Wed, Nov 28, 2012 at 1:01 PM, Adam Krebs notifications@github.comwrote:\n\n@rnicholus https://github.com/rnicholus you're right, I was missing the\npurpose of inputName (I thought it changed the 's name property\nduring element creation).\nI am now using the var uploader = new qq.FineUploaderBasic({ ... }) form,\nbut it seems like it doesn't have the behavior I want. It looks like its\nonly job is to create an input element which has hard-coded CSS properties\n(like setting the font to Arial and the fontSize to 118px), which is\nstrongly undesirable in my project.\nAll I need is to have a link that triggers an upload action and has a\ncallback on success. Is the only way for me to do this to use FineUploader\nwith a template?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/501#issuecomment-10815951.\n. You are the second person who has stumbled into this issue.  My assumption was that jQuery plug-in users who are using FUB (as opposed to FU) would always set the plug-in target/selector to the container/parent element for their uploader  UI, which would differ from the button option element/selector.  I assumed the button element would naturally be a child element of this container element.  \n\nFor example:\nhtml\n<div id=\"myUploader\">\n   ...some misc html here...\n   <div id=\"myUploaderButton\"/>\n   ...some additional html here to style your uploader...\n</div>\njavascript\n$('#myUploader').fineUploader({\n   uploaderType: 'basic',\n   button: $('#myUploaderButton'),\n   ...\n});\nI assumed this would be intuitive.  Surely you have a parent element that contains all uploader-related HTML.  Correct?\n. Why do you want to use the form uploader for all browsers?\nOn Wed, Nov 28, 2012 at 2:53 PM, wiredmonkey notifications@github.comwrote:\n\nHi\nI'm trying to fit your plugin into a CMS which I use and need to make it\nuse form uploads via the iframe for all browsers, is there an easy way to\ndo this?\nI noticed a static method called \"isSupported\", if I passed in a config\noption for overriding the value will this cause me any trouble do you think?\nCheers\nShaun\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/502.\n. What do you mean by \"form uploads\"?  There is no way for the server to tell\nif the request was sent by submitting an actual form.  Do you mean to say\nthat you only want to handle multipart encoded POST requests?\n\nOn Wed, Nov 28, 2012 at 3:25 PM, wiredmonkey notifications@github.comwrote:\n\nIt's to avoid having to alter the how the upload works in the CMS, it\ncurrently only supports form uploads and would require me writing to\ndifferent scripts to upload.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/502#issuecomment-10822378.\n. Then you only need to set the forceMultipart option to true.\n\nOn Wed, Nov 28, 2012 at 3:29 PM, wiredmonkey notifications@github.comwrote:\n\nyeah that's what I meant. It's been a long day!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/502#issuecomment-10822543.\n. For all user agents that support the File API, yes.\n\nOn Wed, Nov 28, 2012 at 3:36 PM, wiredmonkey notifications@github.comwrote:\n\nBut it still sends it as a XHR with this option set as true?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/502#issuecomment-10822848.\n. Setting forceMultipart to true will ensure that all user agents send\nmultipart encoded requests.\n\nOn Wed, Nov 28, 2012 at 3:44 PM, wiredmonkey notifications@github.comwrote:\n\nYeah, I'm looking to force all browsers to use the same method of upload\ni.e. multipart encoded POST requests so I can deal with it easily in one\ngo. Not too worried about the File API as my clients users tend to be IE8\ndownwards :(\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/502#issuecomment-10823848.\n. Can this be closed, or did you have further questions on this topic?\n. @ojal15 Please stop posting this as a solution to every question.  I have removed your posts from the other two cases where you have made this suggestion.  You are\nincorrect.  If you want to force multipart requests for all uploads, there\nis an option for that.  Modifying the source code is almost always a bad\nidea.\nOn Nov 29, 2012 6:18 AM, \"Suthar Ojal\" notifications@github.com wrote:\n:::IMMEDIATE SOLUTION:::\nIn \"_createUploadHandler\" function, comment out the following lines (shown\nby \"//\" as prefix).\n// if(qq.UploadHandlerXhr.isSupported()){\n// handlerClass = 'UploadHandlerXhr';\n// } else {\nhandlerClass = 'UploadHandlerForm';\n// }\nThis creates UploadHandlerForm and we dont have to go through Xhr .\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/502#issuecomment-10845037.\n. Based on what I'm seeing in MDN, and microsoft's own developer website, it looks like the accept attribute on input elements is not supported, even in ie10.\n. No response from creator for 2 days.  I'll assume this is resolved.  If not, please let me know.\n. There are many variables to consider here, so this will be a complicated project, if it is to be done correctly.  I have created a new repo just for this project, and I hope to work on it as time allows.  Famous last words.\n. The problem is, you are not returning valid JSON in your response.  Did you\ntry UTF-8 encoding the value of your url property?\n\nOn Sat, Dec 1, 2012 at 8:19 AM, Yop notifications@github.com wrote:\n\n{\"success\":true,\n\"url\":\"upload\\images\\2012-12-01-220758_([tom51.com\n]\u00c2\u00ed\u00b4\u00ef\u00bc\u00d3\u00cb\u00b9\u00bc\u00d32_\u00c2\u00ed\u00b4\u00ef\u00bc\u00d3\u00cb\u00b9\u00bc\u00d32.rmvb)[00.35.22.604].bmp\"}\n. Please provide me with a text version of the console output.  I assumed that was what you originally provided.\n. I'm looking for output from the Javascript console, with the debug option\nset.\nOn Dec 2, 2012 8:20 PM, \"Yop\" notifications@github.com wrote:\nHere're related texts I copied from console.\nresponseText =\nWarning: fopen(E:\\Share\\Yop\\Documents\\My Web\nSites\\YopYan\\1\\upload\\images\\2012-12-03-101739_([tom51.com]\u00c2\u00ed\u00b4\u00ef\u00bc\u00d3\u00cb\u00b9\u00bc\u00d32_\u00c2\u00ed\u00b4\u00ef\u00bc\u00d3\u00cb\u00b9\u00bc\u00d32.rmvb)[00.35.22.604].bmp):\nfailed to open stream: Invalid argument in E:\\Share\\Yop\\Documents\\My Web\nSites\\YopYan\\1\\lib\\uploader.php on line 43\nWarning: stream_copy_to_stream() expects parameter 2 to be resource,\nboolean given in E:\\Share\\Yop\\Documents\\My Web\nSites\\YopYan\\1\\lib\\uploader.php on line 45\nWarning: fclose() expects parameter 1 to be resource, boolean given in\nE:\\Share\\Yop\\Documents\\My Web Sites\\YopYan\\1\\lib\\uploader.php on line 46\n{\"success\":true,\"url\":\"upload\\images\\2012-12-03-101739_([tom51.com]\\u9a6c\\u8fbe\\u52a0\\u65af\\u52a02_\\u9a6c\\u8fbe\\u52a0\\u65af\\u52a02.rmvb)[00.35.22.604].bmp\"}\nfineuploader-3.0.min.js:4\n[FineUploader] Error when attempting to parse xhr response text\n(SyntaxError: Unexpected token W)\n\u00a1\u00aa\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/505#issuecomment-10939636.\n. No response from poster for 4 days.  Feel free to re-open.\n. What is the UploadProgress module?\nOn Dec 1, 2012 11:27 AM, \"Olexiy Zamkoviy\" notifications@github.com wrote:\nI would like to use UploadProgress module (nginx or apache for example)\nwhere it is not possible to use usual progress. How relevant is this ?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/506.\n. Very interesting.  I'll have to look into this some more.\n. I'll schedule this for a later release, where I will spend some more time investigating.\n. Likely a 4.0 feature, or later.\n. Closed for the same reason as #225.\n. This is not a fine uploader problem.  The error means that POST requests are not supported on your server.  You will need to fix this issue on your server.\n. There is currently no way to do this.  You will need to create a new\nuploader for each button.  Fine Uploader could be modified with a new\noption that accepts an array of \"button\" elements.  The uploader would need\nto hidden input elements as a children of each of these buttons.\n\nCan you please describe your specific use case?\nOn Mon, Dec 3, 2012 at 5:11 PM, wiredmonkey notifications@github.comwrote:\n\nHi\nIs it possible to set multiple upload buttons but call the same\nFineUploader? or will this cause issues in IE?\nCheers\nShaun\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/508.\n. I added a feature in the 3.1 branch that will allow you to pass in file objects or your own file input elements.  For the latter type, you will need to listen for the onchange event and only then pass in the file input element, since FU will submit the associated files for upload (or storage, if autoUpload is false) immediately.  \n\nSee documentation for the new addFiles method.\nWill this suffice?\n. Please let me know if there is anything left to do here, or if the newly added addFiles function is not sufficient for your case.\n. Please let me know if there is anything left to do here, or if the newly added addFiles function is not sufficient for your case.\n. I'm probably not going to implement this unless I see several more people verify that this would be useful to them as well...\n. Well, first off, it seems like you would need/want to change the URL based on the response received from your server.  This means the call to change the endpoint would have to happen as late as when the onComplete callback is invoked.    This is far, far too late to make any changes to submitted file properties.  At this point, there is no way to target a specific file at all, without some non-trivial changes to the internal code.  \nPerhaps I don't completely understand your request.  Some code showing exactly what you want to do, in the context of Fine Uploader, may help (assuming I've misunderstood you).\n. I'm still going to need to see others comment on this feature request before I give it priority.  The 3.2 release will contain file chunking and auto resume, both features that will take a good deal of time to properly implement and document.  I only usually have 1-1.5 hrs a day (at night) to work on Fine Uploader, and I don't always get time each and every day to do this.  As a result, I need to give priority to features that I believe will be very useful for many people along with bugs reported by users.\nI'll put this into the 3.3 milestone, but that is not a guarantee that it will be completed in that release.  Again, if I see a lot of comments from users requesting this, I can certainly give it a higher priority. \n. Thanks for your comment.  This is currently scheduled for 3.3.  Without a 2nd maintainer, I really can't promise the feature any sooner.\n. I'm going to start working on this as part of 3.2 now...\n. I have added a setEndpoint API function to the 3.2-IP branch.  It works very much like the improved setParams function.  Please see the readme for more details.  \n@FelixSchwarz @proycon This should address all of your concerns in this case.  If I missed something, please let me know.\n. Please see the addFiles instance function documentation in the readme.  I also fixed a regression caused by introduction of the qq.each function.  Finally, the new method is used internally as well.  This prompted me to change the behavior of onValidate a bit.  Now, the onValidate callback is called for each \"batch\" of submitted files, even if only one file is submitted.\nIn 3.1.\n. I agree with you that this query string param is not necessary in this\ncase, but I'm hesitant to remove this in order to address an issue specific\nto rails.  Certainly you are not the first person to use rails w/ FU.\n Perhaps someone has a solution for you.  Did you see the rails wiki\nposthttps://github.com/valums/file-uploader/wiki/Rails---CarrierWave?\nIn 3.1 (set to release in a couple weeks), you can force all parameters\ninto the request body, instead of the query string.  So, in that case,\nthere will only be one \"inputFile\" param - the actual file data.\nOn Tue, Dec 4, 2012 at 11:58 AM, Anil notifications@github.com wrote:\n\nWhen using IE 9 files are sent using a multipart request. The multipart\nrequest uses posts the field name \"qqfile\" containing the file data.\nHowever at the same time, the query string includes a parameter \"qqfile\"\nthat contains the filename.\nRails assumes that parameters sent in a request have unique names, and\nputs them all into the same \"params' bucket. params[:qqfile] contains the\nfilename, instead of the file data.\nThere is probably a way to dig into the actual data that was posted in\nRails, although it's not a Rails friendly way to do things. That said, does\nit really make sense to post the filename and file data using the same\nparameter name? I tried changing the \"InputName\", however that changed both\nthe query string and field name of the posted file.\nThanks!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/511.\n. Very possible that this is a new bug/feature.  I call those feabugs.\n Anyway, I can take a look at the history of the code just before Andrew\nhanded over the project to me in August.  Right around that time, a LOT of\nrepos were merged in, so perhaps that is when this feabug was introduced.\n If this is the case, I'll mark this as a bug and fix it for 3.1.\n\nOn Tue, Dec 4, 2012 at 12:48 PM, Anil notifications@github.com wrote:\n\nIt sounds like 3.1 will solve the issue then. Thanks!\nI saw some code using a older version of FineUploader (from January I\nbelieve) . I noticed that when using IE the \"qqfile\" query string parameter\nwas not sent (but is sent with an XHR request in other browsers) so perhaps\nthis is a new bug/feature?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/511#issuecomment-11009631.\n. I introduced this in 36a42c33b160cd929a97333a6dd0efe8326df9b4 (2.1).  Not sure why.  I'll mark it as a bug and remove it in 3.1.\n. Fixed in 3.1.\n. Why are you calling the onSubmit callback twice?  You probably don't want\nto do that.  As far as getting the full path of a file - there is no way to\ndo this reliably, cross-browser.  In most browsers, you have no access to\nthis.\n\nOn Wed, Dec 5, 2012 at 12:54 PM, chrispoket99 notifications@github.comwrote:\n\nHello, In my current implementation I have to show the full path of the\nfile that I select, for this I change the onSubmit and this can return the\nfull path, I change the code on _uploadFile:\n.....\n......\nvar fileName = this._handler.getName(id);\nvar filefullName = this._handler.getFullName(id);// omit the replace of\ngetName\nif (this._options.callbacks.onSubmit(id, filefullName) !== false){\nthis._onSubmit(id, fileName);\n....\n....\nand I can get the full path.\nis this correct? or are there a better solution?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/512.\n. I can look into this, if time allows.\n. Sure, that might speed things up.  I have to admit, I'm not very familiar\nwith CommonJs, or any of the associated standards, so I'm not sure how I\nfeel about adopting any of these standards.\n\nOn Thu, Dec 6, 2012 at 8:36 AM, Adam Krebs notifications@github.com wrote:\n\nwant me to make a pull?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/513#issuecomment-11087612.\n. Very interesting, and it looks like the CommonJs format can easily be converted to work with the RequireJs way of doing things as well.  Perhaps I'll squeeze this into 3.1...\n. I think my ignorance of CommonJs & RequireJs is making this a bit more difficult than I anticipated.  However, it doesn't seem like simply adding the code you listed in your initial post will work in this project.  Fine Uploader's qq function is actually defined in util.js, which exists after header.js.  Remember that all scripts are combined for the release.  The order is defined in build.gradle.  So, it seems like the code you referenced will need to be placed after util.js, but that seems odd.  So, perhaps the best place for it is at the end of the combined scripts.  I did this, and all seemed well, (though I needed to make a few changes to your proposed code).  However, I failed to integrate RequireJs during my testing.  Perhaps I simply don't understand RequireJs & CommonJs well enough.  \n\nThat said, I don't plan on moving forward with this without a pull request and, perhaps some explanation regarding simple integration w/ RequireJs, since RequireJs seems to differ from other CommonJs implementations for reasons I do not completely understand at this time.\n. The value of qq is actually set/reset in util.js, so the \"header\" code\nwould need to appear after that, it appears.\nOn Fri, Dec 7, 2012 at 9:43 AM, Adam Krebs notifications@github.com wrote:\n\nIf I get some time early next week, I'll take a crack at it. The rest of\nmy project is in requirejs form, so being able to import qq this way would\nbe a huge boon for me\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/513#issuecomment-11134449.\n. Too close to the 3.1 release date, so I'm moving this into 3.2.  I'll defer this change to you, @akre54, since you are obviously more familiar with CommonJS.  Also, after submitting your pull request, I'd like to know how to easily make your change work with RequireJS, as I was unable to figure this out, though I admittedly didn't spend much time on it.\n. I\"m going to close this for now.  Feel free to re-open if you get some time to open up a pull request.\n. CommonJS support will be added in 5.8.0 (in progress). See #1562 for details.\n. Please open up a pull request with your changes.\n. @HorstBrack can you please submit your changes by opening a pull request.\n. Thanks for your contribution.  I've modified the PHP example accordingly.\n. Can you be more specific about your problem?  What happens when you try to\nupload a file greater than 300 MB? Are you seeing this issue in all\nbrowsers?  etc...\n\nOn Thu, Dec 6, 2012 at 9:43 AM, frozenflat notifications@github.com wrote:\n\nOk I have a problem. I created a ajax based uploader from scratch for a\nweb application about a year ago. It worked great much like file-uploader\nhowever about 3-6 mo ago it stopped uploading files over 300 MB . I was\nlike great they must have changed the browser specs or something. So\nyesterday I implemented you Fine Uploader 3.0 with the full features of\nlisting files and then hitting button to upload. Still can't upload files\nover 300MB. I know it's not the server php cause those settings are dialed\nin plus the fact that I have a small plugin where I use straight instant\nuploading. Like you pick a file and bam it starts to upload. This script is\nbased on your older file-uploader I think version 1.0 even and this can\nupload a multiple GB files no problem!!! So not I like what is causing\nthis. Is this cause of a new streaming ajax that is getting limited? Can\nanyone shed some like on before I go mad :-) . It got to be client side and\nbased on some limitation in newer meth od vs older. I really like your new\nversion with jQuery and want that progress bar but has anyone ran into this\nissue? Thanks for any help you can give me .\nCheers\nRon\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/515.\n. Again, I need specifics in order to assist.  Do you have any server and/or\njs console  logs to share?  Also, what is the 3x setting?\n\nOn Thu, Dec 6, 2012 at 10:59 AM, frozenflat notifications@github.comwrote:\n\nIf I upload a file larger it will get almost to the end and then fail. it\nthen will try the 3x setting and fail each time. no file is seen in the\nupload folder and it just doesn't upload. Fails in all browsers and seems\nto fail no matter what type of file you throw at it.\nThanks for you Help!\nCheers\nRon\nOn Dec 6, 2012, at 11:07 AM, valums/file-uploader reply@reply.github.com\nwrote:\n\nCan you be more specific about your problem? What happens when you try\nto\nupload a file greater than 300 MB? Are you seeing this issue in all\nbrowsers? etc...\nOn Thu, Dec 6, 2012 at 9:43 AM, frozenflat notifications@github.com\nwrote:\n\nOk I have a problem. I created a ajax based uploader from scratch for\na\nweb application about a year ago. It worked great much like\nfile-uploader\nhowever about 3-6 mo ago it stopped uploading files over 300 MB . I\nwas\nlike great they must have changed the browser specs or something. So\nyesterday I implemented you Fine Uploader 3.0 with the full features\nof\nlisting files and then hitting button to upload. Still can't upload\nfiles\nover 300MB. I know it's not the server php cause those settings are\ndialed\nin plus the fact that I have a small plugin where I use straight\ninstant\nuploading. Like you pick a file and bam it starts to upload. This\nscript is\nbased on your older file-uploader I think version 1.0 even and this\ncan\nupload a multiple GB files no problem!!! So not I like what is causing\nthis. Is this cause of a new streaming ajax that is getting limited?\nCan\nanyone shed some like on before I go mad :-) . It got to be client\nside and\nbased on some limitation in newer meth od vs older. I really like your\nnew\nversion with jQuery and want that progress bar but has anyone ran into\nthis\nissue? Thanks for any help you can give me .\nCheers\nRon\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/515>.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/515#issuecomment-11093804.\n. Headers are not meant to be used for storing custom values, such as, in\nyour case, folder ID and order #.  For this, you should use parameters.\n You can set parameters for all files using the params option, and set new\nparameters for each individual file in your onSubmit callback using the\nsetParams function.\n\nOn Thu, Dec 6, 2012 at 5:56 PM, frozenflat notifications@github.com wrote:\n\nThanks rnicholus for you help . I think I tracked it down had to do with\nZend Server which we are trying to migrate to on our new development\nserver. Still doesn't make sense to me , seems to be an php seg fault in\none of the Zend Modules(Zend Optimizer), turned off and works but this\ndoesn't explain the issues on our production machine for my old uploader .\nHopefully this new one built using the fine uploader will fix that\nissue(crossing fingers). I do have another problem you might be able to\nhelp me with . I have to pass customHeaders custom to each file before it\nuploads. can I set these headers right before each file is uploaded? Looks\nlike you can do it for the batch but not as each file goes up. Is this\ncorrect? I need to set and order number of each file and a folder id that\neach file going to go in but I have to do this different for each file. Can\nI change or add custom headers to each file before they upload?\nThanks so much for you help\nCheers\nRon\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/515#issuecomment-11112033.\n. OnSubmit is called once for each file.  The value you pass into the\nsetParams function will replace the existing params for that file, and\nthese params will also apply to the next file, unless you also call\nsetParams when the onSubmit for that file is called.\nOn Dec 6, 2012 7:12 PM, \"frozenflat\" notifications@github.com wrote:\noh one more question reading the docs and put this onSubmit, will this be\nattached to that exact file or all files. I really like to have unique\nparams for each file that gets put into the queue before you hit the upload\nbutton. Will this do that or do I just have to create a look up array that\nwill go along with all files ?\nCheers\nRon\nOn Dec 6, 2012, at 7:35 PM, valums/file-uploader reply@reply.github.com\nwrote:\n\nHeaders are not meant to be used for storing custom values, such as, in\nyour case, folder ID and order #. For this, you should use parameters.\nYou can set parameters for all files using the params option, and set\nnew\nparameters for each individual file in your onSubmit callback using the\nsetParams function.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/515#issuecomment-11113974.\n. Was there another way you wanted to ensure each file has a set of unique\nparams?  Note that you can also pass functions as parameter values.  The\nability to do this makes it possible to provide dynamic parameters, since\nany functions associated with your set of parameters will be re-evaluated\nfor each file, just before the file is sent.\n\nYou should really read my blog post explaining parameters in file uploader:\nhttp://blog.fineuploader.com/2012/11/include-params-in-request-body-or-query.html\n.\nOn Dec 6, 2012 7:23 PM, \"frozenflat\" notifications@github.com wrote:\n\n:-( oh well ok I just keep adding the files to an array that can then be\nused on server for look up .\nCheers\nRon\nOn Dec 6, 2012, at 8:18 PM, valums/file-uploader reply@reply.github.com\nwrote:\n\nOnSubmit is called once for each file. The value you pass into the\nsetParams function will replace the existing params for that file, and\nthese params will also apply to the next file, unless you also call\nsetParams when the onSubmit for that file is called.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/515#issuecomment-11114497.\n. There is a callback (onSubmit) for each file, before it is submitted to the\nuploader.  See the readme for details regarding the specifics of this\ncallback.  You can pretty much anything you want with parameters: use the\nsame params for all files, specify alternate params for each, file, pass a\nfunction as a param value, etc.  Have a lok at the blog post I linked to,\nas well as the readme.\nOn Dec 6, 2012 7:54 PM, \"frozenflat\" notifications@github.com wrote:\nPerhaps I am confused? So I using the file-upload that when you say select\nfile , it will add it to the list which executed the onSubmit, right? But\ntheir is no call back for when I hit the submit button right? Each file\nthat goes up I have to associate an order that it was added to the list and\nthe folder that was selected to add to in my program. The old uploader\nsince I was able to set the header for each file I was able to set the\nheader unique to each file right before it was sent up. It would be nice\nthat if I add a file to the uploader list it can have unique params that\nstay with that file so when the uploader is executed each file had those\nparams sent with it.\nIf I attach a function how would I exactly do this ? Can I tell which file\nis about to go up? something like function(file_name?)\nThanks for all your help\nCheers\nRon\nOn Dec 6, 2012, at 8:36 PM, valums/file-uploader reply@reply.github.com\nwrote:\n\nWas there another way you wanted to ensure each file has a set of unique\nparams? Note that you can also pass functions as parameter values. The\nability to do this makes it possible to provide dynamic parameters,\nsince\nany functions associated with your set of parameters will be\nre-evaluated\nfor each file, just before the file is sent.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/515#issuecomment-11115142.\n. I was thinking it would go either above or below the uploading screenshot i\nadded (just above the \"setup\" section) but it doesn't have to be there.\nI'm just looking for the feature list to be highly visible and fit with th\nrest of the homepage design.\nOn Dec 7, 2012 3:26 AM, \"tellibus\" notifications@github.com wrote:\nHey Ray. Yes I can do that. Do you want them on the very homepage or a\nseparate one?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/516#issuecomment-11123765.\n. I was thinking it would go either above or below the uploading screenshot i\nadded (just above the \"setup\" section) but it doesn't have to be there.\nI'm just looking for the feature list to be highly visible and fit with th\nrest of the homepage design.\nOn Dec 7, 2012 3:26 AM, \"tellibus\" notifications@github.com wrote:\nHey Ray. Yes I can do that. Do you want them on the very homepage or a\nseparate one?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/516#issuecomment-11123765.\n. Awesome!  I made a few adjustments to the listed features, and removed the client directory in favor of a submodule.  \n\nI'll update the features before 3.1 releases.\n. First off, the HTML in your template will not work correctly in IE.  Wrapping a hidden input with a  does not work in IE since IE delegates click events to the , and not the child element (the ).  That really isn't a problem with your pull request, but I thought I'd point it out.\nIt is common to define a simple HTML template in a plug-in.  Lots of other libraries do this, such as twitter bootstrap & jQuery UI, among others.  I have long wrestled with a way to restructure the template options in Fine Uploader, but haven't settled on an option that provides the same flexibility while still keeping this as intuitive as it is now.\nYour approach only provides this functionality for jQuery users.  I have promised that I would not provide features for jQuery users that do not exists for non-jQuery users.  \nThat said, I kind of like your approach, but I'm really hesitant to implement it until I've had sufficient time to think about it and test it out myself.  Also, the fact that this only targets jQuery users is a problem that would likely prevent me from implementing it at all.  If it were to become part of the library, it would need to exist in the core project.\n. I'll look into this in 3.2, perhaps, sometime after the chunking feature is complete.\n. We'll tackle a templating redesign in #867.\n. I'll schedule this for 3.1.  I'll need to think about the best way to handle this.\n. My goal is to allow developers to change the parameters at ANY point in the process.  I also intend to make it simple to change parameters for a specific file, or all files.\n. Changes have been made to make setParams much more useful in 3.1.  Please have a look at the associated blog post for details.\n. I'm not sure what problem you are trying to solve.  Are you saying you want\nthe input element added after the button element in the DOM?  If so, why?\nOn Fri, Dec 7, 2012 at 10:59 AM, Kevin Namuag notifications@github.comwrote:\n\nAt first, I am having problems with the 'button' option on\nFineUploaderBasic(). I never thought it would need to be in a\nor any container for the to be appended until I browsed the source code.\nWould it be possible to have a, say a 'targetButton' option where it can\ndirectly inherit the upload event (file chooser/navigator popup)? Like\ninstead of appending the inside the target button, it will append/insert\nafter the 'targetButton' element or something like that.\nSnippet:\n\nvar uploader = new qq.FineUploaderBasic({\n         targetButton: $('#someButton') // automagically making #someButton upload-ready});\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/519.\n. 1.) You cannot use a  element with a nested  element\ndue to issues with click event delegation in IE.\n\n2.) I'm still not following your request.  Your HTML will not work, at\nall.  In order for your  element to trigger the file dialog,\nthe file input element MUST be a child of the button.  There is simply\nno other way.  How do you expect clicking your  element will\ninvoke the file dialog?\nOn Fri, Dec 7, 2012 at 11:53 AM, Kevin Namuag notifications@github.com wrote:\n\nReason 1\nThe situation I'm in: A client wants me to create an upload form using the\nhtml returned by their server. Now, their server returns  which is not the right element for the 'button'\noption as  will be inserted inside the element. I spent\nalmost an hour trying to figure out why it won't work until I found out it\nneeds to be in a container. To fix this issue, I waited for a couple of\nminutes and awkwardly talked to one of their php devs to change  to a  tag. Just for that reason alone.\nReason 2\nCode Aesthetics:\n lookin' good \nClick Me\n\n or \n\n\nis better written than..\n what happened? \n\n   Click Me\n     this, happened \n\nThis can be argued, but to some people (including me) the first looks\nbetter.\nReason 3\nWhy can't  have what  have?  have rights too.\nThat's HTML racism.\n\u2014\nReply to this email directly or view it on GitHub.\n. Your server or some device in front of your server is likely returning a\nnon-200 response.  Please read the first row of the IE Limitations section\nof the readme:\nhttps://github.com/valums/file-uploader#internet-explorer-limitations.\n\nThe uploader code will catch this security exception, so it should not have\nany adverse affect on the uploader instance.  The only problem is that,\nwith a non-200 response, IE will not return the server's error response to\nthe iframe.  Instead, it replaces it with a default \"friendly\" error\nmessage, loaded from disk.  Accessing this message results in a security\nexception due to XSS restrictions.  As a result, Fine Uploader will report\nthe \"default\" error message in the UI, in this case.\nOn Fri, Dec 7, 2012 at 8:11 PM, kaka notifications@github.com wrote:\n\nI'm getting the following from IE8:\n[FineUploader] Sending upload request for qq-upload-handler-iframe2\n[FineUploader] Received response for qq-upload-handler-iframe2\n[FineUploader] Error when attempting to access iframe during handling\nupload response (Error: Permission denied)\n[FineUploader] iframe loaded\n[FineUploader] Error when attempting to parse form upload response (Error:\nPermission denied)\nserver request CONTENT_TYPE=multipart/form-data\nplease help\nthank you\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/520.\n. I don't have any way to verify this, and it doesn't look like an essential change to the code.  I'm not sure I can, in good faith, merge this in, unless I have at least one other person verify that this works as expected and does not break existing functionality. \n. Thanks!.  Same question as before though: have you tested in IE9 or earlier & non-IE browsers using FU 3.0?\n. @KJLJon Looks like this is no longer a trivial merge, after I merged your PR in issue #526. Can you fix the merge conflicts and commit the changes?\n. Has this been tested with 3.0 using both IE9 (or earlier) and non-IE browsers?\n. @KJLJon Looks like this is no longer a trivial merge, after I merged your PR in issue #526.  Can you fix the merge conflicts and commit the changes?\n. Since you have left out most of your callback code, I can't tell you where\nexactly your code is failing.  However, when executing code in one of your\ncallback handlers, an exception is occurring.  In other words, you will\nneed to take a closer look at your callback handler code and figure out\nwhat you are doing wrong.  The error message that claims the problem is in\nyour onValidate handler may be incorrect.  There is a known issue in 3.0\nwhere an incorrect callback handler name is reported in an exception\nmessage.  That is fixed in the 3.1 branch.  But, again, one of your\ncallback handlers is causing an issue that you will need to track down.\n\nOn Sun, Dec 9, 2012 at 12:45 PM, cob4lt notifications@github.com wrote:\n\nI have a FineUploaderBasic object set like this\napp_obj.Stupovi.fineUploader = new qq.FineUploaderBasic({\nbutton: $(\".browseUpload\")[0],\nmultiple: false,\nrequest: {\nendpoint : app_obj.app_url + \"/uploads\",\nforceMultipart: true\n},\nvalidation:{\nallowedExtensions: [\"jpeg\", \"jpg\", \"gif\", \"png\"],\nsizeLimit: 4194304 //4MB\n},\ncallbacks: {\nonSubmit: function(id, filename){\n//Spremim id tog submitanog fajla za lakse prekidanje uploada\n$(\"#uploadDiv\").data(\"fileId\", id);\nreturn true; //Ako zelim da mi odmah pocne download\n            },\n            onComplete: function(id, filename, responseJSON){\n                if(responseJSON.success){\n                    ....\n                }\n            },\n            onProgress: function(id, filename, uploadedBytes, totalBytes){\n                if(uploadedBytes < totalBytes){\n                                            ....\n                }\n            },\n            onError: function(id, filename, errorReason){\n                console.log(errorReason);\n            },\n            onCancel: function(id, filename){\n                                   ... returning previous foto that was in div\n                                 }\n}\nAnd on one button I have click event set like this\n...\napp_obj.Stupovi.fineUploader.cancel($(\"#uploadDiv\").data(\"fileId\"));\n....\nWhen I click my cancel button, on some image every think works fine, but\non other images I have error that is described in subject??\nWhat object 291? this numbers is changing depending on previous that was\nin div\nthank you\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/524.\n. As to your first comment, you are correct.  There is no contract that specifies the error callback will be invoked only once per file.  In the case of a non-200 response, I thought it would be useful to log the non-200 response code for XHR uploads in addition to the actual server response.  I felt this was reasonable, since it is generally a bad idea to return non-200 responses to mark an error when using this uploader.\n\nAs to your second comment, _error is called only during processing of files, before an upload is attempted.  So, you will certainly never see the same error result in 3 calls to the onError callback.\n. It is certainly possible that some server-side code could return a non-200 response/status code AND an \"error\" JSON response.  In all cases, the text of the \"error\" property in the JSON response should be passed to the onError callback.  That IS part of the contract described in the readme.  Note that this expectation is implied by the presence of an \"errorReason\" parameter.  The readme in the server folder describes this error reason I am referring to here.  If the response code is not 200, it is certainly possible that there is no \"error\" response.  In that case, it seems like the error code would be most important.  I decided that it makes logical sense to simply call the onError callback once if the response code is not 200, and again if there is an \"error\" JSON response.  In both cases, the same file ID is also passed, so I didn't expect this to cause any problems.  \nThe reason why you should really not return non-200 codes to signify an error is due to some a default behavior in IE that will actually rip out anything you return in your response and replace it with a \"friendly\" error message.  When using a hidden iframe to handle uploads (which must be done if XHR upload are not properly supported by the user agent) this message is not parseable by the uploader due to XSS restrictions, since it is loaded from disk.  This means that the onError callback will be invoked with a default error message, and not the message returned from the server.  Also, if using FineUploader (as opposed to FineUploaderBasic), the error message next to the failed file will, again, be a default, generic error message.  See the first row in the \"IE limitations\" section of the readme for reference.\nHope this makes some of these behaviors & restrictions a bit clearer.\n. Ha!  Looking back at my source code, it looks like I did in fact change the code to only log an error once in this case.  If there is a non 200 response code, and no error message in the JSON response, I call onError with the response code, otherwise I only call it with the error message.  This change happened in 2.1.2.  You must be using an old version of Fine Uploader.  \n. If you upgrade to fine uploader 2.1.2 or later, you will no longer see two onError callbacks as well.\n. You are using the 2.2 pre-release, which was actually released as 2.1.2.\nLooking at 2.1.2, i apparently did not make any changes to error handling.\nI was matching up the changed date in version controk with release dates,\nbut perhaps I should have used the issue tracker to determine which release\nmy changes went into.  So, yes, 3.0 will be the earliest release with these\nadjustments.\nOn Dec 9, 2012 11:18 PM, \"Jeff\" notifications@github.com wrote:\n\n/\n- http://github.com/Valums-File-Uploader/file-uploaderhttps://github.com/Valums-File-Uploader/file-uploader\n- Multiple file upload component with progress-bar, drag-and-drop. \n- Have ideas for improving this JS for the general community?\n- Submit your changes at:\n  https://github.com/Valums-File-Uploader/file-uploader\n- Readme at https://github.com/valums/file-uploader/blob/2.0/readme.md\n- VERSION 2.2-SNAPSHOT\n- Original version: 1.0 \u00a9 2010 Andrew Valums ( andrew(at)valums.com )\n- Current Maintainer (2.0+): \u00a9 2012, Ray Nicholus ( fineuploader(at)\n  garstasio.com ) \n- Licensed under MIT license, GNU GPL 2 or later, GNU LGPL 2 or later,\n  see license.txt. */\nI'll take a look into 3.0. Thanks,\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/525#issuecomment-11182289.\n. I'm still not sure I understand how a request, sent by the uploader, will ever not contain a content-type.  The uploader should not ever send a request unless there is a file to upload.  If this is happening, please let me know and provide specific reproduction steps.\n. Seems reasonable to me.  Thanks!\n. What specific problem are you having?\n\nOn Mon, Dec 10, 2012 at 1:09 PM, Michael Dotterer\nnotifications@github.comwrote:\n\nWhen using the FineUploaderBasic it attempts to eval any html response it\ngets. Ideally for the basic uploader it would just pass the html on to the\ncustom handlers.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/527.\n. I'm still not 100% sure we are on the same page here.  Please set \"debug\"\noption to true, and list the exact contents of the javascript console when\na response is parsed.\n\nIt sounds like you are asking for me to modify the uploader to handle a\nnon-JSON response.  If so, that isn't going to happen.  There is simply no\nreason why your response cannot be proper JSON and contain HTML as one of\nthe property values.  Without a valid JSON response, containing a \"success:\ntrue\", how is the uploader to know if the operation was successful?\nOn Mon, Dec 10, 2012 at 1:34 PM, Michael Dotterer\nnotifications@github.comwrote:\n\nI'm using the basic uploader to upload an image and the resource normally\nresponds with an html document that contains, among other things, a status\nmessage to show to the user. Even though it is html and not json the\nUploadHandlerXHR tries to parse it as JSON anyway and logs an error. (\nhttps://github.com/valums/file-uploader/blob/master/client/js/handler.xhr.js#L138)\nLooking at the code again, I might be able to get all the information from\nthe fourth argument sent to the callback, but it would still be nice if it\ndidn't log an error in this case and behaved more like the success handler\non jQuery.ajax where it parses the JSON only when the server responds with\nthe proper content type.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/527#issuecomment-11213474.\n. A response code is not a good cross-browser method for determining if a\nrequest has failed in the context of a pure-javascript uploader.  For\nexample, in some cases, we must fall back to submitting a form inside a\nhidden iframe.  This is required if the user agent does not support the\nFile API.  In this scenario, there is no way to recover the response code\nclient-side.  In fact, if a non-200 response code is returned in this\nscenario, and IE is the user agent, any response content returned by the\nserver will be replaced by a \"friendly\" error message, supplied by IE & the\noriginal response content will be discarded.\n\nOn Mon, Dec 10, 2012 at 2:48 PM, Michael Dotterer\nnotifications@github.comwrote:\n\nHandling a non-JSON response is what I was asking for. Feel free to close\nthis ticket.\nI think the uploader should be able to know if the operation was\nsuccessful from the status code of the response instead of content in the\nbody. In that case, the user would be free to use whatever format they feel\nlike. The full uploader would probably still require a JSON response\nbecause it has more demands on the data, but it would make the basic\nuploader more flexible.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/527#issuecomment-11216809.\n. Thanks again @tellibus!\n. Please read the server requirements section of the readme.  It also looks like you may be using an old version of Fine Uploader.  I suggest you upgrade to 3.0.  If you have other issues, please post them in the forum.\n\nOn Tue, Dec 11, 2012 at 7:57 AM, Andrei Varanovich <notifications@github.com\n\nwrote:\nI have a pretty simple code for the upload component:\nfub = $(self.el).find('.upload')\n  uploader = new qq.FileUploaderBasic(\n    button: fub[0]\n    action: '/api/users/current/profile/upload'\n    debug: true\n    params: authenticity_token: $('meta[name=csrf-token]').attr('content')\n    allowedExtensions: ['jpeg', 'jpg', 'gif', 'png']\n    sizeLimit: 204800,\n    onComplete: (id, fileName, responseJSON) ->\n      $(self.el).find('.avatar').find('img').attr('src', responseJSON.src)\n      return\n    )\nThen I have Rails server which processes the image and responds with the\nrender json: {:success => true, :src => profile.image.url}\nEverything works fine, except that IE9 tries to download the response as a\nfile. Seems like it doesn't like the content type.\nI found this discussion\nhttp://stackoverflow.com/questions/8151138/ie-jquery-form-multipart-json-response-ie-tries-to-download-response\nThe advise is to return text/html and then parse JSON on the client.\nHovewer, with that approach, I cannot get any data in the onComplete\ncallback.\nAny ideas?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/529.\n. Please read the associated blog post for more details on the implementation.  I ended up making this a bit simpler than the original description in this case.\n. Care to elaborate? I generally don't accept feature requests without any description.  Perhaps you'd like to explain why this is important, how you imagine fine uploader would best integrate with angular, etc.\n. Interesting.  I'll look into this more as time allows.  Thanks for bringing this to my attention.\n. Thanks for sharing this.  It is my intent to publish an official Angular directive for Fine Uploader, just as soon as I have some extra time to play around with Angular & become more familiar with this framework..\n. Perhaps we can show how to do this in a blog post.\n. @redterror We do plan on authoring regular blog posts detailing how to integrate Fine Uploader into other libraries, and vice versa.  The first of these blog posts will start either this week or next.  Angular is definitely on our list and will likely be one of the focus of one of these first few entries.\n. Thanks @willvincent.  Just a few comments:\n- No need to write server-side logic to ensure file names are always unique.  Fine Uploader sends a UUID along with each upload request.  You can use that to name your files.\n- Client-side previews will be generated for you starting with Fine Uploader 4.0.  Support for server-side thumbnails for older browser files that cannot be displayed natively will also exist.\n- Starting with 4.0, the templating will be much different.  That is, no more template HTML as a long string in javascript files.  It can (and must) be declared in your document/markup instead.\n. Sure you can.  Store the path or UUID in your DB along with the original file name.  That's how we are doing it, at least.\n. @willvincent Why would you say that 4.0 won't be friendly w/ angular?  The templating change is a good one, IMHO.  HTML doesn't belong in javascript files, it belongs in markup/documents.  Why would this be a problem for an angular directive?\n. Expanding on my last two comments:\n\nIf you find yourself \"renaming files until they become unique\" presumably in a loop, it's time to re-examine your approach as this is a bit kludgey.  The proper way to prevent name conflicts between files in a file system is to either name them using a generated UUID (such as the one provided by Fine Uploader), or store them individually in UUID-named directories.  With the first approach, you can map the UUIDs to the original names in your DB.  If you want to ensure that file assumes the original name when a user downloads it (again assuming the first approach), the proper way to do this is to set the Content-Disposition header in your server's response (containing the file) to the associated GET request (e.g. Content-Disposition: attachment; filename=\"original_file_name.txt\").\nAs far as angular is concerned, I see no reason why moving the template into the document \"won't be terribly friendly with Angular\".  If you need to make adjustments to your template from some javascript in your directive, you can still do that, just as you would modify any other DOM element.  But it's much more intuitive to modify HTML in an HTML file.  It's acceptable in most cases to deal with small amounts of HTML in javascript files, but the size of the template in Fine Uploader continues to grow and become more complex.  Arguably, it should have never been part of the javascript file.  It's simply not proper to work with non-trivial HTML fragments in a javascript file.  Manipulating a long string of HTML is frustrating and unintuitive.  This becomes a bigger problem if you split the integration work of a library like Fine Uploader between a developer and a designer.  In that case, the designer naturally wants to work with the HTML/CSS and leave the JS and other code to the developer.  There were a number of issues with Fine Uploader's templating system, and some of them are addressed by moving the template out of the javascript code.  \nOther issues with templating will be addressed in this (4.0) release as well.  For example, it was not possible to remove an element from the template.  This would cause the uploader to break.  This meant that changes/additions to the template over time would cause existing apps to break if they overrode the template previously (until they updated their template, even if the new element(s) were not needed by the app).  Also, Fine Uploader used the same CSS classes on each template item for both default styling and for selection internally.  This made it complicated to remove or change the CSS class.  Both of these issues will be fixed in 4.0, along with a number of other templating improvements.\n. We intend to write on a blog post detailing how Fine Uploader can be integrated into a Angular-based image-centric application.  In essence, this will function exclusively as an image uploader.  In fact, the goal is to write a guide for a full-stack javascript-only integration of Fine Uploader using Angular on the frontend and node.js on the backend with some advanced client-side custom features.  \nHere's the plan:\n- Dependencies: Fine Uploader, and Angular (also maybe Bootstrap & jQuery since BS requires JQ).\n- Include a document, a directive JavaScript file, and a server-side handler (node.js)\n- Options to be specified via attributes on the directive's container element.\n- Template to be specified in the document\n- Feature support: UI mode, previews, server-side thumbnails (for old browsers), delete file, cancel, retry, drag & drop, chunking, auto-resume\n- Visible & scrollable drop-zone that also displays file list\n- Traditional endpoint support\n- View larger preview/thumbnail in a Bootstrap modal by clicking on smaller thumbnail/preview?\n- Aggregate progress bar\nServer work covered in #1019.\n. This is in progress right now.  Once I have the code working locally, I'll create a blog post complete with code along with a link to all code used in the blog post for those who want to use it as a boilerplate for their own projects.  This will take at least a few more days as I'm a bit rusty with Angular (I haven't used it in a while) and this will be a fairly advanced example.\n. Code for this blog post is being staged at https://github.com/Widen/fine-uploader-examples/tree/master/src/angularjs-nodejs.\n. The code is complete, see: https://github.com/Widen/fine-uploader-examples/tree/master/src/angularjs-nodejs.  I'm writing up a corresponding blog post as well.\n. This issue was closed almost 3 years ago. If you have a bug report or feature request, please open up a new issue. Otherwise you can post on Stack Overflow under the fine-uploader tag.\n. Thanks!\n. Anyone else care to comnent?\n. Are there any potential consequences of the change you are suggesting?\n. You might want to post a reference to this case in the support forum.  Perhaps other PHP developers will be more likely to see it there.\n. You will need to be more specific.  Where, specifically, does the\ndocumentation need to be adjusted?\nOn Dec 13, 2012 5:37 AM, \"templth\" notifications@github.com wrote:\n\nThe documentation is still describing the version 2 style to register\ncallbacks.\nThierry\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/534.\n. The section you are referring to contains examples for the jQuery plugin,\nand version 2 didn't even have a jQuery plug-in.  All of the examples are\ncorrect as far as I can see.\n\nOn Thu, Dec 13, 2012 at 7:17 AM, templth notifications@github.com wrote:\n\nHello Ray,\nThe callbacks section (\nhttps://github.com/valums/file-uploader/blob/master/readme.md#callbacks)\nseems to correspond to version 2 instead of version 3.\nOtherwise, I can see that the other callbacks section (\nhttps://github.com/valums/file-uploader/blob/master/readme.md#callbacks-fineuploader--fineuploaderbasic)\nis up to date.\nThierry\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/534#issuecomment-11333939.\n. Callback are accessible as events using the jQuery plug-in.  The syntax\nrequired for binding to callbacks/events when using the jQuery plug-in is\nconsistent with all jQuery plug-ins.\n\nOn Thu, Dec 13, 2012 at 8:00 AM, templth notifications@github.com wrote:\n\nI understand better now! Thanks!\nPerhaps could you add a listing for the callbacks section (\nhttps://github.com/valums/file-uploader/blob/master/readme.md#callbacks).\nWhy it's not the same way to configure callbacks for both ways? It could\nappear confusing for developers from my point of view...\nOtherwise thanks very much for your excellent tool and documentation. All\nmy comments only aim to help you improving it.\nThierry\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/534#issuecomment-11335198.\n. Can you provide a line number for the error when using the non-minified\nversion?  Also, specific steps needed to reproduce will also help me look\ninto this further.\nOn Dec 13, 2012 9:20 PM, \"Adam Krebs\" notifications@github.com wrote:\nRan into this while testing with fineuploader on IE9:\nUnable to get value of the property 'querySelectorAll': object is null or undefined\njquery.fineuploader-3.0.min.js, line 38 character 98\nIt's a FUB button that I'm using the jquery plugin on. Will get more info\nif you need it.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/535.\n. It sounds like you are indeed running a very old version.  I would suggest upgrading.\n. I suggest you upgrade and see if the issue persists.\n\nOn Wed, Feb 18, 2015 at 8:39 AM, farhantahseen notifications@github.com\nwrote:\n\nEverything is going good, if you suggest anything in this regard i will be thankful to you dear\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/535#issuecomment-74873747\n. According to the web page for that library, Fine Uploader is not used.\n. Ah, looks like the web page simply hasn\u2019t been updated.  I suspect uploadify was dropped due to the abysmal quality of the library.  \n\nThere are quite a few breaking changes between 3.0 (the version uberuploadcropper is using) and the current version (5.1.3).  It\u2019s possible uberUploadCropper code may need to be changed after the upgrade as well.\n. It's possible, but there aren't any commits to that library since early 2013, so that probably won't happen.  If you want to continue to use uber cropper, you'll probably need to fork the repo, update Fine Uploader, and then adjust the uber codebase to account for the changes in Fine Uploader since v3.\n. Sure.  The Fine Uploader docs site includes extensive documentation for breaking changes in 4.0 as well as breaking changes in 5.0.  This should help you make the proper adjustments to uber after you upgrade Fine Uploader.\n. What do you mean by \"handled?  Note that this is not a viable cross-browser option as there is no way to access response codes when the request is initiated by a traditional form submit (something we have to do in browsers that do not support the File API).  Furthermore, non-200 response content is replaced in IE, by default, with a \"friendly\" error message loaded from disk.  This is why all response codes should be 200 and all response content should be valid JSON.\n. If you can modify the response content by adding a 3-digit response code, certainly you can include a success property in the response and ensure it is valid JSON, unless I'm missing something.\n. Can you provide me with an example of a raw response you are describing?\n. Thanks!\n. Can you please describe, in detail, the improvements you made and which browsers you tested with?\n. Excellent work!  Thank you so much for your contribution!\n. This will be part of 3.1.1.\n. Have you tested your \"hack\" with IE9 and older?  Based on what you have listed in your question, it sounds like you may not have accounted for uploads that are not XHR based.  Often, when users attempt to modify the uploader code, they are not aware of all of the code that is in place to ensure everything works smoothly in all browsers and situations.\nThe tricky part here is dealing with browsers that do not have proper support for XHR/ajax-based uploading.  In those cases, we submit a form inside a hidden iframe.  So, the server response becomes the content of the iframe.  It is much easier, especially in this case, for the uploader to expect valid JSON, and consider anything else a failure. \nIs the a reason why you can't simply return your XML as a value of a property, present in a valid JSON response?\nFor example:\njson\n{\"success\":true, \"myXml\": \"<something><somethingelse>bar</somethingelse></something>\"}\nThe above suggestion is what I would recommend you do.  I'm not keen on adding the sort of complexity to the uploader codebase that your feature request would require.\n. Scheduled for 3.2.\n. Noted.  A request for such an option also comes from a fellow developer/co-worker.  So, I plan putting this into 3.2.  It has been marked as a P2.\n. In the 3.2-IP branch, I moved the formatFileName function to the options section so it can be safely overriden.  See the documentation and the source/diff for more details.\n. There is no way to make this happen, cross-browser, without issues.  I've written about why this is not possible in multiple cases.  Please have a look.\n. I'm not sure I understand exactly what you are asking for here.  If you are adding a DOM element yourself, you should currently have no problem selecting it at any time.\n. Are you asking for a way to identify the associated uploader when handling a callback? \n. Changing the context of the callbacks is not going to happen.  The vast\nmajority of users expect \"this\" to point to the current uploader instance\ninside of a callback, which it does.  This allows developers to easily call\ninstance functions.\nOn Dec 19, 2012 5:35 AM, \"NotionCommotion\" notifications@github.com wrote:\n\nYes. This will allow using \"this\" instead of hardcoding the ID in my\ncallback.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/543#issuecomment-11527048.\n. Not that \"this\" inside of a callback associated with the jQuery plug-in wrapper will point to the element associated with the uploader instance.  This is a standard convention, and may be what you are looking for in this case.\n. Please see my post about the jQuery plug-in.  If you are not using the plug-in, perhaps I could provide access to the value of the \"element\" option or the \"button\" option element via a public method.\n. I can provide the HTMLElement object that corresponds to the \"element\"\noption (FU) and/or the \"button\" (FU & FUB) via a public function.  Will\nthis suffice?\n\nOn Wed, Dec 19, 2012 at 9:09 AM, NotionCommotion\nnotifications@github.comwrote:\n\nThanks Ray,\nI currently do not use the jQuery plug-in, but might do so in the future.\nWould you potentially provide access to the \"value\" of the element, or to\nthe DOM? I am looking for the later as I wish to modify the page somewhere\nrelative to the location of the button.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/543#issuecomment-11533097.\n. Ok,  I'll tentatively schedule this for 3.2.  I'm finding that most of my time is now tied up responding to questions & support requests, leaving very little time to actually write code.  As a result, progress on features & bugfixes (at this point, the chunking & auto-resume features) is much slower than it was initially.  As a result, I'm not sure I will have time to complete much in 3.2 other than chunking & auto-resume.  Fine Uploader is becoming much more popular than I anticipated, so I will likely need to start looking for a second person to help maintain the project.\n. Is anyone still interested in this?  Is any of this still needed?  Please speak within the next 2 days, or forever hold your peace.  Just want to make sure before I spend any time on this since no one else has expressed any interest in this.  I'm speaking specifically about the comment just before this one.\n. No need to email me your changes.  I'm going to think about this for a day.  It seems reasonable to be alerted when the element related to the file has been added to the DOM, but I'm not sold on the name of this callback yet.  Again, I just want to think about this for a day or two before I push forward, in case I come up with a more appropriate solution (if a more appropriate solution even exists).\n. I'm thinking of just adding an onSubmitted callback that is invoked at the end of the internal _onSubmit function in qq.FineUploaderBasic.  Thoughts?\n. This has been implemented in 3.4-IP.\n. No problem.  If you haven't already, please examine my commit and let me know if i left anything out.\n. I plan on including this in 3.4.  I'll do some testing of my own, as soon as I clean up the few remaining bugs in the 3.4 milestone.\n. Actually, the title does not say it all.  Are you asking to allow specification name attribute for the hidden file input element created by Fine Uploader?  Or, are you talking about something else?\n\nPlease be more specific about your request, or open up a pull request so I can have a look at what you are trying to accomplish. \n. Why does your server care about the name attribute of the file input element?  It shouldn't.  If you want the server to be aware of some specific property of each uploader instance, you can pass parameters, unique to each uploader instance with each request. \n. Please open up a pull request with your changes so I can have a look.\nOn Thu, Dec 20, 2012 at 11:55 AM, pjfila notifications@github.com wrote:\n\nWell, the project is a huge one and I cannot refactr its logic as easily\nas change a little JS script :) First I have to say, that at the moment\nthings are OK for me. I just updated the fineuploader.js very very slightly.\nThe server side processes a very very huge form full of variables, if it\nencounters two input fields with the same name displays error. As I see it,\nthe simplest way how to avoid it is to change the name of the input. Not\neverything of the project is in my hands so I decided to allow this\nconfiguration of FU instead. And now it works fine :)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/544#issuecomment-11583594.\n. Closing, pending a pull request.\n. Why on earth would you want the Ajax request to be synchronous?\nOn Dec 20, 2012 8:14 AM, \"Philip Helger\" notifications@github.com wrote:\nHi!\nBy default the jQuery version of FileUploader 3.1.1 uses asynchronous\ntransmission mode for XHR.\nCould you please either support the jQuery AJAX stuff or add support for\nsynchronous transmission.\nSimply replacing line 2356\nxhr.open(protocol, url, true);\nwith\nxhr.open(protocol, url, false);\nsolves the issue for us.\nSo a basic request option would be great :)\nKeep up the good work!\n// Philip\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/545.\n. I'm not sure I can explain all the reasons why synchronous ajax requests are a bad idea, because there are so many. The main reason is due to the fact that web browsers (for the most part) are single-threaded.  That is, javascript and rendering tasks all compete for execution on one thread.  If one of these tasks block, the UI becomes unresponsive and nothing else can occur until the blocking task completes.  The one place where synchronous requests are acceptable is inside of a web worker, since web workers execute on a separate thread (not the UI thread).  \n\nUnless your code is running inside a web worker, you should NEVER utilize synchronous ajax requests.  This is simply bad practice.  The problem you described above can be addressed very easily by simply registering a Fine Uploader onComplete callback handler and performing whatever tasks you want after the last file has been sent.\n. Your current code, as listed in your comment, will initiate upload of all\nfiles immediately after initialization of the uploader.  Not sure if that's\nwhat you want to do.\nOn Thu, Dec 20, 2012 at 11:04 AM, Philip Helger notifications@github.comwrote:\n\nHi!\nThanks for the hint. I was not aware that this kind of calls is blocking.\nI'm now trying to build a solution as you suggested like this:\n$('#attachment-obj').on ('complete', function(id, fileName, responseJSON) {\nif (responseJSON.success)\n$('#finvoice').submit();\n})\n.fineUploader('uploadStoredFiles');\nstill trying...\nThanks for your help anyway!!!\n// Philip\n\nI'm not sure I can explain all the reasons why synchronous ajax requests\nare a bad idea, because there are so many. The main reason is due to the\nfact that web browsers (for the most part) are single-threaded. That is,\njavascript and rendering tasks all compete for execution on one thread.\nIf one of these tasks block, the UI becomes unresponsive and nothing else\ncan occur until the blocking task completes. The one place where\nsynchronous tasks are acceptable is inside of a web worker, since web\nworkers execute on a separate thread (not the UI thread).\nUnless your code is running inside a web worker, you should NEVER utilize\nsynchronous ajax requests. This is simply bad practice. The problem you\ndescribed above can be addressed very easily by simply by registering a\nFine Uploader onComplete callback handler and performing whatever tasks\nyou want after the last file has been sent.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11580830\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/545#issuecomment-11581503.\n. This is often asked, so perhaps I will make it a bit easier to track this.\nHowever, you can count the number of calls to your onSubmit handler.  Each\ncall that does not result in a false return value will result in a stored\nfile if autoupload is false.\nOn Dec 20, 2012 12:00 PM, \"Philip Helger\" notifications@github.com wrote:\nSorry for bothering you again, but how can I easily determine, whether a\nfile is in the queue or not if autoUpload is false?\ngetInProgress always returns 0 and I have seen no possibility to access\nthe _storedFileIds array :(\nAny help is appreciated.\n// Philip\n\nYour current code, as listed in your comment, will initiate upload of all\nfiles immediately after initialization of the uploader. Not sure if\nthat's\nwhat you want to do.\nOn Thu, Dec 20, 2012 at 11:04 AM, Philip Helger\nnotifications@github.comwrote:\n\nHi!\nThanks for the hint. I was not aware that this kind of calls is\nblocking.\nI'm now trying to build a solution as you suggested like this:\n$('#attachment-obj').on ('complete', function(id, fileName,\nresponseJSON) {\nif (responseJSON.success)\n$('#finvoice').submit();\n})\n.fineUploader('uploadStoredFiles');\nstill trying...\nThanks for your help anyway!!!\n// Philip\n\nI'm not sure I can explain all the reasons why synchronous ajax\nrequests\nare a bad idea, because there are so many. The main reason is due to\nthe\nfact that web browsers (for the most part) are single-threaded. That\nis,\njavascript and rendering tasks all compete for execution on one\nthread.\nIf one of these tasks block, the UI becomes unresponsive and nothing\nelse\ncan occur until the blocking task completes. The one place where\nsynchronous tasks are acceptable is inside of a web worker, since web\nworkers execute on a separate thread (not the UI thread).\nUnless your code is running inside a web worker, you should NEVER\nutilize\nsynchronous ajax requests. This is simply bad practice. The problem\nyou\ndescribed above can be addressed very easily by simply by registering\na\nFine Uploader onComplete callback handler and performing whatever\ntasks\nyou want after the last file has been sent.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11580830\n\n\u2014\nReply to this email directly or view it on\nGitHub<\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11581503>.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11582034\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/545#issuecomment-11583737.\n. I'll make sure this happens with the next release.  Thanks for the suggestion.\n. I'll probably take this opportunity to enhance the entire automated build/packaging script.\n. This will happen starting w/ the 3.2 release.\n. Why do you need to call xhr.responseText?  As long as your server-side code returns valid JSON with an \"error\" property, the error reason will be passed into the onError callback.  What specific situation are you trying to account for?\n\nOn Tue, Dec 25, 2012 at 5:41 AM, Sumh notifications@github.com wrote:\n\nplease add xhr parameter to onError(String id, String fileName, String\nerrorReason)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/547.\n. For starters, I'd say that using the Javascript alert function in a\nproduction app is generally not a good way to display messages to your\nusers.  I expected most developers to override the showMessage function and\nreplace the default implementation with a more user friendly modal dialog\nthat is consistent with the rest of the application's UI.\n\nThat said, I realize that some, perhaps even many developers will be\ncontent with the default implementation of the showMessage function.  I\nsuspect safari on IOS has a problem with an alert function that is invoked\nin an input element's onChange event handler.  If this is the case, I also\nsuspect the problem can be addressed by simply adding the alert function\ninvocation to the UI thread queue instead of executing inline when handling\nthe onChange event.\nI'll look into this for 3.2.\nOn Dec 25, 2012 11:17 AM, \"turntreesolutions\" notifications@github.com\nwrote:\n\nIf user picks a file bigger than the maimum size or of a non supported\nextension, the javascript alert pops up on the Safari (on iPad haven't\ntested iPhone) and freezes the page. Only way to get out is to close Safari\nall together and re-open.\nNormal js alert() calls on other pages of our app work fine, it is just\nthe alert being spawned from inside of the fileUploader functions that\nfreezes Safari.\nAny insight/help/solution to this issue would be great - i can't figure it\nout :)\nThanks\nMatt\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/548.\n. Thanks for your report.  I've scheduled this for 3.2.  I don't anticipate this being difficult to fix.  \n\nIf my assumption is correct, you can probably work around this issue yourself very easily by overriding the showMessage function in your initialization options with the following code:\njavascript\nshowMessage: function(message) {\n   setTimeout(function() {\n      alert(message);\n   }, 0);\n}\n. Glad the fix worked for you.  I'll probably just modify the default showMessage implementation in 3.2 with the code I listed above (after a bit more testing).\n. Fixed in 3.2-IP.\n. You will have to be more specific about your problem.  If you are finding\nthat files are \"damaged\" server-side, then your server-side code is to\nblame.\nOn Thu, Dec 27, 2012 at 7:44 AM, xoxoj notifications@github.com wrote:\n\nI paid $ 9 for a fine-uploader, but in IE8 upload a picture after picture\nfile is damaged, Firefox and Chrome browser. Code is as follows:\nI'm using django\n\"\"\"\n@author https://github.com/author: Ferdinand E. Silva\n@email https://github.com/email: ferdinandsilva@ferdinandsilva.com\n@website https://github.com/website: http://ferdinandsilva.com\n\"\"\"\nimport os\nfrom django.conf import settings\nfrom django.utils import simplejson as json\nimport time,ImageFile,uuid,Image,StringIO,cStringIO\nclass qqFileUploader(object):\ndef init(self, allowedExtensions=None, sizeLimit=None):\n    self.allowedExtensions = allowedExtensions or []\n    self.sizeLimit = sizeLimit or settings.FILE_UPLOAD_MAX_MEMORY_SIZE\ndef handleUpload(self, request, uploadDirectory):\n    #read file info from stream\n    uploaded = request.read\n    #get file size\n    fileSize = int(uploaded.im_self.META[\"CONTENT_LENGTH\"])\n    #get file name\n    fileName = time.strftime('%Y%m%d%H%M%S'+'_topicimg.jpg')\n    #check first for allowed file extensions\n    #read the file content, if it is not read when the request is multi part then the client get an error\n    fileContent = uploaded(fileSize)\n    if self._getExtensionFromFileName(fileName) in self.allowedExtensions or \".*\" in self.allowedExtensions:\n        #check file size\n        if fileSize <= self.sizeLimit:\n            #upload file\n            #write file\n            file = open(os.path.join(uploadDirectory, fileName), \"wb+\")\n            file.write(fileContent)\n            file.close()\nreturn json.dumps({\"success\": True, \"size\": fileSize})\n    else:\n        return json.dumps({\"error\": \"File is too large.\"})\nelse:\n    return json.dumps({\"error\": \"File has an invalid extension.\"})\ndef _getExtensionFromFileName(self, fileName):\n    filename, extension = os.path.splitext(fileName)\n    return extension.lower()\ndef _changeisize(self, image_file):\n    imgSrcSize = image_file.size\n    width = imgSrcSize[0]\n    #print width\n    height = imgSrcSize[1]\n    if width > 468:\n        if width > 468:\n            now_x_point = (width - 468) / 2\n        else:\n            now_x_point = 0\n            #print now_x_point\n        if width > 468:\n            image_file = image_file.crop((now_x_point,0,width,height))\n            image_file = image_file.crop((0,0,468,height))\n        if width <= 468:\n            image_file = image_file.crop((now_x_point,0,width,height))\n            image_file = image_file.crop((0,0,width,height))\n    return image_file\n@csrf_exempt\ndef img_topic(request):\nallowedExtension = [\".jpg\",\".png\",\".gif\"]\nsizeLimit = 50024000\nuploader = qqFileUploader(allowedExtension,sizeLimit)\nreturn HttpResponse(uploader.handleUpload(request, settings.MEDIA_ROOT + \"upload_topic_img/\"))\n[image: ie8-error2]https://f.cloud.github.com/assets/1118723/32579/6d6d23d4-502b-11e2-8f3b-94cff538812c.jpg\n[image: ie8-error1]https://f.cloud.github.com/assets/1118723/32578/66e213da-502b-11e2-8ac7-a5628248cc38.jpg\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/549.\n. I cannot provide support for your server-side code.  Firefox and Chrome support the File API, which means, by default, files are sent using a lightweight POST request (via XHR) where the file is streamed.  For browsers that do not support the File API, such as IE9 and earlier, the file is sent as a successful form control (also known as a \"part\") inside of a multipart encoded request.  Most likely, you are not accounting for multipart encoded requests.  Have a look at the PHP example in the server folder of the Fine Uploader github project for an example of how to handle MPE requests.\n. What new random filename?  I'm not sure I understand.  Fine Uploader does not provide any \"random\" filenames.\n. Then you can simply modify the php example to return the new filename in\nthe response.  It will then be available for your onComplete callback.\nOn Dec 28, 2012 12:47 AM, \"CODEDEV\" notifications@github.com wrote:\nDear rnicholus\nthis code is php code\nhere server/php.php\nlineno: 244\nif(!$replaceOldFile){\n/// don't overwrite previous files that were uploaded\nwhile (file_exists($uploadDirectory . DIRECTORY_SEPARATOR . $filename .\n$ext)) {\n$filename .= rand(10, 99);\n}\n}\nthis new file name is not available in java-script code\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/550#issuecomment-11726444.\n. Hello Ryan.  The notice you are referring to is a part of the FineUploader UI.  Since you are the first to request such a modification, and since this notice can be hidden quite easily through your own code, it seems like adding another API function or option would add clutter to the library.  \n\nYou can hide the file info at any time using javascript.  Since you are obviously using jQuery, I'll provide a jQuery example:\njavascript\n$('#myUploader').on('complete', function(event, id, filename, responseJSON) {\n   var fileItem = $(this).fineuploader('getItemByFileId', id);\n   setTimeout(function() {\n      $(fileItem).find('.qq-upload-file').hide()\n                 .end().find('.qq-upload-size').hide();\n   }, 5000);\n});\n:warning: The above code is untested.\n. Currently blobs are not supported.  There is a type check in the xhr upload\nhandler to ensure the entity is a File.  Can you please explain your\nsituation a bit more? Why do you want to upload a Blob?\nOn Dec 27, 2012 11:13 PM, \"\u5c0f\u677e\" notifications@github.com wrote:\n\nCan Blob object upload by addFiles method?\nor convert blob to file?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/552.\n. I'll look into this for 3.2, but I'm not sure I'll be able to refactor the code to support this until 3.3.\n. This needs to stay open if you want me to work on it.\n. I'll probably create a new API function specifically for submitting a Blob to the uploader.  I imaging a name can be optionally passed along with the Blob for display purposes.  If omitted, some default text will need to be used.\n. Feature is now part of 3.3-IP.\n. Do not attempt to access variables or functions that start with an underscore.  These are private by convention.  In the near future, they will be completely inaccessible.  There is already a feature request open to allow changes to the endpoint after initialization.  See case #509.\n. Actually, once 3.2 releases, your workaround will break as i have prevented access to all private fields and functions.\n. ...in the upload handlers.\n. I'll see if i can fit this feature into 3.2...\nOn Dec 28, 2012 8:45 AM, \"defari\" notifications@github.com wrote:\nThanks for your answer.\nAnyway, I haven't found any better solution, which could solve this\nproblem for my client-side module. It's because of RESTful backend. I need\nto initialize uploader before any additional data would be received. That\nis why I can't detect which endpoint would be required.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/553#issuecomment-11733057.\n. This is a duplicate of #509.\n. Why would you want to change the protocol type?  I'm guessing you are actually referring to the request method and not the \"protocol\", but why would you want to change that?\n\nOn Sat, Dec 29, 2012 at 7:16 AM, defari notifications@github.com wrote:\n\nHi.\nIt would be nice, if it was possible to set protocol type on\ninitialization of uploader.\nI can open up a pull request with changes, but a bit later.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/554.\n. It looks like the request method is incorrectly referred to as the protocol on the code.  That's likely been there for quite a long time.  I'll fix that, and I'll add an option to toggle between POST and PUT, since either, arguably, are valid methods inn this context.  I don't plan on explicitly allowing the method to be, say, GET, though, since that would not be the correct method to use.\n\nI'll try to fit this into 3.2, but 3.2 is getting crowded, and I'm running out of time.  Out may be moved into 3.3, along with some other features.  I'll have to take another look at the 3.2 schedule this weekend and perhaps reprioritize some of the cases.\n. @defari I'm not sure if you are aware of this but it is not possible to submit a form as a PUT request.  Since the form uploader (used by IE9 and earlier, along with some versions of Android) uses a form submission to upload files, your server-side code will have to handle POST requests anyway.  I'm hesitant to add this feature, since it will only work for XHR uploads.  Please let me know your thoughts.\n. @defari Since you will have to account for POST requests when handling uploads from\nbrowsers that do not support the File API, I'm thinking it makes sense to\nleave the code as it is and close this case.  Is that ok?\nOn Sat, Jan 5, 2013 at 7:23 AM, defari notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus Yes, I do.\nActually, the only way I found before using the Fine Uploader (\ntemporarily ), was form, but not with a PUT request. I catched the form\nsubmitting event, and than I used for file sending something like this:\nvar\n     xhr = new XMLHttpRequest(),\n     formData = new FormData(),\n     onReady = function( e ) { },\n     onError = function( err ) { };\nxhr.open( data.id ? 'put' : 'post', _url );\nxhr.addEventListener( 'error', onError, false );\nxhr.addEventListener( 'readystatechange', onReady, false );\n// here append data ...\n// than send\nxhr.send( formData );\nSo, as I understood, the only way is to change my server-side RESTful API\nservice, and let in some cases to handle POST on update operations..\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/554#issuecomment-11913912.\n. I generally don't provide any support for anything other than the most\nrecent version.  Please upgrade to 3.1.1 and reopen or let me know if you\nhave any further issues.\nOn Jan 1, 2013 4:45 AM, \"Borut Toma\u017ein\" notifications@github.com wrote:\nOn some FU instances I get this error in console:\nTypeError: this._element is null\nthis._element.innerHTML = this._options.template; (line 1018 of\njquery.fineuploader-3.0.js)\nAnd when I select file for upload I get another error:\nTypeError: this._listElement is undefined\nthis._listElement.innerHTML = ''; (line 1299 of\nquery.fineuploader-3.0.js)\nThis is the code:\n$(\"#buttonContainer\").fineUploader({\n    debug: true,\n    uploaderType: \"basic\",\n    multiple: false,\n    maxConnections: 1,\n    button: $(\"#button\"),\n    request: {\n        endpoint: \"FileUpload.php\"\n    }});\nI can't figure it out why do I get this error.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/556.\n. Looks like the gradle plugin that combines the Javascript files was compiled with java 7.  So, yes, you'll need Java 7.\n. This isn't a problem, and jslint/jshint does not flag this as an issue.  But, I'll probably modify the code at some point to prevent the js gradle plugin from flagging this.  This error actually comes from the Google Closure Compiler, which the gradle js plug-in uses to minify javascript.\n. ...note you must compile master (3.1.1) if you plan on supporting Android clients in your app\n. The first parameter in a for loop is not necessarily a \"start value\", it is simply an expression,  It can and usually is used to initialize a variable used in the body of the loop, but that is not the case here.  I'm guessing the parameter is null simply to appease jslint, but it probably should just be empty.  I suspect if null is removed and this is left as an empty/undefined param, GCC will no longer complain.\n. fixed in 3.2-IP\n. Without seeing all of your code, I assume you are, server-side, accounting for a lightweight POST request w/ the file streamed from the client for browsers that support the File API, and a multipart encoded request for all other browsers (such as IE9 and earlier, along with some older versions of Android).  In that case, it doesn't make sense to remove the filename parameter in the request, since your server-side code will not know the filename of the entity associated with the incoming response, if the file is streamed.  \n\nPerhaps you are simply saying that you don't want any parameters present in the query string.  If that is the case, you can simply set the paramsInBody property of the request option to true.  This will force all requests to be multipart encoded, and all parameters will be part of the request body.\n. An anchor tag should work fine.  Your problem is likely caused by the style\nattributes you have associated with your anchor element or perhaps some other flaw in your code.\nOn Wed, Jan 2, 2013 at 4:03 PM, Ray Nicholus ray@garstasio.com wrote:\n\nYou'll have to be more specific about your problem.  What, specific steps\nare you following, and at which point are you running into a problem?\nOn Wed, Jan 2, 2013 at 3:27 PM, bluesclues9 notifications@github.comwrote:\n\nI have tried both 2.1 snapshot version and the new version (3.1) but IE8\ndoesn't let me select a file from the local c drive.\nI have purchased both jquery and non-jquery versions of 3.1 today.\nHope to receive a fix and/or guidelines soon\n-Sri\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/560.\n. Looking closer at your code, your markup is invalid - you neglected to close your anchor tag.  Also, the text node for the button must be a child of the anchor. \n. That is absolutely not the correct change to make.  Simply setting the\ncontent-type to multipart does not make it a multipart encoded request.  If\nyou want to ensure all requests are multipart encoded, you can set the\nforceMultipart request option.  Otherwise, MPE requests are sent only by user agents that do not support the File API (IE9 and earlier, along with some versions of android). \n\n\nOn Thu, Jan 3, 2013 at 12:52 PM, spiraldev notifications@github.com wrote:\n\nI am using Railo version of ColdFusion and the file was not uploading\ncorrectly so in the file below\nfile-uploader / client / js / handler.xhr.js I had to change\nline 108 xhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\nto\nxhr.setRequestHeader(\"Content-Type\", \"multipart/form-data\");\nI don't know if this is the right place to add this, so I am sorry if it\nis not.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/561.\n. Also \"the file was not uploading correctly\" does not tell me anything about the problem you are having.\n. Something server-side is mangling the file, then.\n. That really doesn't make any sense.  Simply setting the content-type header to \"multipart/form-data\" does not make the request multipart encoded.  It sounds like you have some issues with your server-side code that need to be addressed.\n. Fixed in 3.2-IP.\n. Right you are.  I'll re-open this and adjust the title.\n. @twig I've just added a commit that also includes your fix from #576.  Can you please verify that this fixes both problems for you?  Thanks for catching this, by the way!\n. @twig Minor change to that addition in this 3rd commit above...\n. In most browsers, there is no way to determine the full path of the file\nclient-side, so you will not be able to distinguish between files in\ndifferent folders.\nOn Jan 4, 2013 6:10 AM, \"sacher74\" notifications@github.com wrote:\nIs there a way to check in the onSubmit event if a file is already in the\nqueue?\nI'm using uploader with autoUpload option set to false, and I'd like the\nuser can't select the same file more than once. Different files with same\nname (e.g. same file name in different folders) have to be allowed. Thank\nyou\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/563.\n. nope\n\nOn Fri, Jan 4, 2013 at 8:20 AM, sacher74 notifications@github.com wrote:\n\nThank you, Ray. So I think it isn't also possible server-side...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/563#issuecomment-11884140.\n. No response from creator of issue, closing.\n. Most likely your server-side code is not returning valid JSON.\n. https://github.com/valums/file-uploader/blob/master/docs/options-fineuploaderbasic.md#request-option-properties\n. Fixed in 3.2-IP.\n. This is already possible by making use of the onValidate callback.  By utilizing this callback, you can also track the number of files.\n. Currently, there is nothing in the (public) API that allows you to retrieve the size of a file, given an ID.  The reason onValidate callback does not provide IDs for each file is due to the fact that the IDs are created by the upload handler modules, and the onValidate callbacks are invoked before a file is submitted to the upload handler.\n\nThe base upload handler does contain a getSize(id) function.  However, the upload handler instance is private.  I can certainly provide API functions in 3.2 that return the file size (and name) given an ID.  In the meantime, you will need to add a getSize function to qq.FineUploaderBasic that returns the result of the upload handler's getSize function.  \nNote that the XHR uploader will return a file size, but the form uploader will not as there is no way to obtain a file's size (client-side) when using the form uploader.  This means that you will not be able to perform any size-related validation when using IE9 or older, or some versions of Android.\n. Excellent.  I'll likely add the getSize function to the 3.2 release.\nOn Mon, Jan 7, 2013 at 4:19 PM, kleesman notifications@github.com wrote:\n\nI added the following functions to qq.FineUploaderBasic in\nuploader.basic.js and was able to handle everything I needed and eliminate\nthe need to calculate the total file size on the page.\nThanks for your help!\ngetSize: function (fileId) {\n  return this._handler.getSize(fileId);\n},\ngetStoredFilesTotalSize: function () {\n  var totalSize = 0;\n  for (var i = 0; i < this._storedFileIds.length; i++) {\n    totalSize += this.getSize(this._storedFileIds[i])\n  }\n  return totalSize;\n},\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/566#issuecomment-11974792.\n. Feature has been added to the 3.2-IP branch.\n. fixed in 3.2-IP\n. Fixed in 3.2-IP.\n. Instead of adding another parameter to one specific callback, it seems like it would be better to add a function to the API that returns a File object given an ID.  If the user agent does not support the File API, this function would return null.\n. @dipcore Note that your \n\nif (window.File && window.FileReader && window.FileList && window.Blob) {\ncheck can be shortened to if (qq.isXhrUploadSupported() && window.FileReader) {\nAlso note that the window.Blob check is redundant, since window.File is on the same prototype chain as window.Blob and inherits all of its functions and properties.\n. This API function has been added to 3.2-IP.\n. Changed in 3.2-IP.\n. After some thought, i may revert this to prevent an avalanche of support requests from existing users.\n. The plugin is called fineUploader, not fineUploaderBasic.  As the jquery\nplugin documentation states, you must set the value of the uploaderType\noption to \"basic\" if you would like to use FineUploaderBasic when using the\njquery plugin.\nOn Jan 8, 2013 10:42 PM, \"bluesclues9\" notifications@github.com wrote:\n\nHi\nI am trying to use FineUploaderBasic within a JQuery Wrapper and I am\ngetting an error. Can you tell where I broke it?\nPlease note, I am trying to link to an anchor tag\nI can't use FineUploader as it's too heavy for my needs.\nThe call is like this...\n$('a#qq-upload-button').fineUploaderBasic({\nrequest: {\nendpoint: 'server/uploadFile'\n//parms: {UserFile: ???}\n},\nvalidation: {\nallowedExtensions: ['jpeg', 'jpg', 'gif', 'png']\n//sizeLimit: 51200 // 50 kB = 50 * 1024 bytes16\n},\nmultiple: false,\nautoUpload: true,\ndebug: true\n});\nThe error I am getting is\nUncaught TypeError: Object [object Object] has no method\n'fineUploaderBasic'\nAlso,\nI am trying to the actual input file name as a parm, not sure what\nvariable would hold that piece of info.\nI understand there is another option called inputName: with default qqfile\nbut in my case, the server is already expecting certain variable called\nUserFile so trying to populate this parm but not sure where I can get the\ninput file name.\nYour help is much appreciated with this. I am using 3.1.1 Jquery version\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/571.\n. You have not specified a button element option.\n\nOn Wed, Jan 9, 2013 at 8:19 AM, bluesclues9 notifications@github.comwrote:\n\nHi\nReference:#571 https://github.com/valums/file-uploader/issues/571\nI have tried uploaderType: 'basic' as shown below and nothing happens.\nDoesn't even attach input type=file to my element which is an anchor tag.\nI tried in both chrome and ie8.\nInteresting enough, it works if I remove \"uploaderType: 'basic',\" from my\ncode below.\nI am losing my head with this.\n$(document).ready(function () {\n$('#qq-upload-button2').fineUploader({\nuploaderType: 'basic',\nrequest: {\nendpoint: 'server/handleUploads'\n},\ndebug: true\n});\n});\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/572.\n. The target element of your plug-in should be the container holding the\nuploader component.  If you are using the uploader in basic mode, or if you\nare using the uploader in standard mode but want to specify a custom\nbutton, you must specify a button option element.  This is no different\nthan if you were to use the native javascript fine uploader library w/out\nthe jQuery plug-in wrapper.\n\nOn Wed, Jan 9, 2013 at 8:21 AM, Ray Nicholus ray@garstasio.com wrote:\n\nYou have not specified a button element option.\nOn Wed, Jan 9, 2013 at 8:19 AM, bluesclues9 notifications@github.comwrote:\n\nHi\nReference:#571 https://github.com/valums/file-uploader/issues/571\nI have tried uploaderType: 'basic' as shown below and nothing happens.\nDoesn't even attach input type=file to my element which is an anchor tag.\nI tried in both chrome and ie8.\nInteresting enough, it works if I remove \"uploaderType: 'basic',\" from my\ncode below.\nI am losing my head with this.\n$(document).ready(function () {\n$('#qq-upload-button2').fineUploader({\nuploaderType: 'basic',\nrequest: {\nendpoint: 'server/handleUploads'\n},\ndebug: true\n});\n});\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/572.\n. There is no demo code that matches your situation.\n\n\nAgain, if you are using the jQuery plug-in in \"basic\" mode, you must\nspecify a \"button\" option.  See the options section in the readme for more\ndetails on this option.  The element you are specifying as the target of\nyour plug-in is the container for the uploader component, NOT the button\nelement.\nOn Wed, Jan 9, 2013 at 8:27 AM, bluesclues9 notifications@github.comwrote:\n\nI am not quite sure if I understood. I took the same demo code from\nfine-uploader site.\nI thought $('#qq-upload-button2') is my element in jquery specification.\nnot correct?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/572#issuecomment-12046089.\n. Not a bug.  You are not declaring your callback/event handler correctly.  You are declaring your \"complete\" handler correctly, but not your \"submit\" event handler.  Remember, each of these callbacks correspond to events, so you must create your handlers with this in mind.\n\nPLEASE read the jquery plug-in documentation in its entirety before\nposting any more questions.  You can find the documentation here:\nhttps://github.com/valums/file-uploader#using-the-optional-jquery-plug-in.\n. Fixed in 3.2-IP.\n. Addressed in 3.2-IP.\n. 1.) Pull requests are only accepted on In Progress (IP) branches.\n2.) This has been fixed in the 3.2-IP branch.  Please see issue #562.\n. No need for another PR.  I'll just add your fix into the referenced bug.\n. At this point, it is scheduled for 3.4, since I have not had any time to consider how I may implement this.  Perhaps I move the DND code into a separate repo (as it may be able to stand on its own with some modifications) and import this repo into Fine Uploader as a submodule.  I would also need to add the proper hooks into FineUploaderBasic.  This would likely require some refactoring, at a minimum.\nIf I have some time to ponder this a bit more, and/or if I see a lot of other developers +1 this, I may move it up to an earlier release.\n. @jayd3e Is your comment directed at me or at the person who created this request?\n. There is a reason why libraries such as this one exist.  I'm sure you will find it quite difficult/frustrating to roll your own cross-browser file uploader, especially in a week.  There are a lot of tricks in place to appease all browsers, and a lot of  in-depth knowledge of HTML, HTML5, javascript, HTTP, CSS and the associated implementation differences among the browsers required to accomplish this.  I can assure you that simply tackling the drag and drop piece yourself will be your easiest option, if you are sure that overriding functionality provided by FineUploader mode is not worth your time.  Once your drag & drop code handles a file or files, you can simply pass them into Fine Uploader via the addFiles function, and it takes care of the rest of it for you.\nAs far as your last comment, I'm afraid I can't commit to a hard schedule. My first priority is my day job.  I work on Fine Uploader during my free time & lunch.\n. This feature is scheduled for 3.4.  The current release in-progress is 3.3.  At the top of each issue, I usually have a \"milestone\" specified.  Each milestone is generally a month or so of work.  I just started working on 3.3 on Monday as 3.2 was released on Sunday.  \nThis is currently scheduled for 3.4, and not 3.3, since, before yours, I only had one request for this modification.  I have much to think about as far as separating the existing drag & drop code from FineUploader mode.  I'd like to ponder it a bit more to ensure that I make a good long-term decision.  I've found that it's imperative to sit back and really think about each and every change I make to this library to ensure that I can continue to make the code more maintainable, prevent unnecessary refactoring or breaking changes later on, and ensure that the new feature is generic, helpful, and customizable enough so that it is beneficial to the vast majority of users.\nI believe that it should be relatively easy to write your own drag & drop code and simply feed the result (files) into the addFiles API function.  This would likely be easier that modifying the existing code in order to make it a candidate for a release. You can use the code in dnd.js as a model.  Note that dropping of files is only possible in browsers that support that File API.  That rules out IE9 and earlier.\n. Looks like I'll be working on this now due to a requirement for a product that Widen is developing.\n. Before I finish this feature off, I'd like to think about writing a jQuery plug-in wrapper.  This may not be worth the effort and it may require packaging a separate js file that wraps this module as a jQuery plug-in. I also need to do a bit more testing, and attempt to integrate this into some new features I am working on for Smartimage.\n. The dnd module would still be easily usable for jQuery users, even if i didn't create a jQuery wrapper for it as well.  After sleeping on it though, i think i will pursue creation of a jQuery plugin wrapper for the dnd module.  Hopefully I'll be able to wrap up this case today or tomorrow.\n. This feature has been completed in 3.5-IP.  Please see the associated blog post, which provides a short summary of the change along with a link to the readme page for the standalone DnD module.  The readme includes examples for both jQuery and non-jQuery users.  \nPlease open up a case if any improvements are needed.\n. Fixed in 3.2-IP.\n. Moving this to 3.3.  I think I'll do the following:\n- [x] figure out why maxConnections doesn't seem to be respected with the current logic (edit: it is, i overrode maxConnections in the wrong place).\n- [x] cancel the existing in-progress upload if the user selects/drops/adds a 2nd file\n- [x] ensure this behavior is explained in the multiple option documentation as well as in a FAQ entry\n- [x] ensure developers/users can cancel/ignore a dropped/selected/added file if multiple is set to false.  This may be desirable for some users/devs who don't want to cancel the in-progress upload when the user adds a 2nd file\n. Adjusted in 3.3-IP.\n. If you want to see progress of an upload to s3, then fine uploader must be modified to allow uploading DIRECTLY to s3, bypassing your application's server.  That is an interesting feature.\n. I assume you mean that this is only possible on browsers that support the necessary HTML5 APIs, such as the File API.  This is correct.  The same is true for the progress bar anyway.  It seems useful to allow uploading directly to S3 where supported, and then fall back to sending the file to your server for processing in browsers that do not support the required APIs, such as IE9 and older.\n. If you don't mind, I'd actually like to keep this open as a reminder to me.  I'd ultimately like to allow Fine Uploader ot upload directly to S3, if the UA allows this.\n. Directly to S3, bypassing your local server?  No.\nOn Sun, Jan 13, 2013 at 3:17 PM, Pushpinder Bagga\nnotifications@github.comwrote:\n\nI could not understand? Fineuploader does upload to S3... doesn't it?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/582#issuecomment-12200413.\n. Possibly, but I need to take some time to look into this further.\n. I'm afraid I won't have time to look into this further today.  It's unlikely I will even get to this during the 3.3 release cycle.  This is currently scheduled for 3.4.\n. I'm beginning to look into this now for the 3.4 release.\n. There is an article on the AWS site along with some more in-depth documentation that may provide all the documentation I need to (hopefully) make this work.  I don't think this will be a trivial feature to implement.  However, it seems like I may be able to make this possible on all supported browsers.  For browsers that support the File API, looks like I should make use of S3's Multipart Upload REST API to support chunking and resume.\n. Yep, this will likely be a very popular feature.  There are a handful of unknowns as far as implementation is concerned, and this has the possibility to be enough work to make this the only feature in 3.4, but I'm not 100% certain of that yet.  Regardless, this feature is in progress.\n. The form uploader issue is due to the fact that the response is not a JSON response.  Even if it was, it would, by default, come from a different domain, so we have cross-domain issues to deal with.  I plan on using the AWS REST API to support chunking.  I also plan on using the FormData object to construct the request for UAs that support the File API, and, of course, a  for UAs that do not support the File API.  For UAs that do support the File API, the request will be an XHR request, and the response status code along will likely be used to determine success.  For other UAs, such as IE9 and older, we may have to provide a success redirect URL on the same domain that returns a valid JSON response, perhaps as simple as a \"success: true\" response.  If that isn't received, failure is inferred and the generic failure message will be used.  I will also need to send a GET request while constructing the request in both cases that sends the policy \"document\" and expects a policy \"signature\" from the server.  \n\nThere are some other details that need to be addressed (such as the specifics required to support chunking/resume), but the above represents a high-level plan.  I haven't tested any of this out yet, it's just based on my understanding of the AWS API.\n. Another option, instead of sending a request to sign the policy document for each file or chunk may be to ask the server to generate temporary IAM credentials that can be used by the uploader client-side.  It seems like this would require passing the temporary private key to the client though.  That may not be a big deal, given the temporary, scoped nature of this key.  \nYet another option, for integrators with more basic needs, may be to have the server return a signed URL to be used as the S3 endpoint.  This approach means that some of the more advanced features, such as chunking, may not be possible.\n. @ahoward I tend to agree with you on passing the secret key, even if it is scoped and time-limited.  Just an idea I was considering.  \nI'm leaning more towards passing the constructed policy document server-side (JSON), expecting a base-64 encoded signature and a base-64 encoded policy document to be returned, which will be sent as request parameters to S3 along with the file or Blob.  This seems to be the recommended way to do all of this, according to the docs on Amazon's site.  \nI described all of this in a recent post in this case.\n. Each chunk must be signed, along with any other request, but there is no need to ask the server to re-sign each chunk.  The signed policy document from the first chunk can be re-used, as far as I can tell.  I already addressed the private key issue in my post above yours.\n. @coreappdev Thanks for you note.  I'll keep this in mind when I have time to get back to the S3 feature. For now it is on hold until the next release or so, as I am wrapped up in other changes to the library, and my time is unusually limited this month.\n. Hi there @anovak.  Providing an estimate for a feature of this scale is a bit difficult right now.  Fine Uploader is still in a transition period after being transferred to Widen.  We are currently in the process of hiring additional staff to help out with Fine Uploader.  I hope to start work on S3 support in 3.6 but may not be able to get to it until a later release.  I also hope to shorten release cycles to 3 weeks or less,.  There are a lot of other improvements on my list as well.  We are aware that S3 support is a very popular feature and we are going to make it a priority as soon as we have enough resources at our disposal.\n. This is, unfortunately, going to have to wait until our new hire has started as I don't have the time to give this feature the attention it deserves until then.  Moving to 3.7.  This will get top priority as soon as resources hired/allocated are freed up to dedicate their time and help me out with Fine Uploader.\n. I'm going to break this feature up into a couple stories and schedule this for the 3.8 release.  After I've broken this up, I'll close this particular issue.\n. Please see the new associated issues to track progress on this feature in 3.8.  \n@feltnerm We will need to storypoint these new stories before 3.8 work begins.\n. For anyone watching this story, native support for uploads directly to S3 from the browser is now completely functional for all supported browsers in the develop branch.  The plan is to make all of this a part of the upcoming 3.8 release.\n. What is the issue?  I don't know what I'm looking at.\n. Ah ok.  Just make the {uploadButtonText} text node a child of another DIV, so your template should look like this:\njavascript\n...\ntemplate: '<div class=\"qq-uploader without_label\">' +\n            '<pre class=\"qq-upload-drop-area\"><span>{dragZoneText}</span></pre>' +\n            '<div class=\"qq-upload-button btn btn-success\" style=\"width: auto;\"><div>{uploadButtonText}</div></div>' +\n            '<ul class=\"qq-upload-list\"></ul>' +\n            '</div>',\n...\n. It won't work.  There is no way, currently, to determine upload progress in any browser that does not support the File API.  I hope to address this in case #506, but that may not be trivial.\n. While investigating this, I noticed a much more sinister issue (causing this issue).  For chunked uploads, I always, previously, assumed that the sum of all bytes sent for all requests associated with a chunked file would equal the total file size.  Of course, I know this is not true, but I neglected to account for the additional overhead of a MPE request in the client-side code.  Since there is no way to ask the UA for the total size of the request before it is sent, I had to write some code that calculates the expected size of all requests associated with a chunked upload after receiving an onprogress event.  The onprogress event includes the total size of the request (event.total).  I can then calculate the overhead for that request by subtracting the file size from the total request size.  I have to re-estimate the size of all associated chunked requests for each chunked request, since there is no guarantee that the overhead will remain constant, especially if a developer/integrator changes the parameters in the middle of a chunked upload and the parameters are sent as form fields in the request payload (request.paramsInBody = true).  \nWhile this change means that the totalBytes parameter passed to the onProgress callback is not guaranteed to be a constant for MPE chunked uploads, it also means that this number, for all uploads (chunked and otherwise) will always refer to the total number of bytes that must be sent to the server to upload a file.  Previous to my change in this case, the totalBytes parameter of onProgress only fit this definition for non-MPE non-chunked requests (where the totalBytes parameter referred to the total file size).  \nI did some brief testing on IE10, Safari6, the latest Chrome, and the latest FF.  Everything seemed to function as expected after my changes, even when resuming an interrupted upload.  Note that the \"Processing...\" message may never appear in Firefox due to an implementation detail of Firefox's onprogress event notification system.  See my comment in another case on this issue for more details.\nNote that this change required I store additional information in the \"resume cookie\".  As a result, any \"resume cookies\" stored by earlier versions of FU (3.2) will be ignored after upgrading.  This can certainly be considered a breaking change, so I will mark it as such.  All files interrupted after upgrading will, of course, be resumable though.\nThis change is now available in 3.3-IP.\n. While investigating this, I noticed a much more sinister issue (causing this issue).  For chunked uploads, I always, previously, assumed that the sum of all bytes sent for all requests associated with a chunked file would equal the total file size.  Of course, I know this is not true, but I neglected to account for the additional overhead of a MPE request in the client-side code.  Since there is no way to ask the UA for the total size of the request before it is sent, I had to write some code that calculates the expected size of all requests associated with a chunked upload after receiving an onprogress event.  The onprogress event includes the total size of the request (event.total).  I can then calculate the overhead for that request by subtracting the file size from the total request size.  I have to re-estimate the size of all associated chunked requests for each chunked request, since there is no guarantee that the overhead will remain constant, especially if a developer/integrator changes the parameters in the middle of a chunked upload and the parameters are sent as form fields in the request payload (request.paramsInBody = true).  \nWhile this change means that the totalBytes parameter passed to the onProgress callback is not guaranteed to be a constant for MPE chunked uploads, it also means that this number, for all uploads (chunked and otherwise) will always refer to the total number of bytes that must be sent to the server to upload a file.  Previous to my change in this case, the totalBytes parameter of onProgress only fit this definition for non-MPE non-chunked requests (where the totalBytes parameter referred to the total file size).  \nI did some brief testing on IE10, Safari6, the latest Chrome, and the latest FF.  Everything seemed to function as expected after my changes, even when resuming an interrupted upload.  Note that the \"Processing...\" message may never appear in Firefox due to an implementation detail of Firefox's onprogress event notification system.  See my comment in another case on this issue for more details.\nNote that this change required I store additional information in the \"resume cookie\".  As a result, any \"resume cookies\" stored by earlier versions of FU (3.2) will be ignored after upgrading.  This can certainly be considered a breaking change, so I will mark it as such.  All files interrupted after upgrading will, of course, be resumable though.\nThis change is now available in 3.3-IP.\n. Seems possible, but only in browsers that support FileReader.  We'll look into this more in a future release.\n. As far as I know, hash calculation time is proportional to the size of the file to be hashed.  There is nothing we can do about this, as far as I can tell.  \nAnother concern is running out of browser memory when reading the file before calculating the hash.  This, we can probably deal with by splitting files into small chunks and feeding them into an MD5 calculator, chunk by chunk, until we are done.  Most likely, a library such as SparkMD5 would be imported into Fine Uploader to handle hash determination.  SparkMD5 adds some useful features (such as the ability to calculate a hash in chunks) on to fairly well-known md5.js script written by Joseph Myers.  Unless I completely misunderstand the MD5 algorithm and the SparkMD5 source, this should allow us to ensure that we do not exhaust browser memory while calculating a file's hash.\nIt may be useful to calculate the hash in a web worker as well, so we can free up the UI thread.\n. related to #848\n. @shehi Funny you mention this - I already had to implement file hashing client-side in order to support version 4 signature support in Fine Uploader S3 (see #1336 for details). However, that only hashes small chunks, and not an entire file in one go. So, pushing this a bit further and calculating the hash of an entire file client-side is certainly doable, but I think more work is needed for larger files to prevent the UI thread from locking up.\nIn order to complete this feature, I expect to use V4 content body hashing as a model, but expand upon that code as follows:\n- [ ] Hash the file in a web worker wherever possible. Where not possible, we'll need to consider a spinner or something similar.\n- [ ] Determine if there is a more efficient way to hash an entire file, especially one that is multiple GB. \n- [ ] Determine which hashing algorithm to use. I would expect to use the one with least overhead.\n- [ ] Setup a new option that includes an endpoint to send the hash.\n. Small chunk hashing is restricted to Fine Uploader S3, and only when generating version 4 signatures. I feel that this feature needs more input from other users before I consider implementing it. Some questions I have include:\n- Should we hash the whole file, or only a piece, or n pieces/bytes? \n- What hashing algorithm should we use?\nThese are questions that should be answered based on user input, as I want to create a solution that is generally usable.\n. > As I said, partial (as in few chunks) hashing should do the trick\nI'm not convinced that this is the correct approach, and am apprehensive about codifying this as the solution to this problem in a future version of Fine Uploader.\n\nsince it's small amount of data that needs hashing, who cares what algorithm is used\n\nThe server and client must use the same algorithm, otherwise the hashes will never match\n. The per-chunk checksum is already being calculated to support S3 v4 signatures, though it's not being used anywhere else at the moment. If each chunk is hashed, there isn't a good reason to re-hash the entire file as well, since this will add considerable overhead to the process, especially with very large files. As long as you combine the chunks in the order specified, the file is fine. \n. > Is there currently a way to use the per chunk checksum when using a traditional server (not S3)?\nNo, but it likely wouldn't be very difficult to integrate this into the traditional endpoint uploader. \n. This is something I'm looking into now. I don't see this being a feature implemented inside the Fine Uploader codebase. Instead, a couple small changes will be needed to make it possible to write some code that makes this possible using the existing Fine Uploader API and event system. I'll tackle this by making the required changes to Fine Uploader and then I'll write up a small integration example (probably with updates to an existing server-side example as well) that will make it easy for anyone using Fine Uploader in their project to benefit from this feature. My plan is outlined below.\nDuplicate file detection on upload\n\nUsable with any project that uses Fine Uploader.\nBig win for large files.\n2 possible ways to implement this, with \"plan A\" being the ideal.\n\nFor both plans, consider the following:\nOn my MacBook Pro, it takes 5 seconds to hash a 200 MB file in the browser. It will probably take less than a second to ask the server if that hash exists elsewhere. So, about 6 seconds. In either plan, a successful upload must include the client-side hash, which must be stored in the DB for future duplicate detection. If the 200 MB file is a duplicate and we uploaded it anyway, it would take 7 minutes to needlessly upload that same file on my home internet connection (which is quite fast). So, if the file is a duplicate, this 7 minute upload will be skipped entirely.\nAlso understand that changes to Fine Uploader will be minimal. The hashing and server communication is something that integrators will take on. I'll provide a simple example implementation as part of this issue.\nPlan A\nStart uploading the file immediately and start the hashing/duplicate detection process at the same time. Then cancel the upload once the file has been found to be a duplicate. The time to hash and ask the server to run a duplicate check does not adversely affect the upload time, in case the file is not a duplicate. The hypothesis here is that this is the ideal approach in terms of conserving user time.\nTasks:\n\n[x] Update Fine Uploader to accept a \"reason\" for a cancel API call. A file canceled with a reason (such as \"duplicate\") will remain visible in Fine Uploader UI. Ideally the cancel message would be displayed as status in the upload card. The onCancel event will include the passed reason in this case, so other UI implementations (such as React Fine Uploader) can also keep the file representation visible, indicating the passed reason. These are the only changes to Fine Uploader.\n[ ] Generate hash of a large file by breaking it into chunks and hashing each chunk: Blob.slice, FileReader, ArrayBuffer, and SparkMD5. You must do this in your own project.\n[ ] Send request to server endpoint w/ calculated hash. If duplicate, cancel upload w/ message to display on file card. You must do this in your own project.\n[ ] After (if) upload completes, send a request to the server w/ the file hash. Server must save this hash with the file record for future duplicate file queries. You must do this in your own project.\n\nPlan B\nCheck for a duplicate first. Reject if duplicate, otherwise start upload. Since the upload is delayed until hashing an duplicate detection is complete, this will add 6 seconds to the 7 minute file upload.\nTasks:\n\n[ ] Update Fine Uploader to optionally display rejected files. A duplicate file will be rejected in onSubmit, but we want to user to see the file in the upload UI anyway. Ideally the rejection message would be displayed as status in the upload card. These are the only changes to Fine Uploader.\n[ ] Observe onSubmit callback in Fine Uploader. At this point, check to see if the file is a duplicate. You must do this in your own project.\n[ ] Generate hash of a large file by breaking it into chunks and hashing each chunk: Blob.slice, FileReader, ArrayBuffer, and SparkMD5.\n[ ] Send request to server endpoint w/ calculated hash. If duplicate, reject w/ message to display on file card. You must do this in your own project.\n[ ] If file is not a duplicate, do not reject and include the hash as a parameter with the file. Server must store this hash alongside the file record for future duplicate file queries. You must do this in your own project.\n. > Wouldn't this allow anyone to add a file to their own uploads as long as the hash is known of any file on the server\n\nI'm not sure I follow. This is simply a check to determine if a file exists on the server, given its hash. If it does exist, then the file is not uploaded. Can you explain the issue you are seeing a bit more?\n. > another user could simply send 123 as a hash faking a upload with that hash and gain access to my foo.docx.\nHow would they \"gain access\"? As I said before, if the file hash exists, then the file simply isn't uploaded. No one is provided access to anything. \nRegardless, it's up to you to implement the feature however you want. This is really not a \"feature\" of Fine Uploader. It won't be baked into the library. My example will follow the plan described a few posts back.\n. > This being client-side tech, there are plenty of ways to spoof the data being sent.\nA spoofed hash doesn't harm anyone other than the uploader, as their file simply won't be uploaded. At least, that's how I would implement this feature.\n. The only planned change to Fine Uploader is that which is documented in \"plan A\" above (see the first \"task\"). The rest will be an integration which will be demonstrated as described in the same plan.\n. > Well a spoofed hash cannot be detected by the server without the file correct? So if I know the hash of a file on the server I could link it to my user or something.\nSorry, I'm really not following your logic at all. What does \"link it to my user\" mean? How would you do this?\n. I suggest that, if you do end up implementing this feature into your own project, you not simply serve up files without checking for appropriate permissions. The file hashing feature described here isn't really relevant to this discussion of security, since it's not meant to be anything more than a hash comparison.\n. Ah, I see, you had a very specific implementation in mind. But this is not something that any client-side library could ever prevent against. The best defense against this is to ensure you never blindly serve sensitive resources. Instead, a permission check server-side of some sort is prudent.\n. At this point the only changes to Fine Uploader planned to make duplicate file detection possible are represented by the above 3 commits.\n. @shehi I want you to understand that you are advancing a straw man argument. Hopefully you will be convinced after reading my message below. Either way, I'd like this discussion to move back towards the specific items in \"plan A\" from this point forward instead of going on and on about a specific flawed implementation of this that will never be part of Fine Uploader.\n\nThe server side, seeing hash \"123\" already exists in its storage(s), cancels upload and just grants additional ownership access to that mal-intended user. \n\nSimple: don't do this. \nWe're going in circles at this point. I've already mentioned, several times, that Fine Uploader isn't going to internally implement the hashing or duplicate file detection code. You must do this. And you are free to take any security precautions you see fit when you do this based on the nature of your project. Fine Uploader will only be modified to allow a file to be canceled with a \"reason\". That's it. Nothing more. The hashing and server communication piece will be demonstrated as an integration point. I'll likely write an article and provide some sample code. I've updated my initial post above to make this even more clear as well.\nIf your project is coded such that it blindly serves up resources without appropriate permission checks, nothing can be done client side to fix that.\nOnce again, Fine Uploader will not generate the file hashes itself or contact your server to determine if a file is a duplicate, based on the hash. This is entirely up to you. As with anything, keep appropriate security in mind as you code.\n. Fine Uploader isn't going to internally implement the hashing or duplicate file detection code. You must do this. Please read my initial plan above before you comment any further.\n. In fairness, I added/bolded that a few comments back to clarify the goals of this \"feature\". This was clear to me initially, but it seemed I did not convey this clearly to others after seeing comments from you and @stayallive. \nFine Uploader's API and event system will be modified to make it easier for integrators (such as yourself) to implement a duplicate file detection workflow as described earlier. In fact, I've already made all planned changes to Fine Uploader in the 585 branch (these will be part of 5.12.0). See the 3 commits a few posts above for details.\nI'll likely also provide a sample integration and detail it in an article (with usable code). It's possible that this \"sample integration code\" will be further generalized into a standalone library that can be plugged into Fine Uploader (or some other library) to make duplicate file detection even easier to implement.\nI'm not writing the hashing and duplicate file detection code as part of the Fine Uploader library for the following reasons:\n- This would make Fine Uploader larger and more complex. It's already quite large and exceptionally complex.\n- It really doesn't need to be part of the core library. Going forward, features like this should be integrated by example or standalone generic libraries.\n. > wondering though if you were still planning to add the per-chunk checksum feature I had mentioned previously\nI don't recall this feature. Do you have an issue number? At this point, my hands are full with maintaining/supporting Fine Uploader, working on this duplicate file detection case, working on React Fine Uploader, and a number of other projects, and this is in addition to my 9-5 work. So, I don't see the feature you speak of making it into Fine Uploader anytime soon unless someone else contributes the changes. Also, instead of baking this into Fine Uploader, I would most likely mandate that Fine Uploader instead be modified to make this possible. In other words, make the onUploadChunk callback accept a Promise as a return value and allow for per-chunk parameters to be specified via a new API method or a non-breaking update to an existing one.\n. Changes in this case have been released as 5.12.0-alpha.\n. Md5 is perfectly adequate for this feature, and in fact will make life much easier for integrators who want to backfill their DBs with hashes for files already stored in S3. Since AWS already stores the md5 hash for each file in the object's etag header, it's easy and efficient to capture hashes for all files as part of the initial integration effort.\n. After further thought, I think it's important to maintain a zero tolerance policy for rude comments. So, @chadwackerman, I have removed your most recent comment and banned you from the repository. I encourage you to read https://github.com/jonschlinkert/maintainers-guide-to-staying-positive#help-or-do-no-harm before you interact with any project/maintainer going forward.\n. A common theme here is a misunderstanding of the context in which MD5 is used here. Summary: it's not used for security. Instead, we're using it to identify content. Linus Torvalds explains the difference in a detailed post on the recent SHA1 collision attack.. I created a functional prototype on https://github.com/FineUploader/fine-uploader/tree/585-duplicate-file-detection which I used for an internal demo. Cleanup, tests, etc are still needed.. Nothing has changed on the above branch since the last message. It still needs cleanup and tests plus docs. But it works.. Please show all of your code, not just a snippet.  Also, show the uploader-related HTML you have constructed.\n. Do you have a working link where I can check this out a bit closer?  I'm\nnot seeing any issues on my end.  There's not much more I can do without\nhaving a look at your live app.\nOn Tue, Jan 15, 2013 at 1:38 PM, Ben Kempner notifications@github.comwrote:\n\nThat's the only js related to fineUploader, though there is nothing else\nsignificant. Also, it's a blank html page, the only content in the body is:\nUpload Photos\nDoes this work for you?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/586#issuecomment-12285080.\n. No response from the OP for 2 days.  Please re-open if you are able to provide a live example that reproduces your problem.\n. This is something you can do in your forked version, but I don't see the need to upgrade as I generally only use that build file, and the gradle build is an unsupported element of the Fine Uploader repo.\n. If you think that $15 is not worth the years of effort that have gone into this project, then please, develop your own library, or combine the files yourself.  It's an open source project.  Donations make it compelling for me to continue to offer the excellent support I provide the users as well as continue to update the project and respond to feature request & bug alerts.\n\nThe donate link is for those who would like to further contribute, or for those users who combined the files themselves and would like to contribute after-the-fact.\nQuite nice of you to use someone else's hard work and then refuse to donate for all of the hard work that has gone into the project.  That is truly poor form.\n. I only added the paywall in the zip download section at the end of December.  Before adding this, I noted that the library was downloaded over 400 times EACH DAY.  Total donations almost never exceeded $20 PER MONTH.  I have worked on Fine Uploader myself 7 days a week, in my free time, and I have kept up this schedule since August.  It came time to find a way to alert people to the fact that open source software isn't free, and contributions are important to keep such a library alive, as it allows me to justify all of the time I put into this code and all of the hours I spend answering questions from users.  Have a look at the support forums and the issues tracker.  What other projects have such an active maintainer?\nNo one is being strong-armed into anything.  The project is open-source.  If you don't want to pay the $15, you can hop right on over to the source tree and use it any way you want: fork/clone the repo, modify the source files, create your own library based on the source files, whatever.  \nThe fact is, the vast majority of people who use this library to make money for themselves do not contribute anything, to this day.  The donate link is there for those people, should they decide to give something back to the library that has helped them make money themselves.\nHalf of the donations/contributions go to myself, and half go to Andrew Valums.  Perhaps you should watch the following presentation by David DeSandro of Twitter/Metafizzy fame regarding open source projects.  It may open your eyes a bit.\n. @xblaster I don't think you understand what \"open source\" means.  You should read http://opensource.org/faq.\n. Thanks for reporting this, Kyle.  I'll schedule this for a 3.3 fix.\n. This is a tough one.  I'm not entirely sure how I can determine when a draggable has been dragged out of the window in Safari.  All the other browsers have some sort of cue that is evident when examining the dragleave event, but Safari doesn't seem to leave any evidence in the event object that the draggable has left the window.  I'll have to think about this some more.\n. I'm stumped.  I've posted a question on Stackoverflow.  Hopefully someone else knows how to determine when a file has been dragged outside of the window in Safari on OS X.\n. This one is on hold for now.  No bites on stackoverflow yet either.\n. I don't have a solution for this one yet.  Not sure I ever will.  I'll keep it open in case I run across a fix.\n. Moving this out of any specific milestone until I have a way to solve this issue.\n. Still no solution in sight for 3.6.\n. A suitable workaround was committed in #1043.  If we are unable to determine if the file was dragged out of the document, the drop zones will be hidden again the next time the mouse enters the document.\n. Thanks again Kyle.  Scheduled for 3.3.\n. This feature has been added to 3.3-IP.\n. Hi Andrew.  Please open up a pull request.  You'll need to do this against the 3.3-IP branch.  After the pull request is opened, I'll likely take a look.  I have a very specific vision in mind for Fine Uploader, as far as the code is concerned, so I may need to make some modifications to your proposed changes before merging them into the In Progress branch.  So, once I receive your pull request, I'll add it to the 3.3 schedule and will reference it in the existing feature case for the delete button (case #382).  \nI envisioned this happening as an ajax DELETE request, with an expected response similar to the one expected from the server when an upload request is sent.  I think there will need to be some optional mechanism in place to allow the user to confirm the delete as well.\n. I edited my response.  Your pull request should be based off of 3.3-IP, not 3.2. \n. Closing since there is now a pull request, #592.\n. Hello Tino.  To send extra parameters along with each upload request (file), you will need to make use of the params property in the request option, or the setParams API function.  These are both documented quite well in the readme, and there is a link in the readme to a detailed writeup I included in the Fine Uploader blog.  Please have a look.  That should answer your Fine Uploader specific question.\nAs to your second question, all requests sent by the uploader are POST requests.  If the paramsInBody property of the request option is set to true, you will need to make use of the $_POST PHP global to grab the parameter, since this global grabs parameters from the request payload.  If you do NOT set paramsInBody to true, you will need to use $_GET, since it grabs parameters from the query string.  You see, $_GET is not necessarily always used to parse parameters for GET requests.  There is a PHP example in the server directory which should give you more insight.\n. Hi Andrew - It's not possible to easily determine what changes you made, due to some apparent spacing/tabbing issues with your code.  Click on the \"files changed\" tab above to see what I mean.  Can you make the proper adjustments in your branch and push again?  You don't need to open up a new pull request.  I will see any changes you push to your 3.3-IP branch.\n. Ah yes, could be.  All of my development is done in OS X.\nOn Wed, Jan 16, 2013 at 3:20 PM, Andrew Collins notifications@github.comwrote:\n\nYeah, I'll re-do the changes.\nThe problem most likely has to do with line ending differences. I'm\nworking on Windows.\nhttps://help.github.com/articles/dealing-with-line-endings\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/592#issuecomment-12340693.\n. Thanks!  I'll look over this some more this evening, after work and comment.  I have some ideas about adding support for confirming the delete action via a customizable confirm dialog.  Also, I'll want to contribution some way for developers to disable this feature (deleting) if desired.  I'll codify all of my thoughts and plans later this evening, CST.\n. In addition to the code I commented on, I have the following to add:\n1. There should be an option to control whether this feature is enabled or not.\n2. Fine Uploader, IMHO should send the DELETE request itself, and the server should respond in a format similar to the accepted upload response.  If the request contains a \"success\" property w/ a value of \"true\" the UI would be updated (by removing the associated  in FU mode).  Other properties could be passed for the benefit of the onDeleteComplete callback (see number 5 below).\n3. There should be a way for developers to force users to confirm the deletion.  There is already a showMessage function \"option\" that can be overriden.  The default impl uses alert.  There could also be a default showConfirm(...) w/ a default implementation that uses window.confirm(...).  Developers could override this, with, for example, a Bootstrap modal.\n4. There should be a function added to the API for FIneUploaderBasic users.\n5. The onDelete callback would be called before the request is sent.  Perhaps a return value of false would prevent the request.  This would occur before the confirm is launched, which would also affect the outcome of the delete request (depending on which button the user clicks in the dialog).  There would also need to be a onDeleteComplete callback that functions similar to onComplete  This way, a developer could structure their code to display a success or error message when appropriate.  \n\nJust some thoughts.  I fully planned on adding the details above myself, so don't feel obligated to spend more time on this.  Your code is a good start.  Some comments/input from you would be helpful though.  It's always nice to get some input from a fellow developer.\n. Thanks for your time on this.  I've made some adjustments to my comments, more may follow.\n. Regarding feature #382.\n. Not a problem.  \nAndrew - I've merged your work into a separate feature branch, delete-button.  This is where I plan to stage changes for feature #382.  I plan on starting work on that branch tonight, with your changes as a starting point.  I'll keep this pull request open until the discussion has finished, though.  You are also welcome, but not expected, to submit pull requests to the delete-button branch as well.  I'll try to update the remote branch every evening, as I usually do.\n. On second thought, let's continue the discussion in case #382.  I'll move my comments to that case.\n. As the documentation states, FIneUploaderBasic mode provides no UI-related elements or behavior (with the exception of a hidden  element as a child of your button, which, arguably, is not a UI element).  Currently, the drag & drop logic is housed in the dnd.js file in the source tree.  It is, at the present time, tied to FineUploader mode exclusively.  This has always been the case, since day 1.  As you have already noticed, another user has made a similar request (case #577).  \nIn the meantime, you have several options:\n1. Write your own drag & drop code using dnd.js as a model\n2. Use FineUploader mode and make the appropriate customizations by making use of the templates & options, along with your own CSS overrides and javascript (if necessary).\nOption 2 is likely the easiest option.  \nPlease add further comments regarding this subject in case #577.\n. This is documented in detail in the server side readme.  Also, there are server side examples for you to use and follow in the server directory of the github project.  Please have a look.\n. Fixed in 3.3-IP.\n. This should line up with feature #589.\nNote that your changes will not work as expected if the form uploader is used (IE9 and earlier, along with Android 2.3.x and earlier) since there is no way to determine file size client-side without support for the File API.  If the form uploader is used, the file size is undefined.\n. Not a problem, no worries.  It's easy to forget or overlook some of the less obvious cross-browser \"gotchas\" when modifying Fine Uploader's code, unless you work with it often.  That's why I'm here :wink:.\n. Hello again Andrew,\nA few comments about your PR:\n1. I have decided to keep HTML/javascript examples out of the server (examples) directory.  When the options/API change, these examples tend to get neglected.  So, I would like to keep only server-side code in the server dir.\n2. The other PHP files you included may be useful for some developers, but they are outside of the scope of this project.  Most likely, their existence will prompt more support requests, which I do not want to spend time on.  I generally spend about 75% of Fine Uploader time answering questions from users as it is, leaving only 25% or less of my time to write and think about the code & new features.  So, I'd like to keep the server directory as a repository of very simple, barebones examples that handle Fine Uploader requests and send responses.  \nI appreciate your efforts, though.  You can always post your examples in one of your repos, and link to them in a new thread in the support forum.\n. Sounds good Andrew.  Feel free to post a link to your repo in the forums.\n. Excellent.  You may want to create a thread in the support forum as well, in case any PHP people are looking for such examples.\n. It's in the server folder of this repo.\n. Thanks for your help on this Che.\n. Synchronous ajax calls are always a bad idea, unless they take place inside of web workers.  I explained in some more detail why in this post in request #545.\n. What problem are you having, and with what version?\nOn Jan 17, 2013 5:42 PM, \"Samuel Vasko\" notifications@github.com wrote:\n\nJPG an jpg are just killing me now\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/600.\n. No response from poster, closing.\n. You'll have to provide more details about your app.  Perhaps a link to a working demo that reproduces the problem as well.  See the FAQ or the options section for instructions on turning off the drag & drop feature.\n. If that's working at all, then you are using a very old version of FIne Uploader.  You'll have to upgrade to the latest.  My guess is, you are using a version earlier than 3.x.  There were some major breaking changes in 3.x, so you've got a bit of reading to do.\n. I will need to play around with cancelled iframe uploads a bit more in a production environment before I attempt to identify a solution.\n. Never really came up with a solution here, and no one seems to have run into this, or at least reported it, anyway.\n. Your server MUST return a valid JSON response, as documented.  It looks like your server is returning the markup for a page instead.\n\nOn Fri, Jan 18, 2013 at 8:47 AM, xavadu notifications@github.com wrote:\n\nWhen i try to upload an imagen in IE8 i get this error: [FineUploader]\nError when attempting to parse form upload response (SyntaxError: Syntax\nerror)\n// the total FineUploader Log in Debug modeLOG: [FineUploader] Processing 1 files or inputs...LOG: [FineUploader] Sending upload request for 0LOG: [FineUploader] Received response for 0LOG: [FineUploader] iframe loadedLOG: [FineUploader] converting iframe's innerHTML to JSONLOG: [FineUploader] innerHTML = Hocus Pocus Logueado como admin HomeSalir /.nav-collapse ClientesListadoTitulosListadoActoresDirectoresEditorasGenerosLenguajesPaises /.well  /span  /span  /row \u00a9 Hocus Pocus 2012 /.fluid-container  Le javascript             Placed at the end of the document so the pages load faster \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[FineUploader] Error when attempting to parse form upload response (SyntaxError: Syntax error)\n// JS FineUploader Initiation$('#basicUploadSuccessExample').fineUploader({        debug: true,        multiple: false,        disableCancelForFormUploads: true,        request: {            endpoint: '/crud/Movie/upload',            paramsInBody: false,        },        validation: {            allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],            acceptFiles: 'image/*',            sizeLimit: 4 * 1024 * 1024,        },                  retry: {            enableAuto: false,            showButton: true        },            template: '' +                    '{dragZoneText}' +\n                    '{uploadButtonText}' +\n                    '{dropProcessingText}' +\n                    '' +\n                  '',\n        classes: {\n          success: 'alert alert-success',\n          fail: 'alert alert-error'\n        },\n            text: {\n          uploadButton: 'Subir',\n          dragZoneText: 'Liberar aqui'\n        },\n    })\n    .on('error', function(){\n```\n})\n.on('complete', function(event, id, fileName, response) {\nif(response.success == true) {\n    // Set to tmp.filename from the Model process upload\n    $('#poster').val(response.filename);\n    // display the new image uploaded\n    $('#poster_img').attr('src', '/imagefly/tmp/'+response.filename+'/264/375');\n}\n\n});\n```\n// HTML\n\n\n\n\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/603.\n. You said the issue is with IE8.  You should be looking at the response sent\nwhen the user agent is IE.  Clearly, your server is not responding the same\nway when IE is involved.\n\nOn Fri, Jan 18, 2013 at 8:56 AM, xavadu notifications@github.com wrote:\n\nthis is the response of my server (get from chrome console):\n{\"success\":true,\"filename\":\"f76095229e56493c86883ec47472befa3f84fb6d.jpg\"}\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/603#issuecomment-12425045.\n. All the information required to handle upload requests from all browsers is\nexplained, in detail, in the readme.\nOn Jan 18, 2013 11:46 AM, \"xavadu\" notifications@github.com wrote:\nSOLVED\nwhen FineUploader work with-non IE do an AJAX Request, with IE do a POST\nNON-AJAX Request\ni was cheking in my server if there is ajax call no render the default\ntemplate, when i try to upload from IE do a not ajax request them i render\nthe template and there was the problem\nmaybe must be more detailied in the Documentation this issue\nthanks\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/603#issuecomment-12433067.\n. Hey Adam.  Out of curiosity, what was the issue?\nOn Jan 21, 2013 3:38 PM, \"Adam Krebs\" notifications@github.com wrote:\n[image: :+1:] came here to report an issue about postdata on 3.0 and\nfound it was already fixed in 3.1. Thanks for the awesome work.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/604#issuecomment-12518755.\n. Implemented in 3.3-IP.\n. @hulbert What is incorrect about the documentation?\n. @hulbert Oh, I see.  I forgot to update that default value.  Oops!  I'll fix it now.  \n\nChanges to anything outside of the client directory are permitted in master.  I don't make changes to anything in the client directory w/out a new release.\n. Fixed.  Thanks for catching that!\n. What problem happens when you attempt to build it?  Also, what version of Java and Gradle are in your path?\n. I ran into this issue a while back.  I believe I fixed it by upgrading to the latest build of Gradle, which is 1.4, and using Java 1.7 instead of 1.6.\n. :thumbsup: \n. Opera is not a supported browser.  Based on published numbers, it's more of a niche browser than anything else, and not a very good one at that.  The entire response should be logged if the debug option is set to true.  That would be the best place to start (examining the response as Opera sees it).  Perhaps Opera is mangling the response.\n. You might want to try \"text/plain\" if you haven't already.\nOn Sun, Jan 20, 2013 at 7:21 PM, twig notifications@github.com wrote:\n\nAhh yes, forgot about that debug option.\nAnd you're right, the response is blanked out for some odd reason (even\nafter forcing mimetype to be application/json)\nOther than that hiccup, the actual upload/save process seems to be working\nfine on Opera.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/605#issuecomment-12481587.\n. Your problem is caused by a misunderstanding of how the params option works.  With your code, as it is, the value of the \"artist\" input is read and stored as soon as the upload is initialized.  If it changes after this point, the uploader will not know.  You have two options, as documented in the readme and in my blog post on this topic:\n1. Return a function for your \"name\" param.  This will be executed every time the uploader sends a new request.\n2. Call setParams whenever you want to modify the parameter value of \"name\".  \n\nPlease read my blog post on this topic.  It explains how to assign/change parameters for each file at any time after the upload has been initialized.  Also, the setParams function, along with the params option are documented in the readme.  \nAlso, please remove all trailing commas in your javascript.  IE7 will choke when it sees these.\nNote: I edited your post to properly include your code.  Markdown does not have \"[code]\" tags.  Please read more about proper markdown syntax here.\n. @bryangoldberg Your code will not work as you are mixing the jQuery plugin syntax with the non-jQuery plugin syntax.  It is for this reason, partially, that I advise against using the jQuery wrapper.  That and using jQuery to deal with Fine Uploader provides no advantages.  \nThis should work:\n``` javascript\nvar uploader = new qq.FineUploader({\n   element: document.getElementById('upload_template'),\n   request: {\n      endpoint: '/upload'\n   }\n});\n// some time later\nuploader.setParams(newParams);\n```\n. @bryangoldberg Also, be sure that your \"upload_template\" element is NOT the template.  Instead it should be an empty element where Fine Uploader will render.  Your code suggests that this element is in fact the template script, which may not work.\n. Hi there.  Your catch is very much valid and is flagged by jslint/jshint.  I have not yet gotten around to fixing jslint/jshint warnings in uploader.basic.js.  \nI'm going to have to close this PR though, since it is against the master branch, which is frozen, as far as code is concerned.  New development always occurs in the IP (in-progress) branches, so any pull requests must be against an IP branch.\nYou can open up a new PR against 3.3-IP.  Otherwise, this will be addressed once I get a chance to refactor uploader.basic.js and uploader.js (similar to the way I have already refactored the other js files).\n. This is expected and should not adversely affect your application at all.\nI can look into squelching the error log in the Javascript console though.\nOn Jan 22, 2013 7:28 AM, \"ILYAKraynov\" notifications@github.com wrote:\n\nError msg: Error when attempting to parse xhr response text (SyntaxError:\nJSON.parse: unexpected end of data).\nUbuntu 12.04, FF18\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/608.\n. Ah, I see.  I will make sure this is fixed in 3.3, but I doubt that your\ncancel event handler is called AFTER your complete event handler.\n\nFixing this should be as simple as removing the readystatechange handler\nbefore aborting the xhr request.  For example, in the cancel function\nexposed by handler.xhr.js, you can simply add the following line before the\ncall that aborts the request:\nfileState[id].xhr.onreadystatechange = null;\nNote this is untested, but it seems like it should work.\nOn Tue, Jan 22, 2013 at 8:18 AM, ILYAKraynov notifications@github.comwrote:\n\nActually its does. This exception triggers \"onError\" event. This is not\ncorrect behaviour, while we cancel uploading.\nAlso it triggers users \"onComplete\" event before \"onCancel\". If\n\"onComplete\" acts as \"onSuccessfullySend\" it can't be invoked here. If it\nacts as \"onEverythingDone\", I think, it must be called after \"onCancel\".\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/608#issuecomment-12546168.\n. :thumbsup: \nA fix will be in the 3.3 release.\n. Fixed in 3.3-IP.\n. No idea what you are talking about.  Please try to explain your problem\nanother way.\n\nOn Tue, Jan 22, 2013 at 8:32 AM, ILYAKraynov notifications@github.comwrote:\n\nThere is possible to start uploading of new file while previous file is in\nprogress.\nIts cause spamming of log with errors. And \"beforeunload\" will not be\nunbounded.\nUbuntu 12.04, FF18\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/609.\n. My guess is you have also set the multiple option to false?  Am I correct?  If so, the issue is fixed in 3.3.  This is tied to issue #581.\n. Sorry, I edited my response, probably after you read it.  I meant to say: \"my guess is you have the multiple option set to false\".  Correct?\n. Yep, your issue should be fixed in #581 then.  Please read over my solution\nin #581 and let me know if the modified behavior fits your needs.\n\nOn Tue, Jan 22, 2013 at 9:19 AM, ILYAKraynov notifications@github.comwrote:\n\nCorrect. multiple=false\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/609#issuecomment-12548856.\n. So the commit in #581 fixes your problem?\n. Excellent.  Closing this as it is now a duplicate of #581.\n. Why are you using two copies of the same fileuploader.js file?  What are you trying to do? \n. Also, image_crud is using a VERY old version of fine uploader.  I've been\nmeaning to connect with the image_crud developer to discuss an upgrade\npath.\n\nOn Tue, Jan 22, 2013 at 10:09 AM, supercool27 notifications@github.comwrote:\n\nTypeError: element is undefined [Break On This Error] if\n(element.querySelectorAll)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/610.\n. Don't import two fileuploader.js files.  That's your first problem.  Also,\nyou are using a very old version of the uploader, which is not supported.\n I believe the image_crud developer has recently upgraded Fine Uploader.\n Perhaps he will release a new version of image_crud with this upgrade soon.\n\nOn Wed, Jan 23, 2013 at 12:31 AM, supercool27 notifications@github.comwrote:\n\nthank you for your reply. my issue is when i am using 2time in the same\nview its able to upload but queryselectorall methods not getting the\ncorrect dom but first one is wokring perfectly but second one having\nqueryselectorall problem. so i copied fileuploder.js to filuploader1.js.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/610#issuecomment-12583371.\n. I'm afraid there isn't much help I can offer here.  Large uploads work fine for me (I use Java on the backend).  I also don't know what version you are using.  You should set debug to true and/or examine the response from your server to figure out what is going wrong, but the issue is most definitely server-side.  Are you able to reproduce this locally?  Perhaps your application server or ISP is rejecting requests that exceed a certain size?  Is this happening with all browsers?  You're going to have to investigate further on your end to determine what the exact error is and why these requests are being rejected.\n. Can you re-open this pull request against 3.3-IP?  Master is a closed branch (as far as the js src is concerned), and all development happens in IP branches.\n\nThanks for looking into this.\n. Cookies are only required if you are using the auto-resume feature.  Otherwise cookies are not used or required.  If you want to use the resume feature, cookies must be allowed.\n. You'll have to provide a more detailed analysis of the problem along with raw request/response data for the requests in question, sample code, and a description of how you are handling CORS support server-side.  It seems like, in theory, this should work, but I've never tested in this type of an environment, so I can't say for sure.  I'd need to explore further.\n. ...also, what is the specific user agent you are testing on?\n. no response from poster, closing\n. Thanks Adam, I hope to have time to look into this further during the 3.3 release cycle.  For organization sake, this PR refers to #513. \n. Hmm, I didn't intentionally close this.  I'm not even sure how that happened.\n. In fact, I don't even have the option to re-open it.  Hmm\n. 2 other PRs were listed as being closed by me at the same time, and I also can't re-open them.  I'm not sure what's going on here.\n. Oh, I know why.  It may be due to the fact that I removed the 3.3-IP branch, since I've merged it into master.\n. You'll have to re-open against the 3.4-IP branch, which I still must create.  Sorry about this.\n. 3.4-IP has been created\n. There is no way to upload files in IE9 or earlier, along with Android\n2.3.x via XHR, so all upload requests are multipart encoded.\nOn Wed, Jan 23, 2013 at 10:45 AM, Anon notifications@github.com wrote:\n\nHey,\nIf I use forceMultipart: false it works in Firefox and Chrome etc, but in\nIE9 with the same code I still get:\nContent-Type: multipart/form-data;\nboundary=---------------------------7dd22d287a0a18\nIn Chrome / Firefox I get:\nContent-Type:application/octet-stream\nIs this a known bug or am I doing something wrong?\nThanks\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/617.\n. Fixed in 3.3-IP.\n. Hi there.  Thanks for this, but I generally only accept bugfixes to example files, or adjustments that provide support for a specific Fine Uploader feature.\n. Thanks for catching these issues Andrew.  My constant need to refactor things into layers of abstraction sometimes bytes me (ha!).  The first change seems great.  I added comment/suggestion for your 2nd change.  I really appreciate you taking the time to look over this code.  I doubt anyone else is.\n. I received a 2nd request for this in as many days.  I may start to attempt to reproduce this in my testing environment tonight.  If I can easily do that, I may just start investigating solutions.\n. I guess I'm not really following your logic here.  The only way to send a request that contains a file when using IE9 or earlier is to use form submission, which requires we embed a form for each file in a separate iframe.  The response from the server is parsed by reading the contents of the iframe.  So, we need a way to access this iframe.  If the domain of the sever generating the response does not match the domain of the server to which the request was sent, there is no way, as far as I know, to access the contents of the iframe.  The iframe contents should be completely replaced by the server's response, so I'm also not sure how message passing is possible here to overcome this issue since there will be no javascript in the iframe that listens to message requests.\n\nPerhaps I am misunderstanding you.  If so, it might be best to illustrate your theory by creating some code based on the existing Fine Uploader code, and including it in your next message.\n. I'm going to pull this into 3.3 and start looking into this now.  If I end up going down a rabbit hole, I will move it back into 3.4 so I have more time to research.\n. I've been playing around with a few ideas.  The easiest solution seems to be the following workflow:\n1. Server checks the X-Requested-With header on the request.  If it does not exist, or if it does not equal XMLHttpRequest, the request has come from an iframe.\n2. If the request was send by an iframe, return the following response w/ a Content-Type of text/html:\njavascript\n<script>parent.postMessage('{success: true}', '*')</script>\n1. Client-side, the form handler listens for a message event.  If it receives one, it uses the data from the message as the response and doesn't bother trying to access the contents of the iframe.\nThis seems like it should work for IE8 and up.  Getting this to work may be a bit trickier in IE7, but I think we can make this work by creating a postMessage polyfill that changes the location hash of the parent (uploader) window to the response properties.  When the uploader window detects that its location hash has changed, it can parse the hash value.  This will be a bit tricky as I will have to create a js file with this polyfill and the server will have to import this polyfill in another script tag.  The response iframe also needs to know the URL of the parent (uploader) window as well to make this work, which may make this messier/tricker still.\nA simpler solution would be to either drop support for IE7 entirely (I'm tempted) or to say XSS uploads will not work in IE7.\nThoughts?\n. I think I can get this support working quite nicely in IE8+.  I think I can improve on my initial plan (above) as well (i.e. make it simpler for Fine Uploader users/integrators).  I'm seriously considering just saying \"fuck IE7\" (as far as upload XSS support is concerned and in general).  I've created a poll to track user input on this.\n. Work on this is being staged in the cors branch.\n. My next step is to write up some documentation explaining the associated\nconcepts (for those not familiar with CORS) along with what\ndevelopers/integrators must do server-side to enable cross-domain support\nfor both uploads and delete file requests.\nThe XSS option was renamed.  You are likely looking at old commits.  I made\na bunch of changes within the last 18 hours.  If you really don't want to\nwait for the documentation, you can look at the Java server-side test\nclass (\nhttps://github.com/valums/file-uploader/blob/799393abcc38939c77ff679450194cfdda85fe39/test/fineuploader/UploadReceiver.java)\nI'm using and keep the following in mind:\n1. The new cors.expected option must be set if you want FU to handle CORS\n   requests.  If this is set, your upload response MUST be text/html, and must\n   contain a script tag (that imports iframe.xss.response.js)  immediately\n   after the JSON portion of your response.  The associated file will be\n   executed when the response is loaded in the iframe client-side.  As you can\n   see, it will post a message to the parent (uploader) window with the JSON\n   response.  Your JSON response also MUST contain a UUID property w/ the UUID\n   of the associated file.\n2. You must set all response headers for XHR XSS requests appropriately (as\n   explained in the CORS W3 spec).  Keep in mind that ALL Fine Uploader XHR\n   CORS requests are pre-flighted, so you must handle the associated OPTIONS\n   requests appropriately.  Of course you can cache the responses of these\n   OPTIONS requests by including a Access-Control-Max-Age header w/\n   an appropriate value in your OPTIONS response.\n3. There is also a sendCredentials property of the new cors option.  If\n   this is set, you must strictly follow the spec that outlines credentialed\n   CORS requests, as far as your responses are concerned.  This means no\n   wildcard Allow-Origin headers in your response, and you must also include\n   the Allow-Credentials header.\n4. Note that CORS requests for the delete files feature are not possible in IE8\n   or IE9 since XDomainRequest does not support pre-flighting.  So, for those browsers, the delete feature is disabled if CORS support is enabled via the appropriate option.\n5. IE7 is not supported at all, as far as CORS requests are concerned.\nPlease let me know if you run into any issues, and please note that any of\nthis code may change before it is merged into 3.3-IP.\nOn Tue, Jan 29, 2013 at 12:47 PM, CenterbrookSales <notifications@github.com\n\nwrote:\nExcellent. I'd like to test this out, although I'm not sure that I'm\nbuilding it correctly... I added ${jsSrcDir}/window.receive.message.js to\ncoreFiles, and the build seems to work OK, but I may be missing\nsomething.\nIs there anything special I need to do (besides serve up\niframe.xss.response.js)? I notice there's an xss option, but I can't see\nthat it's ever used. Also, from a quick glance, it seems that createIframe\ndoesn't do anything different. So I'm wondering how to get started working\nwith these changes.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/621#issuecomment-12850597.\n. I think all CORS stuff should be in the cors branch now.  I tested on FF, Chrome, IE10, IE9, and IE8.  After I write up a blog post & update the main and server-side readme, I'll merge these changes into 3.3-IP.\n. This has been implemented in 3.3-IP.  I messed up the merge a bit, so the merge does not include a message that ties it to this case.  All commits with a prefix of CORS apply to this fix.  That would be:\n- 227c3b9ea33f7fb7b9834b455e856b87c32c0928\n- bd7536e9f742ad6ae28100d54f016610d7956077\n- 4a7e398349f5073036f6ad223a0b6950fea3cb4d\n- 1e28e0a0bb722541b276ca070c77ccb6d5032e1d\n- 799393abcc38939c77ff679450194cfdda85fe39\n- e738465db43ecf31028c57166d48fad6689e7378\n- 25b65f87b37154012be3249f23f2719b4549dca3\n- cdf0371e9db0207bf65ecb83142d40867a402bee\n- 1ce8a6652674dad0802ab555fa43ba9258d3ec39\n. Please see this blog post for more info on CORS support.\n. Yes, this is certainly one way to, theoretically, defeat the friendly error message issue if the developer must return a non-200 response code.  I will go ahead and include this, but a couple notable issues with this approach:\n1. It seems unlikely that most, if any developers will use such a workaround.  It is likely much easier to simply return a 200 response.\n2. I have received a few reports of environments where some middleware is actually rejecting the request and returning a non-200 response.  That is, middleware that the developer has no control over.  In those cases, the problem is not fixable by adding whitespace to the response since the developer has no way of doing this.\n\nThanks for adding this to the readme though.  It's always good to give users another option to work around IE issues. \n. Note: I had to make a small adjustment to your PR.  Note that markdown doesn't seem to work inside of HTML tags.  I had to replace the markdown for the MSDN link with an actual anchor tag.\n. Please post support requests in the support forum.  You will also need to provide some information that can be used to troubleshoot your issue.  Please see the \"troubleshooting\" section of the readme before re-posting.\n. It seems like this should be implied/outlined already in the above \"values\" section...\n. Thanks for the PR.  It has been merged.\n. I'm a bit skeptical of the \"fixes\" detailed in some of the links you've provided, but I will look into them more thoroughly.  I do have a case set aside, #621, to investigate further.  I haven't spent much time looking into this as of yet due to the fact that I honestly have not received many requests to support this type of environment at all.  That and it adds a bit of  complexity to the code and testing.  \nMy employer is also using Jumploader on another project.  In fact, I was responsible for integrating Jumploader into that particular project.  It is being used as an alternative to Fine Uploader as it is obviously easier to provide many more cross-browser features using Flash or Java.  I completely agree that client-side Java is effectively dead and should be avoided at all costs.  Flash is in that same category as well, IMHO. \nI'm going to close this case, but only because it is a duplicate, for the most part, of case #621.  This case will automatically be referenced in that case.  Please feel free to add any additional comments you may have to that (or this) case.  Note that #621 is not scheduled until 3.4, but it could potentially be moved into 3.3.  I'll need to setup an environment that allows me to reproduce XSS issues such as this one. \n. Yes I think this may work in a very specific case (such as yours), but a few comments:\n1. To make this more general-purpose, I don't think we can assume that the host portion of the URL will always be \"www\".\n2. In your case, the request is sent to \"foo.com\", but the request is coming from \"www.foo.com\".  If the request is actually sent to \"bar.foo.com\" and the response is coming from \"blah.foo.com\", it seems like document.domain on both the response page AND the form page must be set to matching values.\n3. This does not address a case where a request is sent to \"a.com\" and is returned from \"b.com\".  To handle that case, I think some mechanism that involves the server informing the client to redirect to an agreed-upon static resource that returns the response will be required. I have to think about this some more.\nI really need to spend a non-trivial amount of time to work this out for all situations.\nRegarding #621.\n. ...as such, I'm going to have to close this PR.  I'll need to find a generic solution that will work for all cases with documentation for developers to modify their server-side code accordingly.  However, anyone else in your specific situation will be able to find this PR by utilizing the issue tracker's search feature.\n. It could be updated, but I would have to change it every time a new version is released.  You should be using the released, combined version-stamped js and css files found in the download/releases section and not the individual files found in the source tree.  I'll update the documentation to indicate the fact that the fineuploader.js file, along with the css file will include the version number in the filename.  It really isn't a big deal though.  I don't anticipate anyone having a problem figuring out that the combined js & css files they downloaded are the ones that must be imported, instead of a file that does not exist.\n. GitFlow looks interesting.  I'll probably look into that a bit more when I get some time.  Thanks!\n. Keeping this open so i remember to clarify the imports on the demo pages.\n. Updated.  I also moved all displayed demo code to Github gists.  I'll probably do some further cleanup on the demo page next.\n. This has been addressed in 3.3-IP.\n. The issue tracker is for bug reports and feature requests.  Please post support requests in the support forum.  Also, when you post your support request, please note what specific problem you are having.  I don't see any mention of your specific issue here.\n. Thnanks.  I've thrown this into 3.4, but 3.4 is looking full at this point.  We'll have to see how the schedule looks over time.  The priority of this can certainly be bumped up if I see a bunch of others commenting on this case.\n. @TheGAFF That's a good point.  I'm not sure there is anything standing in the way of Knockout users integrating this into their application.  I imagine it wouldn't be too difficult to do so, and I'm not sure what general-purpose code Fine Uploader could provide to make this easier.  If anyone wants to respond to this, please do.  If not, I'll close this request in a few days.\nI have received a similar request for AngularJS.  As I become more familiar with Angular, I have the same questions about #531.\n. Were you not seeing the file before you implemented the change I suggested as well?  Please show your client-side code.  The code in the example folder should work just fine.  \nAlso, please show me the exact contents of the \"upload\" function that you modified.\n. I'm not a PHP guy, so I can't say for sure if your server-side code is correct.  All I can say is that the code in the server folder is correct.  \nMy suggestion:\n1. Post the exact contents of the upload function that you modified.\n2. Have a look and/or post the contents of the request body for an IE upload request.\n. The problem does appear to be in your handling of the request server-side.  It is clear, looking at the request body, that the file is being sent.\n. No, not browser-specific changes are required on your part, client-side.  Fine Uploader handles that for you.\n. The qqfile param IS sent for ALL browsers.  In fact, you can even see it in the request body you posted earlier.  It's a form field.\n. This has been fixed in 3.3-IP.\n. I'm not really sure how to help you.  This parameter is sent for all multipart encoded requests.  Have a look at the raw request in Chrome or FF or Safari to verify.\n. Oh, I thought you were having problems obtaining this value in a browser other than explorer.  This parameter is not sent in explorer since there is no way to determine the file size client-side.\n. It might be difficult to reliably determine that if the user agent does not support the File API.  In my projects that use Fine Uploader, I disable the ability to cancel uploads when the form uploader is used via the disableCancelForFormUploads option.  I plan on providing a way to determine, server-side, if the entire file has not been sent in 3.4.  See #602 for more details.\n. Andrew, this won't work in FineUploaderBasic mode, since there is no UI contributed by fine Uploader in this mode, and the classes option does not exist along with the listItems.  If such an API function is to be provided, it must work for both modes.  I would expect such an implementation to require that we track success/failure in an internal array or numeric variable, which is updated whenever the internal onComplete callback is invoked.  Then, we would use this internally tracked value to respond to the getSuccessful API call. \nI have not implemented such a function as it is fairly easy for users to track this on their own, simply by maintaining a variable that is updated each time their onComplete callback handler is called. \n. Understood.  In it's current state, this API function can't be included in uploader.basic.js since it only applies to uploader.js.  I will keep this case open, mark it as a feature request, and perhaps get it into 3.3 if I get some extra time.  I should probably be able to get this working in an hour or so, including testing.\n. I might be able to fit this into 3.3, but 3.3 is already quite full, and I'm limited on time in February due to other obligations.  Scheduling, tentatively, for 3.4.\n. I'm thinking this should be called \"getNetUploadCount\", instead of \"getSuccessful\".  The reason for this is due to the fact that deleted files would not be counted.  A deleted files is technically a successful upload.  \nThoughts?\n. I'll probably go with getNetUploads.\n. Completed in 3.5-IP.\n. I don't think I'm going to get to this in 3.3.  3.3 is quite full, and my time is especially limited during most of February.  Also, there is much to think about here.  Scheduling (tentatively) for 3.4.\n. I'm now working on this feature for 3.4.\n. I think it makes sense to reject all files in a batch if, at the time of submittal, the number of selected/dropped files exceeds the number of files allowed.  This behavior should probably not be configurable at all.  Otherwise, the files will be accepted based on the order they are received, which is not something a user can control.  As a user, I would want the opportunity to re-select a subset of my original file select after being notified that I have exceeded a file limit instead of having the uploader simply upload ever file in the list until it hits the file limit.  This is a behavior we are utilizing in one of the products I am involved in that utilizes Fine Uploader.  Thoughts?\n. This gets a bit complicated with the retry feature.  For example, say the fileLimit is 3.  3 files are selected, and one fails.  When should we allow a new file to be selected?  That file may succeed after a retry attempt at some point, or it may not.  No way to say for sure.  \nSome ways we can deal with this\n- Allow the user to select/drop another file and simply fail a retry attempt on a file the number of successful uploads equals the fileLimit\n- Always count a failed file against the file limit\n- Never count a failed file against the file limit\nThe last two options are probably not desirable.  I'm thinking the first option may be the only reasonable choice.\nAlso, the delete file feature adds a bit more complexity.  If a file deletion is ordered and succeeds, this, I assume, should open up another slot for an upload.  For example, if 3 files are uploaded successfully, and the fileLimit is 3, the user can't upload another file.  But, if one of those files is successfully deleted, the user may upload one more file.\nComments?\n. Work on this feature is being staged in the file-limit branch.\n. Seems to be functionally complete in the file-limit branch.  I'll write a blog post, update the readme, and fire off some status updates tomorrow when I merge this into 3.4-IP.\n. I think I summed up the change pretty well in the readme up.  Probably no need for a blog post.  It would be quite short anyway.  Sending out status updates though. \nThis feature is now implemented in 3.4-IP.\n. Hi there, thanks for this contribution.  Have you tested in IE9 and older & Chrome/Firefox?  Also, can you list what specific features of Fine Uploader your example will handle?  Possible choices are:\n- chunking\n- auto-resume\n- handling parameters in the query string\n- handling parameters as form fields in the request payload\n- handling multipart-encoded requests\n- handling non-multipart-encoded requests\n. The company I work for is also moving in this direction, which is why I brought it up.  In the very near future, none of our products will support IE7 or earlier.  Even if I keep IE7 support around a bit longer, which I may do, there are certain features that will not work in IE7.  For example, I'm currently adding XSS/CORS support in 3.3.  This will NOT work in IE7 and it's not worth anyone's time to make it work in IE7.  IE9 and earlier are limited as well to some degree as far as CORS support is concerned (since they don't support pre-flighting requests), but I digress.\nIE7 support for Fine Uploader may continue for a while, but its days are numbered, and there will start to be a feature parity gap between IE7 and IE8-9.  I realize that some companies are still relying on IE7 due to an abundance of internal legacy tools, but this is a very bad place to be indeed.\n. ...via ActiveX.  Yuck.\nOn Tue, Jan 29, 2013 at 2:43 PM, Andrew Collins notifications@github.comwrote:\n\n[image: :+1:] At some point all versions of IE have made me [image: :cry:]However, I do have fond memories of IE 5.0 and its spiffy\nXMLHttpRequest object.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/637#issuecomment-12856793.\n. IE10 appears to be decent, compared to older versions of IE (as far as\nHTML5 support is concerned).\n\nOn Tue, Jan 29, 2013 at 2:53 PM, Ray Nicholus ray@garstasio.com wrote:\n\n...via ActiveX.  Yuck.\nOn Tue, Jan 29, 2013 at 2:43 PM, Andrew Collins notifications@github.comwrote:\n\n[image: :+1:] At some point all versions of IE have made me [image:\n:cry:] However, I do have fond memories of IE 5.0 and its spiffy\nXMLHttpRequest object.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/637#issuecomment-12856793.\n. @thomas83 Hello there!  Based on survey results, about 25% of those who responded\nsaid IE7 support is important to them.  It is likely that I will continue\nsupport for a bit longer, but I will be taking another poll in the near\nfuture to see if the user base has changed a bit.  Even with IE7 support,\nthere is no way to guarantee future feature parity between IE7 and the rest\nof the IE browsers, due to the lack fo HTM5 support in IE7.\n\n\nOn Sat, Feb 2, 2013 at 2:18 AM, thomas83 notifications@github.com wrote:\n\nPlease continue to support IE7. A lot of my clients from China still use\nthat. I've already paid for a version, and willing to continue to pay with\nnew features if IE7 can be supported.\nThomas\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/637#issuecomment-13026309.\n. I will take another poll during 3.5 development.  For now, IE7 lives on.  Support WILL be removed in the future at some point though, so start preparing your clients to upgrade to a modern browser.\n. Even after I \"remove support\" for IE7, I don't intend to start deleting code that will break FU in IE7.  At some point, I might do that (to clean up the codebase) but certainly not immediately after I drop support for IE7).  After I drop support for IE7 in the future, I'll just simply stop testing in IE7.\n. I agree with your statement, but, the fact is, I received a big response from IE7 users who also utilize Fine Uploader.  By continuing support for IE7, I am prolonging the inevitable.  More and more libraries and applications are dropping official support for IE7, and Fine Uploader will as well, at some point in the not-too-distant future.  I described what this means, exactly, in one of my recent posts on this topic (in response to a concerned IE7 user).  I just came across a new web-based app that only supports IE10 (actually IE9 to a limited degree), as far as IE goes.  I like Jeff Atwood's style.\n. I would say you are grossly oversimplifying the work required to develop a good cross-browser uploading tool/library.  My guess is you haven't attempted this yet, and you will be quite frustrated if you do.\n\nMy goal isn't to remove support for \"difficult browsers\".  Cross-browser support is a big part fo this library, but that doesn't mean every browser since the beginning of time should be supported.  It is prudent for libraries to push users to shed insecure and problematic browsers, such as IE7, IE6, Safari for Windows, etc.  The future of web applications depends on it, in fact.  \nThere is a good amount of overhead involved when supporting IE7, such as securing an environment with a real IE7 browser, and actually testing all features in IE7.  Some features will never work in IE7, such as CORS support.  \nAlso, I'm not sure what \"bloat\" you are referring to.  Most, if not all features, have been heavily requested by users of this library.  Perhaps you are also confusing bloat with code required to ensure everything works properly, cross-browser.\n. I think I've already addressed your points previously in this thread.  Should Fine Uploader support IE6, IE5, Netscape, and Mosaic as well?  Certainly we have to draw the line somewhere. I can't support every browser since the beginning of time.  Surely you don't take \"cross-browser\" to mean every browser ever created.  IE7 is quickly falling into the same category as IE6.  It is insecure, its market share is quite low, and, quite frankly, its becoming more trouble than its worth to support.  As I mentioned earlier in this thread, I don't plan on ripping out code that allows existing features to work in IE7 immediately after I drop IE7 support, but, at some point that may happen.  Why?  To keep the codebase clean.\n. @FastieSystems Currently, one of my big concerns is time, and I have very little of it since I am the only resource on this project, and I am only able to work on Fine Uploader in my free time.  However, that may change soon.  If it does, I would expect a lot of big improvements to this library, including continuing support of IE7 along with support of additional browsers not currently supported.\n. A lot of Fine Uploader is in flux at this particular time.  Big changes are in progress, and I will discuss those in the next couple weeks.  I haven't decided when I will drop IE7 support.  However, I have no plans to drop all support for IE7 in the immediate future.  It is possible that some new features may be excluded for IE7 users, but I don't intend to make any code changes that will break the uploader in IE7, and I plan to continue to test in IE7 as well.  \nWhen I have decided when IE7 will no longer be supported, I'll be sure to let everyone know. \n. With new resources added to the project as of today, I'm no longer considering removal of support for IE7 at this time.\n. Revisiting this for a near-future release.  IE7 use is now below 1% worldwide.  The first step will be to simply stop testing at all in IE7.  Following that, all IE7-specific code and documentation will be removed.\n. IE7 will no longer be officially supported starting with 5.1.0.  All IE7-related code/workarounds will be removed in 6.0.0.\n. This is the first case up for development in the 6.0 release.\n. This appears to be complete and is currently being staged on the release/6.0.0 branch.\n. Changed to reflect my desire to remove support for all versions of IE older than IE11. This will mark the start of a move away from legacy support and towards support of modern browsers only. This will likely occur in 6.0 or a later major release. \n. New goal for 6.0 - remove support for all browsers older than IE11.. Hi there, thanks for this contribution. Have you tested in IE9 and older & Chrome/Firefox? Also, can you list what specific features of Fine Uploader your example will handle? Possible choices are:\n- chunking\n- auto-resume\n- handling parameters in the query string\n- handling parameters as form fields in the request payload\n- handling multipart-encoded requests\n- handling non-multipart-encoded requests\n. This is not a problem, but it would be helpful if you could create a readme.md file inside the li3 directory you created that includes the text from your last comment.\n. No need to create a new PR.  Since this PR is based off the the master\nbranch of your copy of the repo, simply add the file to appropriate\ndirectory the master branch of your repo and push to your repo.  It will\nthen appear in this PR.\nOn Thu, Jan 31, 2013 at 3:17 PM, symbiat notifications@github.com wrote:\n\nSure, not a problem, only Im not sure how to add that to this pull request\n(or would I create a new pull request?).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/638#issuecomment-12966294.\n. Thanks!\n. I guess I'm not sure what your question is.  Can you be more specific?  Also, the issue tracker is for bugs and feature requests.  Please post support questions in the support forum.\n. I'm afraid I'm not familiar with the Closure compiler at all.  Perhaps I will have some time to look into this in a future release.\n. Not sure we care about this anymore.  We're using uglify anyway.\n. Please explain the specific problem and how your change addresses this.  I'm not a PHP guy, so I'll have to be sure you have tested in all browsers before merging this as well.  Thanks!\n. I just read up on fopen in PHP.  It seems like your change is needed, since the PHP manual says:\nIf you do not specify the 'b' flag when working with binary files, you may experience strange problems with your data, including broken image files and strange problems with \\r\\n characters.\n\nCan you confirm that your fix will work on all platforms?  Again, I'm not a PHP developer, so I'd like to confirm.\n. Excellent.  Thank you for the detailed description.  I'll merge this in.  Thanks for your contribution!\n. Looks like something went wrong with your pull request.  You can go ahead and submit pull requests for anything not in the client directory on master, if you'd like.  I'll re-open your last pull request.\n. Addressed in 3.3-IP.\n. I suppose I could do that, but you really should be utilizing qquuid.  Otherewise, you will have problems if two files w/ the same name are uploaded, I would think.  This becomes more important if you utilize chunking, auto-resume, or the new delete files feature in 3.3.\n. ...also qqtotalfilesize is quite important for determining if a file has been cancelled or corrupted.\n. Can you explain, specifically, why these parameters would cause code to fail?\n. The 200 code is not sufficient.  When uploading a file in any browser that does not support the File API (IE9 and earlier, or Android 2.3.x and earlier), we must resort to building a form inside a hidden iframe, and then submitting the form.  There is no way to check the status code of a response from a server in this case.\n. ...I updated my answer above after my first attempt.\n. Shouldn't be too hard to implement this after #214 is finished.\n. The target image types for this feature are likely processed images (not images direct from a camera).  With that in mind, I'll likely just use the image height & width according to the browser after rendering the image in an <img>.  For processed images, this will always work as expected.  For direct-from-camera images (JPEGs), the height and width may vary depending on the browser and the orientation of the camera.  I could go one step further and parse out the width/height EXIF values for JPEGs, but I'd really like to avoid this if possible, especially since the target for this validation is likely processed images only.\n. This feature will be part of 4.1.  It's currently complete in the develop branch.\n. Looks like a merge conflict issue in a16eded removed some necessary code for image validation in uploader.basic.api.js.  That is being investigated now.\n. Please post your code, along with your HTML, in the support forum.  Also, I can't access your code via the link, it appears to be password protected.\n. Works fine for me on IE10.  In fact, it even works fine on the demo page (http://fineuploader.com).  \nI can tell, just by looking at your code, that there is an issue.  You are passing a jQuery object as your button element to Fine Uploader.  This will never work, unless you are using the jQuery wrapper.  Please fix this via $('browse-photos')[0].  If you have any further questions, please post in the support forum.\n. It is not a known issue.  The only Windows mobile device supported at this time is the surface tablet.  I have no way to test with the Lumia 920, so I can't say it is supported.  If you happen to figure out why this isn't working, please let me know, but I have no way to look into this.\n. I'm hoping Microsoft provided a way to debug javascript running in IE on a Win8 mobile device.\n. No further communication after a month, so I'm closing this.  If more resources are added to this project, I will likely be able to certify Fine Uploader on more mobile devices, such as this one.\n. We don't have any Windows phones in-house, so we cannot confirm at this time.\n. Yes, you need to return a valid JSON response.  This is explained in the\nserver-side readme:\nhttps://github.com/valums/file-uploader/blob/master/server/readme.md#response.  If you have further questions, feel free to post in the support forum.\nOn Tue, Feb 5, 2013 at 4:47 PM, mig007 notifications@github.com wrote:\n\nI bought your tool and I'm trying to integrate it today, I am using\nasp.net, I created a page FileUploadHandler.aspx\nI added code to save the files\n//Uploaded File Deletion\nif (Request.QueryString.Count > 0)\n{\nstring filePath = @\"c:\\DownloadedFiles\\\" +\nRequest.QueryString[0].ToString();\nif (File.Exists(filePath))\nFile.Delete(filePath);\n}\n//File Upload\nfor(int i=0; i < Request.Files.Count; i++)\n{\nstring fileName = Path.GetFileName(Request.Files[i].FileName);\n        //sb.Append(\"File: \" + (i + 1) + fileName + \"\\r\\n\"); ;\n        string location = Server.MapPath(\"~/Uploads/\") + fileName;\n        Request.Files[i].SaveAs(location);\n    }\nThe files upload and save perfectly into the directory, but the\nFineUploader says that the upload failed. Do i need to return a code or\nwrite something that shows that I saved them?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/650.\n. I generally don't include readmes in the zip as it is possible I may make slight adnustments or error corrections to the readme, even after release.  The email you received from pulley includes a link to the main readme, which references server-side readme I mentioned above.  The comments at the top of the js file should also contain a link to the readme. \n. This is not a support forum.  Please only post feature requests or bug reports here.  Also, your question doesn't really make sense.  You cannot \"create a File object\".  A File object is created for you to represent a File on a user's filesystem in javascript.\n. Oh, I see.  You are asking about creation of a File server-side in python.  Anyway, this is not the place to ask server-side language specific questions.  Please use Google, Stackoverflow, or a python/django-specific internet forum for these questions.\n. The requests sent to the server are explained, in great detail, in the server-side readme.  Please start reading the main readme, which links to the server-side readme.\n. This is not a support forum.  Please only post bugs or feature requests here.\n. https://github.com/valums/file-uploader/wiki/Releases\n. This is all explained in the latest blog post at http://blog.fineuploader.com.\n. You can do whatever you want with the source code. It's open source.\n. The answer to your first question is: sometime in February, most likely.  The answer to your section question is covered, in detail. in the blog post.  Please read the entire blog post.\n. No.  All of the source is available in the source tree.  Make use of it however you'd like.  The combined files, also minified are available via the link I posted in one of your other cases.\n. Please post support questions in the support forum.  You can use any button you like, contributed via the button option.\n. @andrew-kzoo I agree with everything you mentioned in your last post.  I do find myself dealing with questions that have already been answered, in great detail, in multiple places.  I have spent a great deal of time on the documentation, and I continue to improve it every release.  \n\nI do receive a lot of questions from inexperienced developers who essentially want me to do their jobs for them.  There is only a finite number of hours in a day, and if I spend all of that time developing applications for others, I don't have time to answer real Fine Uploader questions, and work on the code, and do my real job outside of Fine Uploader.  As it stands, all of my free time is consumed by this project.  Don't get me wrong, I like working on it, but I consistently get comments from people who expect me to do all of the integration work for them, and then answer general javascript or sever-side language questions on top of that.  It is not uncommon for me to actually troubleshoot live code on a user's website.  If you look through the forums, both here and in the support forum, you will see that I have done that on numerous occasions.  Almost all \"issues\" are the result of a developer's inexperience or lack of desire to read the documentation I have so carefully laid out.  \nAs and more of my time is consumed fielding these questions, I tend to get a bit irritable, as you can see.  Especially when users balk at the fact that I'm trying to get some compensation for my efforts.\n@davidwindell Regarding your last comment, my employer is currently considering such a scenario.  There are many obstacles to overcome to make this happen, though. \n. Is anyone opposed to me deleting all posts before Andrew's second-to-last post, reopening, and renaming this thread appropriately?  Suggestions on the new name for the topic are welcome, but nothing before Andrew's 2nd to last post applies to what this topic has morphed into.\n. Changes have been made, and this is now tagged as a discussion & re-opened.  Feel free to adjust any existing comments as needed.\n. > Perhaps a clear set of guidelines should be presented to would-be issue posters that details acceptable and unacceptable issues?\nThere is such a set of guidelines, which I have linked to in the issue tracker section of the readme.  It is, currently, near the bottom of the readme, though.  It seems like a lot of people who post questions don't bother to read the readme, anyway, but I suppose I could answer such opened issues by linking to the guidelines I just referenced.\n. :thumbsup: I plan to take some time and read this (when I find some free time).\n. Another good read that a colleague pointed me at: http://java.dzone.com/tips/java-pdf-tools-alternatives.  Read the (short) article, for context, but the comments are where most of the interesting information exists.\n. No activity here for almost a month.  Methinks this topic is dead, so I'm closing it.  If anyone objects, let me know, and I'll re-open.\n. Everything appears to be working properly to me.  It is your responsibility to set the success property on the response.  Your server-side code must return a valid JSON response, containing a \"success\" property w/ a value of \"true\" if the request has succeeded.  This is described in the readme.\n. What is the specific error?  Also, please include the contents of the\njavascript console when you reproduce this issue.\nOn Fri, Feb 8, 2013 at 7:30 AM, alandurkin notifications@github.com wrote:\n\nHi. Thanks for your response. I can see that now in the readme although I\ndidn't pick it up from my initial reading. I'll stick that in on the server\nside to resolve this. However, I'm still getting the error on your demo\npage. I'm on IE7 and WinXP.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/661#issuecomment-13290193.\n. I've repoened this case.  I don't currently have a way to test on a real IE7 browser.  I simply use IE9 or IE10 and set the browser to emulate IE7, which is usually good enough.  If you are seeing an issue in a real version of IE7 on the demo page, I would be very interested in seeing the contents of the javascript console, although that may not provide many clues since IE7 doesn't support the console object.  I'm also curious if you are seeing the same issue with your local code (after you have modified your code to return a valid JSON response w/ a success property.\n. Ah yes, the content-type of your response MUST be text/plain.  I would suggest doing this for all browsers.  This is also mentioned in the server-side readme, as others have run into issues with other content-type values on their responses.  I think it's also in the FAQ, but I'd have to look.\n\nIf it is broken in IE7 only on the demo, then something may have happened when I recently updated the demo a week or so ago.  Can you also list the exact demo page/url with the issue, in addition to the javascript console output when you have time to reproduce this next?\n. Thanks for following up with this Alan, and thanks for the donation.   I rarely receive donations outside of the releases page links, so I sincerely appreciate your contribution.  Happy uploading!\n. I'm not sure what your question is or what it is you are trying to do.\n. If you are reporting a bug, asking for support, or filing any other request, please have a look at the guidelines before you post any further.\n. I'm still not sure what your question is, or what you are trying to do.  Looking at the screenshot you provided, I'm even more confused.\n. I already pointed you at a document that explains why live examples are preferred.  Create a live example and link to it here.  There are many free sites that will allow you to do this.  I am spending a bit too much time fielding your questions as it is, but if you create a live example, I'll take a look.\n. When you copied the example from my source tree, you did so incorrectly.\n Have another look at the javascript that you modified in the section of\nuploader-demo-jquery.js that deals with the manually triggered uploads.\nOn Sat, Feb 9, 2013 at 8:52 AM, programmister notifications@github.comwrote:\n\nExample:\nhttp://testing.1gb.ru/fineuploader/test/jquery.html\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/662#issuecomment-13332019..\n. Look again, this time a few lines lower.\n. You are calling the uploadStoredFiles function on an arbitrary jQuery object, and NOT the jQuery object/element associated with Fine Uploader.  Also, it is not clear that you understand the difference between a button and the uploader container, since you are setting the button option with a value that should really be used as  the target of your plugin, and the target of your plugin instance is an element that should be your button.\n. This is a CSS issue with your button element that you will need to investigate yourself.  I'm sorry, but I don't really have time to track down css issues in every application that uses fine uploader.  If you do indeed find a bug with Fine Uploader, please open up a pull request with the fix.  Until now, I have received no similar issues related to the button option.  There are examples on the demo site where custom buttons are used (as well as the demo page you are using - see the FineUploaderBasic mode example at the bottom).\n. There is an existing feature request that covers this (#582).  It may already work in some scenarios, but I'm not sure as I have not tried to upload to S3 w/ Fine Uploader yet, and I haven't spent time researching this yet either.  I plan on investigating further in the 3.4 release cycle and adding/claiming explicit support for uploading directly to an S3 bucket.  \n\nIf you have further comments on the topic, please post them in #582 (the associated feature case for the 3.4 milestone.\n. Why can't you simply use a CSS selector like this to target the text div?\ncss\n.qq-upload-button > DIV {\n   text-align: center;\n}\n. I certainly haven't committed to any such model, and future releases, such\nas 4.0, may include drastic changes to the templating options, as I'm not\nreally happy with them right now at all.  I'm not sure it is necessary to\nattach a CSS class to each and every element created by the uploader.  That\nseems like overkill.  The button text element is reachable via the button\nelement class, which seems reasonable.\nOn Sun, Feb 10, 2013 at 9:36 AM, krheinwald notifications@github.comwrote:\n\nCan be done - did it. Does not fit the class based overall model, though.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/664#issuecomment-13351432..\n. This is explained in the \"comments\" section of the php.php file.  For future support requests, please use the support forum.\n. Your endpoint is something you must determine.  Ultimately, it will be a path where your server-side upload request handler resides.  This path can either be absolute, or relative to the address of the page serving the uploader.\n. Since others are not seeing issues in IE10 (including myself), additional measures will be required for me to investigate further.  Can you provide a link to a live app where this can be reproduced?\n. If there was an html file at one point, it was likely removed.  I don't allow html or javascript files in the server examples section as I don't maintain most of these examples (they are contributed) and these client-side files tend to decay and become out-of-sync with the project.  You will need to build your own html/javascript files based on the current documentation in the readme.\n. Need to follow up with Apple on this one. \n. Not seeing this in iOS 8.4. If you are having issues, the solution is to update to the latest iOS.\n. I'm not seeing any issues on my end.  Everything appears to be working as expected.  Please provide all of your client-side code, as well as the version of fine uploader you are using, along with the specific steps to reproduce, including browser type.\n. Ah, you are using 3.1.1.  I'm not seeing this in 3.2, which is the latest\nrelease.  If an issue does exist in 3.1.1, it is likely fixed in 3.2.\n\nOn Thu, Feb 14, 2013 at 10:12 AM, fieldingwilsonintuit \nnotifications@github.com wrote:\n\nThanks for the quick response.\nI'm using jquery.fineuploader-3.1.1\nHere's the complete code:\n$('#uploadBtn').fineUploader({\nrequest: {\nendpoint: '{{ share_files_url }}',\nparamsInBody:true,\ninputName: 'file'\n},\ndebug:false,\nmultiple:!isMobile(),\ndragAndDrop:{\nextraDropzones:[$('#uploadArea')],\nhideDropzones:false,\ndisableDefaultDropzone:true\n},\ntext: {\nuploadButton: ' ',\ndropProcessing:''\n},\nretry: {\nshowAutoRetryNote:false\n}\n}).on('submit', function(event, id, fileName) {\nuploadCount++;\n$('.qq-upload-list').show();\nfileName = fileName.replace(/ /g, '_');\n$(this).fineUploader('setParams', {'name':fileName,'action':'{{\nAction.UPLOAD }}','description': ''});\n}).on('complete', function(event, id, filename, responseJSON){\n$('#boxBarFiles').fadeOut(200,function(){\ncompleteCount++\nif(responseJSON.success)\n{\nvar url = \"{% url customer_share_files_list tax_response_id=\ntax_response.id %}\"\nvar target = $('#fileWrap');\n$(target).load(url);\n$('#boxBarFiles').fadeIn(500);\n$('.qq-upload-success').hide(5000);\nif(completeCount+cancelCount==uploadCount){\n$('.qq-upload-list').hide();\n}\n}\n})\nif(typeof _gaq!='undefined')\n             _gaq.push(['_trackEvent', 'ShareFiles', 'Upload',filename]);\n      }).on('cancel', function (event,id,fileName){\n          cancelCount++;\n          if(completeCount+cancelCount==uploadCount){\n            $('.qq-upload-list').hide();\n          }\n      });\nSTR:\n1. Select 6 files\n2. Files 1-3 upload, while files 4-6 are queued.\n3. Once the current uploads complete 4-6 start to process\n4. file6.txt is the first file of the second batch to complete\n5. file4.txt, file5.txt will all be recorded with the name- file6.txt\n[image: dbview]https://f.cloud.github.com/assets/2056956/157407/341b9c7a-76c1-11e2-8bd1-3bb91e1a4415.png\n[image: webview]https://f.cloud.github.com/assets/2056956/157408/343efb5c-76c1-11e2-8e43-528df21c42bb.png\nThe database has a field for the file path (a link to the location of the\nfile) and a field for the name (the name displayed on the webpage). The\nfile path field reflects the correct filename but the name field reflects\nthe duplicates.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/670#issuecomment-13560187.\n. I would be surprised if this was an issue in Fine Uploader, as I have not received any complaints about the params passed to the onSubmit callback so far.  Looking at your code a bit closer, I think the issue is not in the parameter passed to the callback, but rather in your call to the setParams API function.  You should probably pass a second parameter to your setParams API call (the ID of the file).  Have a look at my blog post on the setParams function for more details, if you need them.\n. I'm going to assume that my suggestion fixed this issue.  Feel free to re-open if it did not.\n. A few thoughts:\n\nFirst, i don't think a simple filename check is the best way to check for duplicates.  Surely two files can contain different content but have the same name.\nAlso, what, specifically, does startLoading call in the existing code? \n. I think I see your approach here.  Generally speaking, I'd like to make these sorts of tasks as easy as possible for users/integrators.  This means doing most of the work in the Fine Uploader library, such as making the ajax request, parsing the response, etc, but perhaps allowing an integrator with atypical requirements to override this behavior.  \nI'd like to take a closer look at your code, and perhaps adapt it into a version of Fine Uploader at some point.  I have been generally hesitant to provide a \"duplicate file detection feature\" until I found a way to efficiently calculate a hash for a file client-side.  Until then, it may be prudent to provide some way for integrators to check for duplicate files based on filenames.  I personally wouldn't find this useful in my projects that use Fine Uploader, since filename comparisons are not enough to detect duplicate filenames in my apps, but others could potentially find this useful.\nIf you could, please open up a pull request against the 3.3-IP branch, and thanks for your work on this.\n. Thanks for your explanation and kind words.  I'll drop this into a future milestone, and reference a similar case (#585) .  If you get around to opening up a PR, I'll tie all of these items in the project together for future reference when I begin to integrate such a feature into the library.  Either way, I'll look into this more during a future release cycle.  If I receive a bunch of \"+1's\" or similar requests, I may push it into the next release cycle, but that's not likely as I plan on starting the next release cycle shortly.\n. I'll probably have to boot this into 3.6 due to time constraints.\n. My implementation plan can be found here: https://github.com/Widen/fine-uploader/pull/692#issuecomment-14668184.\n. This is also somewhat related to #805.\n. I'd also like to add that I probably should allow the same return values (described in https://github.com/Widen/fine-uploader/pull/692#issuecomment-14668184) for the onValidate callback, in addition to the onValidateBatch callback.\n. I really want to think about this a bit more, and probably push it back a bit more.  I'm not completely happy with introducing additional conventions to address this need.\n. I favor the approach outlined in #848.  That's the direction I see Fine Uploader heading, potentially.\n. I'm not sure what library you are using, but it isn't this one.  We are only at version 3.2 (soon to be 3.3)\n. This is a very, very old library that is no longer supported.  In fact, it\nhas not been supported since after 2010.  You are posting in a forum\nattached to a replacement for that library.\nOn Fri, Feb 15, 2013 at 12:15 PM, sachintaware notifications@github.comwrote:\n\nHi rnicholus!!The details of the file I have are as follows\n/*\n- Ajax upload\n- Project page - http://valums.com/ajax-upload/\n- Copyright (c) 2008 Andris Valums, http://valums.com\n- Licensed under the MIT license (http://valums.com/mit-license/)\n- Version 3.6 (26.06.2009) _/ I was redirected to GIT after hitting\n  this link http://valums.com/ajax-upload/!! May be I am wrong but\n  still,is there a Cross Domain_ implementation for this??\n\u2014\n  Reply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/672#issuecomment-13620032.\n. The next version, 3.3, implements CORS support for all supported browsers, except for IE7.  3.3 will release in the next week or less, I suspect.  In the meantime, 3.2 is the latest release.  See #621 for more details.\n. You can check the value of the getInProgress API function in your onComplete callback handler.\n. There is API documentation.  All functions, options, and callbacks are documented in the readme.\n. No problem.  I realize that the current readme is a bit long, so I've split it up a bit in the 3.3-IP branch to improve readability.\n. @yairEO The documentation for the allComplete event is listed with all other events on the events page on the docs site.\n. @70074512 The current case of the allComplete event is correct in the context of the jQuery plug-in, and consistent with all other event names.\n. This change is not necessary.  All you need to do is set the paramsInBody option to true (which will be the default in 3.3 anyway), and set your token as a parameter.  It will then be passed in the request payload.\n. Hello again Robert.  I'm not a PHP guy (and I didn't write the PHP example) but I think this issue may have already been fixed in PR #641.  If not, or if your code fixes additional defects, please let me know,  The contributor in #641 explained his fix for what seems like the same problem as well, so perhaps reading that will help you to determine if your fix is redundant or not.\n. Thanks for the explanation Robert.  As I ask all contributors that modify example code in languages other than Java (since I only test/maintain the java example), can verify that your changes have been tested and work with all browsers/OSes supported by FU?  I'm not sure how much of this applies here, but, just in case.\n. Thanks Robert.  I'll probably merge this in tonight.\nOn Feb 15, 2013 2:11 PM, \"Robert K\" notifications@github.com wrote:\nJust finished testing on Linux, and successfully uploaded a file with 3\nchunks.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/675#issuecomment-13625618.\n. Why is this a problem, exactly?  Parameter names or values with non-ascii characters will be mangled if they are not URI encoded.\n. I see you've recited the spec, but i don't see how that solves the initial\nsituation i described.  Go ahead and have a look at a request with a non\nascii character in a parameter that is not uri encoded.\nOn Feb 17, 2013 1:01 AM, \"ampt\" notifications@github.com wrote:\nThe default Content-Type of a multipart/form-data part is text/plain, so\nthat should mean nothing is encoded. But if you have non-ASCII data it may\nbe encoded if it does not match the default encoding.\nhttp://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.2\nIn my case I have field names with brackets so uri encoding these in the\nbody of the reqeust results in two separate parameters and not an array of\nparameters.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/676#issuecomment-13681833.\n. ...I'm seeing a bunch of garbled text, and my default encoding is utf-8.\nOnly after i url encode the parameter am i able to receive the parameter\ncorrectly, server side (after decoding it)\nOn Feb 17, 2013 2:50 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\nI see you've recited the spec, but i don't see how that solves the initial\nsituation i described.  Go ahead and have a look at a request with a non\nascii character in a parameter that is not uri encoded.\nOn Feb 17, 2013 1:01 AM, \"ampt\" notifications@github.com wrote:\n\nThe default Content-Type of a multipart/form-data part is text/plain, so\nthat should mean nothing is encoded. But if you have non-ASCII data it may\nbe encoded if it does not match the default encoding.\nhttp://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.2\nIn my case I have field names with brackets so uri encoding these in the\nbody of the reqeust results in two separate parameters and not an array of\nparameters.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/676#issuecomment-13681833.\n. If you are having an issue, please post a url where i can reproduce and\ninvestigate further.  I have not received a similar complaint yet and this\ncode has been in place for a while, so I'd like to have a closer look.\nOn Feb 17, 2013 2:57 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\n\n...I'm seeing a bunch of garbled text, and my default encoding is utf-8.\nOnly after i url encode the parameter am i able to receive the parameter\ncorrectly, server side (after decoding it)\nOn Feb 17, 2013 2:50 AM, \"Ray Nicholus\" raygarstasio@gmail.com wrote:\n\nI see you've recited the spec, but i don't see how that solves the\ninitial situation i described.  Go ahead and have a look at a request with\na non ascii character in a parameter that is not uri encoded.\nOn Feb 17, 2013 1:01 AM, \"ampt\" notifications@github.com wrote:\n\nThe default Content-Type of a multipart/form-data part is text/plain, so\nthat should mean nothing is encoded. But if you have non-ASCII data it may\nbe encoded if it does not match the default encoding.\nhttp://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.2\nIn my case I have field names with brackets so uri encoding these in the\nbody of the reqeust results in two separate parameters and not an array of\nparameters.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/676#issuecomment-13681833.\n. Thanks much for your thorough explanation, and your time.  I'll look into\nthis more when i get some free time over the next day or so.  I am about to\nrelease a new version, and I'm a bit hesitant to include this type of a\nchange to the code so close to release time, but if a change needs to be\nmade it will definitely go into 3.4.  I'll keep this thread updated with my\nprogress.\n\n\n\nIs everything i said acceptable, or is this a blocker for you?\nOn Feb 17, 2013 6:08 AM, \"ampt\" notifications@github.com wrote:\n\nThanks for looking into this. I've done some more tests and to answer your\ninitial question a little more, here is what I've found:\nWhy is this a problem, exactly? Parameter names or values with non-ascii\ncharacters will be mangled if they are not URI encoded.\nI guess it depends on the encoding you are using and the enctype used when\nsubmitting the form.\nMy example HTML document is set to utf-8, so that is the encoding of the\npage, by default this means that the form data submitted will be utf-8\nencoded also. If you want to force a particular encoding then you can use\nthe form attribute accept-charset.\nI've got a proxy in the middle and watching the data as it is sent from\nthe browser to the server, the text data sumitted with non-ASCII characters\nis all garbled. But that is because the tool I'm using is showing me the\ndata in Mac (OS Roman) encoding.\nWhen receiving the data on the server side, it is expecting the data to be\nutf-8 encoded, and since the data was sent encoded in utf-8 there is\nnothing that needs to be done.\nAnother thing to note is that forms submitted via POST default to\napplication/x-www-form-urlencoded which is just like putting one big\nquery string in the body of the request. Obviously this should be\nurlencoded. It is a little different for POST requests with an enctype of\nmultipart/form-data, which according to the HTML spec states that the\ndefault Content-Type is text/plain and the default encoding seems to be\n7BIT, unless specified via the Content-Type and Content-Transfer-Encoding\nfor each part.\nPlease see this gist https://gist.github.com/ampt/4971171 as the\nexample I've used. This is a very simple example that just focuses on the\nencoding problem of non-ASCII characters.\nLet me know if there is any further information that I can provide that\nmay help.\nAlso for clarity here is some screenshots of the same POST request, one\nsent with application/x-www-form-urlencoded and the other sent with\nmultipart/form-data:\n[image: application/x-www-form-urlencoded]https://f.cloud.github.com/assets/158654/164902/0d7b5ab6-78fa-11e2-8526-ee765d9c1394.png\n[image: multipart/form-data]https://f.cloud.github.com/assets/158654/164903/160ab0c8-78fa-11e2-81bb-2cdaa96aae3a.png\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/676#issuecomment-13684912.\n. Note that, in browsers the support the File API, I'm using the FormData object to send the request.  So, there is no  element, and there is no form submission.  The FormData object is filled with parameters and the File or Blob object and sent using XMLHttpRequest.  As far as browsers that do not support the File API, such as IE9 and earlier, along with Android 2.3.x and earlier, an actual form inside of a hidden iframe is submitted to initiate the request.  Just thought I'd mention that in case you were not aware, to be complete.\n\nI too set the encoding type of the page to UTF-8 via a meta tag.  When I actually parse the request server-side and pull out the parameters, if the parameters are not URL encoded, they are still garbled.  I suspect this might be the fault of the application server I am using in my test environment.  Perhaps I need to make a configuration adjustment.  I suspect you are using Tomcat or nginx.  Is this correct?  I am using Jetty for testing purposes, but Tomcat in any production environments.  \n..continuing to look into this.  If I'm comfortable with any changes I make, I may include them in the upcoming release.\n. Wow, do I feel like an idiot.  After some more testing and configuration changes to my test application server, it's clear that you are completely correct here.  There was some very low-level code in my testing environment that was not treating parameter values as UTF-8 strings.  In fact, it was using the default character encoding on the server.  I realize that this \"issue\" existed for a while, but never took the time to properly investigate and simply resorted to URI encoding the form field values (and the form field names).  I'm going to undo all of this, adjust my test and Java example code, update the documentation, and most likely include it as part of 3.3. \nThanks again for bringing this to my attention and forcing me to take the time to properly look into this a bit more.  It's quite embarrassing that I let this issue exist for so long. \n. This has been fixed in 3.3-IP.\n. Thanks for getting back to me on this! Its always nice to have people\nfollow through.  I'll take a closer look and keep this and the associated\nfeature case updated with my progress.\nOn Feb 17, 2013 6:56 AM, \"pinkfoot\" notifications@github.com wrote:\n\nProvides a hook to permit custom pre-flight checking/processing of file\nlist, e.g detecting file conflicts, etc.\nYou can merge this Pull Request by running\ngit pull https://github.com/pinkfoot/file-uploader 3.3-IP\nOr view, comment on, or merge it at:\nhttps://github.com/valums/file-uploader/pull/677\nCommit Summary\n- issue #671: onBeforeStart callback added, to enable custom\n  pre-flight checking/processing of file list\nFile Changes\n- M client/js/uploader.basic.jshttps://github.com/valums/file-uploader/pull/677/files#diff-0(34)\nPatch Links:\n- https://github.com/valums/file-uploader/pull/677.patch\n- https://github.com/valums/file-uploader/pull/677.diff\n. I hope to look into this more in 3.4.  I've scheduled it appropriately.  I'm adding another reference to #671 so I can simply click it to see the associated case.  I'm lazy.\n. Not sure how this was closed. I didn't knowingly do this, and I can't re-open for some reason.\n. This was closed when I merged 3.3-IP into master, and deleted 3.3-IP. If you could, please move your changes into 3.4-IP and open up a new PR. If you don't have time to do this, no worries, I'll mark this and get to it anyway.\n. Hi there, Maxim.  I see you have elected to move your question to the support forum, so I will answer it there.\n. Your english is just fine, no need to apologize.  As far as your pull request is concerned, you are absolutely correct.  Just by chance, I think, another user posted the same issue (#676).  I plan on fixing that issue before 3.3 releases.  So, I'm going to close your pull request since I am tacking this issue in another case.\n\nI also noticed that your pull request includes some other seemingly unrelated changes/enhancements.  If you'd like to propose only these in a separate pull request, I'd be happy to take a look, but I can only consider those as part of 3.4, since 3.3 is frozen, as far as features are concerned.  You will likely want to wait to submit your pull request, if you choose to do so, until after I have at least fixed the issue in #676.\n. I think this is a good idea.  I'll also likely provide an API function for FineUploaderBasic mode users.  I'll schedule this for 3.4.  I already have a lot of items scheduled for 3.4, so it may be pushed into a later release if things get too crazy.\n. @laeubi This is not really possible for all features.  However, there are some such utility functions that cover feature support.  I'll be sure to keep this in mind when working on this particular case in the next version as well.\n. @laeubi That's a pretty good idea.  I'll keep that in mind when I start work on this case.  I may split off your idea into a separate case, but for now, I'll keep it here. Thanks again.\n. I'll start looking into this now for 3.5.\n. I'll start looking into this now for 3.5.\n. So, my plans here are:\n1. add a unsupportedBrowserMessage option and default behavior when FU is used in a browser which doesn't support <input type=\"file\">, e.g append an \"unsupported browser\" message to the top of the container element.\n2. Create a qq.supportedFeatures object that contains flags for each feature.  This object can either be populated/initialized completely when the library loads, or it can be loaded (and values cached) on demand.  The former may be easiest.  I don't think this will result in a noticeable increase in library init/startup time.\n. This is actually going to be quite tricky to implement.  The test required to determine if file input elements are supported requires the existence of the body element.  My intent is to initialize all feature flags during initialization of the uploader, but the uploader code may be loaded before the body tag is present.  On approach is to simply initialize the feature flags after the window's \"onload\" event.  However, this may be too late, especially if the code integrating Fine Uploader uses something like jQuery's document.ready() check, which may fire before the window's \"onload\" event.  I'd rather not duplicate the logic in jQuery's ready function.  It may just be easier and less risky (in terms of breaking Fine Uploader entirely for existing users) if I resort to the dreaded user agent string parsing to determine if IOS5 is the current user agent.  \nThoughts?  \nAlso, testing support for file input elements requires either access to an IOS5 device (I'm not sure I have access to such a device) or access to an IOS5 simulator.  Apple has made it very difficult to run an IOS5 simulator with the latest xcode in Mountain Lion.  The only IOS simulator with the latest versions of xcode on mountain lion is 6.x.  I'm attempting to download xcode 4.4.1 in hopes of running the IOS 5.1 simulator bundled with that, and we'll see how that works.\n. I was able to run an IOS5 simulator by navigating to the simulator packaged in the xcode 4.4.1 disk image.  After eliminating the code that depends on the body tag in my file input support detection code, the lack of file input support was still detected.  I will need to confirm that adding the file input element to the DOM is not required to accurately detect lack of file input support on a real IOS5 device though.  \n. I have completed all planned work on this feature.  I still need to run some tests on a real IOS5 device before I merge this into 3.5-IP.  \nA new object containing flags that correspond to features, qq.supportedFeatures, is documented in the docs/feature-detection.md file.  I've also linked to it in various places throughout the documentation.  \nI also append a <div> containing the contents of the new unsupportedBrowser property of the messages option if FineUploader mode is in use  and uploads are not possible in the current user agent.  Uploads are not possible if a file input element is not supported, or if the expected property of the cors option is set to true and the current user agent does not support XHR2 uploads and window.postMessage is not implemented by the user agent.  If this type of message is required in FineUploaderBasic mode, or if the default (simple) styling of this message in FineUploader mode is not sufficient, the integrator can check the value of the qq.supportedFeatures.uploading flag before initializing Fine Uploader and react appropriately.\n. Tested and confirmed on a real IOS5 device.\nThis has been completed in 3.5-IP.\n. This is in reference to feature #382.  I vote for requiring integrators/sysadmins to allow IIS to accept DELETE requests.  I don't much like allowing the request method to be adjustable.  DELETE is the correct method to use here.  It's possible other environments have been adjusted to prohibit DELETE requests.  In those cases, DELETE requests will need to be allowed to use this feature.  I'm fine with that.\n. I'm going to close this, but it can always be re-opened if there is more to discuss here.  I initially marked this as a documentation item, but I'll wait to add a FAQ entry until it becomes clear that this is needed.  Thanks!\n. Not sure how this was closed.  I didn't knowingly do this, and I can't re-open for some reason.\n. This was closed when I merged 3.3-IP into master, and deleted 3.3-IP.  If you could, please move your changes into 3.4-IP and open up a new PR.  If you don't have time to do this, no worries, I'll mark this and get to it anyway.\n. Yes, you must return a valid JSON response, as detailed in the troubleshooting section, and the server-side readme.  It looks like you did not follow the steps in the readme necessary to complete your integration of Fine Uploader.  Please do this, as it will save you a lot of trouble and confusion in the future.\n. Thanks!\n. javascript\nonSubmit: function() {\n   numFiles++;\n}\n. There doesn't need to be.  Use the code i provided.  Adding a new api function or option to solve a simple problem is not the best solution.  Besides, your function name is a bit vague at best and misleading at worst.  It will only list files that are submitted when autoUpload is set to false.  Utilizing the onSubmit callback is the best way to determine how many files have been submitted to the uploader.\n. When developing and maintaining a general-purpose library, used by many, it is important to keep a few things in mind.  One of those considerations must be to keep the noise level low.  This means, don't clutter up the API with functions that are not necessary.  There are already a lot of API functions, and the library doesn't need yet another that either replaces a few lines of code or addresses a need that is not shared by most or even many users.  The function you are proposing falls into both of these categories.  \nIf you want to count the number of files submitted, you can do so in a few lines of code, as proposed earlier.  I'm not sure why that isn't elegant.  As far as the name is concerned, that is indeed part of the problem.  In order to make it clear to integrators, it would need to be named appropriately.  I honestly don't know what sort of name would be appropriate.  Most likely a long name, which is also not desirable.  To make it more general purpose, we will need to add more code.  Instead, incrementing a counter in your onSubmit callback is much simpler.  \nThe existing API functions and callbacks can and should be used to solve various problems.  A new callback, option, or API function is not necessary for each individual problem.  It might seem like a new API function is an elegant solution to you, but it is not from my perspective.\n. @andres-torres-marroquin This case is closed, and this is not a support forum.  It is a forum for submitting bugs and feature requests.  Take some time to read the documentation (note the link to the support forum in the main readme) before posting rude comments here.  And please, show a little forum etiquette.\n. @andres-torres-marroquin You have no idea how many emails, issue/feature related posts, and support requests I receive each day.  Not to mention the work I do planning features, and then actually coding them.  I generally don't flag posts associated with closed cases for follow-up unless it is clear that the post will result in the case being re-opened.  At the present time, none of this is part of my actual job, so I do this as time allows, mostly in my free time, though my employer currently allows me to handle support requests during the day.  I do my best to address all questions and comments, and this can be seen if you take a minute to look at the issue tracker and support forums.  I challenge you to find another open source project with a maintainer as active and involved as myself.  You can make my life a bit easier by reading the documentation, not hijacking closed cases, and having a little patience.\n. @andres-torres-marroquin You have no idea how many emails, issue/feature related posts, and support requests I receive each day.  Not to mention the work I do planning features, and then actually coding them.  I generally don't flag posts associated with closed cases for follow-up unless it is clear that the post will result in the case being re-opened.  At the present time, none of this is part of my actual job, so I do this as time allows, mostly in my free time, though my employer currently allows me to handle support requests during the day.  I do my best to address all questions and comments, and this can be seen if you take a minute to look at the issue tracker and support forums.  I challenge you to find another open source project with a maintainer as active and involved as myself.  You can make my life a bit easier by reading the documentation, not hijacking closed cases, and having a little patience.\n. I'm completely confused as to what you are trying to do and what problem you are having.  Regardless, please post support questions in the support forum.  Please show your code as well.\n. The request headers you have provided do not give me any insight into your issue.  Looking at the first screenshot, though, it is pretty clear that your server is returning an invalid response.  My guess is that you have issues on your server AND you are not properly handling the retry request.  \nIf you have any further support requests, please post in the support forum.\n. The X-File-Name header was removed in 3.2.  I removed it as I don't particular like using unnecessary X headers.  The file name is available in the request payload by default (for MPE requests).  It looks like this example needs to be updated.\n. You are half-right.  If the request is multipart encoded, the content-length equals the entire size of the request.  If the request is not MPE, the content-length value equals the file size.  For MPE request, a new parameter exists for the file size: \"qqtotalfilesize\".  Note that this parameter is only sent for MPE encoded request, and only if the associated browser supports the File AI (otherwise the file size is not determinable client-side).\n. Any consensus on which of these two pull request I should merge?\n. Fixed in #689.\n. Hi there, and thanks for this.  Have you verified in IE9 and earlier, along w/ Chrome, FF, or Safari?  Does this happen to support chunking as well?\n. Thanks!\n. I plan on looking into this shortly.\n. A problem I'm running into here: header.js and footer.js have syntax errors.  I realize that this is not an issue if all files are combined, but I do not combine these files in my test environment, nor do I combine them on the demo/home page.  It's important that I am able to work directly with the individual files in these two environments.  \n@akre54 What are your thoughts on resolving this?\n. This was closed again, automatically by Github, when I released 3.4 and deleted the 3.4-IP branch.  I created a new issue, #776, to track future work on this.\n. I actually don't intend to distribute multiple files.  There is a downloads section where I provide up-to-date code combined into one file.  I separate the library into files in the source tree to make it easier for me to test and maintain them.  It's quite difficult to work with a 4200+ line javascript file.  I carved the giant javascript file into modules starting with version 3.0, which has made it much easier to read and understand the library, IMHO.\n. I still want to keep this on my radar, in case I come up with a way to make this happen.  I've created a feature case: #789.\n. Is there any reason you cannot access the qq global object/namespace created by Fine Uploader?\n. That's going to be quite a migration effort.  A lot has changed since valums/file-uploader.  That even predates my work on this project.  \nAre you actually loading both versions on the same page to construct two separate instances of the uploader?\n. If you're making use of templating in both, then you'll have a bit more work since that stuff changed quite a bit in 4.0.\n. @mrjoelkemp Let us know if @feltnerm's suggestion works for you.\n. This is in the process of being implemented for 5.8.0 in #1562.\n. Again, I don't know anything about this Rails plug-in your are using, so I can't help you with that.  You will need to take this up with the plug-in developer.  \nHandling multipart encoded requests in Chrome is no different then handling multipart encoded requests in IE.  However, if you want a non-multipart encoded request to be sent for File API browsers anyway, this is documented in many places, such as the server-side readme.  Please read the documentation for more details on how to control the various properties of the requests.\n. Sounds like you need to coordinate with the rack developer to update his/her plug-in.  No changes to the Fine Uploader code should be necessary.\n. I've thought about this some more, and have the following comments:\n1. I'm not sold on the callback name, though I don't have a better name (yet).  I'll need to think about this name some more. \n2. I think the best way to do this would be to make this new callback a promissory callback.  That is, a callback that returns a promise.  I'm assuming that the integrator will need to make some sort of ajax call here, and requiring a promise allows Fine Uploader to defer further action, without blocking, until the ajax call has succeeded (with information about possible duplicates) or failed.\n3. If there are duplicates, perhaps, by default, in FineUploader mode, the showPrompt function can be invoked.  The user can type in an option, say \"overwrite\", \"cancel\" or \"skip\".  I suppose many integrators might want to override this dialog with something a bit nicer looking, but that is easy to do.  I will probably want to give this a bit more thought, as I'm not crazy about having the user type in a choice, but I'm not sure there is a better way to do this without introducing a new UI element (that many integrators will likely want to override anyway).\n4. Perhaps I should provide a default ajax GET request that queries the server for a response, given the proposed file names.  The user can turn this off via an option and send their own request in the onBeforeStart callback.\n5. For FineUploader mode, I'd need to provide some UI element to alert the user to the fact that we are waiting on a response from the server in case the duplicate files request takes a non-trivial amount of time.  I already draw a larger spinner below the select files button after the user drops a folder for this very reason.  This spinner disappears after the entire folder tree has been parsed.  Perhaps I can use the same spinner with a different message.  \n@pinkfoot Thoughts?  Comments?\n. I've thought about this some more, and I don't actually think another callback is required.  The onValidateBatch callback can be used to deal with this.  Currently, a return value of false means that the batch should be ignored (preventing the files from being uploaded).  I think I could also accept a promise as a return type.  On success, the promise could deliver the names/ids of the duplicate files and possibly a description of how to proceed.  The return of a promise means that no blocking is required.  Fine Uploader will internally register a callback that will be executed when the associated ajax call returns.  Have a look at the qq.Promise documentation, along with the associated code for specifics.\nFor example, in FineUploader mode, user drops 2 files.  The onValidateBatch callback is invoked, and the integrator has an ajax call that asks the server if these files are acceptable.  Immediately, the callback returns with a promise.  Fine Uploader displays a spinner until the ajax call returns.  The callback notifies Fine Uploader of this event by calling either the success or failure functions on the promise instance. Assuming the ajax call is a success, the success function could be called, passing in the details regarding the duplicate files.  This could then result in a call to showPrompt where the user would be asked how to proceed (skip, overwrite, cancel).  \nIn FineUploaderBasic mode, the onValidateBatch callback could return a promise, make the ajax call, process the response, and then optionally invoke a dialog asking the user how to proceed.  After all of this is done, the success function can be invoked on the promise, passing in a list of the duplicate files along with details on how to proceed (overwrite, skip, cancel) based on the user's selection in the dialog.  \nFine Uploader can optionally make this even easier for users by making the ajax call itself.\n. Just to summarize, I would like to implement this by making the following changes:\nAllow a qq.Promise to be a valid return type from an onValidateBatch callback\nIf a promise is returned, the value passed to the success callback would need to contain a duplicates property with FileData objects for each duplicated file/Blob, according to the server.  An optional action property could also be contained in the object passed to the success callback that specifies how the uploader should proceed (overwrite, skip, or cancel).  If the former property is the only property contained, the showPrompt function will be invoked to ask the user how to deal with the duplicates.  This assumes FineUploader mode.  In FineUploaderBasic mode, both the action and the duplicates properties must be passed to the success callback, otherwise the uploads will simply proceed.  When in FineUploaderBasic mode, it is assumed that the integrator will display some sort of dialog to prompt the user for input as part of the onValidateBatch callback, or use some other method to determine how to deal with the duplicates, if they exist.  Note that if no duplicates are declared in the value passed to the promise's success callback, the uploads will proceed.  A boolean value of false will still be a valid return type (signaling that the uploader should reject all items in the batch).\nDocumentation updates & blog post\nAt this time, I don't have any plans to allow Fine Uploader to send a request on behalf of the integrator to be sent that asks for the server if any of the files in the batch are duplicates.  If integrators ask me to do this, I will oblige if there are well-defined requirements for this request.  In the meantime, it seems least intrusive to simply update the code associated with the onValidateBatch callback to handle a returned promise and write documentation to explain this feature to integrators.  \nLimitations\nCurrently, we can only really detect duplicates based on filename and file size.  Other file attributes are not really available client-side.  In fact, file size is not available in IE9 and older due to lack of File API support.  The onValidateBatch callback is appropriate for this feature since all available data for each file in the batch is already passed into this callback.  If we can parse more information about files in the future, they can be easily added to the passed object.  Ideally, I'd be able to efficiently calculate a hash for the file, see #585, but I'm not sure that can be done efficiently yet.  Also, I think non-files (Blob objects) are not appropriate for this feature, since Blob objects do not have name attributes.  I may need to annotate each \"FileData\" object in the array passed to the onValidateBatch callback with a type (file, or blob).  \nPlease chime in with your thoughts.  If this sounds acceptable, I will likely close this PR and update #671, which I will use to track this feature.\n. Any comments regarding my last post?  I'm not sure I'll get to this in 3.4.  3.4 development will likely stop in a few days as I will be overseas for week or so, and then will need to focus on testing 3.4 for release afterwards.\n. Sorry, Github automatically closed this when I release 3.4 and deleted the 3.4-IP branch.  I'll be tracking work on this issue for 3.5 in case #671  from this point forward.\n. Thanks for submitting this.  As of now, this is scheduled for investigation and possible implementation in 3.5.  3.4 is most likely over-full right now.  I'll provide more updates when I begin investigating this a bit more.  \nIf any other users see this as valuable, please comment.  More comments = higher priority.\n. Moving to 3.7.  I would also like to point out, that another solution may be to simply fade out completed file elements  (as they complete), leaving only the in-progress and failed files.\nIf 3.6 goes quicker than expected, I can bring this one back in.\n. Eh, on second thought, I'll put this in 3.6.\n. Eh, on second thought, I'll put this in 3.6.\n. I remember attempting this a while back and giving up due to a few workflows that were difficult to deal with.  My attempt is documented in case #439.  If anyone is interested in this feature at all, please read my comments in #439 and comment here (or there, if you must).  If I don't receive any comments in the next few days, I will move this into 3.7.  If I don't receive any comments after a reasonable amount of time into 3.7, I may close this altogether as \"will not implement\".  I'd also like to see if more than 1 user is interested in this.  A reasonable way to deal with a long list of files is to, perhaps, remove successfully uploaded files (as they complete) from the UI (via a display:none style or some sort of jQuery hide animation), leaving only the in-progress and failed files.  \nThoughts anyone?\n. Thanks for your quick response @larslemberg.  I'll give this a bit more thought.  Worse case scenario, I'll punt it to a later release to give this more time to simmer.  Generally, I only like to make changes to the library that I think would be beneficial to many Fine Uploader users.  The concerns I noted in #439 led me to believe that most users would find the new behavior less than useful.  However, you have outlined a real-world workflow that I will definitely ponder over the next few days before I do anything further with this case.  Perhaps others have similar requirements.  I'll post an update after I've thought about this some more.\n. I can see doing something (hopefully) simple, like prepending each batch of selected/dropped files to the list and not worrying about ensuring the order in which the files upload matches the order they appear in the UI.  For example: say a user drops 10 files, and the first 3 of that batch are in progress.  Then, the user drops 5 more files.  Then, the user drops 3 more.  The upload order will be: the first 10 (in the order they appear), followed by the next 5, followed finally by the last set of 3.  This, of course, will not match the order they appear in the UI anymore since the batches will be prepended to the list in the UI.  I can see this behavior (prepnding the batches) being controlled by an option specific to FineUploader mode (defaulting to \"off\").\nIs everyone ok/happy with this proposed behavior?  Any comments?  Or, would some other behavior be more useful/appropriate? \n. Looking into this now for 3.6...\n. Looking into this now for 3.6...\n. Ask and ye shall receive.  I've implemented this in 3.6 (currently in the develop branch).  There is a new property available when using FineUploader mode under the display option: prependFiles.  It defaults to \"false\", but when set to \"true\" batches of files are added to the top of the list in the UI.  If batch selection/DnD is not supported, each individual file is added to the top of the list after it is selected.\n. Please see my note in the other case you commented on (#688) and make the appropriate changes to this pull request.    Also, please let me know if you have tested in both IE9 (or earlier), and Chrome.  Thanks!\n. I'm afraid I don't really understand your last comment.  If you are handling MPE requests, you really should use the qqtotalfilesize parameter, if available.  If handling non-MPE requests, use content-length to verify the file is the expected size.  What browsers did you test this in?\n. @nnmware Please post this in the support forum, with your code, and I'll be glad to help.\n. Closed in favor of #689.\n. This will be dealt with in #680.  The PR was automatically closed when I deleted the 3.4-IP branch.\n. Thanks Danny.  I'll schedule this for 3.4, but 3.4 is already quite full.  If I don't get to it in 3.4, I'll research further in 3.5.\n. For reference: the associated thread in the GetSatisfaction support forum.\n. That seems to be the way the web is going.  My employer is in the process of replacing a Java applet uploader in their web apps in favor of Fine Uploader as well.  Java on the client-side is dead and buried.  Flash is next.\n. Looking into this now for 3.5...\n. As requested, I have removed all default styles previously associated with the .qq-uploader container element.\nThis has been addressed in 3.5.\n. I reverted my change here. Removing the default relative positioning of the container element (.qq-uploader), causes the child div that holds the drop zone (.qq-upload-drop-area) to fill the entire page when (the drop zone) is visible.  This is due to the fact that .qq-upload-drop-area is absolutely positioned, with top and left values set to 0.\n. Thanks.  This looks potentially useful.  I'll take a closer look sometime this release cycle.  I have some qunit tests that I will run, and possibly add to as part of this process.\n. Sorry, this was automatically deleted when I released 3.4.  I've created a new issue, #775, to track this.\n. Hello @behigh.  Since you contributed this pull request, the licensing for Fine Uploader has changed.  Please respond within the next 5 days if you are willing to keep the code you have contributed in the repo.  Note that the code will be licensed under either the GPL v3 license or the Widen commercial license.  In either case, it will become the property of Widen and Fine Uploader.  If you are not comfortable with this, I will not use your code in the library.  If you do not respond within 5 days of this message, I will assume that you are not willing to contribute the code to the repo under the conditions I have just described. \n. Thanks @behigh.  I'll look more into your proposed changes after I complete the next couple in-progress cases..\n. This results in some breaking changes as far as request parameters are concerned.  We'll have to deal with it in as part of a future major version release.\n. 4.0 or later\n. Not sure this is necessary or makes sense.  We already have a blog post that includes instructions on swapping out the dialogs using alertify.js.  This post also includes some basic modifications to the default template to add some bootstrap styling.\n. Thanks!  I'll merge this in shortly.\n. Thanks!\n. What is the purpose of this pull request?  All you've done is add a mootools core js file to the root of the source tree.\n. Closing, as I'm not sure what the intent of this pull request is, and no description has been provided.\n. The bootstrap styled example exists on the home page.  The other items you have mentioned are not specific to bootstrap.  Please have a look at the readme and the demos on the home page.\n. No response from poster after 3 days.  Closing.\n. You can setup your own validation rules and enforce them via the onValidate\ncallback.  There is no way to determine if the same file has been\nselected.  If you want to prevent multiple files with the same name from\nbeing dropped or selected, you can certainly do that.\nOn Feb 28, 2013 6:14 PM, \"JonoB\" notifications@github.com wrote:\n\nAt the moment, it seems possible to select the same file more than once if\nyou manually trigger uploads.\nIs it possible to prevent this?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/702\n.\n. Also see case #671 for more information.\n. I'd prefer to not add an option for this and leave implementation of requirements such as this one up to integrators.  There are valid reasons to upload files with the same name.  For instance, files with the same name from different paths on the file system.  Also, preventing duplicate filenames using the code you have provided will have bad side effects in IOS, since IOS uses the same stock filename for each file (image.jpg). \n. Also, your code will fail with an Error in IE8 or earlier since Array.prototype.indexOf was only first implemented in IE9.  Use the polyfill I created: qq.indexOf.  See documentation for this function and other similar utility functions in the qQuery section docs.\n. Take another look at the main readme page and this time please actually\nread it.\nOn Mar 1, 2013 7:50 AM, \"Ra\u00fal Ferr\u00e0s\" notifications@github.com wrote:\nWhere did the detailed documentation go?\nThere was a page describing all accepted arguments, events and callbacks\nbut I can't find it.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/703\n.\n. How do you know you are dealing with the same file?  Simply based on the name?  I hope not.  This is not solid logic.  If you are accepting files from an IOS6 client, all files will have the same name, all the time.  If the client sends a Blob in the request (as opposed to a file), the name is determined by a qqblobname param, which may or may not be unique.  What if your user uploads two files with the same name from two different paths on their filesystem? \n. How do you know you are dealing with the same file?  Simply based on the name?  I hope not.  This is not solid logic.  If you are accepting files from an IOS6 client, all files will have the same name, all the time.  If the client sends a Blob in the request (as opposed to a file), the name is determined by a qqblobname param, which may or may not be unique.  What if your user uploads two files with the same name from two different paths on their filesystem? \n. The examples can't possibly account for each use case, and modifications are necessary in many, if not all, cases.   It is expected that you will modify the example to suit your needs.  If I receive a number of other users with the same request, I will consider modifying this file.  Until then, it seems reasonable to simply comment this out if it is not a helpful behavior in your app.\n. I think you are looking for the onError callback, which is called, among other times, when a default validator causes the file to be ignored.  Have a look at the callbacks section of the readme for more details.\n\nAlso, I'd like to use the Github issue tracker to track bug reports and feature requests only.  Please open up support requests such as this one in the support forum in the future.  Thanks!\n. I think you are looking for the onError callback, which is called, among other times, when a default validator causes the file to be ignored.  Have a look at the callbacks section of the readme for more details.\nAlso, I'd like to use the Github issue tracker to track bug reports and feature requests only.  Please open up support requests such as this one in the support forum in the future.  Thanks!\n. 3.4 is insanely full at this point.  I'll schedule for 3.5, but that's pretty full too.  On the plus side, progress on this project will likely pick up for good within the next few weeks.\n. After some additional thought, it seems like this can be achieved without adding another API method.  For example, you can set a flag that is set whenever your onSubmit callback handler is invoked, and then reset again when you call the uploadStoredFiles API method.  You mentioned in your original request: \n\nI need to know if the Fineuploader has files or not to upload.  \n\nYou can do this by checking the value of this flag when the user clicks \"save\".  I really don't want to clutter up the API with something that can be accomplished with a simple flag.\nI'm going to leave this open for another day or two before closing as \"will not implement\" in case you want to discuss this further.  Hopefully I did not miss something here, but if I did, I'd like to discuss.\n. No one has requested this, and properly oriented scaled versions seems useful enough.  Perhaps the scaling feature can be expanded at some point to generate modified versions (such as properly oriented) of the original file at the same resolution as the original file.  #1061\n. There are no plans to work on this case.  We already orient scaled images correctly.\n. I don't believe this is something that I or anyone else can fix.  \nHere is my explanation, from the FAQ:\n\nQ: I have created a  element for my uploader button, but this doesn't seem to work in IE.  Why?\nA: In IE, the button element receives the click event, instead of the child input element.  Use a  or a  or an  instead.\n. onComplete is and should always be called when the upload completes.  This is why it is called onComplete on not onSuccess.  If the responseJSON parameter has a property of success with a value of true, you know that the  upload succeeded.\n. Are you 100% sure your complete event handler is not called?  My guess is that it actually is called, but something is failing inside of your callback in IE8, specifically.  Have you looked at your javascript console?  Surely there are errors there.  You've only shared a portion of your code here, so I can't say for sure what is happening.  Please provide a live example if you'd like me to investigate further.\n. Sounds good.  I've tested this callback on the demo page w/ IE8, and all looks well to me.  Perhaps you could try this as well.  Go to the display image thumbnails demo (near the middle of the page).  Select a file that meets the listed requirements.  If you see the stock image appear below the file listing (the child with a green and white shirt), then this signals that the \"complete\" callback handler has been invoked.  This is using Fine Uploader 3.3, which, presumably, you are also using (since you haven't said otherwise).\n. ...also, please show me the contents of your javascript console when this happens.  I will be shocked if no errors are present. \n. Hi Craig.  Im not familiar with this term \"reproducer\".  Is this something specific to ASP?  Anyway, If you could provide a link to a running example with this problem, I can take a peek.\n. Strange that this only caused a problem in IE8.  Knockout was on my short list of javascript libraries to play with, but I have been wrapped up in AngularJs lately, and am loving it.  \n\nI'll close this.  If you would like to keep it open for some reason, let me know.\n. I would be interested in looking at this, but perhaps it would be easiest if you pasted any existing code required to reproduce this into something like jsfiddle and provide a link in this case.  This way, I can look into this and potentially come up with a better solution without spending time attempting to reproduce this myself, since you have already successfully reproduced this issue.  I'll re-open this case, pending a working example that I can spend some time examining.\n. FYI, it looks like attaching a file an email-based github issue response does not work.  Feel free to send the zip to fineuploader-issue710@garstasio.com, and I'll take a peek.  Thanks!\n. Not going to do this.\n. completed in #805 \n. Not sure how important this is.  Moving to 3.7.\n. Probably not going to do this.\n. Depends on #716, so, moving to 3.7.\n. Addressed in 3.5-IP.\n. Not going to happen in 3.6.  Perhaps 3.7, but more likely not until 3.8 or so.\n. There's no obvious benefit here anymore.  Closing.\n. seems reasonable.  Thanks!\n. Seems like a reasonable request.  I'll consider sending the XHR object, if it exists, as a parameter when invoking the onError callback.  Sound good?\n. I'll start looking into this now, since it should be a trivial adjustment.\n. This has been implemented in 3.4-IP.  Ironically, I think the onError callback may have included this parameter at some point, but I believe I removed it.  I can't remember why and am too lazy to hunt through the history to determine why since it seems like this should be passed if available anyway.\n. I fully expect this to be worked on as part of this release cycle (3.4).  I likely won't release 3.4 until the end of this month, though, since I will be out of the country and unable to work on Fine Uploader for about a week (starting this saturday).\n. Ha! I already merged it into 3.4.  I didn't even notice!  I'm guessing your question was regarding the release of 3.4, which I addressed in my last sentence.\n. Hard to say.  Big changes are on the horizon.  Could be this release or next.  Either way, you can always rebase, or, at worst, re-clone.\n. Looks good to me after a brief peek.  If everything tests out, :thumbsup:.  You can probably get the added benefit of testing this more as your write a blog post on how to integrate alertify and/or bootbox dialogs into FU.\n. Whoa!  I should look at submitted pull requests a bit closer I guess!  Thanks for bringing this to my attention.  I'll fix it now.\n. demo.html has been removed in 3.4-IP.\n. This is likely a 4.0 task.  Perhaps other browsers will be added along with Opera.\n. This may be simple since Opera is now using blink.\n. I anticipate that this will be closer to a 2 (instead of the original 5) as far as storypoints are concerned.  Since Opera is essentially Chrome, I don't think this will be difficult. This is a 2 instead of a 1 \"just in case\".\n. Opera 15+ will be supported starting with FU 4.1.  It has complete feature parity with Chrome.\n. My biggest problem with markdown or a markdown-esque syntax is that you are limited as far as styling your documentation is concerned.  Fine Uploader has quite a bit of documentation, and it's easy to get lost or frustrated when looking at a sea of black and white.  This is why I originally suggested we create an HTML version of the docs.  Docco is appealing in that it allows us to add the documentation to the code itself, but I'm concerned (without knowing much about Docco admittedly) that it will not be flexible enough for this project.  Some elements of the documentation probably do not belong in the source code, for example.  \nI think the goal here is to make the documentation:\n- searchable\n- easy to read\n- appealing visually\nFor example, I like some elements of RaphaelJs's documentation (but I'm not crazy about the formatting).  Another example of better-than-markdown documentation, in my opinion can be found in the KnockoutJs project (though it's not perfect).\nPerhaps some sort of documentation templating system exists that would generate HTML for our docs and allow us to define styles for them based on some set of conventions. \n. For example: 3.3 is a new \"version\".  If I do release a hotfix version, such as 3.3.1, I will be more than happy to email the zip to those who have contributed to the associated release (3.3 in this example) upon request.  \nI generally follow accepted standards as far as version conventions are concerned.  That is, 3.0 represents a major release with significant changes to the entire product.  3.1 represents at least a month of work that includes bug fixes, new features, and enhancements.  3.1.1 would (and did) include a fix for a serious issue detected in 3.1 (Android clients could not upload).  The latter is considered a hotfix release, and wold be emailed to those, upon request, who contributed to 3.1.  \nThis model has been setup to allow me to focus on coding and support, without having to deal with the overhead associated with maintaining a list of those who have contributed to 3.1 or 3.2 releases and then enforcing contributions for the 4.0 release.  Your complaint is valid, but I simply don't have the time to enforce a pay-per-license model, or a pay-per-major-version model at this time,\nUntil more resources are added, I am the only one maintaining the code, fixing bugs, answering support questions, etc.  So, I have chosen a model that allows me to focus on these things. More resources will likely be added to this project this month.  When that happens, the payment model will most likely change to something a bit more intuitive, such as a commercial licensing fee instead of a per-download fee.\n. Thanks for your understanding.  As more resources are added to this project (most likely this month) big improvements will begin to occur.  The current payment model will be one of the many changes.  The model is currently being discussed at this time.\n. Moved to Widen/fine-uploader-server.\n. Yes, you are  correct.  This DIV is required in IE7.  This was likely accidentally left off when I moved the example code to gists last month.  Thanks for catching this.\n. Fixed!\n. You can do whatever you want with the file, after your server-side code handles the upload request.  Of course you can't simply point the uploader at a directory and expect the file to appear.\n. Your question doesn't really make any sense.  Of course you need a server\nto handle the HTTP request.  Based on your question, it sounds like you are\nnot a software developer.  This library is targeted at software developers.  In order to utilize this library, you must have\nat least a basic understanding of CSS, HTML, javascript, and HTTP.  It is\nlikely in your best interests to pass this integration effort to a coworker\nor associate who is familiar with these concepts.\nOn Tue, Mar 5, 2013 at 8:58 AM, priyapanigrahy notifications@github.comwrote:\n\nI mean using HTML5 File API (without introducing any server side\ncomponent).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/726#issuecomment-14443896\n.\n. Forgot about button.js, so I converted that file first.  Now, on to the last 2...\n. Not 100% optimistic about this attempt since these two files are so complex and critical, but I'm willing to give it another try here...\n. I remember why I have punted on this several times before.  The amount of effort required to properly hide the \"private\" properties and still allow inheritence between FU and FUB is probably not worth the effort and all of the regressions that this will initially create.  At least I converted button.js.  I'll probably think about this from time to time and many make another stab at it later on.\n\nAt least the jQuery plug-in prevents (easy) access to these \"private\" properties.  Most people seem to be using the jQuery plug-in anyway.\n. 1. I don't accept pull requests for anything in the client directory on the master branch.\n2. This has already been implemented in the 3.4-IP branch.  See #718.\n. I can't say for sure as I haven't looked into this yet.  Please see case #389 .\n. Yep, that seems about right.  I simply haven't spent time diving into camera access.  I'm going to close this case.  Let me know if you want it open for some reason.\n. Hi there.  I can certainly pass the XHR object to the onComplete callback.  Please be aware (if you are not already aware) that the XHR object will not be passed if the user agent does not support the File API.  \nI'll mark this as an enhancement and tentatively schedule this change for 3.4.\n. Sorry.  This fell off my radar somehow.  I'll get it into 3.5 for sure.\n. Completed in 3.5-IP.\n. The examples on the home page reference the combined javascript file.  It's much easier to include the combined, version-stamped javascript file then to include all files in the source tree.  The files are split up in the source tree to make them more maintainable.\n. Scheduled for 3.4.\n. Described further at https://getsatisfaction.com/fineuploader/topics/removing_hidden_input_when_file_is_deleted.\n. This has been implemented in 3.4-IP.\n. There already is ample documentation on the delete feature.  This is all explained in my blog post which is referenced in the readme in several places.\n. Ok.  What do you have so far, and what specific questions do you have?\n. First off, why are you writing all of this code to handle dragging and dropping?  DnD is provided for you in FineUploader mode.\n. ...also, what is this \"deleteAttachment\" function?\n. Oh, I see.  You are using basic mode.  Why are you using basic mode?  The forceConfirm option does not apply to basic mode.\n. First off, the forceConfirm option does not apply to basic mode.  That only works when using FineUploader mode.  Second, there is no need to send the ajax DELETE request yourself.  Fine Uploader does that for you when you call the deleteFile API function.  The deleteFile function doesn't return anything.  You must rely on the associated callbacks to get the status of the delete operation.  \nFine Uploader will send a DELETE request, and the resource associated with that request will be the UUID of the file.  Fine Uploader always sends a UUID with each file upload request.  You need to associate these UUIDs with the files server-side so you can handle the DELETE requests.\n. You don't have to send anything.  Fine Uploader sends the UUID for the associated file.  The ID parameter represents the ID of the file for this session.  It is simply an integer that starts at 0 when the upload is initialized and is incremented for each file submitted to the uploader.  The UUID is an ID, also created by Fine Uploader, unique among all sessions.  You must set the endpoint in the deleteFile option appropriately, yes.  This is no different than setting the endpoint for the upload requests in the request option.\n. The URL will look exactly as described in the W3 spec for a DELETE request.  In this case: \"{yourendpoint}/{file_uuid}\".\n. In which callback, and why do you need this client-side?\n. Again, you don't need to send the UUID.  Fine Uploader does this for you.  You provide the endpoint address and Fine Uploader will add the appropriate UUID and any parameters, then it will send the request.\nYou don't need to build any URL.  Just specify the address where Fine Uploader should send the DELETE request.  Simply make the deleteFile API call, and Fine Uploader does the rest.\n. Since you are using basic mode, of course you will have to add the delete links/buttons yourself to the DOM.  Each link, when clicked, would need to call the deleteFile API function and pass the local ID of the associated file as a parameter to that function.  Fine Uploader will then send a DELETE request to your sever.  Server-side, you must parse this request, grab the UUID from the URI path, find the associated file, delete it, and then response with a 200.\n. You certainly don't want to re-create the uploader each time the user clicks the delete link!  You need to call the deleteFile API function when the user clicks the delete link.\n. $('#uploader').fineUploader('deleteFile', fileId);\n. The PHP example was not updated to handle the delete file request.  I hope to have the examples updated at some point in the future, but I don't usually maintain any of these myself, with the exception of the java example.  Andrew Valums updates the PHP example when he has time.  It shouldn't be hard at all to handle this request.  In my blog post, I describe the request and how you should handle it.  You can apply this logic to your PHP code.  It's really nothing more than a DELETE request with the UUID as the last element in the path.  Once you delete the file, you just respond with a 200.\n. I hope I have answered your questions, so I'm going to close this case.\n. This has been requested before.  I have not implemented this due to the fact that this is not possible in all browsers.    In IE9 and earlier, a form is constructed and submitted in order to upload the submitted file.  Unfortunately, PUT is not a valid value for a form's method attribute.  So, sending files via PUT requests would not be possible in all IE browsers other than IE10.\n. duplicate of #554\n. I'll close this, but I'm willing to add support for this if enough users are interested.  I just figured that it wasn't worth the effort since you will have to account for POST requests regardless, unless you don't support IE9 and older.\n. @radek This is certainly possible, but not in IE9 and older.\n. I'll re-open this.  The addition of a method property on the request option could be easily added and enforced.  This new property will be ignored in older browsers, as well as Fine Uploader S3 and Azure.\n. The only way to work around this would be to modify the internals of Fine Uploader, specifically the setParamsAndGetEntityToSend method in the qq.traditional.XhrUploadHandler constructor function.\n. The traditional endpoint upload module doesn't extend/use AjaxRequester.  So, if you are looking to allow for PUT uploads to traditional endpoints, that won't work.\n. I meant to couple the traditional upload handler to AjaxRequester, but never got around to it.\n. This has been implemented in develop as 5.2.0-3 and will be part of the next 5.2.0 release.\n. 5.2.0-5 accounts for PATCH, and also allows PUT/PATCH for upload success requests.\n. Not sure i understand the problem.  Also, iron browser is not a supported browser at the moment.\n. I have not seen any issues myself in chrome, or any other browsers, and I've tested extensively.  Please provide a functioning test case on jsfiddle, or something similar, so I can look into this further.  A link to a live example also works.  \nI won't be using any jQuery code inside the core, as this project does not have any hard dependencies, and I intend to keep it that way.  Furthermore, native map functions are not supported well in all browsers (such as in IE8 or older).\n. Also, is this reproducible on the demo page?  I've read over your case several times and I'm having a hard time following your logic.  A simple list of steps needed to reproduce the problem, along with a description of observable issues along with the expected outcome would be helpful here. \n. Sounds good.  If you have a working example that reproduces this behavior, I'd be interested in seeing it and exploring myself.\n. I see.  Can you provide some code that reproduces this issue?  I'll need to reproduce before I can look into fixing it.  Since you are already seeing this issue, I'm hoping you can post some code that I can use to reproduce.  Once that is in place, I can schedule work on this.  Thanks!\n. Sounds good.  No rush.\nOn Mar 10, 2013 11:17 AM, \"clubnite\" notifications@github.com wrote:\n\nSure, please give me some time. I'm on it and will post some code as soon\nas i can reproduce it.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/735#issuecomment-14683838\n.\n. Forgive me if I sound condescending or rude here.  That is not at all my intent.  However, you are suggesting that I modify the code to account for a situation that might occur if some 3rd-party dependency, MooTools in this case, decides to insert invalid items into the allowedExtensions value array.  There is an entire website devoted to these types of fixes.  I'd like to keep my code off of that website, if possible :laughing:.  Seriously, though, this type of fix to address an extreme edge case caused by, what I see as, a bug in a 3rd-party tool is not something I'd like to introduce into this codebase.    Introducing this type of a fix will likely elicit a \"WTF?!\" when someone else (even myself, possibly) comes across this code in the future.  However, I do sympathize with you, given the situation here.  I suppose it wouldn't be hard for me to simply add this check, though.  Certainly much easier than writing this long reply.  Thoughts?\n\nI'll admit I'm surprised to see that MooTools still exists.  That is, surprised, not happy.  Prototype and Mootools are both frameworks that made very bad architectural decisions up front when they decided to extend the DOM.  I keep my distance from either of those frameworks, when I can.  That's another topic though.\n. Well, i can certainly add this check to the code.  I'll mark this as a\nthird party bug and address it this release.  For the record, i didn't say\nanything about jquery earlier as i wasn't sure jquery was causing this\nproblem, since i use jquery in all of my projects that make use of Fine\nUploader.  After i make this change to the code, if you could also verify\nmy fix in your specific environment, that would be helpful.  Thanks for\nyour time on this.\nOn Mar 10, 2013 2:00 PM, \"clubnite\" notifications@github.com wrote:\n\nThanks for your sympathy ;-) Seriously, i absolutely agree with you and i\nknow the Joomla! core developers are about to drop MooTools step by step.\nBut until this is done, they must keep it part of the system as there are\nmany unsolved dependencies from the past to be solved and ported to jQuery\nyet. I can't imagine that this kind of type check together with a comment\nline why this is used would anybody make to think \"WTF?!\". From my point of\nview this would look like code from a developer who is thinking in advance\nand taking the stupidity of others (other frameworks) into account to have\nits plugin working properly in an unreliable environment, wouldn't you\nagree? But you are right, it is not your responsibility to catch\nincompatibility issues caused by third party libs. I wonder why you did not\nargue like that as soon as i mentioned jQuery to be involved, which is a\nthird party lib as well. ;-)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/735#issuecomment-14686850\n.\n. @clubnite Please have a look at my fix in the prevent-non-string-in-allowedextensions branch and ensure this fixes your issue.\n. Well, a function definition is not a string, unless that definition is enclosed in quotes.  In that case, it's not really a function definition.  \n\nqq.isString(...) will return false is this is passed in as an arg: function() {return 'foo';}, for example.\nAre you saying that function definitions are \"stringified\" before they are added to the allowedExtensions array?  This is even stranger than I thought.\n. Just to clarify, the qq.isString test should return false for all inputs other than the following:\n1. A string literal, i.e. \"foo\", or \"bar1\", etc.\n2. A string created using the String constructor, i.e. new String(\"foo\").\n. This fix has been merged into 3.4-IP.\n. Support has been moved to Stackoverflow.  See the support page for more information.\n. Something is definitely amiss on your end, as I'm sure all of this works.  You'll need to provide me a live, working example that reproduces this problem so I can take a closer look.  A link to your web app is one such option.\n. Ah, I see the problem.  The jQuery event is always the first parameter passed to an event/callback handler.  You are accounting for this in your \"submit\" handler, but not in your \"complete\" handler.  Looks like a typo is causing all of this grief for you.  The params in your complete handler are all one off: id = event, fileName = id, and responseJSON = filename.  \nYour \"complete\" handler should be declared like this:\n.on('complete', function(event, id, fileName, responseJSON) {...\nAlso, out of curiosity, why are you looping over the elements with a \"file-upload\" css class, and then instantiating a Fine Uploader instance for each, instead of just doing this:\njavascript\n$('.file-upload').fineUploader(\n{\n   ...\n}\n. Are you asking how you can remove or hide the entire element below the upload button that represents an uploaded file after the file uploads successfully?\n. Coincidentally, I just answered a similar question on Stack Overflow.  It sounds like you may benefit from my answer there as well.  Let me know if this isn't what you were looking for.\n. Thanks Lance!  I'll go ahead and close this case then.\n. Whoa.  I never suspected Erlang and Fine Uploader would ever meet.  Cool, and thanks.\n. Hello Simon. There actually is a case open for this.  See #531.  I am familiar with Angular as of late, but I'm not clear what sort of \"angular\" support is needed here, specifically.  What makes this library difficult to integrate into an angular app currently?  Care to share your thoughts?\n. I'm not quite sure how this library could be refactored into a directive, or if it is even worth the effort, quite frankly.  I suppose the API would sit in another directive, or a controller, but not the API functions that deal with the DOM?  There's a lot of these types of questions that need to be answered before I can work on something like this.  Also, we are really talking about creating a new library, instead of adding a feature to this one.  jQuery support was fairly easy as I simply created a wrapper around the core library.  This is quite different.\n. That brings us back to my original question, though.  I'm familiar with angular.  I've written directives, controllers, services, etc in the recent past.  I'm also, of course, very familiar with the Fine Uploader code.  It's not clear to me what a Fine Uploader directive would do that Fine Uploader doesn't already do.  If we are talking about writing a directive that handles the UI portion of Fine Uploader, well, that makes things a bit complicated.  Where does the rest of the code go?  Why can't an integrator simply create a directive, in a few lines of code, that wraps the existing library?  What arguments would be passed to the directive via attributes?  Certainly not all of them.  \nMy main point is, what is needed here exactly?  What specific problems are angular developers finding when they attempt to integrate the existing code into their projects?  I've come across at least one implementation of a directive using Fine Uploader, but I can't find the link currently.  Anyway, the directive was fairly specific to this user's application.  That's what I would expect, quite frankly.  I'm not sure what a generic Fine Uploader directive would look like, or if it is worth the effort to create one.  \nIf a Fine Uploader angular directive would be useful, I'm looking for very specific problems that need to be solved in the angular world.  That is, problems or annoyances that developers run into while attempting to integrate Fine Uploader into their apps. \n. Hi there.  I have no way to currently test the MVC code.  So, if you could, please open up a pull request with your tested changes.  Thanks!\n. If someone wants to offer a PR & test, we can re-open.\n. Thanks!\n. If I were to add a request timeout, I would need to:\n- ensure both XHR & iframe/form upload requests, along with all other (DELETE) requests use this timeout\n- make this timeout configurable and optional\nI think this timeout would be disabled by default. I'll look into this more in 3.5.\n. @Maigre Can you possibly tell me a little more about your situation?  What sort of number are you thinking of using as your timeout value?  How would you expect this timeout to work?  \nI am asking based on the following observations & facts:\n- There is a timeout property on the XHR object, but this is apparently NOT supported in any webkit browsers (Chrome & Safari)\n- The timeout property on the XHR object, where supported, apparently is reset whenever there is some activity between the client and server, even before the file/request has been completely sent and the server has sent a response.\n- There is no native \"timeout\" property for form-based uploads.  We have to resort to form submission for browsers that do not support the File API (IE9 and older).\nIn order to make this timeout work cross-browser, I'd have to code my own timeout support for webkit browsers.  I'd also need to create some sort of a timeout for form-based uploads (in order to make this feature cross-browser), but I'm not sure it is possible to make it behave like the timeout property on the XHR object.  This is due to the fact that there is no way for me to determine if the connection between the client and server is still active (or if the server is even receiving the request).  I simply have to wait for the onload event on the associated iframe.  \nThoughts?\n. Pushing this to 3.6, or until I receive more feedback on this request.  If I don't receive any feedback within the next couple release cycles, I'll close this as \"will not implement\".\n. Moved to 3.7.  If I don't get any feedback during work on 3.6, I will probably close this as \"will not implement\".\n. No response after a month, closing.\n. XHR timeouts are now supported in Chrome/Safari, so perhaps we should look into implementing this.\n. I'm going to look into this as part of 5.11.9, since network errors (particularly pulling the connection mid-upload) causes the upload to hang for a long time. That seems like a bug to me, and if we can make this less of an issue, even in a subset of browsers, that seems like a big win.\n. I think I now remember why I kicked this can down the road for so long. Setting a timeout on an XMLHttpRequest instance does not function as one would expect (or at least as I would expect). The clock starts ticking as soon as the request is sent. If the request does not complete before the timeout expires, the browser cancels the request. I would expect the request to timeout only if there is no HTTP traffic for a length of time equal to the timeout value. \nThe problem with the standardized behavior of XMLHttpRequest.timeout is that it may be very tricky to determine an appropriate and effective value. When you choose a timeout value, you have to consider that some internet connections are faster than others. For example, if you choose a timeout value of 5 seconds, with a chunk size of 5 MB, the request will always timeout for files being sent from a typical home internet connection with available upstream bandwidth of 4 Mbps, since each 5 MB chunk will take about 10 seconds to complete. But for faster connections, this timeout may be appropriate. A safe value may be ineffective since it probably has to be a fairly large one.\nIn light of this, I'm strongly considering abandonment of this \"feature\". Another option: advise integrators to set a reasonably high value, but this honestly seems like it may cause more problems than it solves. I'm open to input, but I'm putting this on hold for now.\n. This does not appear to be a Fine Uploader question.  You will need to post these types of questions on stackoverflow.  Thanks.\n. You told me your click handler is not called.\nOn Mar 15, 2013 5:39 AM, \"odissea\" notifications@github.com wrote:\n\nWell everything is working fine and as expected, calls are also correct\nbut the plugin just don't execute the DELETE-Request so I think this is the\nplugins' issue.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/744#issuecomment-14954034\n.\n. When you stepped through the code to see why the request is not being sent, what did you see?\n. You'll need to provide me a live, working example if you'd like me to investigate further, such as a link to your app. \n. Sure.  You can email me for this case at fineuploader-744@garstasio.com.\n\nOn Fri, Mar 15, 2013 at 9:18 AM, odissea notifications@github.com wrote:\n\nSince I can't send you private messages through GitHub, would you kindly\ngive me an e-mail adress where I can send login credentials and link of my\napplication ? (It's private)\nThanks, odissea\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/744#issuecomment-14962966\n.\n. Please switch to the non-minified version of the Fine Uploader library.  It's impossible to debug minified code. \n. Ugh, this appears to be a bug specific to FineUploaderBasic mode.  \n\nThe flaw is on the 2nd line of _onSubmitDelete in the FineUploaderBasic module.  It should only prevent sending of the delete request if the onSubmitDelete callback returns \"false\".  Instead it does this if the return value is not true.  The FineUploader module handles this correctly, but not the FineUploaderBasic module.  \nAn easy workaround is simply to contribute your own submitDelete callback/event handler that always returns true.   This seems to address this specific issue and allow the DELETE request to be sent.  However, I noticed that your server will respond to this DELETE request with a 405, which suggests that you have not allowed DELETE requests in your server yet.  You'll need to do this.\n. GET is not appropriate for a request that modifies resources, but I suppose I could allow it to be sent as a POST.  That would require a bit of refactoring though.  DELETE requests must have the UUID of the file to delete in the URI path, and any other parameters in the query string.  POST requests should generally have params in the payload.  I'm not sure if I should send the UUID of the file to delete in the URI or as a param for POST requests.  I'd need to think about that.\nI don't think I'll allow POST requests to be sent to delete a file in the next version.  In the meantime, you'll need to be sure that your servers allow DELETE requests.  If you'd like me to make the method configurable, please open up a feature request.\n. This issue has been fixed in 3.4-IP.\n. Hmm, I can't seem to reproduce this anymore.  I'm using Chrome Beta 26.0.1410.43.  Perhaps this was fixed in an update since my last attempt?  I'll try out Chrome stable and see if it happens there.\n. I'm having trouble finding a formula to reproduce this.  I have found one particular alias where this is reproducible, so I'll start there.\n. Should be fixed in 3.5-IP.  @jnoer Can you confirm that this fixes the issue you were seeing?\n. I'm going to call this fixed as I cannot reproduce the issue anymore.\n. @andrejordao Please let me know what serious issues you were having, and if the current version fixes them.  In the future, please file bug reports if you encounter serious issues, as I was not aware of any such issues with IE10.\n. I'll look into this more, hopefully, in 3.5.\n. Moving to 3.6.  May be moved further off still.\n. Bumping this to 3.7, unless others express interested in support for this old version of Firefox.\n. No plans to support this version of FF.\n. I'll look into this further, tentatively, in 3.5.\n. Addressed in 3.5-IP.\n. As Uriah mentioned, I think it is prudent to investigate some improvements to the implementation of the addFiles API function. I'll look into this more in 3.6.\n. Completed in 3.6.\n. @cvpsmith It is entirely up to the sever-side code to place the uploaded files into a specific directory structure.  Currently, the path information is not passed along with the files.  It is possible to pass this information along with the POST request, but, of course, only in Chrome 21+.  I can see why this may be useful information for some users.  I can investigate passing the file path in a specific parameter, when this path information is available.  I'm not sure I will get to this before 3.6 though.\n. Looking into this now for 3.6...\n. Eh, there's going to be a bit of a problem implementing this, due to a bug in Chrome (that has apparently existed since mid-2012).  \nLong story short, this bug means I won't be able to determine the file path in Chrome 21+ unless the files are dropped.  In other words, I will not be able to determine the path of Files selected via the \"select files\" dialog.  I guess I could simply pass the path only for dropped files, but I'm wondering if that's really worth the effort.  Maybe it is.\nComments?  Thoughts?\n. Bumping this to 3.7.  There is a good chance it will continue to be bumped until the bug I filed against Chrome is addressed\n. It seems like relative path information is only really useful when a directory is dropped.  The path that is reported by the Filesystem API is the path relative to the top-level-dropped directory.  This is only something we can report in Chrome and Opera at this time, since no other browser supports the Filesystem API, which is critical to this feature.\nA new dragAndDrop option will be added: reportDirectoryPaths.  It will default to false.  If set to true, a \"qqpathfromroot\" parameter will be sent with the upload request if the file is associated with a directory drop on a qualifying browser.  The value of this parameter will be the path of this file from the top-level dropped directory.  \nFor non-traditional endpoints, such as Amazon S3, the parameter will be prefixed appropriately.  In the case of S3, this parameter will be \"x-amz-meta-qqpathfromroot\" for non-chunked uploads.  For chunked uploads, we will need to include a x-amz-meta-qqpathfromroot header in the initiate multipart upload request, which must be accounted for in your bucket's CORS rules.  Again, though, this header will only be sent if the new dragAndDrop.reportDirectoryPaths option is set to true.\nI'm not going to merge this feature into the develop branch until I've taken some time to think about this a bit more and get some opinions from internal users who might find this data helpful.  This is being staging in the feature/directory-paths branch, where it appears to be completely functional.\n. @kbubb @nmall Please see my comments above.\n. Looks like this will not make it into 4.3.\n. This can be completed at any time, but I want to hold off until your team has time to integrate this into Smartimage and provide feedback.\n. This is going to sit until we have some time internally to discuss and test in one of our products that requires this feature.\n. @anishgarg Keep in mind this is only possible if dropping a folder in Chrome or Opera 15+, and the path string sent along with the upload request is only relative to the top level folder that a user dropped.\nWhat is your specific use case?\n. Ok.  The plan is to simply append a \"qqpath\" parameter to each upload request if we can determine the relative path of the uploaded file.  \nFor example, consider a directory named \"foo\" that is dropped into Fine Uploader in Chrome or Opera:\n[foo]\n....file1.txt\n....file2.txt\n....[bar]\n........file3.txt\nqqpath request parameters for each file will be:\n- \"file1.txt\": \"foo/\"\n- \"file2.txt\": \"foo/\"\n- \"file3.txt\": \"foo/bar/\"\nIs this what you are expecting?\n. It might be possible to fit it into the current release cycle (4.4) which\nshould be completed in mid-March.  The likeliness of fitting this into 4.4\ndepends on the aggregate progress bar feature (in progress).  If that\nfeature goes smoothly and nothing else comes up, we can probably fit it in.\n Otherwise, it will likely be part of 4.5.\nOn Thu, Feb 27, 2014 at 5:42 PM, anishgarg notifications@github.com wrote:\n\nThanks for you quick replies :).\nYes, what you have mentioned is exactly what I need.\nI know its soon. However, did you guys finalize about your plans when you\nare going to release with this enhancement?\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/750#issuecomment-36306087\n.\n. Working on this now for 4.4.\n. This feature will be part of 4.4.  For Fine Uploader UI users, a qqpath param will be sent with each file, if the feature is enabled via Fine Uploader UI's dragAndDrop.reportDirectoryPaths option.  \n\nFor those making use of the standalone drag & drop module, a qqPath property will be appended to each File handled by the drag & drop module (provided a path can be determined).  The value of this property can be sent with the upload request via the setParams method.  \nNote that this feature should work for all endpoint types.\n. You can access the qqPath property on the actual File object, which can be obtained via the getFile(id) API method.\n. @laeubi Can you provide more information about your setup?  Posting your client-side code would help me better understand why you must rely on function-based parameter values for your application.  There are other ways to control parameter values.  For example, you can call setParams in any available callback.  \nPlease post your client-side code, and we can discuss this issue further.\n. A couple questions here:\n1. Why are you providing your own file input element?\n2. Why are you using function values for the params option instead of just calling setParams from, say, the onUpload callback?  The file ID & name is passed to this callback, and it is invoked only once per file.  I know you provided some explanation regarding your decision to not use the setParams API function, but I'm not really following your logic, so you may be to explain a bit more.\n. @laeubi I'd like to have a look at your web app so I can better understand your problem/setup.  Is there some way you can give me a peek?  Perhaps my help will be a bit more useful if I better understand your specific situation.\n. @laeubi Are any changes still required here, or did you resolve this by making use of #780?\n. Typo.  I meant to say #760.\n. What sort of \"hack\"?\nIt may make sense to evaluate only once, but that will add a bit of complexity to the code, and it's not clear if the functions should be re-evaluated if the upload is retried.  I can see why it may be useful to re-evaluate on retry.  My inclination is to hold off on \"fixing\" this until I hear from more users.\n. Ignore the last commit.  I associated it with the wrong issue by mistake.  It should have been associated with #784.\n. Closing this as it's quite old and I'm not certain anything needs to be done here. If additional integrators have concerns or suggestions, I will consider re-opening.\n. @kleesman Please provide a link to your live app where we can reproduce this.\n. I have reproduced this issue on Chrome Beta (26).  I also verified that it does not occur in Firefox.  This is not a serious issue, and since I am already in the testing phase of 3.4, I will have to defer further investigation on this until at least 3.5.  Thanks for the report!\n. Looking into this now for 3.5...\n. I've reproduced with a very simple HTML file that includes nothing but a simple \"onbeforeunload\" handler.  This appears to be a bug in Chrome.  I've filed an issue and am awaiting a response from the Chrome team.\n. A Chromium developer has asked me to provide a screencast to aid in reproduction.  I will do this as part of my work in 3.6.\n. Not seeing this anymore in latest chrome.\n. @odissea Please provide a link to your live app were I can investigate further, or please post a working example on jsfiddle.  Thanks.\n. Will do. I'll investigate further on monday, using the URL and username/password you emailed to me when investigating case 744.\n. Thanks for taking care of this @tellibus.  It world have been a while before i reached it in my queue.  Much appreciated.\n. @dtucke It looks like you are using a very old version of this library.  Certainly pre-3.x.  You will need to upgrade to the latest version before we can go any further.  After upgrading, please open up a support request if you run into any issues.  Thanks.\n. @sebastienros Does this address the issues described in #741?\n. Thanks.  You might want to hold off on a PR for a few days, as there will be some big changes to the repo either tomorrow or Tuesday.\n. This issue is 2 years old no one has complained or offered a fix.\n. @sebastienros If you can offer a PR, we will certainly re-open though.\n. I'll look into this more in 3.5.  Thanks for the explanation and suggested fix.\nI think maybe the best way to fix this is to use something like this:\nObject.prototype.toString.call(maybeBlob) === '[object Blob]'\nIf the above returns true, the object is a a Blob.\n. I have QUnit tests for many of the functions in util.js.  As I add more resources to this project, more browser-based (webdriver) tests will be written.\n. Fixed in 3.5-IP.\n. This is a confirmed bug in IE7-IE9.  It was likely introduced during some major refactoring that was part of 3.2.  This is an easy fix and I will address it in 3.4.  The first line of the reset function in handler.form.js needs to be removed.\n. Fixed in 3.4-IP.\n. Is there some reason why you can't/didn't use the setParams and setEndpoint API functions?  It seems a bit redundant to provide a way to set the params and endpoint here when you can already do this via the API.\n. Hmm.  I'll give this some thought in 3.6.\n. Looking into this now for 3.5...\n. This has been completed for 3.5.\n. There is no way to determine file size client side in IE.  Please see the IE limitations section (linked to in the readme) for more such IE limitations.\n. If you read my comment above you will understand why.\n. Please post support requests in the support forum.  Thanks.\n. Thanks James.  There may be some other minification-related issues, especially with very aggressive minifiers.  The gradle plugin uses the Google closure compiler.  If we use \"advanced\" mode when minifying the javascript, we run into other problems.  There is currently an open case where I plan on looking into this more.  Please see #640 for more details.\n. Thanks for the feature request.  I'll look into this more in 3.6.\n. I'll start looking into this now for 3.6.  Perhaps this could be as easy as allowing you to return a UUID in your success JSON response.  That UUID would replace the one generated by Fine Uploader.  That is, Fine Uploader would take this UUID and replace it with the one it maintains for that file internally.  I think you could simply return a UUID property with a value in your response. \nIt looks like you suggested all of this in the last part of your message above.  \n@yoks How does this sound?\n. Implemented for 3.6.\n. Jason mentioned that he was also able to reproduce in 3.4-IP.  I'll attempt to reproduce now...\n. Seems to be working fine in 3.4-IP.  Let's see if it's just broken in 3.3.1...\n. Also seems to be working fine in 3.3.1.  I haven't received any other reports of this, so this may be not be a Fine Uploader issues.  @jnoer Let's talk about this some more tomorrow.\n. This turned out to be an issue unrelated to Fine Uploader.\n. Going to run a few tests with Smartimage tomorrow.  If all looks good, I hope to have time to release 3.4 tomorrow night.\n. I'm not sure I understand your question.  Are you asking about sending values that correspond to form fields along with each file upload request?  If not, could you please elaborate a bit more?  Perhaps provide me with a more detailed/complete, real-world example.\n. Why do you want to have your own file input(s)?  What sort of application are you developing?  \nAs far as a \"submit\" button is concerned, you can set the autoUpload option to false, create a simple button that, when clicked, calls the uploadStoredFiles API function, and then use the setParams API function in one of your callbacks, such as onUpload that passes in the values of the non-file input fields.  These field values will then be sent as parameters along with the POST request.\n. Note that Fine Uploader already sends a multipart encoded POST request by default for each file.  As mentioned in my post above, you can associate any parameters you want with this request via the setParams API function, or the params option.\n. Ok, you are asking for a way to have multiple files sent in the same request, correct?\n. A few things:\n1. Note that the multiple attribute is not supported on file input fields in IE9 or older, so this will never be possible in those browsers.\n2. There is currently no way to attach multiple files to a single upload POST request sent by Fine Uploader.  I haven't seen a good use case for this yet, and providing this ability would require refactoring and a good amount of work.\n3. You can certainly use your own file input fields and register an onchange handler on each field where you pass the file(s) to Fine Uploader for submittal/upload.  Have a look at the addFiles API function, which allows you to submit files or blobs directly to Fine Uploader via the API.\n. Fine Uploader will work in IE7 as well.  It also probably works in IE6, but IE6 is not officially supported.\nThe fact that files are never sent in the same request is not due to cross-browser support.  It is theoretically possible to refactor Fine Uploader to send multiple files in one request for all browsers.  However, this behavior has never existed in Fine Uploader as it makes many of the features a bit more complicated, and it is not clear to me what is gained by allowing multiple files per request.\n. Thanks for this pull request, and I'll investigate further in 3.5.  You may want to re-submit this pull request against 3.4-IP though, since pull requests are merged in to IP (in progress) branches, and not master.\n. Verified as an issue...\n. Fixed in 3.5.  Thanks for catching this @wedo-aasousa.\n. It looks like you have mixed your other pull request (#768) into this one as well.  \nYour particular situation seems atypical and your pull request does not account for non-XHR uploads, such as those sent from IE9 and earlier, along with Android 2.3.x and older.  However, I can understand, potentially, a need to override the default response parser.  So, I'm going to keep this open and perhaps give this some more thought.  \nI'm not sure if you are only supporting browsers that support the File API, or if you just neglected to handle cases where the File API is not supported and a form inside a hidden iframe is submitted to upload a file.  Please comment on this as well.\n. Replaced by #995.\n. @jnoer Is this the smallest number of files where this is reproducible?  If not, can you please provide the lower limit, as far as number of files is concerned?\n. Ok.  I'll look into this more in 3.5.\n. After some thought, I'm not sure it is important to ensure a user can drop 6,000 or more files simultaneously.  A web-based solution is probably not the correct approach for someone with this need.\n. Let there be analytics!\n. @uriahcarpenter Hmm, it doesn't appear to be tracking visitors, at least not my visits.\n. It looks like the init function on clicky is not being executed.  I executed it manually and was tracked.  Looking into this now...\n. Fixed now.  The script elements were not being executed in the order the appeared in the footer markup doc.  I'm not entirely sure why, but I suspect they way footer.html is being imported into each back (via jQuery.get) had something to do with it.  So, I am now using jQuery.getScript() to import the clicky script and then waiting for jQuery to call me back when the script has been loaded before i call clicky.init().  There's no need to keep the noscript section, since the footer won't load anyway if javascript is disabled.\n. Split off into #863, #864, and #865.\n. I'm working on this now for 3.7.  Some things to consider/test:\n- [x] Should the auto-resume feature key on the new filename, or the old one?  I'm thinking new.\n- [x] Server-side code will now need to look for a \"qqfilename\" param if this feature is turned on.  FU will have to send this new filename as a parameter.\n- [x] Disable \"cancel\" action while editing a filename?\n- [x] Is clicking off of the input or causing it to otherwise lose focus a good enough time to persist the changed name?  I think so.\n- [x] Do we need a (configurable) edit icon next to file names that can be edited?  Probably.\n- [x] Should we make the original name accessible somewhere?  Yes, via the upload-data (getUploads) module.\n- [x] Should users be able to change the extension as well?  Probably not. \n- [x] Hitting enter \"saves\" the change. \n- [x] Hitting tab \"saves\" the change and moves to the next filename field.\n- [x] Add a class name to the inputs so they are easier to style/select\nPerhaps I should have @avo or @joshuaArd take a peek at the UI when I'm done.\n. Feature has been completed for 3.7.  See the blog post for details.\n. Notice the following issues I'll have to patch:\n- [x] Tabbing while in one of the visible edit filename text fields does not focus the next field in the DOM.  This is due to the fact that Firefox is apparently the ONLY browser that does not support the focusin event.  I'll probably have to add a focus event handler to each text input after a new file item is added to the DOM.\n- [x] Clicking on a filename below an exposed filename text input only hides the exposed text input.  It should hide the exposed text input and show the text input associated with the clicked filename, as it does when you click a filename above an exposed text input.  This appears to be an issue in all browsers.\n. Both items should be addressed now.\n. Keep in mind that this will require server-side cooperation from integrators like yourself who want this feature outside of Chrome.  In short, you'd have to proxy pasted images from your own server if the image is from a different domain if the server hosting the image doesn't implement the CORS spec (or if the browser doesn't support CORS for images).\n. For that particular workflow, CORS shouldn't be a factor.  I can see how this might be useful, but I'm wondering why you don't just suggest your testers use Chrome to make their lives easier.  I can certainly increase the priority of this feature, though.\n. That all makes sense.  I'm going to schedule this feature for 4.1 (the current release cycle).  I was originally going to put it into 4.1, but moved it out after lack of response from users.  With your comments and internal requests, I think it makes sense to look into this for 4.1.\n. Keep in mind that there are some unknowns here that make this potentially tricky.  I know this can be done, but I haven't spent a lot of time considering exactly how I'm going to fit this into the existing feature set and supported workflows.  Nonetheless, I'll be looking into it during this cycle.\n. After some more research, I've concluded that the only additional browser I can support for this feature is Firefox.  Safari and IE simply cannot handle pasted images from the clipboard.  The method for obtaining an image pasted from the clipboard in Firefox requires the use of a contenteditable <div>.  \nIt looks like I will have to hide this <div> and focus it whenever the user starts their paste operation by pressing CMD/CTRL.  This will, of course, take the focus away whatever element already has focus.  I suppose I could return focus to the original element after the paste is complete, but this will likely cause problems where the upload form contains form fields (such as text input fields).  \nAnother option would be to embed the specified paste target/container as a child of a contenteditable <div>, and simply handle the paste event when it reaches this parent.  This would not require I mess with focus, and would (theoretically) ensure the feature works in FF just as it does in Chrome (to the user) since the paste container  must be focused for the image paste feature to work in Chrome.  However, this would prevent integrators from specifying document or <body> as a paste target in Firefox.  It will also likely break (poor) selectors on sites that take hierarchy into account.\nI'm thinking that, given the obstacles associated with enabling this feature in Firefox, I should put this off until a later date (perhaps until Firefox implements the Clipboard API).\n. Blocked until these browsers support the Clipboard API.\n. To my knowledge, this is still only properly and completely supported in Chrome. \u00a0Do you have evidence of support in other browsers? \u00a0Did something change in Firefox recently to allow support?\nOn Tue, Oct 14, 2014 at 7:56 PM, dfoor notifications@github.com wrote:\n\nIt looks like several browser support this now. Has it been addressed?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/774#issuecomment-59142977\n. Yea, I saw that. \u00a0I believe that has claimed support for Firefox for a while, but it has been broken as long as I can remember. \u00a0Haven't tried again recently. I'll test it out on other browsers and update this case. \u00a0Feature detection for this feature has been impossible due to lack of a ClipboardEvent constructor function, which still seems to be an issue in most browsers.\n\nOn Tue, Oct 14, 2014 at 8:32 PM, Sam Sehnert notifications@github.com\nwrote:\n\nHere's the current support as per caniuse:\nhttp://caniuse.com/#search=clipboard\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/774#issuecomment-59145912\n. Looks like Firefox (and possibly other browsers) still require the paste target to be a contenteditable div, and the only access to the file is via a data URI which then must be converted to a Blob. \u00a0This is far from ideal, so I\u2019m still calling this not supported. \u00a0\n\n\u2014\nSent from Mailbox\nOn Tue, Oct 14, 2014 at 8:37 PM, Ray Nicholus rnicholus@widen.com wrote:\n\nYea, I saw that. \u00a0I believe that has claimed support for Firefox for a while, but it has been broken as long as I can remember. \u00a0Haven't tried again recently. I'll test it out on other browsers and update this case. \u00a0Feature detection for this feature has been impossible due to lack of a ClipboardEvent constructor function, which still seems to be an issue in most browsers.\nOn Tue, Oct 14, 2014 at 8:32 PM, Sam Sehnert notifications@github.com\nwrote:\n\nHere's the current support as per caniuse:\nhttp://caniuse.com/#search=clipboard\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/774#issuecomment-59145912\n. Conversion of a data URI to a Blob is the easy part. \u00a0Fine Uploader already has code to do that internally in the scaling/image preview modules.  We\u2019d have to determine which approach to use to extract the pasted image, perhaps based on the paste target? \u00a0I can see how pasting to upload may be useful in other browsers, but I don\u2019t see it as a high priority to get this working outside of Chrome (relatively speaking). \u00a0Also, the required approach to get a handle on the pasted image is a bit kludgey, as it involves using setTimeout or setInterval to wait for the browser to create the IMG element after the paste with a src attribute representing the pasted image. \u00a0\n\n\nI\u2019ll keep this open, and perhaps we\u2019ll get to it at some point.\nOn Wed, Oct 15, 2014 at 12:17 PM, dfoor notifications@github.com wrote:\n\nI see--thanks for looking into this; I got excited when I saw it on caniuse and just wanted to check.\nWould it be possible to convert the target on a browser case basis, and then use something like this to do the conversion?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/774#issuecomment-59241555\n. >was wondering if browser now fully support it\n\nGood question. Further investigation with backing evidence is the next step before going forward.. That fiddle is a bit noisy and I don't have the time to read through it. The best approach would be to see how far we can get with the implementation in Fine Uploader that already works for Chrome. Perhaps it is as simple as making a few trivial adjustments to make use of support for the clipboard API in other browsers. . They must use a contenteditable div of course. Hello @behigh. Since you contributed the associated pull request (#697), the licensing for Fine Uploader has changed. Please respond within the next 5 days if you are willing to keep the code you have contributed in the repo. Note that the code will be licensed under either the GPL v3 license or the Widen commercial license. In either case, it will become the property of Widen and Fine Uploader. If you are not comfortable with this, I will not use your code in the library. If you do not respond within 5 days of this message, I will assume that you are not willing to contribute the code to the repo under the conditions I have just described.\n. This results in some breaking changes as far as request parameters are concerned. We'll have to deal with it in as part of a future major version release.\n. No plans to implement this anymore, unless anyone feels strongly.\n. duplicate of #789\n. Completed in 3.5-IP.\n. Fixed in 3.4.1.\n. Completed in 3.5-IP.\n. I'm not seeing any issues with the progress bar or % complete indicator in Firefox.  What version of Fine Uploader and Firefox are you using?\n. @worldspawn Your request is a fairly odd one, and certainly atypical.  So, I just want to make sure I understand your specific goal(s) here.  You are definitely the first to request something like this, specifically.  I'd like to be sure you understand the limitations of this workflow.\n1. Drag and drop of files will not be possible.  This is due to the fact that we cannot create a file input element with a predefined value.\n2. Most of the other features of Fine Uploader will be inaccessible, since communication with the server will be handled outside of the library.  These features include manual/auto retry, chunking, auto-resume, and, quite frankly, almost all of the features Fine Uploader provides.\nWhat you are asking for here does not require a library.  If you want multiple file input elements on a form, simply create multiple file input element on a form - no library required.  If you are using anything other than IE9 or earlier (or the most part) you don't even need multiple file input elements, necessarily.  You can associate multiple files with one file input elements via the file chooser in those browsers.\n. Currently, Fine Uploader is not designed to serve your specific need.\nFine Uploader does create file input elements for each selected file, but only for browsers that do not support the File API (IE9 and older mostly). Also, it creates a file input inside a form inside of a hidden iframe. There is one iframe per file. Fine Uploader then submits these forms to upload the file, waits for the server response, and then parses it.\nFor browsers that do support the File API, file input elements and forms are not used internally at all. The File API is used to submit the files via XHR.\nFine Uploader behaves this way as this serves the needs of the vast majority of developers looking to add cross-browser upload support to their web application.  It also allows for a great number of features to be built into the library, such as progress tracking (for File API browsers), chunking & auto-resume (also File API only), auto/manual retry, upload via paste, and on and on.  Your particular scenario is not one I've knowingly come across before.\nIn order to accomodate your use case, there would need to be modifications made to Fine Uploader. Perhaps it would be prudent to create a separate small library to handle this (your) particular situation since this would be a significant departure from the goal of the existing library.\nRealistically speaking, though, I am not sure when I can fit this in. Priority is given to popularly requested features, bugs, and features that I think would benefit a large number of people. This particular request does not seem to fall into any of those categories at this time. Perhaps if other users show an interest in this kind of support, I can update the priority accordingly. Unfortunately, I have a finite amount of time and there are many other cases in my queue.\nPerhaps there are some adjustments to the existing library that would be just as appealing? For example, would it benefit you to simply allow Fine Uploader to submit multiple files in one request? That has been requested before, but in each case I was able to convince the requestor that this was not at all necessary in their case. Your case may be different, though. I'm certainly willing to continue discussing this until we figure something out.\n. @worldspawn I'll have to address any further comments in about 8 hours.  It's after midnight here.\n. Just caught your last comment.  One more response for me tonight.  \nI would agree.  It doesn't seem uncommon to have a form with a requirement to allow the user to associate multiple files and multiple non-file-input elements.  As you have mentioned, the way to deal with this when using Fine Uploader is to send each of the form field values along with each (file) POST request and sort this out server-side.\nPerhaps Fine Uploader can/should be adjusted to make this particular scenario (multiple files and form fields on one form) a bit easier for integrators such as yourself.  Let me give this some more thought, and I'll comment on this after I've pondered this some more.\n. Perhaps Fine Uploader can include a new option: singleFormMode.  The option could have several properties, such as enabled, and formName (or formId).  If the formId property is set, Fine Uploader could parse the associated form's input fields and include the associated names and values as parameters in the MPE POST (upload) request.  Fine Uploader would need to \"submit\" this form.  This seems reasonable.  Note that the endpoint property of the request option is the same as the action attribute on a form element.\nIf this new option is enabled, the following would be true:\n- autoUpload mode would be forced to \"false\".  This assumes that the user would want to press a button (such as \"submit\") to submit the form, which would also submit the files.\n- All files would be sent in the same (one) request.\n- The chunking feature would be disabled\n- The autoResume feature would be disabled.\n- The onProgress callback would contain progress information for the set of files.\n- The maxConnections and inputName options would be irrelevant.  Either that, or the value defined for inputName would include an index incremented for each file.\n- paramsInBody in the request option would be forced to true, as would forceMultipart.\nOther than features listed as being disabled above, I think all other features could be supported in this workflow.\nA few other notes:\n- The default UI provided for FineUploader mode would have to be a bit different.  For example, there would probably have to be only one progress bar, and one spinner.  Also, perhaps the server could and should return status for each file individually (using each file's Fine uploader assigned UUID).  Or, the server could return a blanket success or failure message.  The former convention would be required to note which files had failed and succeeded both in the FineUploader mode UI and even in FineUploaderBasic mode w/out the pre-built UI.  This assumes integrators would care about per-file status, which I think is very possible.\n- There would be no way to cancel a specific file.  The entire request would have to be terminated.  The cancel API function would have to be a NOP in this case, and cancelAll would have to be the only choice.\n- The id parameter of the setParams API function would have to be ignored.  The same is true for setEndpoint and retry.\nThoughts?\n. The requirements for your app don't align very well with the goals of this library.  Addressing your specific requirements would likely have to occur in a simple albeit separate project.  I'm not sure supporting this type of workflow would fit into the library as it stands.  I could certainly entertain the idea of creating a smaller library/repo that satisfies this specific workflow, but it would be difficult to justify that action until it is apparent that other users have the same specific requirements as yourself.  As far as my previous post on the single-request existing form based workflow, that is something I can potentially work into this library.\nIf you are interested in support for your workflow and don't want to hand-code it, you can certainly \"spread the word\" and get others to comment on this case.  Currently, though, it's hard for me to justify spending time creating a separate project with this use case in mind.  Sorry I couldn't be of more help.\n. @andrewdmoreno I haven't given this any more though, but it is not yet closed as I'd like to discuss it with the team at some point.  \nI do understand the scenario you have described.    However, sending multiple files in a single request adds some complexity to the code for sure.  Instead of sending multiple files in one request, perhaps there is some way to easily assign the same parameter value to each of these files, send them separately, and have the server group them together based on this parameter convention.  \nFor example, perhaps your modal could contain a file input element that allows the user to select additional pages (files).  You could add an onchange handler that submits these files to the underlying Fine Uploader instance via the addFiles API method, along with whatever paramter(s) needed to group them together.  The addFiles method allows you to pass parameters with files directly.\n. @paolobroccardo We are going to discuss support for this more internally before one of the next few release cycles.  Keep in mind that the workflow you describe does not allow support for some of Fine Uploader's features, such as chunking and auto resume (to name a couple).  Please have a look at my comment for more details, and provide your own feedback.\n. Non-UI features will be the primary loss, such as chunking and auto-resume.  \nFine Uploader already uses the multiple attribute by default on all browsers that support it.  You are asking Fine Uploader to send all files/input fields in one request.  This is certainly possible even without the multiple attribute, but, again, this workflow means that some of the more advanced features of Fine Uploader will not be available to you.  \nClient-side preview generation really doesn't have much to do with the feature request described in this thread.  Fine Uploader does have an open feature request to generate client-side previews.  See #868 and #869 for more details.\n. I can see adding better support for existing forms, and allowing all form fields (including file input elements) to be sent in one request.  We will discuss internally.  Anyone interested in this feature, please comment further.\n. @JonoB The initial feature request here was for Fine Uploader to add file input fields to an existing form and allow the user to simply submit the form outside of Fine Uploader's control.  Subsequent follow-ups from users have requested support for a similar workflow.  \nAs far as your request is concerned, Fine Uploader already sends form fields along with each chunk or upload request, but the value of these fields must be set via the params option or the setParams method.  I suppose Fine Uploader could read an existing form and send that along with the files, that would be fairly simple to do.\n. I think we will need to consider supporting this to some degree in Fine Uploader within the next few releases.\n. We will need another meeting to discuss this further.  There are details that need to be worked out.\n. After internal discussion, we would like to provide support for Fine Uploader to easily and seamlessly integrate with an existing <form>.  Essentially, this feature will primarily target integrators who simply want to add file upload support to an existing HTML form.  Presumably, this form contains user-supplied data that needs to be associated with the uploaded files server-side.  In order for this to work, a reference to the HTML form on the page must be passed to Fine Uploader during initialization.\nBy default, when using this workflow:\n- All valid submitted files will be sent in one request.\n- Chunking will be disabled (as this is not possible if all files are sent in one request)\n- The autoUpload option will default to false.\n- You will not be able to cancel a single in-progress file, only all in-progress files.\n- The onProgress event will report the aggregate progress for an entire group of in-progress files.  This means that the passed id and name parameters will be null.  Another option may be to pass an array of IDs and names that represent all files in the group.  The implementation of #384 (also currently scheduled for 4.3) may affect this as well.\nThe goal is to ensure this workflow is supported in all supported browsers.  I believe this workflow will be allowed if using Fine Uploader S3, but the defaults will have to be a bit different (can't send all files in one request), and any form fields will be attached to the objects in S3 via x-amz-meta headers.\nAnother goal is to allow the defaults discussed above to be overridden for those who want to utilize chunking, retry, auto-resume, etc.\nI think there are potentially a number of challenges here, particularly regarding Fine Uploader UI.  For instance, with all default settings:\n- What should progress bars look like?  Should we have one aggregate progress bar instead of per-file progress bars?  Should we keep the per-file progress bars and update them with the total progress of the group (treating them as aggregate progress bars)?  Should we not show any progress at all?\n- Should each file have cancel/retry buttons next to it (even though we can only retry or cancel the entire group)?  Should we just have one button per group?\nThis seems like at least a 13-point story.\n. The default case, where all files are sent in the same request, is going to require a substantial amount of refactoring.  As I dig into the code, it's clear that supporting this is going to be even more difficult than I anticipated.  \nI'm going to start this feature by simply sending the attached form's input values along with each file, maintaining the existing \"one file per request\" behavior.  It seems like that will be relatively easy to support.  We're going to have to discuss again how important it is to have all files sent in one request, as that behavior will require unprecedented changes to the internals of the library, along with significant adjustments to behavior of the API in this context.  \nThe above behavior will be morphed into this case.  Supporting multiple files per request will be covered in #1113.\n. This issue has become a bit long-winded, so I'm going to explicitly define goals:\n- [x] Assume the default workflow will be manual uploads (not automatic after file submission)\n- [x] Only parse all relevant inputs in the form just before uploading & send these as params with each \n- [x] Default: Look for a form on the page w/ an ID of \"qq-form\".  This can be overridable by providing another ID or an actual form element reference.\n- [x] Default: Use the form's action attribute value as the request.endpoint.  Ignore the action if a request.endpoint has been explicitly defined.  One of the two must be set though.\n- [x] Default: Intercept form submits.  Fine Uploader will essentially call uploadStoredFiles internally when it intercepts submission.  Perhaps allow this behavior to be overridden via an option.\n- [x] Implement conventions to allow integration of Fine Uploader into a page with an existing form trivial.\n  upload request.  Ignore irrelevant form inputs, such as type=\"button\", type=\"file\", type=\"image\", etc.  Ignore other elements in the form, such as <label>.\n- [x] Only send radio and checkbox values if they are checked.\n- [x] Support for HTML5 input types (probably get these for free, but need to verify).\n- [x] Support for <select> elements: send selected <option>.\n- [x] Validate forms before uploading (assuming this is supported by the UA).\n- [x] Create a new callback/event that is triggered when all uploads are complete.\n- [ ] Add form-support module to custom build generator.\n. I upped this to an 8 point story with the addition of form validation.  That will add a bit of complexity to this feature.  This will only be possible in browsers that natively support form validation, as we will utilize the constraint validation API.  We will probably also want to have the browser display the built-in validation notes on an invalid form, which will involve a bit of trickery.  In order to accomplish this, we will need to first determine if the form is valid via the constraints API.  If the form is invalid, we will then need to render a hidden submit button that we will have to programmatically click.  Clicking a submit button appears to be the only way to trigger the built-in validation UI cues.  The native submit method on an HTMLFormElement does not do this.  I'll have to ensure that this is a workable solution in all browsers that support the constraints API.\n. This feature is complete in the develop branch, and the plan is to release it with 4.3.\n. Please provide a functional example demonstrating the issue you are having.  At the very least, please show your code and describe your problem a bit more.  \n. I noticed immediately that you are importing the jQuery plug-in wrapper version of Fine Uploader but not making any use of it, which seems a bit odd.  That likely has nothing to do with your problem, just something I noticed.  I'll try to re-create this locally.  If you have this deployed to a live site, please email it to me at issue782@fineuploader.com as this may be most helpful.\n. I took a closer look. First off, It appears like you believe Fine Uploader will render the file template inside of the  element you have provided in the HTML portion of your code.  You have also, however, duplicated that same  in the template option.  Fine Uploader will attempt to render the file list inside of the bootstrapped-fine-uploader container, leaving you with an invalid document and an empty table below it.  Also, you will have two elements on the same page with the same ID.  \nNone of this seems to be causing this problem, though.  The problem happens when Fine Uploader attempts to convert your modified fileTemplate into elements.  It does this by creating a , assigning the contents of the template to the innerHTML property of the , and then extracting the created elements from this .  The user agent strips out all of the table tags since the HTML fragment is not valid by itself.  \nI have an open case to make drastic improvements to the templating in Fine Uploader.  Case #517 is perhaps a step in that direction.  I'm not entirely sure, offhand, how I would handle your situation though.  What you can and probably should do is utilize FineUploaderBasic mode instead.  This mode is intended for users who want to deviate in a non-trivial way from the pre-built UI provided by FineUploader mode.  You will still get all of the cross-browser upload related features in FineUploaderBasic mode with the freedom create your own UI.  I am actually using FineUploaderBasic mode in a project of mine as we speak.  \nIf you do elect to use FineUploaderBasic mode, and also want to incorporate Fine Uploader's drag and drop module, I'm actively making that much easier in the 3.5-IP branch.  See case #577 for more details.\n. Fine Uploader will use whatever protocol the page hosting it is using.  Regarding setting the endpoint, please see the options documentation or one of the many demos.  Simply specify the relative path to your server as a value for the endpoint property of the request option.\n. For any further support questions, please post in the support forum.  See http://fineuploader.com/support.html for more information.  Thanks! \n. Hello Sebastian.  Are you the same person who created this thread on Stackoverflow?\n. Displaying files uploaded from previous sessions on a page seems a bit out of scope as far as upload libraries are concerned.  Why do you want to display previously uploaded files?  Perhaps if you discussed your web app a bit more, I could be of more help.\n. No response after 2 days.  Closing.\n. No response after 2 days.  Closing.\n. @hilobok What you are asking for is really not related to the function of uploading files.  Fine Uploader really isn't a general-purpose UI tool.  The default UI is really only designed with uploading files in mind.  It seems like non-uploaded-related tasks, such as the one you are describing, should be handled outside of Fine Uploader.\n. @ironyee  If this is a feature you would like to see, please describe, in detail, how you would expect it to function.\n. What does your \"edit\" button do, exactly?\n. I'm really looking for details regarding how you would expect this to work.  For example, how would you expect Fine Uploader to get a handle on previously uploaded files?  Does you edit button reload the page, or just re-render an element and re-instantiate Fine Uploader?\n. I see.  Well, this all seems fairly reasonable.  I still think this is probably beyond the scope of this library, but there have been a number of requests for this feature.  So, I'm going to re-open this case, and we will discuss some more internally.  It is important that we all agree on an implementation, so I am hoping others will comment on your proposal here as well.\n. Adjustments to the last post by @ironyee regarding server response:\n- No need to return the ID.\n- UUID must be returned\n- Key must be returned for S3 \n- Alternate delete endpoint (optional)\n- Preview/thumbnail URL (optional)\n- Alternate delete file params (optional)\n- File size (optional)\n. @nick4fake Work on this feature is scheduled for the current release cycle.  See the last set of comments for details.  If the planned implementation does not match up with your expectations, speak now before work on this feature begins.\n. I plan to start work on this today.\n. Tasks to tackle for this feature:\n- [x] Create session option w/ endpoint property.  By default, a GET request will be sent during initialization, with the ability to re-send the request on reset as well via a refreshOnReset property.\n- [x] Create session module to handle initial file list.\n- [x] Create onSessionRequestComplete callback.\n- [x] Create new ajax requester for sending the GET request.\n- [x] Unit tests.\n- [x] Create \"Initialize File List\" feature page.\n- [x] Add feature-related doc links to navbar(s) & feature list\n- [x] CORS support documentation\n. I accidentally associated a482346ab44cdd0013c6cd439debb6b9d577d27b with the wrong issue in the commit message.  It should have been associated with this issue.\n. Note that file items loaded into Fine Uploader during initialization will be counted when determining if you have reached your validation.itemLimit.  This seemed to make the most sense to me, but If this does not fit into a specific workflow, please let me know as soon as possible.\n. @nick4fake Yes, it's complete and will be part of 4.2.  You can read the documentation on this feature in the development branch at http://docs.fineuploader.com/branch/develop/features/session.html.  4.2 is set to release on Wednesday.\n. If you set the session.refreshonReset option to true, Fine Uploader will send a new GET request for the initial file list when you call the reset API method.\nFor any more questions regarding use of Fine Uploader, please post on Stack Overflow under the fine-uploader tag. \n. Issue #1191 covers exposing a public API method that would allow canned files to be easily added from any source. I've moved that case into version 5.6.0, which I will begin working on immediately. Please follow that case for updates.\n. Issues caused by work on #577.\nThanks for catching this.  This isn't a problem when using the jQuery plug-in wrapper since the wrapper replaces callbacks with calls to jQuery.triggerHandler.  If you change the referenced line to qq.extend(options, o, true), does that fix the problem for you?\n. I've pushed a fix to 3.5-IP.  Please let me know if this fixes the issue for you.\n. Thank YOU for catching this.\n. Can you please provide more information about how you encountered this error, what browser you were using, and what version of Fine Uploader you were using?  Also, the code you provided is not formatted correctly and seems to contain some incorrect code.   Can you please fix this.  Thanks!\n. Can you please provide more information about how you encountered this error, what browser you were using, and what version of Fine Uploader you were using?  Also, the code you provided is not formatted correctly and seems to contain some incorrect code.   Can you please fix this.  Thanks!\n. Yes, if you are using a browser that supports the File API, you must submit either an array of File objects, a File, or any other array-like object containing File objects, such as a FileList.  For browsers that do not support the File API, you must pass an <input> element into the addFiles API method.  \nI realize that this is s bit confusing/inconvenient.  There is an enhancement request, #749, to make use of the addFiles method a bit more intuitive.\n. The filenames are not \"qqfile\".  The name of the file form field in the payload of each request is \"qqfile\".  By default, Fine Uploader sets the file parameter's key name in the request to the value of inputName property of the request option.  You can change this default value, but it will be used for all upload requests. \nYou can always pass different parameters for each request via the setParams API function.  I realize this may not be ideal since the file ID is not available until the files are submitted to the uploader.  Another user has proposed a change that would allow you to add context/params along with each file submitted to the addFiles method.  Please have a look at case #760 and comment on it if this is something that would be useful to you as well.\n. You can also target params for a specific file by passing the file's ID to the setParams API method.  However, as I mentioned, this ID is only first available to you in your onSubmit callback handler.  Please look at #760 and see if the proposed changes will address your situation.\n. I'll move #760 into this release (3.5).  I hope to start thinking about this a bit more next week or so.  It's possible that this may be moved into 3.6 if I run out of time though.\n. @tejinderss Note that I just completed case #760 in the 3.5-IP branch.\n. This no longer seems prudent.\n. Yep, lets make this happen in 4.2.\n. @Ixonal I can't guarantee support for TypeScript as I don't use (or ever plan to use) TS. However, I am aware of the need to make integration w/ AMD/CommonJS/ES6 Modules a bit easier. At the moment, I'm the only one available to tackle these sorts of things, so if you think this can be solved in a quick PR without breaking anything else, I would be willing to take a look and consider it for a near-future release.\n. There are a couple other namespaces to maintain, other than qq. Currently, ExifRestorer and CryptoJS. I'm guessing we don't want these to remain global objects, so that will need to be accounted for as well.\n. Yes, I think perhaps the way to handle this may be to wrap the entire concatenated JS file in an IIFE, and then, as you suggested, export the qq object based on the type of module system available. Am I missing something?\n. It sounds fairly straightforward, but nothing is ever as simple as it seems. I'm a bit apprehensive to commit any changes and call this \"done\" though, as I'm not making use of any module loaders in any of my code. I could give it a whirl as part of 5.4.0, but we'd need some confirmation from users who rely on these systems, such as yourself.\n. The quickest solution here is going to involve properly exporting qq object. Seems like this is the most important goal, and shouldn't be too difficult.\nEverything else (build enhancements, exporting each internal module, etc) is secondary and not something I have time to complete at the moment. I've moved this into 5.4.0.\n. For proper module support, I imagine we will need to do a bit of refactoring. To make this less confusing to use and document, since we will still want to support users who do not want to use a module system to import Fine Uploader, there will probably need to be some breaking changes. I think this is a prudent time to remove the qq namespace, and instead make everything available via a FineUploader object.\nFor CommonJS support, I imagine all of the individual source files that make up Fine Uploader already will be exported as modules. The root of the distributed directory will contain several JavaScript files, such as \"s3.js\", \"azure.js\", \"ui.js\", etc. Each of these will pull in other required dependencies from the library.\nSo, if a user wants to pull in Fine Uploader core for traditional endpoints:\njavascript\nvar FineUploader = require('fine-uploader')\nvar uploader = new FineUploader({\n   // define config option values\n})\nThe above module will be represented by a \"fine-uploader.js\" entry point file in the root of the fine-uploader distribution directory.\nIf a user wants to pull in Fine Uploader UI for traditional endpoints:\njavascript\nvar FineUploader = require('fine-uploader/ui')\nvar uploader = new FineUploader({\n   // define config option values\n})\nThe above module will be represented by a \"ui.js\" entry point file in the root of the fine-uploader distribution directory.\nIf a user wants to use Fine Uploader S3 w/out the UI modules, their code will look something like this:\njavascript\nvar FineUploaderS3 = require('fine-uploader/s3')\nvar uploader = new FineUploaderS3({\n   // define config option values\n})\nThe above module will be represented by a \"s3.js\" entry point file in the root of the fine-uploader distribution directory.\nIf a user wants to pull in Fine Uploader UI for S3 endpoints:\njavascript\nvar FineUploader = require('fine-uploader/s3-ui')\nvar uploader = new FineUploader({\n   // define config option values\n})\nThe above module will be represented by a \"s3-ui.js\" entry point file in the root of the fine-uploader distribution directory.\n...etc. At least, this is how I would expect it to be structured at the moment.\n. This is a priority for 6.0, but I see a lot of work ahead in order to do this properly.\n. In light of the efforts associated with Modern Uploader, I'm going for a quick and dirty (but effective) solution - simply provide access to the qq object via CommonJS, AMD, or the window. I will begin working on this at once. Once complete, I hope to release this as 5.8.0.\n. I expect to release 5.8.0 next week with AMD/CommonJS support unless I hear form anyone with requests for implementation changes. Once 5.8.0 is released and AMD/CommonJS support is in place, it will not be changed in any breaking fashion in subsequent releases. So, please let me know if anything is missing.\n. Closing - please follow #1562 for updates regarding support of CommonJS in Fine Uploader 5.8.0.\n. completed and added to the master & 3.5-IP branches\n. Looks like you are issuing this PR against the wrong branch.  I assume you meant to use 3.5-IP...\n. No worries, I made the change myself in 3.5-IP.  Thanks for catching this!\n. You are not returning a valid JSON response as described in the server-side documentation.  Please have a read and adjust your server-side code appropriately.\n. Then the endpoint you have specified client-side (in your Fine\nUploader integration code) is incorrect.\nOn Wed, Apr 17, 2013 at 10:35 AM, Oscar Martinez\nnotifications@github.comwrote:\n\nBut it's never getting to the Function, I added a BreakPoint and it never\nhits the breakpoint.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/792#issuecomment-16513170\n.\n. If you have any further support requests, please see the support page.\n. That file should not be in your client-side source tree.\n. Is there some reason why you cannot simply toggle the visibility of the\ncontainer element holding the uploader based on the buttons you are\ndescribing?\nOn Apr 17, 2013 5:13 PM, \"EddGarciaG88\" notifications@github.com wrote:\nI have an option buttons: Yes and No. If i check \"Yes\" , I want to set\nenabled the fineupload, If i check \"No\" I want to set disabled the\nfineupload. By default, the option \"No\" will be selected when the page\nload.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/793\n.\n. The simplest way is often the best way.\nOn Apr 17, 2013 6:20 PM, \"EddGarciaG88\" notifications@github.com wrote:\nNo, I just I am exploring every options, I agree, that's a more simple\nway, but I like to view another options like enabled/disabled, so, is this\nimposible?...I was reviewing the code, I've done changes for do this but\nI've not had succesfully....\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/793#issuecomment-16541702\n.\n. This option can be used to specify a container for your \"select files\" button.  The file input element is hidden as a child of this container element.  In FineUploader mode, a default button is provided, but you can override it.  No UI elements, including a button, are provided for you in FineUploaderBasic mode.  If you want a button in FineUploaderBasic mode you must specify a container element for the button option.  \n\nPlease see the documentation and demos for more details.  Also, please see the support page for information on where to post support questions.\n. Why not just use the itemLimit validation option?\n. The best way to determine if a file has been rejected is to listen for statusChange events.   You will want to look for a status of qq.status.REJECTED.\n. If the user attempts to submit too many items, a messages.tooManyItemsError message will be passed to your onError callback.\n. No problem.  We always try to provide the features and support that none of the other libraries provide.  We also understand that there are always things we can do to improve the library.  Should you have any suggestions, don't hesitate to open up a feature request as well.\n. What version of fine Uploader, and which version of windows?\nOn Apr 18, 2013 5:20 AM, \"cina2012\" notifications@github.com wrote:\n\nhi.\nthanx for nice work.\ni used fine-uploader with jquery, asp.net mvc and bootstrap.\ni have problem in ie 10, but in other browser (firefox,chorom, ie8,9)\nworked fine.\nin ie 10 stop sending in 0% and do not call server function.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/794\n.\n. I'm not sure I understand what specific problem you are having anymore.  Do you have a link to a live site where I can take a look?\n. No response after 3 days.  Closing.\n. Please see http://fineuploader.com/support.html for support questions.  The issue tracker is for bugs and feature requests only.  Furthermore, your question is addressed in the documentation/readme.  Please read the documentation starting from the first page in the root of the github project. Thanks!\n. @ozkarservices Not a problem.  That's what I'm here for :wink:.\n. Working on this now for 3.5...\n. This is the last scheduled case to be tackled for 3.5.  So, after I am done with this, about 3-5 days of testing will follow.  If all looks good after that, 3.5 will be released.  So, perhaps in about a week or so, maybe a bit less, maybe a bit more.\n. Oscar - If you have a feature or enhancement request, please create a new issue in this repository, name the issue and provide an appropriate, details description of the request.  The Github issue tracker is for feature/enhancement requests and bug reports.  After it is received, I will schedule it for a future release taking usefulness, difficulty, and appeal of the request into account.\n. Looking closer, this is actually a bug in the code.  0-byte files should be accounted for.  This is a regression caused by work on case #461, dating all the way back to 3.0.\n. Fixed in 3.5.\n. Don't think we will be tackling this after all.\n. How, specifically, would you like the delete button/link to behave?\n. Fine Uploader already provides a \"delete file\" feature (added in 3.3).  If enabled, a simple anchor element, \"delete\", will appear next to the file (in FineUploader mode) if the file is able to be deleted.  When clicked, a DELETE request is sent to the endpoint specified in the deleteFile option.  \n\nYou can re-style the delete anchor by contributing additional styles via a css file for the anchor with the css class of \"qq-upload-delete\" or you can override the fileTemplate option appropriately.  The first approach may be the easiest and is probably the best choice.  \nYou can read more about the \"delete file\" feature in my blog post on this topic.\n. The UUID should be the last item in the request's path.\n. Oscar, I'd like to add/correct a few things with your approach:\n1. You can pass parameters along with the DELETE request via the params property of the deleteFile option.\n2. You shouldn't have to pass any sort of extension along with the DELETE request.  My guess is that, when handling the upload request, you are naming the files using the UUID and leaving them extensionless.  Perhaps a better approach would be to save the files with the original name/extension inside a directory with a name that equals the UUID.  Then, when handling the DELETE request, you can simply delete the directory and its contents.\n3. You do not have to return a response with \"success: true\" or \"success: false\".  The \"delete file\" request works differently.  You only need to return a response with a 200, 202, or 204 status code.  You can read more about the delete file feature in my blog post on this topic, as well as in the server-side readme.\n. Fixed.  No need to use any javascript for this.  I can simply include the <script> tag next to the gist in my blog.\n. This is likely an issue caused by your CSS and/or markup.  Please post in the support forum.\n. This was originally a 3 point story, but was changed to 5 points due to the extra work involved surrounding documentation and server-side handling of XDR requests.\n. Blog post at http://blog.fineuploader.com/2013/06/37-cross-origin-delete-file-support-for.html.\n. Rev'd to RC2 due to revert of #696 - bug found during testing.\n. 3.5 is ready to be released.  Next steps: blog posts (changelog), minimal updates to home page, merge into master, email commercial license holders.\n. @andrew-kzoo Yep.  The current version of the commercial license can be viewed on the licensing page.\n. Note that my mention of \"commercial license holders\" is just a reminder for me to email these license holders with the zips for the newly release library.\n. Me too.  I'll see if I can fit that into this case.\n. Working on this for 3.6...\n. completed in 3.6\n. The IEEE is pretty clear that 1 MB = 1000000 bytes.  While some OSes don't follow this definition, such as Windows, others do, such as OS X.  Here is one such reference: http://physics.nist.gov/cuu/Units/binary.html.  It is clear that there are those in both camps (powers of 2 and powers of 10) that are willing to argue their side.  That said, I'm for not changing the code as it follows a standard/codified definition.\n. Working on this now for 3.6...\n. Completed in 3.6.  Note that I also switched the reporting code to use powers of 10 (decimal), since the SI prefixes are already used I believe it is prudent to follow the SI standard consistently.  I would consider user-agent string sniffing in the future to change the reporting (decimal vs binary) based on the OS.  Not sure this is worth the effort though, personally.\n. Thanks for creating this request, Andrew.  I'm going to tentatively schedule this for 3.6.  I can't guarantee that this will stay in 3.6 though, as 3.6 is completely overloaded at this time and I need to go through it and move a bunch of features into later releases.  I'll keep this in mind as I prioritize the issues though, since I think allowing Fine Uploader to accept promissory return values from callbacks would be beneficial where an asynchronous method of obtaining further information in response to a callback invocation is required.\n. working on this for 3.6 now...\n. Callbacks that may benefit from promissory return values are:\n- onSubmit- ask user for additional data to be sent as parameters along with the file\n- onCancel - ask user to confirm cancel\n- onResume - allow user to prevent resume from occurring\n- onValidateBatch - allow user to prevent items from being uploaded.  Also see my comments in case 692\n- onValidate - allow user to prevent a single item from being uploaded\n- onSubmitDelete - allow user to confirm delete in FUB mode (or add params for the request)\n. I would not expect a call to the onSubmit that returns a promise to block all other submitted files.  If this is your desired behavior, you can simply queue up calls to your onSubmit.  For each call, you would create a promise instance, add it to a queue along with whatever context from the callback invocation you require, and return the promise.  You would process each promise in the queue in order.  After the user has dealt with each file, fulfill the promise and move on to the next.  Fine Uploader will not go any further with that specific file until the associated promise is fulfilled.\nDoes this make sense?\n. Are you asking if what I outlined in my previous message will be possible given multiple simultaneous selections?   If so, the answer is \"yes\".  It makes no difference when the files are selected or how many files are selected/dropped.  If your callback handler returns a promise, Fine Uploader will not process that particular file any further until the associated promise is fulfilled (by calling the success or failure methods on the promise instance).  This allows you to process the callback further via an ajax call or a non-blocking dialog, for example.  This also allows you to build up a queue of these promises (created for each file on each onSubmit callback invocation) and deal with them sequentially.  Again, Fine Uploader will wait to process each individual file any further until the associated promise is fulfilled. \n. TODO: blog post explaining the new permitted return types for these callbacks\n. Implemented in 3.6.  Please read my blog post for more details.\n. onResume is likely going to be changed back to a non-promissory callback in 5.0.  It's not clear what the use case is for a promissory onResume, and a promissory return type was only ever supported (unknowingly) for traditional endpoints.  This was removed in a 5.0-related development branch near 8b881ff7768519da1048653b5c7fbcf840db27c6.\n. Event is only the first parameter passed if you are utilizing the jQuery plug-in.  Fine Uploader does not pass this parameter, and it is not really part of the callback invocation as far as Fine Uploader is concerned.  When using the jQuery plug-in, callback handlers as supposed to be treated as jQuery event handlers.  The jQuery plug-in code in the project invokes these handlers via the jQuery triggerHandler method.  jQuery passes its Event object as the initial parameter as a result.  \nNote that this event object is passed by jQuery for ALL callbacks.  It is expected that jQuery users are aware of the fact that jQuery event handlers always receive an Event object as the first parameter when any associated handler is invoked by jQuery.  I have also pointed this out in the jQuery plug-in documentation.\n. I might look into this at the start of 3.6 after all.\n. I plan on continuing to use this model.\n. You are mistaken.  The size will never be valid in ie9.  There is no way to determine the size of a file client side in ie9 or older.\n. If it was not undefined, what was it? Also your code that retrieves the\nsize from the callback parameter is very bizarre.\nOn Apr 24, 2013 6:55 AM, \"Martin Mose Hansen\" notifications@github.com\nwrote:\n\nOkay thanks for your fast reply! Okay, but what i ment with 'vaild' was\nthe size is not undefined the second time it hits the validate. Actually\nthat was my problem because it messed up my validation. Sorry for confusing\nyou.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/808#issuecomment-16921913\n.\n. Are you talking about IE9 still?  Fine Uploader provides no file size for IE9 and older since it is not possible to obtain this size client side.  If you are seeing a size, your code is doing something funky.  I'm not sure why you are doing this to try to obtain the file size:\nfileOrBlobData.handleObj.handler.arguments[1][0].size;\n\nWhen you should be doing this:\nfileOrBlobData.size\n. This doesn't seem very important after some reflection.\n. One thing we will also miss when testing in a *nix environment is Safari for OS X and all mobile browsers (Safari on iOS6 and Android stock at the moment).  I think it's reasonable and excellent to get a lot of the items mentioned in #852 automated on any browser at this point.  Firefox and Chrome are the big ones, certainly.  I'm all for using BrowserStack or Sauce Labs, or some other similar service.  That's certainly the ultimate goal.\n. I see that you've already prioritized some of these using Huboard.  Nice!  I may make adjustments, FYI, but I agree these should be near the top.\n. > can anyone view the Huboard site, or is it just those with commit access?\nHuboard will only show repositories associated with your Github account.\n. @feltnerm Let's create another case to handle linting.  I'll take a closer look shortly.\n. I generally don't include the html, README, and LICENSE files.  I probably should include the LICENSE file though.  The readme for that version should always be accessible from the home page, ideally.  Also, I don't currently minify the CSS file.  It's pretty small at this point without minification.  The same goes for iframe.xss.response.js, which is only useful if the CORS support in non File API browsers is desired.\n. Current release process documented in #856.\n. No plans to do this in the future.  Interested early-adopters can build from source using grunt.\n. Seems useful.  I'll add this to 3.6.  Thanks!\n. Seems useful.  I'll add this to 3.6.  Thanks!\n. Hmm.  Perhaps this could include a status field as well, and could return all files for that session.  Also, perhaps, a parameter could be passed to this function to filter the results (based on status).  Can you open up a new feature request for this?\n. Looking into this next for 3.6...\n. This has been implemented for 3.6.\n. Thanks Andrew.  I apologize for not creating an IP branch for 3.6 yet.  Ultimately, this PR will have to be against that IP branch.  I'll create one tonight.  After I do, you should be able to simply adjust the branch for this PR in Github without creating a new PR.\n. Thanks Andrew.  I apologize for not creating an IP branch for 3.6 yet.  Ultimately, this PR will have to be against that IP branch.  I'll create one tonight.  After I do, you should be able to simply adjust the branch for this PR in Github without creating a new PR.\n. The new \"in-progress\" branch is now \"develop\" since I am attempting to use git-flow in this project. Can you base your PR on the \"develop\" branch?\n. My guess is that there is a problem elsewhere in your code, perhaps something you have not listed.  You will need to provide a link to a live version where this is reproducible, so I can take a look.  Also, please provide the version of Fine Uploader and the browser you are using.\n. I'll probably update the PHP example to include support for the delete file feature in the next month or two.  In the meantime, please see my blog post on the delete file feature for a high-level explanation of how you should handle the request sent by Fine Uploader when a file deletion is ordered.\n. Edd, as the posting guidelines (at the top of the new issue forum) state, this forum is for bug and feature requests.  There is a support forum for support requests.  Also, if you have not done so already, please read my blog post on the delete file feature.  Everything is explained in this blog post.  Thanks!\n. Seems like a simpler fix would be to do nothing other than change this line:\nstyles.opacity !== null\nto this:\nstyles.opacity != null\nDoes this fix the problem for you?\n. Why do you need to remove these headers?  CORS will work just fine with them.  Just be sure to handle the preflight (OPTIONS) request.\n. No response after 2 days - closing.\n. @antongorodezkiy Please open a new question either here or on Stackoverflow. This issue is 2 years old.\n. Several requests for this.  Tentatively moving to 3.7.\n. Addition of folder upload support in chooser requested: http://stackoverflow.com/questions/17328840/folder-upload-without-drag-and-drop.\n. I hope to make this part of the next release.\n. @feltnerm please review and comment\n. The intent of this feature was twofold: allow users to tie multiple buttons to one instance, and to eliminate the need for multiple uploader instances.  The first goal is fairly easily achieved.  The second, even after everything listed in the original case description, is not.  In order to eliminate the need for multiple uploaders, we would also probably have to all independent file templates for each button/drop zone.  After some thought, it's not clear how important or useful it really is to ensure that multiple Fine Uploader instances are never needed on the same page.  \nMy modified plan for this case is:\n- extraButtons option that takes an array of objects with element, multiple and validation properties.\n- the itemLimit property of validation will be ignored if declared on any extra buttons.  The root validation.itemLimit value will always be used, and this limit will be shared among all buttons/drop zones.\n- API method to tie a submitted file to a specific button\n- support for selecting directories via an extra button\nNote that this modified plan still allows for buttons to send files to different endpoints or associated alternate params with each button.  First, maintain a map of endpoints/params for each button.  Then, add logic to an event handler that calls the API method to determine which button a file is associated with.  Finally, call setEndpoint or setParams, passing the endpoint or params associated with that button, along with the file ID.\nI can open up another case with the items required to remove the necessity to ever have multiple uploaders on the same page.  That case will likely be prioritized based on user and internal feedback.\n. > What happens when one extraButton's endpoint is across origins whilst another is not?\nIf any of the uploads will be cross-origin, the cors.expected option should be set to true.  As long as the server doesn't distinguish between cross-origin and non-cross-origin requests in its response (for IE9 and older), there should be no issue.\n. Fixed in 3.6.\n. Instead of calling \"cancel\" on the handler, I'm thinking of creating a new handler method that resets/deletes all state for a specific item.  The XHR and form implementations of this method would be used internally where appropriate as well.\n. I ended up making some adjustments to your proposed changes.  Please see 4b4a561 for details.  You request has been implemented though.  Thanks for the request!\n. Excellent!  Be sure to let me know if you run into any issues.\n. Thanks Andrew.  I'll put this into 3.6, but it may have to wait until 3.7.  Perhaps this could include a status field as well, and could return all files for that session. Also, perhaps, a parameter could be passed to this function to filter the results based on status, name, or size.\n. Looking into this next for 3.6...\n. No problemo.  I haven't really given this case any thought yet, so I'll take a bit of time to mull it over first.  \nThe new hire for the Fine Uploader team, @feltnerm, is starting on Monday.  Once he is settled and I am on Fine Uploader full-time, there will likely be a significant increase in Fine Uploader repo activity.\n. @andrew-kzoo or @andrewrcollins I realized that, midway through implementation, I never really asked for specifics regarding your use of or need for this new API method.  Can you enlighten me?  \nAlso note that I plan on including a status for each item in the returned data structure, and will also provide some way to filter the results.\n. Oh, cool.  Thanks for the info.  It's always valuable to know how others\nare using this library.\nOn Tuesday, May 21, 2013, Andrew Collins wrote:\n\nEither one identifies me, during the day @andrew-kzoohttps://github.com/andrew-kzoootherwise\n@andrewrcollins https://github.com/andrewrcollins.\nWe're using Fine Uploader as the file uploader component of a form builder\nsystem. Ultimately, when a form is validated and submitted, lists of\nsuccessfully uploaded files are collected from each file uploader component\nas described above:\n[\n  {\n    name: \"Example.jpg\",\n    uuid: \"d12fd2c2-09ec-4c98-bcc7-ff0427cd5f25\"\n  },\n  {\n    ...\n  }]\nThese sets of pairs of uploaded file names and UUIDs are associated with\nspecific form fields (e.g. pictures or attachments), combined with other\nform fields (e.g. name and address), and POSTed via AJAX to a server-side\nscript. This script populates the form entries and form files tables. Until\nthe form is submitted files can be uploaded, cancelled, and deleted through\nthe file uploader components as each has its own temporary scratch area for\nfile uploads.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/822#issuecomment-18223215\n.\n. I added a new API method: getUploads, along with a new callback: onStatusChange.  See the updated documentation and/or code for more details.\n\nThis should be functionally complete.  I just need to write some unit tests.  I may also write a blog post, but I'm not sure that is warranted.  I'll give it some thought.\n. This feature is complete for 3.6.  Blog post is at http://blog.fineuploader.com/2013/05/query-fine-uploader-for-upload-stats.html.\n. The original documentation is correct.  Your modification is not.  You are looking at documentation that applies to Fine Uploader 3.5, not 3.3.\n. This was really a \"1\", so I changed the storypoint.\n. Let's say you wanted to hide a representation of the file in the UI when using FineUploader mode.  Before this change, the following code was required:\njavascript\nvar element = $('#myFineUploader').fineUploader('getItemByFileId', someId);\n$(element).hide();\nAfter this change, all you need to do is:\njavascript\n$('#myFineUploader').fineUploader('getItemByFileId', someId).hide()\n. Addressed in 3.6.\n. Thanks for catching this bug.  I'll merge this in sometime during the 3.6 (current) release cycle.  One request, though: can you please switch the branch from \"Widen:master\" to \"Widen:develop\"?  This will require a new PR.  Master only contains release code, and the develop branch is for unstable in-development code.  Thanks!\n. It looks like you are still targeting the master branch.\n. That should do it.  Thanks!\n. I will review and merge if all looks well in this release cycle (3.6).\n. @Beldur The issue you uncovered is real.  If the user submits a file that was previously interrupted, and the resume feature is enabled and supported, a new UUID will be returned on the getUuid API method call until the onResume callback returns successfully.  After the onResume callback returns successfully, the persisted UUID is used.  It seems like the persisted UUID should always be used, even if the onResume callback fails (due to a return value of false or a promise that is fulfilled via a call to the promise's failure() method).  \nYour pull request doesn't address the case where the onResume callback fails.  I took a peek, and it seems like it makes most sense to simply set the UUID in the internal fileState array for that file in the add method.  If a persisted UUID exists, we use that one.  Otherwise, a new one is created.  Let me know if you find any issues with this logic.  You can see my changes in the commit just above my comment here.  \nThanks again for catching this.\nFixed in 3.6.\n. No.\n. This forum is for bug reports and feature requests.  Please post on SO for support requests.  See http://fineuploader.com/support.html for more details or the guidelines link at the top of the \"new issue\" form.\n. See the blog post describing this change.\n. You'll have to provide more information then this.  The link at the top of the new issues page explains how to properly file a report.\n. ...for example, log messages from the javascript console would be helpful here...\n. No, that is definitely not the issue.  The documentation is pretty clear about returning a content type of text/plain since IE does not handle application/json properly in responses.\n. It seems pretty clear that your response is not valid.  I suggest looking at the raw response in Chrome's network tab.  I'm sure you'll find that it is invalid.  This is a support request, and support is handled on SO, so I'm closing this.  I don't see any bug in Fine Uploader here.\n. Let's not re-invent this wheel.\n. Can you discuss why you are calling reset() inside an onComplete callback handler?  What, specifically, are you trying to achieve?\n. I should probably prevent Fine Uploader from throwing this error after calling reset() inside of an onComplete callback handler.  But, in the meantime, is there some other place you can call this, outside of this handler?  \nAlso, a few more notes about your code at http://jsfiddle.net/cotoadvance/6NgqE/\n- Don't reference any internal properties that begin with an underscore.  These may change or be removed at any time.  They are private by convention.  The _filesInProgress property reference in your code can be replaced with a reference to the getInProgress() API method.\n- Don't use console.log in your code, in case the log method is not supported by the browser.  Use qq.log instead.\n- No need to set the multiple option to true.  That is the default value.\n- Be careful with your use of indexOf on arrays.  This method is not supported in IE8 or older.  Use qq.indexOf or $.inArray instead.\n- Since you are using jQuery in your project already, you should really consider using the Fine Uploader jQuery plug-in wrapper instead.\n. Fixed in 3.6.\n. Fixed in 3.6.\n. This needs to be discussed a lot more.\n. Already in-progress in another repo.\n. Fixed in 3.6.\n. Since I wrote this, I realized that this sort of feature support is useful in some situations.  Some APIs may require support for non-MPE requests (such as Amazon's S3 Multipart Upload REST API, which I am now implementing in Fine Uploader 3.8).  However, keep in mind that lack of support for non-MPE requests server-side means your web app will never be able to support uploads in IE9 or older.\n. No plans to remove this support.\n. You have left out portions of your code, such as the uploadComplete function.  Also, I would suggest you not extend the Fine Uploader instance, which you are apparently doing (by adding additional properties to it). \nI test multiple instances frequently, and have not run into any issues.  What version of Fine Uploader are you using? \nPlease provide a fully functional example so I can have a closer look.  I would imagine that there is some issue in your code that is causing this problem, but I can't confirm anything without a fully functional example.\n. This appears to be a pretty interesting problem.  I had a quick look and reproduced in IE9 with 2 uploaders - 1 file per uploader.  Clicking \"send files\" resulted in 2 POST requests (expected).  The first request was aborted for some reason (according to IE's network tab at least).  The second request (for the second file, presumably) seemed to list the 1st file, and it succeeded.  The 2nd file was listed as \"pending\" forever while the first file was listed as successful.   I'll have to spend some more time digging into this.\n. Yes, this is what I am seeing.  I'll start looking into this more during\nthis release cycle.\nOn Sunday, May 12, 2013, idjhuang wrote:\n\nWell, I found the same problem as rnicholus said, and the problem exist on\nIE9 too.\nIn addition, if I start the next uploader after previous uploader finish\nuploading file, then all files could be uploaded, but the status of\nuploaders still be pending except first one.\nOn the other hand, if I start the next uploader before previous uploader\nfinish uploading file, then previous file would be aborted.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/838#issuecomment-17788687\n.\n. I don't understand what you are trying to do here.  Why do you need to use\nthe getFile method?\n\nOn Monday, May 13, 2013, idjhuang wrote:\n\n@rnicholus https://github.com/rnicholus As you said, I may use one\nfine-uploader instance to upload all files of all order items with order\nitem information attached with the files. But I would like to use\nfine-uploader as file selector, for it could support multiple file\nselection and drag & drop.\nI may pass the files contains in these selectors to the uploader before\nupload all selected files. But fine-uploader API getFile(id) is not\navailable on browsers not support File API, so I still get stuck on IE. Any\nsuggestion to workaround?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/838#issuecomment-17814494\n.\n. Ah, I see.  You simply prefer having multiple buttons on the page to make the page more intuitive for your customers.  Well, in that case, one option is to have multiple uploader instances.  This is not an ideal approach though.  I do have an open feature request to allow Fine Uploader to create multiple styled \"select files\" buttons (see case #819 for more details).  This would probably be most ideal, but I haven't started work on that feature yet.  \n\nAnother option is to simply create your own file input elements (one for each order), register an onchange event handler for each, and then pass the associated file input element into the addFiles API method for the one FU instance.   Note that you will need to have the most up-to-date version of Fine Uploader (3.5) for this to be most effective.  Starting with 3.5, you can simply pass a file input element into the addFiles API method, regardless of the browser.  Fine Uploader will extract any associated files.  You can also ask Fine Uploader to add additional drop zones (e.g. 1 for each order container).  See the dragAndDrop option in FineUploader mode for more details.\n. I can't see how that would be useful.  Either use one instance with your\nown additional file inputs or use multiple self contained instances.  Using\nthe former, you can pass the additional inputs into fine uploader.  It's\nnot particularly difficult to create your own file inputs and feed them to\nfine Uploader.  As far as styling them goes, as I said, that can be done\nautomatically by the library in the future.\nOn Monday, May 13, 2013, idjhuang wrote:\n\nWell, it would be great if the addFiles API method could extract files\nfrom another fine-uploader instance.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/838#issuecomment-17830004\n.\n. Working on this now for 3.6...\n. Fixed in 3.6.\n. IE6 is no longer supported.  Let me know if you run into any issues on\nsupported browsers as a result of my changes here.\n\nOn Tuesday, May 14, 2013, idjhuang wrote:\n\nIt's OK on IE 7/8/9, IE 6 can upload but with style sheet issue. Thank you!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/838#issuecomment-17864705\n.\n. Thanks Pablo.  Can you base this change off of the \"develop\" branch?  I only merge into \"master\" during the process of releasing a new version.\n. Thanks Pablo.  Can you base this change off of the \"develop\" branch?  I only merge into \"master\" during the process of releasing a new version.\n. Thanks for reporting this.  I'll take a peek once I get my hands on an ICS device.  Likely sometime today.\n. This doesn't appear to be an issue specific to Fine Uploader.  If I create a page with nothing but <input type=\"file\" multiple>, I still cannot select multiple files on an Android device.  Hmm.\n. It looks like Android simply doesn't support the multiple attribute on file input elements.  I could have sworn this worked at some point in the past.  Maybe I'm imagining that though.\n. Looking at support for HTML5 form features, it seems like this never should have worked officially.\n. This will be a documentation item for 3.6.  I'll investigate a bit more as well, perhaps.  I suppose it's possible that this attribute was unofficially supported in some builds of Android.\n. Certainly with the stock browser.  Do you have Chrome installed on your device?  I don't, at the moment.\n. Just found a device with Chrome, 1 sec...\n. Verified - it doesn't.  \n\nMobile browsers definitely present a new set of challenges and limitations.  Android already doesn't handle chunking correctly, and I've had to add code in the past to deal with overly-aggressive (standards-violating) POST request caching in iOS6.  Also, iOS6 does not allow camera access AND multiple file selection on the same file input element.  \nIf Android simply doesn't support the multiple attribute, there is nothing I can do to allow the user to select multiple files in one dialog, unfortunately.  I'll be sure to document this and possibly add some code to detect support for this to the features module.\n. Verified - it doesn't.  \nMobile browsers definitely present a new set of challenges and limitations.  Android already doesn't handle chunking correctly, and I've had to add code in the past to deal with overly-aggressive (standards-violating) POST request caching in iOS6.  Also, iOS6 does not allow camera access AND multiple file selection on the same file input element.  \nIf Android simply doesn't support the multiple attribute, there is nothing I can do to allow the user to select multiple files in one dialog, unfortunately.  I'll be sure to document this and possibly add some code to detect support for this to the features module.\n. @sayanb I've added an entry to the FAQ.  I'm unaware of a way to programmatically detect lack of support for a multiple attribute on a file input element at this time.\n. Looks like Nexus devs will have access to L starting today.  If anyone uncovers any info on this, please post here.\n. The nexus was running\"L\", correct?\nOn Fri, Jun 27, 2014 at 4:48 AM, Bjorn Bos notifications@github.com\nwrote:\n\nWe have tested this on a Nexus and were very disappointed to find out we still couldn't select multiple images.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/840#issuecomment-47325997\n. Well, perhaps support will ship with the final version of L. \u00a0I guess we will have to wait and see.\n\nOn Fri, Jun 27, 2014 at 7:09 AM, Bjorn Bos notifications@github.com\nwrote:\n\nCorrect, on a Nexus 7\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/840#issuecomment-47336551\n. https://twitter.com/raynicholus/status/482555924817920000\n. You will be able to do this once it is supported by the OS. There is no \"workaround\".\n. @ruinunes It is allegedly supported in Android 5.x, but only with the Chrome 49+ browser on Android. I haven't verified. Source: http://caniuse.com/#feat=input-file-multiple.\n. Thanks for catching this!\n. Thanks for catching this!\n. 5.1 is getting crowded.  In order to accelerate release, I'm bumping this to 5.2.\n. This is being staged in the css-updates branch.  \n\nRemaining items to complete/adjust  for 5.2.0:\n- [x] Fix upload button to top of container\n- [x] Move total progress bar to right of upload button\n- [x] Additional style/color for buttons.  Colors should be button-specific.\n- [x] Display drop zone text inside visible drop zone (only when dropping is supported)\n- [x] Update site/5.2.0 branch with new styles/templates.\n- [x] Replace all default dialogs with new <dialog> element (where supported).  Style these consistent with the rest of the new UI as well.\n- [x] Enforce a max length via CSS for filename & status.  Do this as well for the legacy CSS.\n. This is done, other than updating the docs (in progress)\n. Works fine for me.  If you are still having issues, please provide more info.  Otherwise, I'll assume this was a temporary issue and will leave this closed.\n. Thanks for the report.  I'll take a closer look sometime tomorrow.\n. Looking into this more now...\n. Mentioned by a user in a SO thread.\n. @danielwalls The size of the minified file is really not what you should be looking at.  Your server is most likely gzipping the javascript files before it sends them off.  In that case, you are only dealing with about 14 KB for Fine Uploader.  Are you really worried about a 14 KB file?\nThe primary reason for opening this case did not involve file sizes, but that is a potential (small) benefit. \n. Also, either allow license holders exclusive access to this generator, or completely replace the existing system and non-license-holders will be signed up for a trial (with limits to the number of downloads per address).  All generated files for licenseholders can either be emailed or downloaded via the web, non-license-holders must provide a valid email to receive the generated file(s).  See #955 for more details.\nThis addition may affect the points for this story.  Perhaps it should be re-story-pointed.\n. Examining the code and making adjustments now...\n. As the guidelines for contributing state, this section is for bug reports and feature requests.  Please see http://fineuploader.com/support.html for support request information.\n. I'm a bit confused.  You are checking for the existence of a duplicate file in onSubmit, but still allowing the file to be submitted to the uploader?  Why?  Can you describe your app in some more detail?  I feel like I am missing something here.  Why do you want to keep the file around if you don't want to upload it?  Also, what sort of specific user action coincides with the keyup event you are handling?  \nAlso, since you are using the file name to detect duplicate files, I assume you are not supporting any iOS6 devices at all, is this true?\n. I take it your are using FineUploaderBasic mode and sending the file name as a custom parameter along with each file, correct?\n\nI'm firing off an XHR request to check if the inputted name already exists or not.\n\nI'm still a little fuzzy on this keyup event.  What key is the user pressing here?\n\nIf the file name isn't available, I'd like to force the user to input a name for the file manually. Until they do, the file shouldn't be uploaded.\n\nThe problem with iOS6 is that all images have the same name (image.jpg).  For some reason, videos have a variable file name though, such as IMG_0095.MOV.\nAs to your original question, the answer is: there is not currently a way to prevent a submitted file from being uploaded once it hits the onUpload callback handler.  Currently, the only way to prevent a file from being uploaded is to prevent it from being submitted (by returning appropriate values in your onSubmit, onValidate or onValidateBatch handlers).  \nI could certainly allow a false return value from an onUpload handler to prevent that specific file from being uploaded.  That's easy.  The tricky part is determining what should happen to that item if the return value for that callback is false.  There are a few options:\n- Treat it as we treat a false return value in onSubmit,onValidate, oronValidateBatch: remove the file entirely and make it inaccessible.\n- Consider the upload a \"failure\".  This would make it possible to upload the file again via the retry API method (or the retry link that would automatically appear next to the file) but only the the retry feature is enabled.  If this feature is not enabled, the file is effectively dead.\n- IfautoUploadis set to \"false\", we could simply throw the file back into the internal array of \"stored\" (not yet in-progress) queue.  A call touploadStoredFileswould make another attempt at such files.  IfautoUpload` is set to \"true\" however, it's not clear how another attempt can be made at uploading these files.\nSo, there are really two problems here:\n1. Making such an enhancement to the library general-purpose enough to cover a number of workflows.\n2. Representing a file that has been prevented from uploading in both the UI and internally.  \nThere was a similar request to yours: #671.  This request differs from yours in that it requires the user to decide if the file should be skipped or overwitten before the file is completely submitted to the uploader.  I kind of like your approach a bit better though.  I would like to support your workflow, as I think it may be a workflow that others may want to follow in the future.  I just need to give this some thought, given the issues I described above.\n. Like I said, I like the idea of displaying a \"rejected\" file and requiring the user to deal with this issue before the file is actually uploaded.  A \"duplicate\" file situation is the only case where this makes sense to me, but perhaps there are other, more specific situations that would benefit from this as well.  \nIt seems like I could provide a way to mark a file as \"invalid but salvageable\".  I can see a specific return value in an onSubmit handler or onValidate handler triggering this.  It seems like an API method would be needed to change the state of such an item as well.\nI'll need to think about how I represent this file internally, and in the FineUploader UI.  This certainly won't be part of 3.6.  Maybe 3.7.  I'm not sure yet.  I'll think about this more over the next few days or so.\n. Looks like I considered something like this a while back.  See the third item in #797.\n. Maybe the simplest solution is to allow a return value of false or a promise to be returned in an onUpload callback handler.  If a file is rejected here, by default, it would appear as \"failed\".  You could utilize the retry API method to re-send it if this failure is tied to some user input or temporary condition.  Perhaps the default failure message can be specified in the callback's return value somehow.\n. Note that I'm currently implementing support for a return type of Promise for the onUpload callback in #1917. Rejecting will attempt to auto retry if auto retry is enabled and if the rejected object does not contain a preventRetry: true entry. . For starters, why are you not using the Fine Uploader jQuery plug-in?  You are already clearly using jQuery in your project.  You could rewrite the above code like this:\njavascript\n$('.checkin-button').each(function(idx, anchor) {\n   $(anchor).fineUploader({\n      uploaderType: 'basic',\n      button: $(anchor),\n      multiple: false,\n      request: {\n         endpoint: $(anchor).attr('href');\n      }\n   })\n      .on('complete', function(event, id, name, response) {\n         //some processing here\n      });\n});\nThat aside, have you considered simply preventing the browser's default click action on your anchors?  Something like this:\njavascript\n$('.checkin-button').click(function(event) {\n   event.preventDefault();\n});\n. Ah yes, I think I know why.  It's pretty odd to use an anchor as your Fine Uploader container AND as the upload button.  Why are you doing this, exactly?  What is the significance of an anchor in your situation?  Can you tell me more about your application?  \n. I should also mention that I'm a bit surprised this works in any browser.  Fine Uploader doesn't directly handle click events on your button.  Instead, these click events are delegated to the opaque input element that Fine Uploader embeds inside the button you provide.  I would expect all browsers to follow the path listed in the href attribute of your anchor.  Personally, in your case, a data attribute for the endpoint address seems most appropriate, with a '#' value for your href.  You mentioned that this is not desirable though.  Why is that?\n. Disregard my comment about containers.  That really only applies if you are using the jQuery plug-in or FineUploader mode.  You are using neither.  \n\nI'm confused as to why disabling the click event stopped the uploader from working, I didn't stop propagation of the event, just the action itself.\n\nThis prevents the uploader from working as preventDefault prevents the browser's default action from occurring.  In this case, the browser's default action is to display a file chooser dialog.  Remember that Fine Uploader adds a file input element as a child of your anchor.  Any click directly targets this file input element.  Propagation is not a factor here, and preventDefault does nothing to stop an event from bubbling.  \nI suppose Fine Uploader could be modified to stop any click events from bubbling past the file input element, but I'm not sure that is a reasonable change to make, as existing libraries may expect to consume this click event as it bubbles.  As far as your href attribute, if you create an anchor with an href attribute, you should expect the browser to redirect to the path defined in that attribute when the user clicks on the anchor.  If you don't want this to happen (you don't) you should set the href attribute to \"#\".  This is not specific to Fine Uploader.\nIf you insist on supplying the endpoint address in the href attribute on your anchors, you can perhaps do something like this:\n``` javascript\n$(\".checkin-button\").each(function(index, item){\n  var uploader = new qq.FineUploaderBasic({\n    button: item,\n    multiple: false,\n    request: {\n      endpoint: $(item).attr('href')\n    },\n    callbacks: {\n      onComplete: function(id, fileName, responseJSON){\n        //some processing here\n      }\n    }\n  });\n$(item).prop('href', '#');\n});\n```\nNotice my addition to the 2nd-to-last line.\n. Did my suggested adjustment fix the issue in FF?\n. Hi there, and thanks for the contribution.  Can you re-initiate this request against the \"develop\" branch?  \"Master\" is a closed branch that only contains the latest stable version of Fine Uploader.  All development happens in the \"develop\" branch.  Thanks!\nP.S. Ignore the warning from Travis CI.  We are still stabilizing our new automated environment.\n. Can you describe your workflow a bit more, and why this error message is useful to you in this case?  I'm wondering if some users prefer this to be a NO-OP (if no files are left to upload).\n. Closed for the same reason as #225.\n. In case this video disappears, the issue is that the drop zone remains visible even after dragging the file out of the window, correct?  Is this issue specific to FF 20?  I can't reproduce with FF 21 (also on OS X).\n. I took another look at your video.  It seems like, the only way to reproduce this is to drag a file onto the page, then drag it back up to the title bar and then out of the window.  That's a bug, but a pretty low-priority, low-impact, edge-case.  There is a similar bug with Safari that I have been unable to solve as of yet, though I haven't spent much time on it as it too is a low-impact issue.  See #588 for more details.\nThanks for reporting this, I'll take a look at this (and probably #588 again) in the near future.\n. A suitable workaround was committed in #1043.  If we are unable to determine if the file was dragged out of the document, the drop zones will be hidden again the next time the mouse enters the document.\n. # Tier 1\n\ncan we discuss the goals of a \"proper\" release?\nYes, let's do that tomorrow.  I should document the current release process.  In fact, I will.  Stub at #856.\n\nAfter some thought, I'm not sure nightly builds are something we should deal with/worry about anytime in the near future.  I'm guessing automated documentation fits in with this as well.  We can discuss more on Tuesday.  \nAs far as development is concerned, I currently use Jetty locally, running inside of IntelliJ Ultimate.  This has worked pretty well for me so far.  We will each probably need our own development environment/test server anyway.  This will need to be portable, so I personally think this is the way to go.  \nTier 2\nThis is probably fairly far off in the future.  We can discuss more during or sometime after story pointing on Tuesday.\n. :thumbsup: \n. This is the process I currently follow.  Every step is manual at this point.\n1. Update readme, jQuery manifest, gradle properties file\n2. generate jQuery and no-dep zips\n3. check release zips in to downloads branch\n4. merge develop into master\n5. update all links in any blog posts for new release to point at master branch docs (instead of develop)\n6. update all version numbers in HTML of gh-pages\n7. update download links in gh-pages\n8. update link to release notes blog post in gh-pages\n9. add any new features to index.html feature list w/ an adjacent \"new.png\" img.\n10. update submodule containing master code in gh-pages\n11. update any js imports & demos in gh-pages if needed (lazy lately)\n12. merge any dev branch in server repo into server repo master\n13. update submodule containing server code in master\n14. tag new version in master (results in update in jQuery plug-in registry\n15. tag new server repo version\n16. twitter post announcing release\n17. email license holders w/ release announcement and zip files\n. Looks like this is a bug in Safari on iOS.  I was able to reproduce in iOS 6.1.4 and 6.1.3.  I didn't try anything older.\nI was able to reproduce with nothing more than a <input type=\"file\"> element that adds a span containing the file name for each selected file in an onChange handler.  As the number of files selected increases, so does the time it takes for the onChange event to be fired, noticeably.  \nThe next action item here is to file a bug with Apple and pester them until it's fixed.\n. I filed a bug with Apple.  This issue is easily reproducible outside of Fine Uploader.  I created a fiddle that reproduces the issue as well.\n. Nope nothing from Apple.  Sorry.\nOn Tuesday, May 27, 2014, Bjorn Bos notifications@github.com wrote:\n\nDid you hear anything back from Apple about this? Can't believe this\nhasn't been fixed by now, very annoying bug that drives my users crazy...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/857#issuecomment-44244166\n.\n. Keep in mind that Apple doesn't seem to give their browsers a high priority.  Unless a bug prevents the browser from opening, it's unlikely that Apple will ever fix it.\n. Looks like Apple closed this bug as \"insufficient information\", even though I provided a working live page that reproduces this issue, along with steps required to reproduce.  Sigh\n. This issue still exists in iOS 8.4.\n. That's because all browsers in iOS are Safari, for the most part. But Fine Uploader only explicitly supports Safari Safari anyway.. Hi there, and thanks for the pull request.  Don't mind the Travis CI build failure note.  We're still working on that.  \n\nI think I would prefer this to be optional, and default to the original behavior.  It's possible that, instead of hiding the select files button, some integrators might want to add a click handler (along with some code that prevents the browser's default action) that informs the user why they cannot upload more files.  Perhaps some integrators may want to keep this button visible, but style it a bit different as well in this instance.  \nNo need to make these changes to your pull request though.  I can make the appropriate changes once I get to this in the next release cycle or so.  This won't make it into 3.6 as I am currently in the testing phase, but I'll look into it for 3.7.\nThanks again!\n. Yes, that may be the most flexible approach.\n. My plan is to go with @sergiodlopes suggestion.  Most likely, there will be a \"qq-disabled\" class added to the select files button, with some default styling that also results in Fine Uploader ignoring any attempts to invoke the file chooser dialog.  Integrators can specify their own style for this CSS class if, for example, the preference is to simply hide the button.\n. After some more thought, this is starting to seem like a solution to a problem that doesn't really exist, and not a very good solution at that.  Addressing this request would add more complexity to the code, and it's not clear that any additional complexity would be worth the very little benefit associated with this change.  \nWhile this would prevent the input dialog from appearing if the item limit has been reached, it doesn't do anything for a user that is able to upload, for example, only 1 more file.  Also, it does not do anything for users who prefer to upload files via drag & drop.  Furthermore, it's not really clear what is gained here.  Perhaps we save some users a few seconds that would otherwise be lost if we prevented them from clicking the select files button.  \nIt seems like a better solution might be to simply register an onStatusChange callback that checks the value of a call to the getNetUploads() API method.  I'm more in favor of allowing integrators to leverage the existing API in some cases, such as this one, rather than making some assumptions regarding expected behavior/appearance of the UI. \nI've attempted to make the API as useful as possible for solving these types of problems without adding additional complexity to the code.  If I receive a lot of requests to build this behavior into Fine Uploader, and there is agreement on what that behavior is, I will reconsider.  Until then, it seems reasonable for integrators to simply make use of the API as described.\nI've made a few changes to the ordering of calls to the onStatusChange in callback in 3.7 in order to ensure that this approach works as expected.\n. I'll post a code sample tomorrow showing how to leverage the onStatusChange for integrators that want to disable the select files button when the user cannot upload any additional files.\n. Here is some sample code, as promised.  This assumes that you have some style associated with the \"disabled\" CSS class.  One simple set of attributes attached to this class may set the background-color (of the button) to \"grey\" and the color to \"lightgrey\".\n``` javascript\nvar itemLimit = 3;\n$('#myUploader').fineUploader({\n    request: {\n        endpoint: \"/upload/receiver\"\n    },\n    validation: {\n        itemLimit: itemLimit\n    }\n})\n    .on(\"statusChange\", function(event, id, oldStatus, newStatus) {\n        var netUploads = $(this).fineUploader(\"getNetUploads\");\n    if (netUploads === itemLimit) {\n        $('.qq-upload-button').click(function(event) {\n            event.preventDefault();\n        })\n            .addClass('disabled');\n    }\n    else {\n        $('.qq-upload-button')\n            .off('click')\n            .removeClass('disabled');\n    }\n});\n\n```\n. This is officially tabled, correct?  If so, let's move it out of 3.9.\n. May be covered by #1063.\n. Going to work on the PHP example in 3.9.\n. Dropping from the schedule for now.  May continue this later.\n. Don't think we really need this \"epic\" anymore.  There are only a few individual stories at this point.\n. No requests for this.  Closing, but this can be re-opened if I receive feedback.\n. Chrome in iOS & Android will be officially supported starting with 4.1.  Note that feature support differs for mobile Chrome, depending on the OS.  See the browser support matrix on the docs site for specifics.\n. No requests for this.  Closing.  We can re-open if anyone actually asks for this.\n. I already corrected a similar issue #758.  The easiest way to fix this is probably to take a similar approach.  That is, change:\nmaybeObj.constructor === Object\nto:\nObject.prototype.toString.call(maybeObj) === '[object Object]'\n. I'll look into this more during the current release cycle.  Perhaps you\ncould confirm if that change addresses your issue as well.  It should be\nfairly easy to modify the code and try that out.\nOn Thu, May 30, 2013 at 4:32 PM, ianmstew notifications@github.com wrote:\n\nThanks, good call. That would be nice and inline and do the job with less.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/866#issuecomment-18709853\n.\n. Great.  Thanks for the confirmation.  I'll look into this further on my end\nduring the 3.7 release cycle, which will start in a day or two.\n\nOn Thu, May 30, 2013 at 4:48 PM, ianmstew notifications@github.com wrote:\n\nJust did. I applied the change you suggested and fine-uploader works\nperfectly in our application (without the extra jquery code).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/866#issuecomment-18710696\n.\n. A few comments on @feltnerm's proposal above:\n- The renderTemplate method sounds interesting, but I don't anticipate making that part of this story.\n- Supporting functions inside templates also sounds interesting, but, again, probably out of scope here.\n- We can (and should) remove the classes option in Fine Uploader UI.  CSS classes should be used exclusively for styling.  Currently they are used for styling AND selecting internally.  Fine Uploader UI should, instead, use some sort of custom attributes to locate a portion of a template or fileTemplate.  These attributes will be included in the default template elements and can be left alone.  If integrators want to re-style portions of the template, they can remove or adjust the CSS classes without fear of breaking Fine Uploader UI.\n- We can also probably remove the text option in Fine Uploader UI.  Text can be specified in the templates directly.\n- We can perhaps allow an ID or an HTMLElement to be specified as a value for the template and fileTemplate options.  The default values will be set to the default IDs created for the template <script> tags in the distributed source files.  Integrators can choose to either use these IDs and leave the option values alone, or change/remove the IDs and pass in the new ID or elements as values for the two template options.\n\nMost likely, all of this will happen along with the preview/thumbnail generation stories referenced in Mark's comment above.  The release will likely be 4.0 as all of the changes described in this story will be breaking.\n. > provide a default index.html inside of each zip?\nThat's the easiest short-term solution, yes.  It should probably be a well-formed & complete HTML document as well.\n\nWhat happens when the templates have not been defined?\n\nNot sure, maybe nothing?  Maybe an error?  If Fine Uploader UI is being used, I think an error is most appropriate.\n. So here are the current goals of this feature/story:\n- Move template-related HTML out of the javascript source file and into the integrator's document.\n- Remove any confusing or redundant options (such as classes and text) that exist solely due to the complexity associated with editing existing template options.\n- Allow integrators to omit any portion of the template that does not apply to their application.\n- Allow integrators to change or omit any CSS classes on template elements without breaking the uploader.\n- Make it easier to modify the look and feel of UI mode or simply fall back to core mode.\n- Make upgrading to this version as simple as possible, even though there will be breaking changes.\n- Pave the way for native preview support\nIn order to accomplish those goals, we will need to complete the following tasks:\n- Remove the template and fileTemplate options.  Combine them into one template, and require this be included in a script tag in the user's document.  Actually, I lied about the template option.  Don't remove it, simply change it to take an element or ID of the associated script tag.  A default value should exist (say \"fuTemplate\") that matches the default ID of the script tag that houses the default template in the HTML file packaged with Fine Uploader.  The template option would take either an ID or an element (or a jQuery object if the wrapper is in use).\n- Include default text w/ variable sections in the default template.  Aside from the variable sections, the text can be modified in any way.  This will mean that most, if not all of the text options can be removed. \n- Include default CSS classes with default template, but allow integrators to change or remove these.  Select template elements internally via new CSS classes that are exclusively used for selection, and not styling.  This means that most, if not all, of the classes options can be removed.\n- Update the examples, at least on the website, to include the default templates.\n- Update the documentation.\nI anticipate other improvements will go into this task, such as: \n- Avoid attaching style attributes to elements via javascript (instead attach classes that can be changed via options) (such as when hiding an element)\n- Move template-related stuff into a separate js file\n. As always, your praise is much appreciated Andrew!\n. Depends on #867\n. The primary goals for this feature/story are:\n- Make it simple for core and UI integrators to provide client-side image previews for all modern (File API supporting) browsers.\n- UI-only: Display previews, by default, in the default template.\n- UI-only: Display a placeholder image while preview is being generated, and a different placeholder if a preview cannot be displayed.\n- UI-only: Allow integrators to provide their own \"no preview\" placeholder images by MIME type.\n- (secondary): Provide an alternate \"gallery\" template for larger more-image centric apps\n- (future?): Allow integrators to specify max dimensions for previews?\nTo implement:\n- Draw (depending on the template properties) a <canvas> or <img> element with the appropriate placeholder when the file is selected.\n- Update the element with the preview or the \"can't display\" placeholder after the preview generation attempt has completed.\n- Provide a preview option that includes a placeholder property (object).  This can contain a map of placeholder image paths by MIME type.  Wildcards will be permitted.\n- Allow for the server to return a URL for a preview image in the upload response (for previews that cannot be generated client-side, or if the server wants to generate an alternate or higher-quality preview server-side).\n- Provide a drawThumbnail method that draws the preview onto either a provided <canvas> or an <img>.  This will have a promissory return value with success and failure fulfillment depending on the outcome of the preview generation.\n. Note that this feature includes a change that ensures a \"qqfilename\" parameter is always sent with all traditional endpoint upload requests.  This was done to make it easier and more consistent for servers to parse the file name without having to strip off path information that IE may send along with the name associated with the file's multipart boundary filename field.\n. Depends on #867\n. The primary goals for this feature/story are:\n- Make it simple for core and UI integrators to provide client-side image thumbnails for legacy browsers (e.g. IE9 and older)\n- UI-only: Display thumbnails, by default, in the default template  (already completed in #868).\n- UI-only: Display a placeholder image until we receive the thumbnail URL from the server response, and a different placeholder if the URL is not received.\n- UI-only: Allow integrators to provide their own \"no preview\" placeholder images (already completed in #868).\n- (secondary): Provide an alternate \"gallery\" template for larger more-image centric apps (already completed in #868)\n- (future?): Allow integrators to specify max dimensions for thumbnails (already completed in #868)?\nTo implement:\n- Draw an <img> (or <canvas>, if supported) element with the appropriate placeholder when the file is selected.\n- Update the <img> with the thumbnail or the \"can't display\" placeholder after the response has been received from the server.\n- Provide a preview option that includes a placeholder property (object).  This can contain a map of placeholder image paths by MIME type.  It would be nice if MIME types would be determined based on file extension, but, initially, we would probably just ignore all but the wildcard.  In other words, there would only be one placeholder for files without thumbnails.\n- Require the server to return a URL for a thumbnail image in the upload response.\n- Provide a drawThumbnail method that sets the src attribute of the passed <img> element appropriately.  The return value will be promissory.  The success method can be called by Fine Uploader on the returned promise if a URL is provided, or failure when the response is processed but no image path is provided.\n- Provide the ability to not insert thumbnails in these legacy browsers via a preview option property.\n. Note that this feature includes a change that ensures a \"qqfilename\" parameter is always sent with all traditional endpoint upload requests.  This was done to make it easier and more consistent for servers to parse the file name without having to strip off path information that IE may send along with the name associated with the file's multipart boundary filename field.\n. I suspect the first error message you listed is a bug in Fine Uploader similar to #758 and #866.\nTo test this theory, can you insert the following code just before you initialize Fine Uploader.  That is, before your initial $('#fineUploader').findUploader({...});?\n``` javascript\nqq.isFileOrInput = function(maybeFileOrInput) {\n    \"use strict\";\n    if (window.File && Object.prototype.toString.call(maybeFileOrInput) === '[object File]') {\n        return true;\n    }\nreturn qq.isInput(maybeFileOrInput);\n\n};\n```\nThis will override the check that Fine Uploader uses to determine if the submitted item is actually a File.\n. Looks like this is a section of the code that doesn't delegate to a utility function to check if the passed object is a File or a Blob.  It, too, is not accounting for the context of the instanceof comparison to differ on either side of the statement.  \nPlease send an email to github870@fineuploader.com and I'll send you a patched version of 3.6 that should address all of these types of checks.  If this ultimately fixes your issues, then I will release a hotfix.\n. Cool.  I'll be sure to release this as a hot fix in the next day or two.\nOn Saturday, June 1, 2013, joero4 wrote:\n\nThe patched file solved my problem. Thanks.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/870#issuecomment-18797288\n.\n. I could see making this option toggleable via the API.  Keep in mind that Fine Uploader will only send a limited number of concurrent delete requests.  This number matches the maxConnections option.  So, if you are deleting a bunch of files, there may be a noticeable delay before all DELETE requests have been sent.  Maybe you are just better off sending one ajax request to your server with the UUIDs of all files to delete just before you reset?  \n\nAnother option is to ensure all uploaded files are stored in a temporary directory server-side, and are only moved to permanent storage when the user clicks some sort of submit button client-side.  Files in temporary storage can be removed after they are x number of days old.\nJust some thoughts.\n. Cool.  I guess I'll close this then, unless you have any objections.\n. Based on the error messages, your server side code is not returning a valid JSON response.  Responding to Fine Uploader's requests is covered in great detail in the documentation here.  Please have a look at the documentation along with the server-side examples (there is even one for PHP).  Also, the issue tracker is for bug reports and feature requests.  Please see the support page on the home page for information about filing a support request.\n. Covered by #862 \n. Thanks for submitting this.  This is indeed a regression created in 3.6.1.  The regression was caused by a change made to fix #870.  \nThis was yet another regression created when I modified the code to handle environments that involve multiple windows.  \nThe change I cited above breaks Fine Uploader in IE8 specifically due to some (IMHO) sound logic that is not followed by IE8.  qq.isInput first checks if the window has a concept of the HTMLInputElement \"interface\".  If it does, it expects any input element will have a value of \"[object HTMLInputElement]\" when calling toString on the parameter (using Object.prototype.toString).  Obviously, IE8 doesn't subscribe to this logic, as the value is \"[object Object]\".  \nThe same faulty/inconsistent logic is present in IE7 (when calling toString on a host object), but this particular issue is not a problem in IE7 since IE7 does not expose the HTMLInputElement \"interface\" and, therefore, we skip right over to the next check which looks a bit closer at the potential host object in an attempt to identify it as an input element in the absence of the existence of the HTMLInputElement interface.\nThe simplest fix is, as you suggested, to change the \"else if\" to an \"if\".  The change is being made on our end and, after some more testing, a 3.6.3 hotfix will be released.\n. Fixed in 3.6.3.\n. Seems potentially useful, but I don't see how we can support this in non-File API browsers since Dropbox made some odd decisions when creating their API.  For example, the API documentation specifically states that it expects the entire contents of the upload request to be the file.  This essentially means that we cannot send MPE requests, which are required when uploading files from non File API browsers (such as IE9 and older).\n. The documentation on the requests made by Fine Uploader are actually quite detailed.  The first page of the readme contains a bunch of reference links, for example.  The very first link is titled \"Server side guidelines and documentation\".  The very next link is titled \"Server side examples\" which provides basic server-side examples in a number of server-side languages, including node using express.  \nThis forum is for bug reports and feature requests, as detailed in the link at the top of the \"new issue\" form.  Please see the support section of the home page for instructions on opening support requests. \n. This is ongoing.  If we reach a point where either enough code is commented and/or we want to publish a docker/docco site for Fine Uploader code, we will do that.\n. It's not obvious why this is happening here.  Do you have a live example where this is reproducible?\n. I had some hopes of fixing this by attaching a change handler to the upload button container (instead of the file input element).  This works in all browsers, other than IE8 and older.  Unfortunately, change events do not bubble in IE8 and older.  \nSo, to deal with this issue, please see http://stackoverflow.com/questions/18476872/fine-uploader-only-works-for-a-single-batch-of-files/18495838#18495838.\n. After sleeping on it, I think I may just revert all of my changes surrounding the auto-detection of cross-origin requests.  This adds a lot of complexity to the code, and it's not clear if any real (non-edge-case) benefits exist.  \nHere were the original reasons:\n- Allow integrators to send some files to x-origin and some same origin in the same uploader instance (edge of and edge case)\n- Allow integrators to avoid having to deal with the iframe/xdr stuff in IE if the port is the only difference between endpoint and target (edge case, and probably never going to happen in production)\n- Eliminate one option that has to be set for CORS environments (cors.expected). \n. I will not be able to accomplish even the 2nd list item in the case description.  For some reason, all browsers (or at least all the browsers I tested - FF & Chrome) preflight the upload request, even though I am following the W3C spec's guidelines for prevention of preflighting as far as I can tell.  \nSo, to get to the bottom of this, I checked out the Webkit source code, and found something a bit surprising.\nIn XMLHttpRequest.cpp:\n``` c++\nvoid XMLHttpRequest::createRequest(ExceptionCode& ec)\n{\n    ...\noptions.preflightPolicy = uploadEvents ? ForcePreflight : ConsiderPreflight;\n\n...\n\n// The presence of upload event listeners forces us to use preflighting because POSTing to an URL that does not\n// permit cross origin requests should look exactly like POSTing to an URL that does not respond at all.\n// Also, only async requests support upload progress events.\nbool uploadEvents = false;\nif (m_async) {\n    m_progressEventThrottle.dispatchEvent(XMLHttpRequestProgressEvent::create(eventNames().loadstartEvent));\n    if (m_requestEntityBody && m_upload) {\n        uploadEvents = m_upload->hasEventListeners();\n        m_upload->dispatchEvent(XMLHttpRequestProgressEvent::create(eventNames().loadstartEvent));\n    }\n}\n\n...\n\n}\n```\nSo, it turns out, registering on onprogress event handler (to track upload progress) forces any cross-origin request to be preflighted.  I haven't looked at Firefox's source, but I wouldn't be surprised if it used similar logic.\nSo, this enhancement cannot be implemented, unfortunately, unless we remove progress tracking.  That hardly seems worth it.\n. This appears to be a 3rd-party bug in IE7.  According to the W3C spec, a null (or presumably undefined) parameter value should not result in an exception.  \nWe will need to work around this.\n. @feltnerm Can you verify that your tests are passing after this adjustment?\n. Looks like a simple typo in both handler.xhr.js and handler.form.js.  It should be calling onUuidChange internally.  onUuidChanged does not exist, obviously.  I'll fix this tonight and push out a 3.6.4 hotfix release.\n. I just released 3.6.4, which addresses this issue.  Thanks for your report.\n. I also found an issue with the retryButton property of the text option.  It was incorrectly listed as retry instead of retryButton.\n. We should probably work linting into the build.  Eventually (soon), bad lint = bad build.\n. Thanks for the report.  We will look into this shortly.\nOn Friday, June 14, 2013, a-ivanov81 wrote:\n\n$(document).ready(function () {\n  var uploader = new qq.FineUploaderBasic({\n      button: $('#upload')[0],\n      request: {\n          endpoint: '/image/upload'\n      }\n  });\nvar dragdrop = new qq.DragAndDrop({\n      dropZoneElements: $('#upload')[0],\n      callbacks: {\n          processingDroppedFilesComplete: function (files) {\n              uploader.addFiles(files);\n          }\n      }\n  });});\nException: Cannot convert 'element' to object\nElement is null. In utils.js on 'attach' function\nBut dnd continue to work.\nTested on Opera12, Chrome27\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/891\n.\n. Please also let me know what specific version of the Uploader you are using.\n\nOn Friday, June 14, 2013, Ray Nicholus wrote:\n\nThanks for the report.  We will look into this shortly.\nOn Friday, June 14, 2013, a-ivanov81 wrote:\n\n$(document).ready(function () {\n  var uploader = new qq.FineUploaderBasic({\n      button: $('#upload')[0],\n      request: {\n          endpoint: '/image/upload'\n      }\n  });\nvar dragdrop = new qq.DragAndDrop({\n      dropZoneElements: $('#upload')[0],\n      callbacks: {\n          processingDroppedFilesComplete: function (files) {\n              uploader.addFiles(files);\n          }\n      }\n  });});\nException: Cannot convert 'element' to object\nElement is null. In utils.js on 'attach' function\nBut dnd continue to work.\nTested on Opera12, Chrome27\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/891\n.\n. After a quick look at your code, my guess is that this problem is caused by\nyour dropZoneElements option.  As the readme states, this should be an\narray.  Furthermore, since you are already using jquery, I'm not sure why\nyou are not simply using the jquery wrappers as well.\n\n\nOn Friday, June 14, 2013, a-ivanov81 wrote:\n\nSources from current master\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/891#issuecomment-19448622\n.\n. What version of fine Uploader?\n\nOn Friday, June 14, 2013, Rion wrote:\n\nThe Drag-and-Drop functionality doesn't appear to be working at all within\nChrome (however it works perfectly fine using IE 10).\nI created a Stack Overflow question (\nhttp://stackoverflow.com/questions/17110148/fineuploader-drag-and-drop-issue-in-chrome)\ndiscussing the issue in more detail, but was able to reproduce it through a\nJSBin example and locally.\nAll of the other functionality is working as intended (such as manually\nuploading a file by clicking) however Chrome doesn't seem to recognize the\naction of dragging and dropping at all.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/892\n.\n. I have tested on Windows 7.  Will try 8 now...\n\nOn Fri, Jun 14, 2013 at 9:18 AM, Rion notifications@github.com wrote:\n\nAfter testing with a few colleagues, it appears as though it is only\noccurring on Windows 8 machines running Chrome (at least so far that is the\nonly environment I have been able to reproduce the issue in).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/892#issuecomment-19459451\n.\n. It's working fine for me on Win 8, Chrome 27 as well.  I have been using your jsbin and the fine uploader demos in an attempt to recreate.  I'm closing this as I suspect there is not a Fine Uploader bug and is instead some issue specific to your environment or setup.  We can discuss further on SO.  If this does turn out to be a FU bug, I will re-open.\n. Sounds cool.  A totally unnecessary distraction though.\n. You are working inside of a cross-origin environment, correct?\n. Yes, it does.  You should not be using iframe.xss.response.js unless you are operating in a cross-origin environment.\n\nFine Uploader does not look for a posted message in the iframe uploader response unless the cors.expected option is set to true.  Furthermore, the Content-Type of the response must be \"text/html\" in this case.\nAgain, though, you shouldn't be using this file in a same-origin environment.\n. I'm a little confused here.  What specific problem are you experiencing?  First, it seemed like you were utilizing iframe.xss.response.js in your response.  Now, I'm not really sure what you are doing.  What does your response look like, and what specific issue are you noticing when the response is received by Fine Uploader?  I'm not aware of any response parsing issues, and I'm quite certain that these would surface during testing.  So, it seems like there must be some issue with your server code or your understanding of how Fine Uploader parses responses.\n. All upload requests coming from IE9 and older are iframe requests.  They have to be, as you cannot upload files via XHR in IE9 and older.\nAlso, as I mentioned before, you should not be using iframe.xss.response.js unless you are in a cross-origin environment.  The sample servlet has the cross-origin response code commented out, as it is only to be used in cross-origin environments.  I'm guessing you uncommented this code.  \nSince you are in a non-CORS environment, all responses should be valid JSON.\n. No problem.  The examples could use a bit more documentation to avoid this type of confusion.\nFor the record, this would have worked even in a same-origin environment as long as you have cors.expected set to true.  The special (commented out by default) response is required when an iframe is used to upload files as this is the best way, IMHO, to overcome the cross-origin limitations associated with iframes.  \nIn a typical CORS environment when the iframe uploader is used, the server responds with a response that contains the valid JSON portion of the response, followed by a script tag with a path to iframe.xss.response.  Assuming the Content-Type of the response is \"text/html\", the browser executes the code in iframe.xss.response.js, which parses the JSON portion of the response and passes it to Fine Uploader via postMessage.  If cors.expected is set, Fine Uploader registers a listener (receiveMessage) for these messages inside the iframe upload handler.  Message passing here allows Fine Uploader to receive the response if its parent window's origin differs from the origin of the server returning the response.\n. Which email client?\nOn Wednesday, June 19, 2013, pratikshelar87 wrote:\n\nHi,\nOne of my user tried to drag and drop a attachment directly from a email\nclient directly into the dropbox, expecting the file to be uploaded. But\nthe file did not get uploaded. But when he saved the file from email client\nlocally and then tried to drag and drop it worked. Could you let me know\nthe issue here.\nThanks\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/896\n.\n. Unfortunately, Outlook does not provide the necessary information required by the browser to handle dropped files.  So, this is not currently possible.\n. Due to lack of JSON support, I do not plan on natively supporting IE7.  However, I may not prohibit use of IE7 with the S3 uploader.  Normally, I would disable the upload and possibly include a message indicating that this browser is not supported.  For integrators that must support IE7 w/ S3 uploads, you can include Douglas Crockford's json2.js polyfill.  This should permit the uploader to work correctly in S3 mode.  \n\nIn #846, we may add the option to include polyfills like json2.js in the combined file for cases such as this.\n. Looks like this is already true as of 4.0 in b5e2dba941588b654156b99fc89909cf73ef7f32.\n. Since Safari and Firefox (21 and older) seem to not support the third (file name) parameter of FormData.append, I'll have to shelve this change.\n. Why do you want to prevent uploads from being resumed client side, and how\ndo you determine which files should not be resumed?\nOn Thursday, June 27, 2013, Aidas Klimas wrote:\n\nI need to remove items from getResumableFilesData() function.\nFor now i am using this function:\ncancelResumableFile: function (file) {\n            var cookieItemDelimiter = \"|\";\n            var cookieName = \"qqfilechunk\" + cookieItemDelimiter +    encodeURIComponent(file.name)\n                + cookieItemDelimiter + file.size\n                + cookieItemDelimiter + maxChunkSize;\n            qq.deleteCookie(cookieName);\n       }``\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/902\n.\n. It sounds like you are trying to solve the wrong problem here.  You don't\nwant the user to be able to upload at all once they exceed their allocated\nspace, correct?\n\nOn Thursday, June 27, 2013, Aidas Klimas wrote:\n\nThen user exceeds his space usage, i send preventRetry parameter, although\nresume cookie is set. For that reason i need preventResume parameter.\nMy response example\n{\"errors\":{\"userId\":[\"Not enough space\"]},\"preventRetry\":true,\"preventResume\":true,\"uuid\":\"6d71b8b2-1039-4d29-9d2d-e0ab0922b1a0\"}\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/902#issuecomment-20110447\n.\n. What does any of this have to do with the resume feature?  Just reject the\nfiles server side, if you don't want to accept them? Or/and disable the\nUploader client side if you don't want to accept any further files from a\nuser.\n\nOn Thursday, June 27, 2013, Aidas Klimas wrote:\n\nYes, i already have client side validation, but it does not work on all\nbrowsers, because IE8 and IE9 does not support getSize method. Also you can\nnever trust client side validation.\nCurrently the only way to solve this is to pass success parameter and\nhandle errors on \"onComplete\" callback. But i don't this is a proper way\nand this might cause some confusion.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/902#issuecomment-20117901\n.\n. I'm guessing you did not know that you can reject files, server-side with a response.  Please see the server-side readme for details.\n. It still sounds like the resume feature is really not related to your problem, unless I'm misunderstanding something.  What Fine Uploader does internally shouldn't matter here.  You are going to reject the file server-side no matter what.  So, why does it matter if Fine Uploader sends a portion of the file, or the whole file?\n. If you want to mark a file as not-resumable, your server's error response should contain a \"reset\" property with a value of \"true\".  If you also include a \"preventRetry\" property with a value of \"true\", Fine Uploader will not retry the failed upload AND will mark it as non-resumable.\n. It's still not clear to me that this cancelResumableFile function is needed.  As mentioned earlier, you can provide an appropriate response from your server to \"cancel a resumable file\".  \n\nI'm not keen on storing anything other than what is absolutely necessary in the cookie, and it's not clear that the persistence of endpoint and params for resumable files is something that would be important for most integrators.  Perhaps if I receive a number of requests for this, I can schedule it.\n. Seems reasonable.  I'll add to it the \"enhancement\" queue and we will discuss internally. \n. @achung-miovision This isn't a PR. Remaining in that PR:\n\nunit tests\ndocumentation\n\nIf someone can tackle those items, I can merge and release after some manual tests on my end.. It seems like you could simply utilize Fine Uploader to upload images and then pass information about those images to TinyMCE.  Is this what you are trying to do?\n. It seems like the best way to handle this would be to create an upload plug-in for TinyMCE using Fine Uploader.  There is at least once such plug-in out there that uses Fine Uploader, but it's a fairly old version of the library and is not licensed correctly.  \nI'll mark this case as a feature and schedule it appropriately.  If others also express interest in this, we may just write our own Fine Uploader plug-in for TinyMCE.  In the meantime, you can use Fine Uploader as you normally would, and then pass the image paths to TinyMCE via  TinyMCE's image_list option.  Here is a forum post explaining this, assuming you are using TinyMCE4.\n. I'm guessing that the server-side language is irrelevant, even with TinyMCE.  You should be able to use nodejs now.\n. I've tagged as \"integration\" and \"to discuss\".  Perhaps we will write a\nTinyMCE plug-in at some point.  Let's keep this open.\nOn Tue, Jul 16, 2013 at 11:26 AM, Mark Feltner notifications@github.comwrote:\n\nUm... this is good to close?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/904#issuecomment-21054274\n.\n. The current set of priorities places this feature request a few releases out at this point.  We are currently working on 3.9, which will primarily cover support for multiple file input elements (#819) along with creation of a custom build generator for the home page (#846), among other items.  Then, 4.0 is likely to be the next release, where we will tackle a major change to the templating in Fine Uploader along with client-side preview display and generation for images (#869 & #868).  The TinyMCE plugin work will likely not make it into the schedule until 4.1.\n. We hope to start researching and working on this within the next few releases.  Are there any specific requirements you have for an upload component in the context of tinymce?\n. Not by me. I don't understand what the problem is here.  What, specifically, are you expecting?\n. Everything appears to be working as expected based on the information you have provided.  Perhaps there is a misunderstanding of what the id parameter means.  If you are, instead, looking for the UUID, you can access that from the API.  I'm going to close this case.\n. The ID is the ID, and the UUID is the UUID.  If you are wondering why you may need the ID, have a look at the callbacks and the API methods.  It is used in many instances, and is a number that is unique to one specific uploader instance.  It is incremented with each submitted file.  The UUID is just what a UUID is supposed to be: a universally unique ID.  It is used to identify files sent with the request to support a number of features, such as chunking, auto-resume, deleting, etc. \n. I'll probably add something to the FAQ in case someone else is confused by the presence of both IDs and UUIDs in the library.  It looks like there isn't one place where these are both documented.\n. Don't know if anyone is even using Firefox OS.  Anyway, perhaps this has been sorted out in the final version of the OS?\n. This will be an ongoing task.  We plan to create blog posts regularly discussing integration with other libraries.\n. Please post support requests under the fine-uploader tag on Stackoverflow, as described in the message at the top of the new issue form and on the support page of the website.  The issue tracker is for bugs and feature requests only.\n. Here's a link to the Promises A+ standard documentation: http://promises-aplus.github.io/promises-spec/\n. I would really like to make this part of 5.0.  The qq.Promise module must pass all A+ promise tests at https://github.com/promises-aplus/promises-tests.\n. then/promise is pretty barebones.  There isn't even a defer function provided.  We could, perhaps, augment it.  I've thought about pulling in a promise library, but perhaps RSVP would be more appropriate.  Still, I think the \"no required dependencies\" motto we've tied ourselves to would likely prevent us from doing this.  I'm hoping we can just modify qq.Promise to be compliant.\n. Yep, that is a possibility.  Looks like when is much smaller than Q or RSVP as well. \n. After further investigation, I'm favoring RSVP.js instead for the following reasons:\n- I've used RSVP.js in multiple other projects, and I like it.\n- It's closely tied to Ember.js and as such will likely be maintained as/if the promise spec changes.\n- It appears to be the smallest fully-fledged promise library, even smaller then when.\n. I'm upgrading this to 8 SPs due to the degree in which Fine Uploader's home-grown promise module diverges from the promise spec.  There's a fair amount of refactoring/risk involved here.\n. After some thought, instead of refactoring the entire library, we'll simply ensure that integrators can use Fine Uploader's promise impl or any A+ certified promise impl when communicating with Fine Uploader.\n. Also, should be \"SemVer\" to match the wording in the spec.  Let's use \"Fixes\" in commit messages and let the merge close these as well.\n. Since it was merged into master, yes.  I re-opened it before I realized it\nwas merged into master, since we should only be closing cases after they\nare merged.\n\nOn Mon, Jul 15, 2013 at 9:12 AM, Mark Feltner notifications@github.comwrote:\n\nThis should be closed, no? \"SemVer\" is displayed and the link takes you to\nthe 2.0.0 version of the spec.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/911#issuecomment-20971901\n.\n. Good catch.  This will be fixed in (likely) the next release.  I may issue a hotfix release if others comment on this case as well.  You can easily make this change yourself though.  You can easily serve a corrected version from your server with the CORS response.\n. Yes, we should definitely cover this with unit tests.\n\nOn Mon, Jul 15, 2013 at 9:14 AM, Mark Feltner notifications@github.comwrote:\n\nWhat about refactoring this line out into a function to make it\nunit-testable and catch other possible parsing errors (?)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/913#issuecomment-20972029\n.\n. I don't think this is a saucelabs issue.  I suspect there is some issue\neither with our build, with test reporting, or with SauceLabs configuration.\n\nOn Mon, Jul 15, 2013 at 9:10 AM, Mark Feltner notifications@github.comwrote:\n\nNot sure what's going on either. One issue is that the img source on both\nREADME.md and the overview page in the docs is pointing to:\nhttps://saucelabs.com/buildstatus/feltnerm when it should be pointing to\nhttps://saucelabs.com/buildstatus/fineuploader . Interestingly enough,\neven this image is displaying an 'unknown' status. Blame it on saucelabs?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/914#issuecomment-20971743\n.\n. That suggests something is wrong, perhaps with our reporting.  I've visited\nother projects using SauceLabs where the badge is correct.\n\nOn Mon, Jul 15, 2013 at 9:15 AM, Mark Feltner notifications@github.comwrote:\n\nEven on the Saucelabs site https://saucelabs.com/u/fineuploader it's\n'unknown' (top-right corner) even though the last 25+ builds have appeared\nto have succeeded. The browser matrix is all green as well.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/914#issuecomment-20972123\n.\n. You could email SL and see what they have to say...\n\nOn Mon, Jul 15, 2013 at 9:17 AM, Ray Nicholus rnicholus@widen.com wrote:\n\nThat suggests something is wrong, perhaps with our reporting.  I've\nvisited other projects using SauceLabs where the badge is correct.\nOn Mon, Jul 15, 2013 at 9:15 AM, Mark Feltner notifications@github.comwrote:\n\nEven on the Saucelabs site https://saucelabs.com/u/fineuploader it's\n'unknown' (top-right corner) even though the last 25+ builds have appeared\nto have succeeded. The browser matrix is all green as well.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/914#issuecomment-20972123\n.\n. Why do you think the add files method only allow input file elements?  What\nare you trying to submit, specifically?\n\n\nOn Monday, July 15, 2013, wesleywong wrote:\n\nCurrently working on Dropbox chooser API to get the account image and\nwould like to use back the Fineuploader function to upload. But understand\naddFiles API only allow input file type. Is there any other workaround way,\nlike convert base64 image data?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/915\n.\n. As detailed in the API documentation, you can pass a file input element, many file input elements, a File, or many Files.  There is also an addBlobs method, if you need to pass a Blob or Blobs, instead of a more specific File.  If you have any further support questions, please see http://fineuploader.com/support.\n. Is there any particular reason why you want to use Fine Uploader for this, instead of simply sending the links to your server via an ajax request?\n. Without knowing more about your app, I'm not sure what specific recommendations we can make, but the most straightforward way to handle this is to simply send these links to your server via ajax.  You can update the UI appropriately to hide this implementation detail from the user.\n. What we have will do for now.  We can open a new case if requirements change in the future.\n. Why have you posted two completely unrelated code fragments here?  In your first post, you are not using the jQuery plug-in.  In your second post, you clearly are, but only show one line of your code.  \n\nI can only guess that, in your second post on this issue, this is not the element associated with a Fine Uploader instance.\n. That's a pretty old version.  I recommend trying the newest version to see if that addresses your problem.  Quite a bit has changed since 3.1.1, in every area of the code.  I wouldn't expect this problem to exist in the newest version, as I haven't encountered this myself.  This can be re-opened if you experience the same issue w/ 3.7.\n. @danielwalls There are quite a few demos on FineUploader.com.  In fact, most pages on FineUploader.com have multiple instances of Fine Uploader running at once.  Regardless, there is nothing special that needs to be done when using multiple instances of Fine Uploader.  Simply create multiple instances and use them however you like.  There is really nothing to demonstrate in that context.\n. Regarding the documentation, I also agree.  The docs are better than before, but there is still remove for improvement.  We will be tackling that soon.\n. SP only applies to searching at this point.\n. Have a look at the License section at the bottom of the overview page.   It contains information about the license as well as a link to build your own version for GPL v3 users.\n. The documentation site has a page dedicated to building your own version of Fine Uploader.  http://docs.fineuploader.com/contributing.html.  The docs site is pretty clearly linked to on the home page, via a a large button, and in the repo's readme.  I realize that we should probably rename the \"contributing\" link to \"building\" or something similar.\n. The readme in the root of the project links to the documentation.  Looks like the link in the root of the client dir is a bit stale.  We've redone the documentation several times already, and the home page has been restructured as well.  It's easy for us to lose sight of something like this.  I'll update the client dir's readme in the next version along with some other related documentation.  \nFine Uploader is a substantial product with a significant amount of complexity.  The build process is quite complex as well, and that complexity will only increase as #846 and other related cases are tackled.  Some of the dependencies are related to the cross-browser automated unit and integration tests that we are constantly updating and improving.  Other dependencies are related to the build itself, and some of those dependencies have dependencies as so on.  Once you run npm install once, subsequent updates shouldn't take very long.\n. We will take your suggestion into consideration as we are constantly re-evaluating our delivery model for the library.  It is always a bit tricky to satisfy the truly open-source users and still ensure that the project is financially sustainable so that we can continue to justify assigning resources to maintain, evolve, and provide excellent support for the library.\n. I can't provide any assistance without more information.  You say you are using IE10, but the error you have posted suggests you are using IE9 or older.  Also, you are doing some odd things with your options and have not mentioned what version of Fine Uploader you are using.  This appears to be mostly a support request at this point, and support requests are not handled in the issue tracker.  I'd encourage you to take a closer look at the documentation and then see the support page if you require technical support.\n. Ruben,\nFine Uploader does not distinguish between image and non image uploads at\nthis time.  Also, this sounds like more of an application-specific requirement.\n You can enforce these types of specific requirements yourself by simply\nperforming a check when your users click a button before calling Fine\nUploader's uploadStoredFiles API method.\nOn Saturday, July 27, 2013, Ruben Coolen wrote:\n\nI would like to have the option to add additional fields per image upload\n(like name and description) and possibly an option to make them mandatory.\nAlot of times you really need this functionality, and want to save it in\nyour database.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/928\n.\n. What problem does this solve that Fine Uploader doesn't already provide a solution for?\n. It seems like you should be able to accomplish this with Fine Uploader by specifying a drop zone and a button that point at the same element.\n. No prob.  Let me know if this doesn't actually work as expected.\n. This should be moved to the docs site\n. This seems pretty old. Closing, but will re-open if recent versions of Android still have this issue.\n. No longer needed after templating changes in #304 \n. This feature is complete.  Unit tests and documentation is included as well.  I still have to branch gh-pages and integrate this into fineuploader.com.  I'll probably add this feature to the S3 demo as well.\n. If you are talking about the Content-Disposition headers in each multipart boundary, then this is the browser's work, not Fine Uploader's.  If you have a specific support question, please see http://fineuploader.com/support.\n. The two items you are referring to: file names with special characters and\nsize validation, are completely unrelated.  So, I suspect something else is\ncausing this issue for you, perhaps something in your code or client side\nenvironment.  I personally use at least one file with umlauts in the name\nduring development and manual testing and have used such a file for several\nreleases now. Please provide a functional script, with html, that\nreproduces the problem.  If you can point me at a live example, that would\nwork as well.\n\nOn Tuesday, August 6, 2013, berlindisplay-max wrote:\n\nWhen I have the sizeLimit validation enabled and try to upload a file with\n\"\u00e4\" or other umlauts, the selected File never gets loaded and gets stuck on\nthe fileSize validation.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/936\n.\n. Also, I just noticed that you mentioned Ubuntu.  Have you tested on other oses without issue?  Which browser(s) are you having this problem with in Ubuntu?  All of them?\n. I do not normally perform any pre-release tests in Ubuntu: only Windows,\nOSX, iOS, and Android.  I'll setup an Ubuntu VM when I can here and look\ninto this further.  I'm a bit buried with the S3 feature documentation at\nthe moment, so I may not get to this until tomorrow or later this week.\n\nOn Tuesday, August 6, 2013, berlindisplay-max wrote:\n\nI should have mentioned this is only on Ubuntu. Everything works fine on\nWindows, not sure about OS X since I only noticed this now and don't have\nan Apple at work.\nI first found the issu on ubuntu Firefox where it just stopped doing\nanything and thought it had something to do with the file javascript api,\nbut testing on chrome the umlaut gives me a \"allowedExtensions\" error\nalthough the extension is valid, maybe the problem lies in that validation?\nLive example is here:\nhttp://blnd-testshop.lerollup.fr/de/rollup-displays/rollup-eco-light-basic-850.html\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/936#issuecomment-22176466\n.\n. Thanks for bringing this to my attention.\n\nOn Tuesday, August 6, 2013, berlindisplay-max wrote:\n\nok, obviously it's not a pressing issue at all, since ubuntu users are so\nfew, just thought i'd mention it. Thanks for the quick replies.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/936#issuecomment-22176996\n.\n. @berlindisplay-max I'm not able to reproduce this.  Please let me know if you are still seeing this with current versions of Ubuntu and Fine Uploader.\n. Hi Rodney.  Putting aside the complexities of supporting this for now, I guess I don't see how uploading multiple parts simultaneously would decrease the total upload time.\n\nLet's say you have a 10 Mbps upstream pipe and you are uploading a 10 MB file.  Normally, this file, if using your entire pipe (and ignoring any other overhead) could be uploaded in 8 seconds.  Now, if we split it into, say, 2 chunks of 5 MB each, and send each chunk one after the other, the 1st chunk uploads in 4 seconds, and the 2nd 4 more seconds, for a total of 8 seconds.  Now, if we send both chunks at once, they are still both sharing the same 10 Mb pipe, so I don't see how the total upload time could magically decrease to less than 8 seconds.  \nAm I missing something?\n. Yes, I will agree that this particular scenario would benefit from sending multiple chunks at once.  However, the exact same benefit can be obtained by setting the maxConnections option to 5 and allow up to 5 files to upload simultaneously as well.  It seems like a safe bet that most, if not all, web apps can expect to have users that select/drop multiple files at a time or nearly at the same time.  In that case, why not just allow 5 files to upload at once?  It's already possible with the current version of Fine Uploader (and has been possible for a long time).  Is there something specific about your web app that would not make this a simpler and just-as-effective solution?\n. Yes, I will agree that this particular scenario would benefit from sending multiple chunks at once.  However, the exact same benefit can be obtained by setting the maxConnections option to 5 and allow up to 5 files to upload simultaneously as well.  It seems like a safe bet that most, if not all, web apps can expect to have users that select/drop multiple files at a time or nearly at the same time.  In that case, why not just allow 5 files to upload at once?  It's already possible with the current version of Fine Uploader (and has been possible for a long time).  Is there something specific about your web app that would not make this a simpler and just-as-effective solution?\n. I'm going under the assumption that your users are going to upload more than one file at a time.  Let me know if this is not true, and please provide details about your web app or customer base that would suggest this is the norm among users of your app.\nWith that in mind, let's go with @alexmcmillan's example again of a 100 Mb pipe with a load balance in front of, say, 5 servers with a maximum throughput of 20 Mbps per server.  The load balancer distributes requests appropriately.  \nLet's say a user submits or drops 5 files.  What is the difference between uploading those 5 files simultaneously, but sending the chunks for each individual file consecutively, versus sending 5 chunks of the first file in parallel, then doing the same with the next file once the first file is done, etc?  It's not clear to me what the advantage of the latter approach is, especially since the former approach is already supported by Fine Uploader.\nAlso, keep in mind that all browsers impose a maximum number of requests that can be executing per hostname at once.  Chrome and most modern browsers have a limit of 6, I believe.\n. Ill address your points when I have more time, but keep in mind that you\ncan only realistically upload about 4 chunks in parallel.  Also, parallel\nchunk uploading will add a non trivial amount of complexity to the code\nbase.\nOn Thursday, August 8, 2013, Michael Mitchell wrote:\n\nmaxConnections only benefits multiple file uploads it is absolutely fine\nfor that situation, the situation where parallel chunk upload would benefit\nwould be for large file uploads therefore maxConnections does not solve the\nfeature request.\nThe above two situations are the areas that this feature would benefit.\nParallel chunk uploading would allow uploads to reach higher speeds since\na 1MB chunk is so quickly uploaded on a high speed connection it never\nreaches its peak speed.\nIt would also make scaling in large deployments more effective as above,\nthe situation of limited speed per server or a server that is already under\nheavy load means the user is stuck uploading at whatever that single server\ncan give it, allowing parallel uploads means the user has better luck of\nattaining greater speeds for a single large file Upload.\nmaxConnections does not solve the problem up uploading a 700Mb video as\nthat file will always be limited to the upstream speed of a single server,\nmaxConnections is only helpful for uploading lots of small files that\nprobably don't require chunking anyway.\nBandwidth is an issue for scaling, this would help solve that problem...\nit is more cost effective to deploy lots of small servers to increase\ncapacity rather than using larger single servers with massive upstream\ncapacity.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/937#issuecomment-22368016\n.\n. Yes, you are correct.  The simultaneous request limit is per hostname.  Allowing you to specify the endpoint per-chunk would add still more complexity though.  \n\nIf your server bandwidth is a notable bottleneck, have you considered using a cloud service that scales for you, such as AWS?  AWS offers a high-performance storage service (S3) that is built to scale in order to handle ridiculously high demand.  In fact, we are just finishing up a feature that will allow you to upload files directly to S3 from the browser in all supported browsers (including IE7), bypassing your local servers (for the file bytes at least).  \nI have tagged your feature request as \"to discuss\".  That means that we will discuss it internally at our next planning/story-pointing meeting.  If we feel it is something we should schedule, it will be story-pointed and prioritized.  \nYou may have already glanced at the issue tracker in this project.  If not, I can tell you that there are a lot of features in the queue at this time.  Features are determined to be high-priority if a good number of users request the feature, or if we at Widen feel that the feature would benefit a great number of users.  Then there are the normal priority features: those that would only benefit a smaller portion of users.  \nWhile I can see how your request might benefit you, it's not clear that it would be a useful feature for many other users.  In fact, it is likely to a feature that is rarely used, in my estimation.  That classifies this as a low-priority feature.  Low-priority features that are complicated to implement aren't likely to be implemented in the near future, or ever, quite frankly.  This is due to the fact that Fine Uploader, like all projects, has a limited number of resources.   It will take months and months for us to make it through even a portion of the current list of high priority issues. \nThe possibility of this making it into the schedule greatly increases if a good number of other users comment on this case.  It looks like we have users from two separate organizations commenting here, unless I'm missing a connection.  That's a good start, but I'd really need to be more convinced that this is a feature a good number of users could benefit from.  Other low-priority feature requests have been bumped to high-priority based on user input.  \nI'm not opposed to continuing this discussion.  Perhaps something can be worked out, but, again, we have a finite number of resources here on this project, and a finite amount of hours in a day, with many other higher priority features in the schedule at this time.  I'd be willing to discuss in a chat room or in some other real-time environment if anyone thinks it will be helpful to the discussion.\n. > What are the security implications with uploading directly to a storage service like S3?\nIt is fairly easy to lock down your AWS S3 bucket to prevent a malicious user from compromising your files.  Also, your local server is required to sign requests (using your secret key stored server-side) before Fine Uploader sends them off.  I have a lengthy blog post written up that covers all of this (including how to lock down your buckets) for users who want to upload directly to S3 using Fine Uploader.  The blog post is not publicly available yet, but will be when Fine Uploader 3.8 releases (hopefully some time next week).  \n\nWill it still support resuming?\n\nYes.  In fact, all Fine Uploader features are supported when using the upload-to-s3 module.  \n\nI'm not quit sure that feature would solve the small chunks problem as I mentioned above.\n\n\"Small\" chunks are generally not a good idea due to the overhead associated with sending such a request.  The minimum chunk size (enforced by Amazon) is 5 MiB.  Furthermore, S3 will theoretically (automatically) scale to such a degree that the throughput bottleneck will likely not be the endpoint (S3).\n\nWill you support cloudfiles?\n\nSeems possible, but it's not yet in our schedule.  In fact, you are the first to request it.  We have discussed it internally (at a very high level), but that's about it.  It looks like cloudfiles allows HTML form uploads and recently added CORS support for their REST API.  So, that's promising.  I'd invite you to open up a separate feature request for this, if you'd like us to consider it.  The tight integration with Amazon S3 that 3.8 will provide was a significant amount of work, and I suspect cloudfiles will be no walk in the park either.  But, if is something rackspace users would like to have, we will certainly prioritize it accordingly.\n. @michaelmitchell Fine Uploader 3.8 has been released w/ native support for S3.  You can play with a live demo on fineuploader.com, which also contains links to documentation which explains the support in more detail, if you are interested.\n. The only obvious use case where sending simultaneous chunks would be beneficial involves a single large file.  \nWhen several files are being uploaded simultaneously, sending simultaneous chunks per file provides no additional benefit in most cases.  This is due to the fact that all browsers restrict the number of simultaneous open requests per host.  Fine Uploader enforces this restriction by preventing no more than 3 upload requests at a time (though this is configurable).  Granted, we could be a little more flexible with this restriction by tracking open requests per hostname.  If you are sending each file to a different endpoint, only then does the ability to upload simultaneous chunks make sense.\nAdding this behavior to Fine Uploader may not be simple.  The following high-level tasks must be completed:\n- Azure, S3, and traditional upload endpoint handlers must be refactored to allow for multiple simultaneous chunks to be uploaded.  The current design only allows chunk 2 to be uploaded after chunk 1 has been successfully uploaded\n- Ensure progress events are invoked with the proper values when multiple chunks are uploading for the same file.\n- Figure out what to do if chunk 1, 2, and 3 are in progress, and a subset of these chunks fail.  \nI think the hardest part will be refactoring the handler code to allow for this behavior.  This behavior should also be tied to an option, that is turned off by default.  Also, as with any feature, the devil is in the details.  I'm sure more complexities will pop up during development of this feature, as we will need to break an assumption that the library has relied on since the creation of the chunking feature.\n. We are aware that this is becoming a popular feature request, and will prioritize it accordingly.  It's likely that this will make it into a near future release.  The current release cycle, 4.4, is full at this time, but perhaps 4.5.  \nWe always give priority to heavily requested features, and this one is certainly a popular one.\n. I'm moving this up the list as I see it is a high-priority feature in light of the response from the community.  I think the best approach may be to make an attempt to use all available connections (per the maxConnections option) to upload the set of files.  If maxConnections is set to 3 (the default) and 1 file is submitted, and that file is chunkable, it will be uploaded 3 chunks at a time.  If 2 files are submitted, As many as 3 chunks between the two files will be uploaded simultaneously.  \nI don't see an obvious need to create a new option to enable this.  Preferably, Fine Uploader will send multiple chunks for a file at once whenever possible by default.  \nRetry and resume attempts may be very complicated to restructure in order to accommodate this workflow.  I've increased the story points to reflect this.  Fine Uploader doesn't track specific chunks in the upload handlers. Instead, there is a concept of the number of chunks that have yet to be uploaded or the index of the last chunk that was attempted.  If a number of chunks for a file are attempted at once, this assumption breaks down, especially if only one of these chunks fails to upload.  We will probably have to persist the index of the last consecutive chunk to successfully upload (for the resume feature).  The retry code should probably only attempt to upload any chunks that haven't uploaded successfully yet though.  \nProgress tracking may be a bit tricky as well.\nThis is no longer an S3-specific feature.  It should probably apply to all endpoint types.\n. Currently scheduled for 4.5.\n. After further investigation, this feature will probably have to be disabled by default and tied to an option.  Otherwise, we run the risk of breaking any app with a server that expects chunks to be sent one at a time, in order.  I suspect most traditional endpoint handlers will look for the last chunk request and then attempt to combine all chunks.  With this feature, the last chunk may arrive at the same time or even slightly before previous chunks.\n. After some more thought and internal discussion:\nGoals\n\nUse all available HTTP connections to upload files: 1 connection per chunk.  Max # of connections is specified via the existing maxConnections option.\nConnection distribution algorithm is greedy: give out available connections on a first-come-first-server basis.  For example, let's say we have two files are in the queue, 3 available connections, and the first file requires 6 chunks to be uploaded.  All 3 connections will be given to the first file until there are less than 3 chunks remaining to be uploaded.  So, all 3 connections will be used to upload the first 3 chunks, then we will continue to use all 3 connections on this file until we only have 2 chunks remaining.  At this point, 2 connections will be given to upload the last 2 chunks and the 3rd connection will be given to the 2nd file for its first chunk.  As the 1st file finishes its remaining chunks, the available connections will be distributed to this 2nd file to allow it to upload its chunks in parallel.  \n\nNon-goals\n\nAn option to turn off the greediness described in goal 2.  In the scenario described there, the first file would only be given 2 connections, and the 2nd file would be given one, so both files are uploading at the same time.  If 3 files were present, each file would only have access to 1 connection at a time.\nAllowing the spread of chunks for a single file across multiple endpoints.  To make full use of this, we would need to allow the maxConnections option to be applied separately to each unique request endpoint domain.  Also, we would need to augment or adjust the API to allow integrators to specify multiple endpoints, with the understanding that Fine Uploader would evenly distribute chunks/files across all specified endpoints, maxing out allowed HTTP connections per unique domain.  Further complexity comes from allowing these endpoints to be adjusted or specified per-file.  I can see how this may be useful, but I'm not sure I want to shoehorn this into this feature, as we already have a lot to do here.\n\nImplementation requirements:\nThis feature will seemingly require a significant amount of internal code refactoring.  Currently, Fine Uploader relies internally on the assumption that each file will only consume 1 upload-related HTTP connection at once.  This makes it relatively straightforward for handler.base.js to distribute available connections.  1 connection per file, and after a file completes entirely, give the free connection to the next file in the queue.\n1. handler.base.js will need to be able to ask the specific endpoint handler to upload specific chunks, by chunk index, if the parallel chunk uploads feature is turned on.  In order to do this properly, the base handler will need to be aware of the remaining chunks for each file, and when a specific chunk upload is complete.  If the parallel chunks feature is disabled the base handler will probably still ask for specific chunks to be uploaded, by index, but ensure that only one connection is allocated per file.  If chunking is not possible or disabled, the base handler will likely just ask the handler implementation to upload the specific file, not specifying the chunk index.  The bottom line here is that we probably need to consider moving more control of the upload process out of the handler implementations and into the base handler.\n2. Currently, we only track the index of the last chunk that completed.  The status of each chunk will need to be tracked, since chunks may easily upload out of order.  This is required to support the retry, resume, and pause features.  This tracking should ideally happen in abstract.handler.xhr.js.  Currently, chunk-related info is mostly tracked inside of each endpoint handler implementation.  We will also need to track the XHR instance associated with each chunk separately.\n3. The retry logic will need to change.  Currently, a retry starts with the chunk after the last successful chunk, and continues until the file is finished.  Now, we will need to be aware of the specific chunks that failed, which may not be sequential.  If any chunk fails to upload for a specific file, the upload will be considered a failure.  If the failed chunk does not succeed after all auto retry attempts, the file will be considered a failure.  However, we will continue to upload chunks associated with other connections available to that file unless those fail as well.  If all connections associated with that file are still failing after auto retries have been exhausted, all connections previously allocated to that file will be redistributed to other files.  All of this means that the onAutoRetry callback may be invoked multiple times for the same file simultaneously if, for example, multiple chunks fail at once and are retried at the same time.  Perhaps we will pass a 4th parameter to onAutoRetry and onManualRetry that includes the chunk index that we are retrying.  The qq.status of a file will only change to qq.status.UPLOAD_FAILED after all auto-retries have failed, and the file is otherwise complete (even if all but one chunk has completed successfully).  As you can see, dealing with failures here is potentially very tricky.\n4. Currently, we only persist the index of the last chunk that uploaded successfully.  The auto-resume feature will need to be aware of which specific chunks need to be uploaded for each file.  This means that we will need to, at the very least, persist the chunk indexes that have yet to upload.  This may also be an appropriate time to switch persistence of the resume data from cookies to localStorage for traditional endpoints, as described in #1024.  The logic that persists this data and reads it back from storage should probably be moved out of the specific endpoint handler implementations and into abstract.handler.xhr.js.\n5. When an upload is cancelled, all XHR requests for that file must be aborted.  There may be multiple XHR requests associated with a file at one time if multiple chunks are being uploaded for that file in parallel.\n6. The pause feature simply aborts an in-progress upload and then starts it up again (effectively \"retrying\" or \"resuming\" it) starting with the chunk after the last successful one.  The changes to resume, retry, and cancel above should effectively cover most of the pause feature.  There is a small amount of pause-related logic in the individual endpoint handlers.  The logic for handling and tracking pauses should probably be moved entirely out of the individual endpoint handler implementations and into either the base handler or the abstract XHR handler.\nServer-side implications\nThere are effectively no changes required server-side for S3 and Azure endpoints.  Both APIs allow for parallel chunk uploading per object/blob.  There is, however, more complexity associated with traditional endpoint handlers when this feature is enabled.  Traditional endpoint handlers may be looking only at the chunk index to determine if the entire file has been transferred.  With this feature enabled, that is not a safe assumption as parts can be uploaded out of order.  Traditional endpoint handlers that want to make use of this feature will need to determine if all parts have arrived before attempting to combine them.  One simple way to do this may be to send an ajax request via a Fine Uploader onComplete callback handler, which should be triggered after the file has been sent in its entirety.  This is probably not an ideal solution, as errors associated with merging the parts will not be reflected in the status of the upload.  It is generally advisable to hold off responding to the last upload chunk request until all parts have been successfully combined into the original file.  This way, the server can easily alert Fine Uploader of a problem via the response (which can be reflected in the UI and the state associated with the file internally).  A common problem that results in merge failure is a mismatch of the actual file size and the expected total file size.\n. @rodneytamblyn @alexmcmillan @michaelmitchell @i0nC4nn0n @jasonshah Would any of you be interested in beta testing this feature once it is more complete?\nThe following tasks must be addressed for the concurrent chunk workflow before this feature can be realistically beta tested:\n- [x] Finish adjustment of progress reporting\n- [x] Fix cancel & cancelAll\n- [x] Fix retry/failure handling\n- [x] Fix auto-resume\n- [x] Handle scaled images (i.e. scaled images are not eligible for concurrent chunk uploads)\n- [x] Fix pause feature\n. @jasonshah Good to hear.  You can follow the progress of this feature here, as all related commits will reference this issue number.\n. Note that my internal tests that involved uploading multiple chunks for a specific file concurrently showed significant improvements in bandwidth utilization.  For example, on our internal network, sending a 110 MB file to S3 with chunk sizes of 5 MB took about 22 seconds when chunks were uploaded one-at-a-time.  When maxing out the default maxConnections for that file (3 chunks at once) the same file uploaded in about 12 seconds.\n. Only a few things left before this can be beta tested:\n- [x] Implement a POST to traditional endpoints after all chunks have been uploaded successfully. This will be a required setting/behavior for concurrent chunked uploads, and optional for sequential one-at-a-time (default) chunked uploads.\n- [x] More unit tests\n- [x] Documentation updates (breaking changes, new feature page, new options)\nIn addition, it will be useful to type up a post on http://blog.fineuploader.com outlining the benefits of concurrent chunk uploads, but this is not required before beta testing.\n. Accidentally mis-tagged the final planned commits for this feature:\n- 3cf084150793b24d4ea30bceeb1a0d3a4166311b\n- a95c180d5b3061b6efcbe8a2ca18abf8cd9da843\n- eb39a59\n. @jasonshah I think we're ready for beta testing.  All feature work has been merged into the develop branch.  I've updated the documentation as well. The concurrent chunking feature page is a good place to start.  Also, there are breaking changes here (as this will be a 5.0 release) so you will want to read the upgrading to 5.x notes as well.  Let me know when you would like to try this out and provide feedback.\n. @jasonshah Thanks for the update.\nIf anyone else in this thread is interested in beta testing before the feature is officially released, let me know.  Otherwise, this will be released as designed.\n. @jasonshah Please send me a message.  I'm not sure I have your address.\n. I'll take a look at the TypeError shortly.  That function should always return false in FF anyway, but true in Chrome and Opera 15+.\nI haven't determined what optimal settings are for chunkSize & maxConnections.  I can tell you that all browsers limit the number of open HTTP connections per host.  For example, I believe that number in Chrome is 6 or so.  Once you hit this limit, there is unlikely to be any benefit gained by increasing the maxConnections value further.  \nThe minimum chunk size for S3 is 5MB, which is the default value when using Fine Uploader S3.  I have only tested with the default chunkSize value myself. \n. The TypeError you are seeing appears to be a bug in Firefox, as far as I can tell.  The items property is part of the DataTransfer interface, but it is coming up undefined in recent versions of FF.  The nightly version of the HTML5 spec suggests that items should be defined.  I'll look around and perhaps file a bug w/ FF.  I guess we'll have to work around this though.\n. Let me backtrack a bit...  After peering at the history of that line of code in Fine Uploader, we may have always been accounting for this undefined property, but 0b5b02f3db3a7f2d02ad005872a706d8a7461b23 introduced a regression that broke this check.  Luckily, that change did not make it into the master branch yet.  I'll re-open #1166 until we get this fixed.\n. @thisiskell I should have this TypeError fixed in 5.0.0-5.  I'll send you an updated build.\n. @thisiskell Can you elaborate on the \"upload cleanup\" step?  I'd like to reproduce this locally so I can ensure it is fixed properly.\n. Ah, upload.cleanup(), thanks.  Yep, we are already using modern.IE vms for\ntesting in IE7+.  I'll make sure this is fixed before the 5.0 release.\nWhat sort of upload speed gains did you see?\nOn Thu, Apr 24, 2014 at 5:14 PM, thisiskell notifications@github.comwrote:\n\nSure, in upload.cleanup(), there is this block of code which is causing\nthe error:\nif (handler._getFileState(id)) {\n            handler._clearXhrs(id);\n        }\nI am testing using in ie8 VM, which can be downloaded here:\nhttp://www.modern.ie/en-us/virtualization-tools#downloads\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/937#issuecomment-41339291\n.\n. What version of safari?\n\nOn Friday, April 25, 2014, thisiskell notifications@github.com wrote:\n\nHey Ray, discovered one more issue: Safari Mac seems to be failing when\nuploading a file to s3 which is larger than 1 chunk. It works fine when the\nfile is exactly 1 chunk.\nHere is what amazon is returning after uploading the last chunk:\nEntityTooSmall\nYour proposed upload is smaller than the minimum allowed size\n12345\n5242880\n0\n12345\n12345\n5\nAnd here is what s3.jquery.fineuploader-5.0.0-5.js is reporting:\n[Error] [Fine Uploader 5.0.0-5] Complete Multipart Upload request for 0\nfailed with status 400.\n[Error] [Fine Uploader 5.0.0-5] Problem finalizing chunks for file ID 0 -\nProblem asking Amazon to combine the parts!\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/937#issuecomment-41418760\n.\n. XML must be included in a fenced code block.  I'll edit your post to fix it.\n\nOn Friday, April 25, 2014, thisiskell notifications@github.com wrote:\n\nStrange, my xml error did not render properly in the comment... I will\nsend it to you separately in an email.\nWe have reproduced now it on 3 machines running Mac Safari Version: 7.0.3,\nand our fineuploader is currently configured to have 20MB chunks with 10\nmaxConnections.\nLet me know if you need any more details from me.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/937#issuecomment-41420680\n.\n. I just took a quick look, and it seems like Safari is choking when we attempt to send multiple chunks of the same file at once.  When we send chunks one-at-a-time, no problem.  Tracing though the code, it looks like Fine Uploader is doing everything correct, but, for some reason, Safari is sending an empty blob to S3.  It's clear that Fine Uploader is even passing a correctly-sized blob to the send method of the XMLHttpRequest instance.  There's a fair number of upload-related bugs in Safari, and Apple never seems to be interested in fixing them.  I'll take a closer look at this next week and see if we can work around this.\n. This might be a WebKit bug first reported in 2012 (and still not fixed?!).  Here's the report: https://code.google.com/p/chromium/issues/detail?id=167111.  This was filed in the Chromium tracker, and, at the time, Chromium was using WebKit.  Safari still uses WebKit, but Chromium uses blink.\n. I think @feltnerm is looking into this now.\n\nOn Fri, Apr 25, 2014 at 4:07 PM, thisiskell notifications@github.comwrote:\n\nConfirmed, disabling multiple simultaneous chunks for Mac Safari did the\ntrick.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/937#issuecomment-41439480\n.\n. The IE8 error, along with the concurrent chunking issue in Safari should now be fixed as of 5.0.0-7.  \n\nThe Safari issue was due to WebKit garbage collecting the Blob too soon in some cases.  I worked around this by keeping each chunk Blob in scope until after the response has been received.  \nNext bugs to fix are the failure to reset an S3 upload when an issue has been detected with a specific chunk, and the occurrence of multiple records for the same chunk index when concurrent chunking is enabled.  The latter issue is not consistently reproducible, but may cause AWS to respond to the multipart complete request with an error due to duplicate ETAGs in the request.\n. Sorry , I meant to say that the fixes should be in 5.0.0-8.\n. I am now unable to reproduce the duplicate etag entry problem as of 5.0.0-9.  We'll look into this more if it crops up again.\n. The order that the files appear in the UI is determined mostly by the browser, and not by Fine Uploader.  If you select or drop a batch of files at once, Fine Uploader is provided an array by the browser.  It then iterates over the items in this array.  By default, if you then select or drop another batch of files, that batch will appear below the first batch in the UI.  You can ask Fine Uploader to place subsequent batches at the top of the list, instead of the bottom, by setting the prependFiles property of the display option to true.  Note that the prependFiles feature was first added in 3.6.\n. Flash is a completely different ballgame.  I have little knowledge of handling uploads via Flash, but I would not be surprised if the behavior you are describing varied between a Flash uploader and a native HTML(5) uploader such as Fine Uploader. \n. I am curious why the order of these files is important to you.  Can you describe a specific scenario?\n. Yes.  For further questions related to licensing, email licensing@fineuploader.com.\n. Have a look at the FAQ, where this specific problem is covered.  Also,\nplease leave the issue tracker for bugs and feature requests.  See\nfineuploader.com/support for more details on opening up a request for tech\nsupport.\nOn Thursday, August 8, 2013, Luis Ricardo Sanchez wrote:\n\nI asked because I received a .json file download response after my upload\nmethod ran succesfully. Any ideas how to fix this?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/939#issuecomment-22371070\n.\n. Please see fineuploader.com/support for tech support.  Also, this specific problem is discussed in the FAQ.  Since you are having this issue, you may not have read the server side docs either, so give those a look as well.\n. You are mistaken.  There is absolutely 100% no way to select multiple files at once in IE9 or older. \n. Which version of IE are you using?\n. Multiple selection works fine in IE10.  As I mentioned before, IE9 and older do not support multiple selection.  The documentation clearly states that this restriction is on IE9 and older, not IE10.\n\nIf it is not working in your code, and it is working in the demo, then there is an issue with your code.  The demos use released versions of Fine Uploader - the same code you have downloaded and are using in your project.  This is a technical support question, so please open up a request on Stackoverflow under the fine-uploader tag as the support page instructs. \n. Looks like you've already posted on SO.  Let's address your question there, since the issue tracker is not for tech support.\n. :thumbsup: \n. or [skip ci]\n. This is still outstanding in 4.0.  Any updates/resolution?\n. Parameters for methods on the API documentation\n. This really doesn't seem necessary, after much thought.\n. @chetanpatel All browsers that support the File API and provide a type attribute on File objects currently use the file's extension to determine the file type.  With that in mind, it's not useful to check both the extension and the type attribute.  The acceptFiles option is a very thin abstraction of the accept attribute on <input type=\"file\"> elements (which has poor cross-browser support).  So, it is not really a validation property, even though it is currently located under the validation option.  \nIf we want to more accurately validate the type of a file, we will need to do so using magic byte parsing/matching, which is an asynchronous process, and requires we maintain a table of these patterns.  This is probably not something we will ever do on a large scale.  Fine Uploader does perform this type of identification for some image files, but that's it.  \nThe goal of this case is to allow users to declare these two options using the same convention.\n. Thanks Shawn, I'll take a closer look in about 10 hours (in the morning).\n What version are you using?\nOn Wednesday, August 21, 2013, Shawn wrote:\n\nIf I have\ndragAndDrop: {\n    disableDefaultDropzone: true},\nand try to call the \"reset\" function later\n$('#file-uploader').fineUploader('reset');\nIt throws an exception because dz is undefined on line 2695.\nSolution is to add if(dz !== undefined) before calling dz.dispose();\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/953\n.\n. I have reproduced this just as you mentioned.  I'll flag it and we will make sure that this is fixed in the next release.\n. Ignore the above commit messages - I incorrectly tagged commits from #937.\n. This seems complete.  Is it?\n. Are you simply saying that you want to be able to specify headers along with the signature request?\n. I just want to make sure I understand your request.  All you want to be\nable to do is specify the headers for the signature request, correct?\n\nOn Friday, August 23, 2013, priyapanigrahy wrote:\n\nI dont know how to set the headers while specifying the signature\nendpoint. It would be great if you can update the above code.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/956#issuecomment-23163325\n.\n. Yes, I would likely add a headers property to the uploadSuccess, and signature options.  I'm assuming that these headers will be the same for each type of request and are known when the Fine Uploader instance is created.  Is this also correct?\n. Ok, I've adjusted the title of this request accordingly.  We will be sure to include this as part of our next release.\n. One more question: why did you set the expected property of the cors option?  None of your request endpoints appear to be cross-origin.\n. Ok.  I would suggest removing the cors option entirely from your \"glue\" code then, since you are not dealing with a cross-origin environment.\n. Note that the deleteFile option already has a customHeaders property that you can use...\n. This has been implemented in the develop branch and will be part of Fine Uploader 3.9.  Note that you don't have to set the Content-Type headers for these requests.  Fine Uploader will set appropriate Content-Type headers for you.\n. Attempting to reproduce now...\n. I have been unable to reproduce following your instructions exactly.  @feltnerm also attempted, without success.  We were both using IE8 on XP.  Is there some other way to reproduce this?  Do you have console/network logs from the client when this is reproducible?\n. I am seeing an \"Access Denied\" message in IE9.  Unfortunately, debugging this is a bit complicated with minified code.  Do you have a way to swap out the minified version with the non-minified version of Fine Uploader temporarily?\n. ..., and it is now happening in IE8 as well (even though I did not change anything).  I am seeing a javascript error on page load in IE8 outside of Fine Uploader though, in respond.src.js.\n. @firepol In order to look at this a bit closer, I'll need you to:\n- Swap out the minified version of Fine Uploader with the non-minified version temporarily\n- Set the debug option to true in your \"glue\" code.\n. I'll take a closer look now...\n. @firepol It looks like all of your issues are caused by your addition of the \"Choose a file\" label.  Everything seems to work fine when you click on the up arrow, which is the select files button contributed by Fine Uploader.  Your \"choose a file\" label, when clicked, then programmatically clicks the upload button contributed by Fine Uploader.  IE does not permit this.  More specifically, IE will not allow you to programmatically invoke a file dialog and then programmatically submit the associated form.   In IE9, an \"Access Denied\" error is logged to the console, which is a symptom of this issue.  IE8 apparently doesn't log an error and just ignores the form submit.  Fine Uploader gets around all of this by embedding an opaque <input type=\"file\"> element as a child of the upload button, so when the user clicks the visible styled button, the <input type=\"file\"> element is naturally targeted by the click.\n\nAgain, you'll need to remove the \"choose a file\" label.  If you need an additional link/element that triggers the file dialog, you will need to create your own opaque <input type=\"file\"> element with a styled div/span/anchor as its parent and register a \"change\" event handler on the underlying input where you pass the <input type=\"file\"> into Fine Uploader's addFiles method where it will take care of the upload for you.  Feature request #819 will make this even easier for you, once it is completed.\n. Note that you can still have multiple upload buttons in your app, even before #819 is completed.  #819 will make this much easier, but this can still be done, as described in my last comment.  In the \"Upload directly via a camera\" blog post, I described how to use the upload via camera feature and allow users to select multiple files in iOS.  The code at the end of that blog entry illustrates how to create your own additional upload button and tie it to an existing Fine Uploader instance.\n. The 4 lines of HTML in my blog post contain inline styles on the file input element and the parent div.  You can see them if you scroll to the right enough in the code example.  The inline styles on the file input element make it effectively invisible.  The parent of this file input is a div, which contains all visible styles. When a user clicks or taps the visible div, the file input in fact receives the actual DOM click event first.  The top-level parent div contains two children, another div with some visible text, and the invisible file input element.  The child div containing a text node is required for IE7 support.  If you include a simple text node as a child of the parent div in IE7, the text will not be visible.  The \"trick\" in my blog post will ensure that users will only see the parent div and the text node, and not the file input element.  This works in all browsers, including IE7 (and IE6, though Fine Uploader does not support IE6 anymore).\nYou should be able to to simply copy the example in my blog post and change the \"Camera\" text node to read \"Choose a file\", and it will probably look about the same as your initial <label>.  You may want to move all of the styling to a CSS file and target the elements via selectors.  I included everything inline in my blog post for the sake of brevity, but that isn't the proper way to do it in a production web app, IMHO.\nIf you have any further technical support questions, please see http://fineuploader.com/support.  There are instructions there that discuss how you can open up a support request.  In summary, @feltnerm and I handle support requests on Stack Overflow under the fine-uploader tag.\n. Also, please have a look at the proposal for #819 and leave a comment in the case if something is not clear, or if you would like the proposed feature to function a bit differently.  We hope to work on #819 as part of the next release of Fine Uploader.\n. Dropping this from the schedule until further notice.\n. This is going to be covered in another way in the near future.\n. Dropping this from the release.\n. Mark - don't you already have something in place for this?\n. @feltnerm Don't tests for this already exist?\n. Is this still a \"3\"?\n. Sounds good to me.\nOn Mon, Mar 24, 2014 at 9:54 AM, Mark Feltner notifications@github.comwrote:\n\nIs this still a \"3\"?\nYes. I think that is fair.\nShould at least check that the zips are valid, the all the expected files\nare included in the zips, & the version number is valid.\nNote that the tests I mentioned above don't actually test for the above [image:\n:cold_sweat:] I'm not sure what would constitute a \"valid\" zip. There's a\nfew ways to go about that I guess: check expected files, names, sizes, ...\nfor now I'd just say bringing the custom build tests up to date would be\ngood. Thoughts?\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/959#issuecomment-38453681\n.\n. Based on our recent internal discussions @feltnerm, this is probably no longer needed.\n. This is going to be covered in the near future outside of this repo.\n. Ignore the commit message above.  I mistakenly targeted this case, but should have targeted #819.\n. You're giving us bits and pieces of information and constantly changing your code.  Let's keep your code constant here.\n1. Do not use the S3 plug-in.\n2. Post your entire HTML document\n3. Post ALL of your javascript.\n4. Post all of your error messages along with the stack traces for each error\n. Sounds good.\n. In the query string of the success redirect response to an HTML form POST upload request, it seems, for the key name, AWS replaces spaces with a \"+\", while it percent-encodes all other non-ASCII characters.  I realize this is allowed by the spec, but it's a bit unexpected and odd.  Why not replace spaces with %20 to be consistent?  Anyway, we'll fix this and roll out a hotfix release.  Thanks for the report.\n. Note that this bug will affect all versions of IE older than IE10.\n. Fixed in 50aa294ddb1056cb2cc11eaeae464d68cad37345.  To be merged into master and will be part of the 3.8.1 hotfix release, to be released today.\n. The jQuery wrapper is being phased out in #1310 as part of 6.0.\n. Implementation notes:\n1. Refactor retry logic in uploader.basic.api.js so that an auto retry can be triggered outside of an upload handler (in this case, in s3/uploader.basic.js).\n2. Allow retry to apply to an upload (handler) or a non-upload (handler).  In this case, we'd want the uploadSuccess request specific to S3 to be re-sent.\n3. Examine the uploadSuccess response for the presence of a set reset property.  If it exists, ask the upload handler to start the upload over completely.  This may be as simple as ensuring that the upload handler wipes out any information about the progress of the upload if the actual upload was successful.  If that occurs, a call to upload on the handler should restart the upload it seems.\n. Story pointing: No one is around, but I'm going to call this a 2 and begin working on it now.\n. If all looks good after some internal testing, 3.8.2 will be released on Tuesday.\n. Released today instead.\n. @mcurry The build failed as we do not allow pull requests against master: only develop or a branch based off of develop.  No worries though, I'll create a case to track this and potentially roll this into 3.8.2 as well, along with #977.\n. If all looks good after some internal testing, 3.8.2 will be released on Tuesday.\n. Released today instead.\n. The problem with these types of features (not related to the task Fine Uploader is designed for: uploading files) is that there are lots of hidden complexities.  Fine Uploader is designed around a single purpose: uploading files.  It was not designed to be a general-purpose UI tool.  Once a feature is added, it tends to add complexity to the code and becomes the target of enhancements requests.  \n\nWe'll add this feature to the \"to discuss\" queue, but it's highly unlikely that it will ever become part of this library, unless this feature request receives a significant amount of support from other users, as it is a bit out of scope.\n. The problem with these types of features (not related to the task Fine Uploader is designed for: uploading files) is that there are lots of hidden complexities.  Fine Uploader is designed around a single purpose: uploading files.  It was not designed to be a general-purpose UI tool.  Once a feature is added, it tends to add complexity to the code and becomes the target of enhancements requests.  \nWe'll add this feature to the \"to discuss\" queue, but it's highly unlikely that it will ever become part of this library, unless this feature request receives a significant amount of support from other users, as it is a bit out of scope.\n. Thank you for catching this, but we do not accept pull requests against the master branch, as detailed in the contributing link at the top of the \"new issue\" form.  We'll fix the issue you caught shortly though.\n. Fixed in 98d66e9a54c29c812a033189112202c850ed8c74.\n. Unless you are submitting a form yourself, outside of Fine Uploader, this will be a lot more difficult to support than you think.  I'm assuming that you are calling setParams and asking Fine Uploader to send the form field values along with each file.  Assuming this is true, it's unlikely that the feature you are asking for will be added to this library any time soon.  Features such as this one that do not directly deal with the library's main purpose, uploading files, have a number of hidden complexities.  There are quite a few other features in our queue right now.  We will mark this as \"to discuss\" but the chances of this being implemented are fairly slim, since this is a bit out of scope for a file upload library.  \nYour best bet is to provide a space for your users to edit metadata for existing files.  Fine Uploader is not designed to handle this sort of task.\n. Why do you want to access this internal property?  If you want to determine if any files have been submitted to the uploader, you can easily do this a number of ways without directly accessing internal properties of the library.  Have a look at the getUploads method in the documentation, for example.\n. It's not clear this is an important adjustment.\n. Changes made in Widen/fine-uploader-server branch.\n. This is most likely an issue with your CSS, and not Fine Uploader, as everything works as expected in IE8 on the home page.  Please show ALL of your code required to reproduce this.\n. This is clearly an issue with your CSS.  The issue tracker is for reporting issues with Fine Uploader's code, or feature requests.  Support is handled on Stack Overflow.  See http://fineuploader.com/support for more details on how you may open up a support request.  \nAlso, I strongly advise you do not modify any Fine Uploader source files, as upgrading will likely be difficult as a result.  Instead, target elements with your specific CSS rules in your own CSS file.\n. Thank you for catching this!  We do not accept pull requests against the master branch, as detailed in the contributing link at the top of the \"new issue\" form, but we'll fix the issue you caught shortly though...\n. Indeed!  I'm going to cherry-pick my latest commit from the develop branch into master shortly and then this will be fixed.  Thanks again!\n. Looks like this regression was caused by changes in 1022138714a5aa060edef840a1b845a1cad0635a.\n. No, after closer inspection, this issue probably goes a bit farther, back to d12c870.\n. This change may have allowed non-jQuery callback syntax to be used with the jQuery plug-in.  Not necessarily a bad thing (maybe even an enhancement) but this needs to be investigated a bit more on Monday. \n. Should be covered by #1112.\n. Looks like submitted movies in iOS7 are reported to be empty (0 size) by Fine Uploader.  Images seem to work as expected.  Looking into this now.\n. This is, without a doubt, a bug in iOS7.  I was able to reproduce with this jsfiddle: http://jsfiddle.net/zrKQD/3/.  If you are wondering why I wrapped the window.alert in a setTimeout, see #548.\nThe issue is only reproducible if the multiple attribute is present on a <input type=\"file\">.  With this attribute set, all browsers on iOS7 report the File size attribute as \"0\".  Removing this attribute results in as-expected size determination by the browser, but, of course, you can only select one file at a time.\nI'm going to file a bug with Apple now.\n. See #990 to follow progress of the MOV file bug I uncovered in iOS7, along with a workaround.\n. Until Apple fixes this in iOS7, there is a very simple workaround.  I've added a function that will allow you to determine if the browser is running on iOS7.  You can use that to set the value of the file input's multiple attribute, so, if you plan on allowing MOV files, you should set the value of the multiple option like this:\njavascript\n$(\"#uploader\").fineUploader({\n    multiple: !qq.ios7(),\n    ...\n});\nThis will remove the multiple attribute from all upload buttons (unless you have contributed an extraButton with a specific value for multiple), but only in iOS7.  This means that users will not be able to select multiple files at once in iOS7, but at least they will be able to upload MOV files!  \nNote that qq.ios7() is new as of Fine Uploader 3.9.\n. Apple doesn't appear to be particularly interested in fixing bugs such as this one.  If you've ever used their bug tracker, you may have noticed that the bug tracker itself is often down in fact.  I have several outstanding bugs with Apple.  \nAll I can tell you is that the bug number (in the bug tracker) is 14975656.  There doesn't appear to be any way to grab a link.  If this doesn't receive any attention from Apple, I will likely be forced to implement a (possibly permanent) workaround for iOS7.  I'm wondering if simply tossing out the file size restrictions/checking for iOS7 MOV files will be sufficient.\n. This should not have been closed.  Re-opening.\n. The first time I ran into this issue with MOV files was iOS 7.0.0.  I tested previously on 6.1.4 and I don't recall seeing any MOV-related issues.  Have you tested on 6.1.4 by any chance?  \nChrome for iOS is not explicitly supported by Fine Uploader at this time.  There is a pending feature case open for us to certify it, though.  See #864 for more info.  I'll look into this more when we get to that case.  I can tell you that Chrome on iOS is a bit less capable than Safari.  For example, upload progress is not supported.  You will likely have a better experience, as far as uploading is concerned in iOS, with Safari.\n. Note that the workaround (which is used in all demos on the fine uploader site) is described in my second comment in this issue.\n. Be sure you are using Fine Uploader 3.9 if you are utilizing the workaround I described.\n. I received the following message from Apple today regarding the bug I filed:\n\nPlease verify this issue in iOS 7.0.4 GM (Build: 11B554a) and reply back with your results.\n\nI'm not sure what the point of this message was.  The bug definitely still exists in 7.0.4 and Apple could have verified themselves in 10 seconds using my jsfiddle link.\n. Note that there is an automatic workaround for this that will be part of 4.1.0.  See #1039.\n. Also present in iOS8 GM, but the workaround triggers a new issue in iOS8, described in #1283.\n. At the request of a Chromium developer, I filed an issue in the Chromium bug tracker as well.  Since Apple isn't interested in fixing this, maybe the Chromium team can include a workaround specific to mobile Chrome.  \nhttps://code.google.com/p/chromium/issues/detail?id=414769\n. This appears to be fixed in iOS 8.0.2.  The workaround will be adjusted in 5.0.7 to only target iOS7 & < iOS 8.0.2.\n1184 will be closed as a result, as it is no longer relevant.\n. I take that back - this is fixed in Safari, but not Chrome.  Chrome seems to be unable to update videos regardless of the configuration at this point.  \nWith the multiple attribute present, they are uploaded 0-sized.  \nWith the multiple attribute absent, files can't be selected at all on iPads running iOS8 (an intentional \"fix\" by Google for #1283).  On other devices, the video upload stalls shortly after starting.  I'm moving this back to blocked until Chrome is fixed.\n. @mikewebaphorism This is a Chrome-specific issue, so everyone is likely seeing this. There is also a similar issue, #1401.\n. @mikewebaphorism \"2015-04-21\" isn't a version. Regardless, this is a Chrome issue. You can follow the status of this by looking at the chromium bug I filed, linked to a few messages back.\n. This may be tied to some changes planned in #1059.\n. This can probably be considered \"by design\" at this point.\n. This isn't going to happen in 4.3.  There are a number of bugs to fix before release and we already have two big features.\n. Building a response parser that works cross browser is more tricky than you\nmight think.  I'm guessing most, if not all users do not have any idea how\nto build one that will work properly in all browsers, so I will end up\ncreating an example response parser, and it will look pretty much like the\ninternal parser.  Refactoring will be required to allow a parser to be\ncontributed.  I guess the bottom line is that I don't see this as an\nimportant feature.  It's not that it will necessarily be difficult to\nimplement, but there will need to be good documentation to instruct\nintegrators how to properly create a cross browser response parser.  Or, we\ncould just continue to enforce the current convention in place and get some\nreal features completed instead.\nOn Tuesday, February 11, 2014, Bilge notifications@github.com wrote:\n\nThis isn't a big feature. The workload burden is placed on the third party\nto implement a parser. You merely need to provide an extension point.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/995#issuecomment-34747638\n.\n. Not going to be part of 3.9.  This would complicate the current convention for non-chunked signature requests.  We would need to move the policy document sent in the request body into a \"policy\" property, to allow for custom params to be specified alongside the policy document.\n. Since this is a breaking change, let's wait until we receive specific requests from customers.\n. The only way to accomplish this without a breaking change would be to allow headers to be specified explicitly for the signature request. \n. Any changes to the body of the request will be breaking changes, so that can't happen until the next major version release. Currently, the payload of the signature request for non-chunked uploads contains, in its entirety, the policy document. \n. Most likely, I will opt to add an API method to specify headers for the signature request, and then you can send the token in a header. I really don't want to commit any breaking changes that requires users to update their server code, ever.\n. Changes to Fine Uploader internal code yes, but I don't see these being breaking changes. A new API method would have to be added to allow users to specify headers for signature requests. That would be a non-breaking change.\n. I can see adding a setItemLimit method to accomplish this in a future version.  In the meantime, perhaps the following will be a sufficient workaround for you.\n\njavascript\n$(\"#uploader\").fineUploader()\n    .on(\"validate\", function() {\n        if (itemLimitOverride > 0) {\n            return itemLimitOverride > $(this).fineUploader(\"getNetUploads\");\n        }\n    });\nThe code above will simply reject any files submitted once your non-zero in-scope itemLimitOverride limit is reached.  The assumption here is that the override variable is set elsewhere in your app once the item limit must be changed.  You can, of course, throw up an alert message in your code as well, if you'd like.\n. Your code is invalid.  The parameters passed to \"validateBatch\" for the jQuery plug-in are \"event, fileOrBlobDataArray, buttonContainer\" in that order.  The first parameter is a jQuery normalized event, the second is an array of file metadata, the third is the container for the associated button element that was involved in the file selection.  \nI didn't test my suggestion using the validate handler, but it should work just fine with minimal adjustments.  I would suggest using/altering my example that utilizes the getNetUploads API method over one that counts DOM elements.  Your method does not account for file uploads that have failed, for example.\n. We aren't able to integrate every feature in a timely manner. \u00a0There are a lot of requests and a finite number of developers and hours. \u00a0Also, the library is becoming quite large and we are currently taking some time to weed out the bugs before we add any new features.\nOn Wed, Sep 10, 2014 at 2:47 AM, Bjorn Bos notifications@github.com\nwrote:\n\nThis issue has been open for about a year now. Any real plans on integrating this option? I have been waiting for it as well.\nWhat I actually would suggest is to be able to pass a function to the itemLimit on construction.\n    itemLimit: function(itemCount) {\n        if(itemCount > 10) alert('more than 10');\n        else if(itemCount > 5) alert('more than 5');\n}\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/999#issuecomment-55081756\n. Working on this as part of 5.1.0.\n. This has been implemented in 5.1.0-7 and will be part of 5.1.0.  I've added a setItemLimit API method that takes a new itemLimit integer as a param.\n. What would this look like?  This would indeed require reading the file client-side.\n. Don't think we will be able to fit this into the schedule, and this is a bit out of scope for this library.\n. Can you describe the use case for this a bit more?  If the document body is null, even with your adjustment, the upload will still be listed as \"failed\".\n. Keep in mind that this file should only be:\n1. Returned in a script tag as part of a response from your server when the request is the result of an upload via form submit targeting an iframe (IE9 or older)\n2. Used if you working in a cross-origin environment\n\nIf you are not working in a cross-origin environment, you shouldn't be using this script at all.  If you are, you should be returning it in a script tag in your response.  If you are doing that, and your document body is null, then your response is invalid as it must contain valid JSON following the conventions outlined in the Fine Uploader CORS documentation.  See the blog or the docs for more details.\n. Your handler is incorrect.  The first parameter passed to event handlers when using the jquery plugin is always \"event\".  Have a look at the jquery plugin section of the documentation.\n. Can you describe the specific motivation for this pull request?\n. Also, pull requests are not accepted against master, only develop.  I'm going to have to close this since it is against master, and master is the released/stable branch. You can either re-open against develop, or open up a request to add this to the existing code.  In either case, please describe why you require a non-200 response from your server for upload requests.\n. 204 is never an acceptable response to a Fine Uploader initiated upload request.  These responses must always contain content to be valid.  As far as 201 is concerned, that doesn't appear to make much sense in this case either.  Can you describe the image service you are referring to?  Do you not have control over this server?\n. Also, this pull request is still against master.  As I mentioned before, pull requests are only accepted against develop.\n. I'm afraid I'm not on board with this change.  The only status code that seems to make sense in the context of upload POST requests is 200, as far as success is concerned.  If you provide more information about the service that is returning a non-200, I will be happy to discuss and perhaps re-open. \n. Hello there, and thanks for catching this!  While we do not accept pull requests against the master branch, we will be sure to fix this issue in the develop branch and master branch at once.  Thanks again!\n. Thanks for the request.  This would be quite easy to add.  Perhaps we can fit it in to the 4.0 release.\n. Due to a couple requests, I plan to make this part of 4.0.\n. The objectProperties.key option allows you to supply a function that returns the key string.  You can insert whatever logic you please into this function.  It will be invoked before each upload, and Fine Uploader S3 will pass the file ID (integer) into your function.  See the documentation for more details.\n. You'll need to provide at least some basic information here, such as reproduction steps and your client-side code.\n. As with the other issue you opened, you will need to provide some basic information here, such as reproduction steps, and your client-side code.\n. A lot has changed since the project was called file-uploader.  The change to Fine Uploader occurred over a year ago.    Fine Uploader Basic is documented as \"core mode\", and is to be used only if you don't want to make use of any of the default UI that Fine Uploader UI provides.  There is comprehensive documentation on the docs site that covers all of this.  Have a look at the getting started section on http://docs.fineuploader.com.\n. Boris - Please use Stack Overflow for support questions such as this one.  This is covered on http://fineuploader.com/support, which I have referred you to in the past.  The issue tracker is for issues and feature requests.  Also, the UUID is not passed to your key function, the ID is passed as stated in one of my previous replies.  To get the name of a file, see the getName API method.\n. Support questions belong on Stack Overflow under the fine-uploader tag, as described on both http://fineuploader.com/support & the link at the top of the \"new issue\" form.\n. No useful responses from Amazon in the forums.  This is going to be postponed until a later release.\n. Amazon has confirmed that they have no plans to stop removing the Authorization header from requests.  This means that we will not be able to make use of the multipart upload API via a CloudFront distribution.\n. The only possible way to upload files that target a CloudFront distribution is to send the entire file in one multipart encoded POST request.  This means that chunking, resume, and pause features are not possible.  If a file fails mid-upload, each retry attempt will need to start over from the first byte.  In fact, no credentialed REST calls are possible at all, since AWS rips off the Authorization header.  \nIf you do not enable the chunking/resume features in Fine Uploader S3, theoretically, uploads to a CF distribution should work, but there is another problem: Fine Uploader S3 expects to be able to determine the bucket name from your endpoint.  If you are uploading to a CF distribution, this assumption is no longer valid.  We would have to allow a bucket name to be specified via an option and API method for CF distro endpoints.\n. @jasonshah  What sort of limits does your customer's proxy enforce?\n. @jasonshah If uploading to CF fixes the issue, I can see why that might be appealing.  The reason I haven't pursued support for CF in Fine Uploader S3 is due to a few reasons:\n- I see chunking, resume, and efficient retries as very important features.  These would have to be turned off if uploading to CF.\n- Since a bucket name would have to be explicitly  specified alongside a CF endpoint URL, this adds more complexity and confusion to the API/options.\n- There are other outstanding issues with CF that make uploads potentially difficult, such as this one: https://forums.aws.amazon.com/thread.jspa?threadID=137627&tstart=0.\n- AWS doesn't seem interested in supporting the upload-to-CF workflow.  There's no telling what other issues may appear over time if we explicitly support this.\n. I'm afraid I'm not familiar with this CDN.  Is the customer cutting AWS out of the picture entirely?\n. Excellent.  Thanks for the update.  That should make it possible for us to modify Fine Uploader S3 to allow uploads through a CF distribution, theoretically.\n. Probably 5.1.  5.0 is currently in development.\nOn Sunday, March 23, 2014, Pulkit Jalan notifications@github.com wrote:\n\nAt the moment its quite hacky to get this working, almost all security\nchecks have to be disabled.\nIs this feature going to be implemented into fineuploader and if so, which\nversion it is planned?\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1016#issuecomment-38382491\n.\n. Thanks for the kind words @cybertrand.  Fine Uploader wouldn't be where it is today without my employer, Widen, and the development help of @feltnerm along with the input of @uriahcarpenter as well.\n\nYou are correct that this feature is scheduled for 5.1, along with several others.  I don't think this will be terribly difficult, assuming there aren't any further hidden obstacles (such as the issue where CF stripped Authorization headers a while back, making this impossible - since fixed).    \nWe are currently working on a hotfix and some administrative (non-feature) tasks at the moment.  Once those are complete, #1198 is first in line, followed by uploads to CF.  \nI suspect that the code changes to Fine Uploader S3 will be minimal to support uploads to CF.  One thing that will need to change is the code that uses the AWS endpoint to determine the bucket name.  You see, we must embed the bucket name in the request, and, with uploads directly to S3, we can programmatically determine the bucket name simply by looking at the S3 endpoint URL.  With uploads to a CF distro, that will no longer be a safe assumption, so we will need to solicit the actual bucket name from integrators via an additional option (and provide an API method for dynamic adjustment).\n. Have you read about the concurrent chunking feature we released in 5.0?\n That allows multiple chunks for a single large file to be uploaded in\nparallel to any endpoint.  That feature is aimed at single-file large\nuploads, since multiple chunks have always been uploaded in parallel (one\nper file) if multiple files are selected.\nhttp://docs.fineuploader.com/branch/master/features/concurrent-chunking.html\nOn Wed, Jun 25, 2014 at 3:22 PM, cybertrand notifications@github.com\nwrote:\n\nThank you very much for the additional information @rnicholus\nhttps://github.com/rnicholus; makes sense about the S3 bucket name.\nIt's great to hear that this should be straightforward to implement and\nthat it should happen soon. On that last note, are you able to share any\nrough timeframes: are we talking about 1, 3, 6 months? I'm asking so that\nwe can make the best decision on waiting vs. implementing now.\nI was also wondering: will the implementation of this feature include the\nability to upload multiple chunks/parts of the same file in parallel? (to\nS3 via CloudFront). That's what we're after in order to accelerate file\nuploads and this would provide a really nice commodity solution, instead of\nhaving to buy and implement a UDP based transfer acceleration solution.\nNote: it would be really useful to have a similar solution for accelerated\ndownloads, whereby your JS client would perform multiple HTTP Range\nrequests to CloudFront/S3 in parallel do download a single large file (I\nbelieve both S3 and CloudFront support this).\nThanks again!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1016#issuecomment-47153458\n.\n. The concurrent chunking feature was implemented as a core feature in Fine Uploader 5.0.  This means that it is supported for all endpoint types: Azure, S3, custom/traditional.  I see no reason why a CF distro would be a special case.\n\nI don't yet have a time estimate for 5.1.  Stay tuned, and I'll try to post it when I know more.\n. Starting work on this now as part of 5.1.0.\n. @jasonshah @pulkitjalan @cybertrand I expect to be done with this in the very near future.  Are any of you interested in testing out the pre-release version to ensure it works with your setup?\n. @jasonshah Thanks for the update.  Please watch this issue for progress.  I'll comment here when I'm done, and will include the pre-release version number.\n. Still working on this.  It turns out that CloudFront is really very poorly designed and documented.  Anything other than a trivial default behavior associated with a GET requests requires fair amount of googling and trial & error to perfect.  Configuring your behaviors, origins, and associated permissions is maddening.  Once I figure out myself how CloudFront works in the context of POST and PUT uploads given a variety of behaviors, I'll begin updating the code.  \nAt the moment, it looks like anything other than an extremely trivial use case (default behavior, one bucket) will require a good understanding of CloudFront by the integrator as Fine Uploader will need to be updated with the proper bucket on-demand, depending on the CloudFront path.  I'll probably add an objectProperties.bucket option that take either a string or a function, similar to the key property.\n. After being contacted by some users today via email, it seems as if the progress on this issue is not entirely clear, probably due to the out-of-date limitations in the initial description of this feature case.\nLet me be clear:\n- Chunking, concurrent chunking, resume, and all other features when uploading to a CloudFront distribution should be possible, and I don't see anything preventing that at this point.\n- I currently have uploads to a CF distro for a default behavior () functioning properly on my development environment for chunked and non-chunked uploads.\n- I currently have uploads to a CF distro for a non-default behavior (i.e. path /uploads/) functioning properly for chunked uploads.  The non-chunked (POST) approach is resulting in a 405 from CloudFront.  It's not entirely clear why this is happening.\nOnce I solve the problem described in my last point above, I'll begin committing changes to the code to support uploads to CF.  There will be some documentation as well, but mostly in the context of typical, simple Fine Uploader workflows.\n. I have the following post in the CloudFront forum, waiting for a response from the CF team.  https://forums.aws.amazon.com/thread.jspa?messageID=588697\n. No problemo @andrew-kzoo.  Thanks for the recognition!  \nI just posted a first commit for this feature in a feature branch.  The goal is to not only support uploads to S3 via CF, but via any CDN that supports POST/PUT/CORS (and doesn't rip off or add headers).  \nSee the commit message for details.\n. Unfortunately I have run into yet another issue with CloudFront's support for uploads to S3.  CF doesn't allow any headers, other than CORS headers, to be forwarded to an S3 origin via a CF distro.  This means that we can't specify an ACL, encryption params, reduced redundancy, custom metadata, or anything else sent along as a header for a chunked file (via the S3 REST API).  This also means that, in its current state, uploads to S3 via CF can't be done \"serverless\" via an identity provider since we must send a session token in an x-header.  \nI've opened a case here: https://forums.aws.amazon.com/thread.jspa?threadID=167234.\n. Just noticed that I already posted something in the CF forums detailing an issue I was having with POSTs to non-default behavior endpoints back in 2013.  No response from AWS.  https://forums.aws.amazon.com/message.jspa?messageID=496076.  It's unlikely that AWS will respond to any of these issues, since their participation in the forums is inconsistent at best.  Most likely, if the CF uploads feature goes out with Fine Uploader 5.1, there will be a lot of warnings in the docs detailing all of the items that are not properly supported by the upload CF workflow due to the shortcomings of this AWS service in this context.\n. Since CloudFront presents very specific challenges to the upload workflow, I've created a new case to address uploads to S3 via a generic CDN that forwards all headers.  CloudFront is still not quite ready to handle uploads to S3 it seems, so this may be delayed until AWS gets its act together.  Other CDNs like fastly handle uploads to S3 without issue.\n. I expect to have support for CDNs ready to beta-test by Monday, maybe earlier.  Anyone who still wants to try this out early, let me know.  I am unable to work around the various issues I'm seeing with uploads to CloudFront, so, at this point, I don't expect to declare that uploads to CF are supported.  However, the changes I made here should work with uploads to CF, provided AWS behaves more like a transparent proxy.  \nI would encourage users to try out the pre-release of 5.1.0 with CDN support against CloudFront and report their results.  If something can be figured out soon to deal with the CF issues I'm seeing, I can report that 5.1.0 supports uploads to CF.  Otherwise, uploads via any CDN that forwards headers will work just fine with the changes I made, provided the bucket is specified, and the CF-specific case will be put back into limbo.\n. If anyone is interested in testing CDN support before 5.1.0 is released.  Please let me know.  The code is part of the develop branch now, and the in-progress section of the docs on docs.fineuploader.com has been updated as well.  I encourage you to try against CloudFront as well, in hopes that you will have more luck than me.\n. Uploads to CloudFront should work, but there appear to be some issues with CF ripping some headers off the REST requests that prevented me from certifying support for CF.  Amazon never acknowledged the issue though, even though I am able to upload files to S3 via a 3rd-party CDN without issue.\n. They told me the same thing a little while back. It isn't true, as far as I can tell. I opened up a support request in December, detailing the issue. The sum it up, sending upload requests to S3 using the multipart upload API via CloudFront still results in removed headers. For example, x-amz-acl and all x-amz-meta headers are removed. Sending the exact same request directly to S3, or via a different CDN (such as fastly) did not result in any problems. The issue was specifically with CloudFront.\n. Yes, uploads to S3 using Fine Uploader S3 should work via any CDN, provided the CDN does not remove any headers.\n. @rbliss Reproducing the issue simply involves setting up Fine Uploader S3 as per usual, specifying a bucket via the new objectProperties.bucket option, and setting the endpoint to your CF distro. You'll see that any custom metadata (sent as x-amz-meta headers) are sent by Fine Uploader, but never actually attached to the object in S3. Since the x-amz-acl header is stripped as well, any specified ACL value via Fine Uploader is ignored and is not attached to the object in S3.\nI haven't tested again since December. Perhaps AWS has finally fixed this?\n. @rbliss I remember an issue with all x-amz headers, not just the x-amz-acl. To your knowledge, the issue is on Amazon's side, is that correct? Do they have any idea when this will be fixed?\n. My understanding was that an OAI is required when making signed requests, otherwise the additional headers attached to the request by CF will be rejected by S3 as they are not accounted for in the signature.\nIn the case of \"bucket-owner-full-control\", I'm guessing the \"owner\" is CF when using an OAI. Is this your understanding? If this is true, then based on the Canned ACL descriptions, public-read will result in the same problem for the bucket owner it seems.\n. The former. This is how Fine Uploader signs all upload requests.\nOn Mon, May 18, 2015 at 4:05 PM, Richard Bliss notifications@github.com\nwrote:\n\nJust a point of clarification: by signed requests, are you referring to\nthe signed Authorization header required to authenticate a request in the\nS3 REST API, or signed urls used to restrict access to objects in S3?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1016#issuecomment-103210881\n.\n. That wasn't my experience before. In fact, the use of OAIs in this context\nwas discussed on the AWS forums.  One example can be found at\nhttps://forums.aws.amazon.com/thread.jspa?messageID=345913&#345913. I'll\nhave to try again without an OAI at some point.\n\nOn Mon, May 18, 2015 at 4:24 PM, Richard Bliss notifications@github.com\nwrote:\n\nJust wanted to double check. You do not need an OAI to send signed\nrequests. In fact, if you turn off the OAI (or never set one up) on your\nCloudfront distro, everything should just work like you were\ninteracting with S3 directly.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1016#issuecomment-103216473\n.\n. Once this is tested and verified on our end, we'll update the S3 Uploads feature page with CF-specific details.\n. Sounds like this is finally working with Fine Uploader S3. I'm continually\nbusy with support and licensing requests, as well as the S3 V4 support\nfeature, but it is still on my radar to verify and update the docs.\n\nOn Mon, Oct 5, 2015 at 9:36 AM Ludovic Fleury notifications@github.com\nwrote:\n\nMy bad, typo. @rbliss https://github.com/rbliss I confirm that with\nyour information, the upload is going smoothly through Cloudfront to S3.\nThank you very much.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1016#issuecomment-145548484\n.\n. Youlll need to fix your comment above. Take another look.\n. Either way, this is a question for the AWS forums, as it appears to be some type of configuration issue on your end.\n. What version of iOS?  Also, do you see the same behavior if you attempt to upload this file on one of the live demos on fineuploader.com?\n. If you are using iOS 7, there is a known issue with the reporting of video file sizes.  This is an iOS issue that I have filed with Apple.  They have yet to respond.  Please see #990 for more details.\n. Code for this example is being staged at Code for this blog post is being staged at https://github.com/Widen/fine-uploader-examples/tree/master/src/angularjs-nodejs.\n. Updated the traditional node.js example in the server repo.\n. Turns out this is a UI-only issue, caused by a bug in the internal templating module's getFileId method.  This method returns a string.  When handling a cancel button click in UI mode, the templating module is used to determine the file ID, based on the target of the click event.  Again, the templating module returns a string as the file ID, say, \"1\".  Then, an internal array of in-progress file IDs is searched.  The values of this array are numbers, so searching for a string never returns the index of the expected array item.  Therefore, the _filesInProgress array is never modified when the cancel button is clicked, and the  beforeUnload handler thinks a file is still in progress when a user attempts to reload or navigate away from the page (since it uses the length of _filesInProgress to determine if files are still uploading.  \n\nThere are a couple ways to fix this, but I may simply eliminate the _filesInProgress array and delegate to the UploadData module instead.\n. Thanks @pwflanagan.  This will be scheduled for a release in the near future.  Possibly 4.3.\n. MPE = Multipart encoded requests.  By default, Fine Uploader sends upload requests multipart encoded.  I would expect Azure to support this type of POST request when uploading an entire file in one request, and then expect a PUT request with the payload consisting only of file bytes when we are uploading a file in chunks.  At least, this is how uploads to S3 work.  Support for MPE requests is vital to allowing uploads from IE9 and older.\n. Note that it might not be possible to support this in IE9 and older due to apparent lack of support for multipart encoded POST upload requests (and the lack of a method to ask the Blob Storage service to respond with a redirect).  See #1096 for details.\n. Relevant REST calls:\n- Put Blob\n- Put Block\n- Put Block List\n- Delete Blob.  We might support this directly from the browser.  We don't support this in Fine Uploader S3 since it would not be possible in IE9 and older (though we may add support for this later in #1099).  Since communication w/ Blob Storage doesn't appear to be possible at all in IE9 and older, it is probably acceptable to add support for this.\n. This feature is currently scheduled for the 4.3 release cycle, which will likely begin tomorrow.\n. @angelsix What does your technology stack look like?\n. Ok.  My plan at this time is to make a request back to the server for each block/API request sent to Azure.  The server will need to supply a signature for the request using a short-lived shared access key (SAS) for the associated operation.  Fine Uploader Azure will then use this signature to construct a SAS URI to perform the REST call on the Blob Storage service.  \nThoughts?\n. The model for Fine Uploader S3 is:\n1. Ask server to sign request\n2. Send request\n3. Optionally contact server after each complete file upload has succeeded.  \nAny other calls to the server are possible (inside of Fine uploader callbacks), but are not built in.  I plan on providing the same functionality for Fine Uploader Azure.\nNote that any parameters specified via the params option or the setParams API method would be associated with the blob automatically by Fine Uploader via x-ms-meta headers on the PutBlob REST call.  Note sure if there is a better or another way to associate metadata with a blob. \n. We will probably only include a .NET server-side example for Azure support.  Unless you are locked into a Microsoft environment, I can't imagine choosing Azure over AWS or Rackspace.\n. Agreed on the support.  I've found forum support for AWS to be less than ideal, to say the least.  I'm quite fond of the AWS API though, and found it and the documentation complete and intuitive when developing Fine Uploader S3.  \nI don't have any experience with Azure before today, and the last time I wrote any .NET code or worked in any sort of Microsoft environment was over 5 years ago.  So, my impressions of Azure are only based on my very initial experiences. \nMy first step into this service was exploration of their CORS support.  I expected this to be lacking, as Microsoft has historically made bad decisions in this area.  Have a look at the XDomainRequest transport in IE8 and IE9 for a prime example of this.  In addition to the apparent lack of API support for browser-based uploads in IE9 and older, I am troubled by the measures required to simply manage CORS rules.  For example, you can easily manage CORS rules via the console UI in AWS.  With Azure, you have to make use of their REST API.  It's odd that they would make you do this, as it seems a bit unnatural to configure CORS for a container programmatically.  In most cases, you would set the rules and never touch them again, or perhaps add an origin at some point in the future.  I don't see a problem with allowing CORS configuration via the API, I just don't see why they would not make this configurable via the admin console. \nIn fact, the Azure admin console looks fairly immature compared to AWS.  Only very basic operations are possible via the admin console.  Unless I'm missing something, it looks like you have no way to manage or even address individual blobs via the Azure admin UI.  Of course this is possible via the API, but it's nice to not have utilize an SDK or an installed application to, for example, take a peek at the objects in a container.\n...just my very initial impressions.  It's likely that I've just overlooking something and some of the shortcomings I've mentioned are invalid.  This will very much be a learning experience for me.\n. Ah, I see.  Thanks for the info!  \nIf you are interested in testing out Fine Uploader Azure in your app once it is functional but before we release, let me know.\n. Please send an email to the licensing address and we'll coordinate from there.\n. I've begun work on the JavaScript to allow client-side uploads to Azure.  I am currently able to upload files using the Put Blob call.  I setup my VSE 2012 environment in a Windows 7 VM and configured an Azure Blob Storage container for my dev work with wildcard CORS rules.  I also have C# code that generates a SAS based on the URI of the blob.  I'm currently generating a fairly-long-lived SAS manually and pasting it into the Fine Uploader Azure JavaScript module.  Obviously, this will be adjusted and we will eventually be sending a GET to the server before each REST call, expecting a short-lived SAS URI in the response.\n. @angelsix When using Fine Uploader S3, if you want to provide users with a link to a private object, you would do the following:\n1. Ask Fine Uploader S3 to send you a POST request when the file is successfully in S3.\n2. In your POST request handler on your server, use the AWS SDK to generate a signed, short-lived URL for the object, and return it in your response.\n3. The URL along with any other information returned in your server's response to the upload success POST will be passed along to your client-side onComplete event handler.\n4. Update the DOM with the link to the object. \nThe process should be largely the same with Fine Uploader Azure, as far as I can tell.  Server-side, you'd generate a SAS URI for that specific blob with READ permission, and set the expiration date to an appropriate time in the future. \n. @joshdvx Thanks Josh.  I responded to your email.  Please give us your feedback on the design choices we are making as this feature progresses, and don't hesitate to ask questions.\n. How would you prefer this link be generated?\n. The MAC address is not something that can be determined in the context of a browser using JavaScript anyway.  I suppose this would be nice as it would allow better client-side UUID generation (instead of version-4 UUIDs which are essentially random numbers).  \nThe link can and should be time-bombed.  You can even set the expiration date to a very small future time, say, a few seconds from now.  This is possible if you are programmatically following the link in your client-side code.  After the link has expired, the resource is no longer accessible through that URL.\n. No, that's not true.  The expiration date is checked when the request is received by the server/Azure.  It makes no difference how long the request is open.\nAs far as I can tell, we will only need a SAS for the blob that we will create after combining the blocks.  I haven't played around with the block-level REST calls yet though.\n. Accidentally left off a reference to this issue off of commit 0ad14f248ff964c59d5d397fd4c2a08c2c9a92ae.\n. Chunking will definitely be supported via the Put Block REST method.\n. My last commit gets me closer to finalizing support for non-chunked upload to an Azure storage container.\n- Blob names can be determined automatically by Fine Uploader Azure using a client-side generated UUID with the file extension appended.  You can also elect to have Fine Uploader use the actual file name as the blob name (generally not recommended).  Finally, you can designate a function that FU will call when it needs to determine the blob name (just before its first upload attempt).  This function must be promissory and can be used to generate a custom dynamic blob name via some client side logic, or by delegating to a remote resource via ajax.\n- Any parameters passed to the uploader via the params option or the setParams method will be attached to the blob via \"x-ms-meta-\" headers.  Even functions are valid parameter types.  Note that support for function parameters is missing in the S3 module (#1105).\n- Auto & manual retries as well as failure detection should be functioning.\nTODO yet for non-chunked uploads:\n- [x] Parse XML error messages from Azure for failed requests and log/report the details.\n- [x] More non-chunked unit tests\n- [x] Optionally send POST request to server when upload has completed.  This will be similar to FU S3's uploadSuccess option.\n- [x] Add a cache-busting timestamp param to the GET SAS request.\n. Are you using \"filename\" and \"blob name\" interchangeably?  What is a \"virtual save path\"?  Also, which specific \"FU request\" are you referring to?\n. There will be a blobProperties.name option which will allow a String/Number or a promissory function value.  If you want to delegate to your server for blob name determination, you will want to contribute a promissory function that makes an ajax call to your server.  When the response from your server is received, you will fulfill the promise, passing in the blob name. \nThe container name per say is not something you would specify.  Instead, you will specify a URL to your blob container via the request.endpoint option.  This can be modified on a per-file basis, if you choose, via the setEndpoint method.  In the context of FU Azure, the endpoint means: Blob container URL.  FU Azure will append the blob name to this URL when it sends a request to Azure.\nAs far as parameters go, you can specify any parameters you like at any time via the setParams method.  If you want to determine parameters after a user drops or selects a file, you can contribute an onSubmit or onSubmitted event handler, determine the virtual path, and pass it off to Fine Uploader via setParams.\n. All items in my message above are complete in this feature branch (feature/azure).\nFinal high-level TODOs: \n- [x] Support delete blob requests directly from the browser (optional feature).\n- [x] Chunked upload support\n- [x] Auto-resume support\n- [x] Prevent retry of signature request if server responds with 403.\n- [x] Ability to decide between chunked & non-chunked upload based on provided options & file size\n- [x] Message if Azure module is used in a non-supported browser (IE9 or older)\n- [x] Original filename parameter metadata to send along with each file\n- [ ] Documentation\n- [ ] C# server-side example code\n. Chunked upload support will begin shortly after I finish delete blob support, which I am working on now.  Chunking will allow us to upload files larger than 64 MB.  With Put Blob, you can upload a file as large as 64 MB in one request.  Any larger, and you must upload in blocks.  There are other benefits to chunking though, such as auto-resume, the ability to pause uploads, and more efficient retries of failed uploads.\n. If you are referring to FileReader, then that is not a factor.  Fine Uploader doesn't need or use FileReader to upload files.\nThere is already an outstanding feature request to allow Fine Uploader to send multiple chunks for the same file at the same time - #937.  That is out of scope for this particular feature.  I haven't considered #937 a priority as I see the benefits of this to be very small in most cases.  The user's upstream bandwidth is generally the bottleneck when uploading to a service like S3 or Azure.  Fine Uploader already will upload multiple files at the same time (3 at once by default).  Uploading multiple chunks for the same file simultaneously is probably not likely to result in any additional noticeable gains in most cases.  Furthermore, browsers have limits as to the total number of open connections at once time.  These limits are relatively low (anywhere from 3 - 8 connections per host).  This is why Fine Uploader only sends 3 files at a time by default (and it is not recommended to change this).\n. I just completed chunking support for Fine Uploader Azure.  There is a bit more to do though.\n. Auto-resume support is covered in the commit above.  Some refactoring is in order after noticing some code duplication between the S3 and Azure endpoint handlers.  I'll probably also revisit a few internal code design decisions.\n. Fine Uploader Azure is now feature complete, as far as I can tell.  I'll begin documentation shortly.  Once there is at least a passable amount of documentation, I'll send out pre-release builds and a link to the docs.\n. Documentation is in place at http://docs.fineuploader.com/branch/feature_azure/.  Last step is to include a C# example in the fine-uploader-server repo and make some adjustments to the build script.\n. Server-side example is complete and currently being staged at https://github.com/Widen/fine-uploader-server/blob/4.3/C%23/azure/FineUploaderAzureServer.cs.\n. I decided to merge this into the develop branch, so you can view the documentation at http://docs.fineuploader.com/branch/develop instead.\n. Are you sure you have the AzureStorage reference loaded in your project?  CorsHttpMethods is in Microsoft.WindowsAzure.Storage.Shared.Protocol.\n. Note that I suspect you must have the 3.2.0 version or greater of the SDK.  I believe MS added CORS-related stuff only recently.\n. Just deleted my last comment.  I was looking at this uploadSuccess: \njavascript\nif (qq.supportedFeatures.ajaxUploading) {\n    $(\"#fine-uploader\").fineUploaderAzure({\n        request: {\n            endpoint: 'https://{ YOUR_STORAGE_ACCOUNT_NAME }.blob.core.windows.net/{ YOUR_CONTAINER_NAME }'\n        },\n        signature: {\n            endpoint: '/signature'\n        },\n        uploadSuccess: {\n            endpoint: '/success'\n        }\n    });\n}\n...which is the first one in the documentation, instead of this one, which you were probably referring to.  It occurs a bit later in page:\njavascript\n$(document).ready(function () {\n        $(\"#fine-uploader\").fineUploaderAzure({\n            request: {\n                endpoint: 'https://{ YOUR_STORAGE_ACCOUNT_NAME }.blob.core.windows.net/{ YOUR_CONTAINER_NAME }'\n            },\n            signature: {\n                endpoint: '/signature'\n            },\n            uploadSuccess: {\n                endpoint: '/success'\n            }\n            retry: {\n               enableAuto: true\n            },\n            deleteFile: {\n                enabled: true\n            }\n        });\nThanks for pointing this out.  The lack of context tripped me up.\n. @joshdvx The expectation is that you build this into your existing web application, which, presumably, already has the ability to host static resources (such as the HTML/js required to display and configure Fine Uploader Azure client-side) and handle client requests (such as the GET and option POST requests sent by Fine Uploader Azure).  \nThe C# example code I provided was not intended to be a fully functional web app, just to provide you with an idea of what is required to handle the requests sent by the Fine Uploader Azure client.  I simply created a C# project in VS, included the appropriate references/dependencies, and started it up.  The HTML/js/page itself was hosted on another server.  You'll need to take the example code I provided, modify it to suit your web application, and integrate it appropriately into your existing or in-progress web application.  \nAt a high-level, with the most basic setup you simply need to ensure you have a server that will respond to the GET requests that Fine Uploader Azure sends before it sends a request to Azure.  The signature.endpoint option should be a path to that server.  How that server is designed is not important to Fine Uploader Azure, as long as it handles the GET requests, and responds appropriately.\n. I'm afraid I won't be able to provide any assistance with ColdFusion. I would expect that most users of Azure are working with a Microsoft stack, which is why I provided a C# example.  You are likely going to need to use an Azure SDK to generate your SAS URI.  I personally was unable to track down the exact algorithm required to generate a SAS.\n. Our goal is to release on Monday, so please let me know in the next 48 hours if there is a critical feature missing or some bug I missed.  Once we are in the process of releasing, new features will have to wait until the next release cycle.\nNote that I think I still have to add some better logging to the Azure module.\n. Excellent.  Thanks for the update @joshdvx.\n. That is a line out of the new internal templating module that I wrote.  Thanks for posting this Craig.  We'll look into it first thing tomorrow.  If it is reproducible, it will likely be fixed as part of a 4.0.1 hotfix release, along with issue #1021.\n. After glancing at the code, this does look like an issue that will only manifest itself when the items in the file portion of the template (such as the buttons) are two or more levels below the .qq-file-list-selector element.  By default, these items are only only level below this container, but in the modified template you posted in your associated Stack Overflow question, they are 2 levels deep.  \nThe fix seems simple, in the section I linked to in my last comment, change:\njavascript\nwhile (currentNode.getAttribute(FILE_ID_ATTR) == null) {\n    currentNode = el.parentNode;\n}\nto:\njavascript\nwhile (currentNode.getAttribute(FILE_ID_ATTR) == null) {\n    currentNode = currentNode.parentNode;\n}\nThe initial code will certainly result in an infinite loop in any browser, provided the buttons are 2 or more levels below the .qq-file-list-selector container.\nAll of this sounds correct, but it's late.  So, I'll investigate more tomorrow.  If you need an immediate workaround (like, tonight) then you should temporarily ensure the buttons are only one level below the .qq.file-list-selector container until this is fixed and a hotfix release is pushed out.\n. Reproduced locally (4.0.0) using the following slightly modified default template:\nhtml\n<script type=\"text/template\" id=\"qq-template\">\n    <div class=\"qq-uploader-selector qq-uploader\">\n        <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n            <span>Drop files here to upload</span>\n        </div>\n        <div class=\"qq-upload-button-selector qq-upload-button\">\n            <div>Upload a file</div>\n        </div>\n        <span class=\"qq-drop-processing-selector qq-drop-processing\">\n            <span>Processing dropped files...</span>\n            <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n        </span>\n        <ul class=\"qq-upload-list-selector qq-upload-list\">\n            <li>\n                <div>\n                    <div class=\"qq-progress-bar-container-selector\">\n                        <div class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n                    </div>\n                    <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n                    <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\"></span>\n                    <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n                    <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n                    <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n                    <a class=\"qq-upload-cancel-selector qq-upload-cancel\" href=\"#\">Cancel</a>\n                    <a class=\"qq-upload-retry-selector qq-upload-retry\" href=\"#\">Retry</a>\n                    <a class=\"qq-upload-delete-selector qq-upload-delete\" href=\"#\">Delete</a>\n                    <span class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n                </div>\n            </li>\n        </ul>\n    </div>\n</script>\nThe easiest way to reproduce is to set autoUpload to false, submit a file, and then attempt to cancel (remove) it.\n. Consider providing backwards compatibility if possible to avoid a breaking change.\n. TODO: Update docs\n. I suspect that cloud-based platforms, which are currently offered by a number of different providers, will eventually be commoditized, and it will be simple to move your infrastructure from one provider to the next.  With this in mind, it's not completely clear that it makes sense to spend a lot of effort integrating with any one provider.  OpenStack is something to watch closely.  As you may know, Rackspace makes use of this standard.\n. @KieranP That's an interesting bit of information.  Do you have a source, such as a bug report you can point me at that describes this a bit more.\n. I wonder if this is also an issue with PUT requests.\n. I'm marking this as blocked until rackspace figures out how to implement CORS.\n. @rodneytamblyn Can you provide a link?\n. Seems like RS may have overhauled their cloud infrastructure recently.  Perhaps this was fixed as a result?  I'll be sure to update this thread next time I get a chance to take a closer look at their API.\n. @KieranP that sounds like the correct way to send files, not a workaround.  In fact, that is exactly how you would upload files to S3 via their API.  I guess I just assumed you were not attempting to upload files via a multipart encoded request originally.  That was likely the problem all along, and not an issue with rackspace.\n. I suspect there is some way to upload via a MPE request as well though.  Otherwise uploads wouldn't be possible in IE9 and older.\n. Work on this never started. There are a number of other features ahead of it at this time, so I don't have a date for you.\n. @zmilan By default, Fine Uploader will send all upload request multipart encoded. This is a default settings as traditional <form> submits are also multipart encoded, so it is quite easy to parse these types of requests since this has been the only way to upload files for a very long time, before the File API was standardized and implemented in most browsers. In fact, this is still the only way to upload files in IE9 and older.\nYou can have Fine Uploader send only the file bytes in the request payload by setting the request.forceMultipart option to false. Any parameters will be included in the URI query string in that case. \nWhen using the traditional uploader, Fine Uploader requires that the endpoint responds with valid JSON, and the response must include a success property with a value of true. If the upload endpoint does not send this in the response, the upload is considered a failure. \n. @zmilan There are no concrete near-future plans to support uploads to Rackspace due to the relatively small amount of customers that use this cloud storage option (compared to Azure and S3). If there is something we can do to make it easier for individual users to upload directly to RS using the traditional Fine Uploader module, we can take that into consideration. \nI can see allowing the expected response to be customized via options. This will probably make uploads to RS in most browsers easier, but there may be other challenges related to EI9 and older. For example, the request will have to be multipart encoded.\n. @zmilan We currently accept 200-204 (#1314), but for traditional endpoints, we still expect a JSON response of {\"success\": true}. Removing this requirement will be a breaking change (and a major one at that). This will have to wait until at least 6.0. Please create a feature request and I'll keep it in mind for the next major version update.\n. I see Rackspace CloudFiles is as being a very small piece of the commoditized cloud file storage service provider. Even Azure is a much bigger player, AFAICT. I'm closing this as I don't see this happening anytime in the near future. Priorities, priorities.\n. Can you please provide a link to a live example where this is reproducible?  This is a very strange and unexpected error indeed.\n. @marbemac This appears to be an issue specifically with builds generated by the build tool on fineuploader.com.  I'm really sorry about this.  This is an unacceptable error, and we will fix this as soon as possible.  I'm not sure how we missed it.\nThe issue is caused by the order in which the custom builder combines the appropriate javascript files.  It looks like the build generator needs a lot more testing as I'm seeing a number of other issues with custom generated builds.  \nI'm going to take the custom build generator down until tomorrow when we will have a chance to fix it.  In the meantime, please send an email to the licensing address and I will send you a non-custom build that will work properly in your app.\n. The build generator has been temporarily blocked off, and I just sent a reply to your email.  Please follow this case for updates on the build generator fix.\n. Here's the plan for tomorrow:\n1. Identify which custom builds are running into this issue\n2. Fix the issue, along with the lack of banner at the top of the combined js file & possibly an incorrect expiration date on the emailed link.\n3. Ensure no other issues exist\n4. Email everyone who has downloaded an affected build after the build generator has been fixed.\n. We found a few additional issues with the custom build generator while fixing the ones discussed here.  To allow for more testing the fix has been pushed to Monday.  This is still top priority, we just want to be sure all bugs have been worked out before the custom builder is re-enabled.\n. Fixed in 4.0.2.  The site has been updated as well.\n. Thank you for this PR.  I can see how it might be useful to receive a callback when each chunk has been uploaded, but I think this new callback should more closely model the existing onComplete callback.\nBefore this can be merged, I plan on making the following changes:\n- Rename the new callback onChunkComplete.\n- Invoke the callback when a chunk has been successfully uploaded, or when it has failed after all auto-retries have been exhausted.\n- Ensure the callback is also invoked from the S3 uploader's XHR handler module.\n- Add the existence of this new callback to the documentation.\nNote that I'm not sure why the Travis build is failing.  It seems like it is unable to connect to Sauce Labs, and I'm looking into that now.\n. @nightwolfzor It probably won't be very difficult.  I can't promise it will be part of 4.1, but we can at least discuss internally about putting it into 4.2.  4.1 is full already as far as planned tasks are concerned.  This could easily be bumped up and make it into 4.1 if I hear from enough users that also want this added.\n. This feature will be part of 4.1.  I'll start work on this at some point in the near future.\n. My completed work on this enhancement can be seen in the commit above.  Here is the implementation I settled on:\n- New callback named onUploadChunkSuccess\n- Invoked by S3 or traditional XHR uploader after each chunk has been successfully sent\n- Passed to the callback: file ID, ChunkData object, JSON response from the server (or just {success: true} if the endpoint is S3), and the associated XMLHttpRequest instance.\nThis is currently in the develop branch, but will be released with 4.1.  Please let me know if anything is missing, preferably soon.\n. The second issue you are seeing is your error, but the first is ours.\nRegarding the second issue, you need to include an uploaderType option with a value of \"basic\" if you are using the jQuery plug-in and are using Fine Uploader Core only.  This is documented in a few places, particularly the jQuery section of the documentation.\nRegarding the first issue: that is a bug and we will fix it in hotfix release as soon as possible.\n. @qobide This fix is part of the 4.0.3 hotfix, just released.\n. Reproduced in the develop branch during 4.1.0 development.\n. Use the reset method.  For future support requests, see http://fineuploader.com/support\n. Also note that the documentation itself will answer most questions, such as this one.  Have at look at http://docs.fineuploader.com\n. The jquery remove method doesn't really do anything other than remove the element from the dom.  If you want the same effect, just remove the element associated with the Uploader instance from the dom.\n. @floatrx \n\nstill important! how to remove instance and unbind all event from js... \n\nJust remove the element.\n\ncan't submit form without files... it's sucks!\n\nNo idea what you are talking about. Details?\n. Fine Uploader's primary goal is to upload files. Sending form data is secondary. Any request sent by Fine Uploader must contain file data. If you'd like to send a form without a file, there are many ways to do that, both using an \"AJAX\" approach and via a traditional form submit, but Fine Uploader will not help you there.\n. Looks like you posted a similar issue on stackoverflow.  What build of iOS8?\n. I didn't see this issue in beta 5.  Looking at the GM now.\nWhat device?\n. Not able to reproduce on the iOS8 GM simulator.  In fact, looks like apple may have fixed #1269.  I'm going to try GM on an iPad shortly.\n. ...what version of Fine Uploader are you running?\n. Just tested the iOS8 GM simulator against 5.0.5 and fineuploader.com/demos (which is running 5.0.2) - not seeing any issues in Safari.  I'll let you know when I verify on an actual device.\n. Hmm, an iPad running iOS8 GM is indeed having this issue.  Not sure why the simulator works just fine.  I'll have to investigate further.\n. Looks like Safari in iOS8 is completely busted for ajax file uploads.  This doesn't seem to only affect Fine Uploader.  \nAnd I am so far unable to hook up the web inspector in my desktop safari to my iPad running iOS8.\n. Looks like the file input element is totally busted in iOS8 safari.  I can't even upload a file with a simple form submit.  Chrome works, but I'm also seeing Chrome crash after clicking the choose files button if the multiple attribute is present on the file input.  Are you seeing this too?\n. ...sorry, I mean that Chrome crashes if the multiple attribute is NOT present.  This happens after I click on the file input and then choose either \"Choose Existing\" or \"Take Photo or Video\".\n. Tracking the latest iOS8 safari issue in #1284, and the Chrome issue in #1283.\n. Duplicate of #588.\n. This will at least partially replace the removal of #774 from this release cycle.\n. After running a profiler in Chrome and Firefox/Firebug, I'm not really seeing any trouble areas, other than client-side preview generation, which is going to be expensive no matter what.  I've already done my best to ensure the most expensive preview-related code is only hit if the feature is enabled and if the file is previewable.\n. The usage stats are largely dependent on region and application, but,\ngenerally speaking, IE11 has a very small market share.  IE8 is the number\none browser among the IEs in terms of general market share.\nThere isn't a clear fix for this, but we will take another look during the\ncurrent release cycle.  I'm. not sure what you mean by the whole page\nbreaking.  We haven't seen anything like that in our testing.\nOn Wednesday, February 12, 2014, JW301 notifications@github.com wrote:\n\nAffects the most-used versions (10,11) of one of the most-used browsers\n(IE), and basically makes drag+drop break the whole page (when the drag\nzone is in front of other elements).\nPlease fix this for the next release\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1043#issuecomment-34864711\n.\n. I've moved this bug into the current milestone, and we'll take a look at some point during this cycle.\n. I'm afraid there is no possible fix for this issue.  I have been aware of this for a while, as the same issue exists in Safari, also with no known fix.  The complexity comes from the behavior that shows the drop zones when a file enters the document.  This is fairly easy to determine.  However, in some browsers, such as IE and Safari, it is impossible to determine when the dragged file has LEFT the document if the chooser/explorer window housing the file overlays the document.  We have been able to reliably detect this in Firefox and Chrome by carefully examining the dragleave event instance and identifying values on the event instance that suggested the object had left the visible window.  These patterns have been codified in the DnD module, are very much hacks and browser-specific.  Unfortunately, no such patterns on the event object exist in Safari and IE as far as I can tell.  \n\nIf you rely heavily on IE/Safari, and/or this issue is likely to cause problems for your users, and you require a drop zone or zones that only expose themselves when a dragged file enters the document,  you will need to style your drop zone accordingly.  For example, if your entire page is a drop zone, ensure that entering the page does not result in the entire contents of the page being replaced with some drag-related animation.  Perhaps a dotted-line surrounding the page is appropriate.  Another option is to simply ensure there is no style change to the drop zone when the file enters the document, only when the file hovers over the actual drop zone.\n. I guess I was mistaken about the exact issue.  I was looking for a solution that would ensure all drop zones were hidden when a dragged file leaves the visible page and returns to the explorer/chooser window when this explorer/chooser window overlays the page.  I was unable to find a way to detect this in IE10+, but, you're right, it is detected properly in google drive.  I'll investigate a bit more.  \nAs far as the other issue: the drop zone is is never hidden after removing the dragged file from the page, that is a regression that I will also look into now.  \nI'm reopening this.  Thanks for your update.\n. I just commited a fix for one issue, and a workaround for another.  The issue where a file is dragged out of the window (where the chooser/explorer window containing the file does not overlay the browser) and the drop zones are not hidden should be fixed.  This issue was present in IE10+.  \nThe issue where the drop zones remain exposed after dragging the file back to the overlapping finder/explorer window in IE10+ and Safari has no obvious fix.  I've worked around this by adding a \"mouseenter\" event listener to the document that will hide any exposed drop zones the next time the mouse enters the browser window.  This seems like a suitable workaround.  \nGoogle drive doesn't have this issue as, presumably, the entire document is the one and only drop zone.  In that case, it's quite easy to determine when any DnD artifacts should be hidden: when the draggable source object leaves the drop zone.  Since Fine Uploader allows you to have multiple drop zones on a page, and the drop zone(s) may only occupy a small portion of the page, we can't simply hide all drop zones when the draggable source leaves a drop zone, we must determine if the file has been dragged out of the document/window.  Unfortunately, this does not appear to be possible in all browsers in some cases, requiring the workaround mentioned earlier.\n. The workaround for IE & Safari is potentially risky.  This needs more comprehensive testing during this release cycle before it is considered \"done\".  I'll test it in more real-world apps shortly.\n. The behavior you described is expected after the fix in this case.\n. The issue tracker is for bugs and feature requests.  See http://fineuploader.com/support for information on obtaining technical support.\n. We will need to redirect readers of the getUploads blog post to the appropriate feature page after we release 4.1.\n. Tasks:\n- [x] Allow integrators to pass a new credentials option (containing secret key, access key, expiration, and optionally a session token)\n- [x] API method to update credentials after initialization\n- [x] Callback invoked when credentials have expired.  Return value should be new credentials - promissory.\n- [ ] Update customizer to only pull in crypto and other client-side-signature-related code if the integrator expresses interest in this workflow\n- [x] Documentation of API/options/callback\n- [x] Feature page discussing this workflow\n- [x] Cautions about private keys on the client\n- [ ] Tests\n- [x] Working demo? (if time allows)\n- [x] Blog post discussing the demo\nThere is enough here for me to call this a 13 I believe, so, I'm changing the storypoints from 8.\n. The feature-work itself is mostly complete in the s3-sign-clientside feature branch.  I would like to provide a functional demo for the client-side signing workflow on fineuploader.com as well.  This looks to be fairly simple to do.  However, I'm planning on the following restrictions:\n- The demo will only support \"modern\" browsers (not IE9 and older).  If we want to avoid a server entirely, we will need to use the AWS and Google JavaScript APIs.  The AWS JavaScript SDK doesn't support IE9 and older, and the Google SDK only supports more current versions of IE8.  I think the goal of this feature is to avoid dealing with server-side code wherever possible, so I'm leaning towards making use of these JS APIs and mentioning that the demo only works in \"modern\" browsers.  If I go this route, I will explain what must be done to support older browsers (IE8 and older will be non-trivial).\n- The demo will only utilize Google as an identity provider.  If we want to use Amazon, it looks like we will need involve some server-side code, and only HTTPS targets and redirects are supported it seems.  I'd really rather not deal with SSL/certificates for this demo.  Amazon has a very weak client-side identity provider SDK and a rather odd set of requirements.  For example, you must pass a secret key with your access token request (Google does not have this requirement).  A server is required as it is unwise to include this key client-side (and AWS doesn't provide any way to make this request in their JS SDK due to this reality).  Also, GitHub pages doesn't support SSL, so we couldn't redirect back to the website.  I don't see a good reason to support Facebook as an ID provider for this demo.\nI plan to discuss the above with the team on Thursday.\nAmong the items on the documentation site's feature page for client-side signing, there will be a section on how to support an entirely server-less Fine Uploader S3 instance on a feature page in the documentation.  This section of the feature page will link to the demo (for a live example).  The demo will include a link to the documentation (for a step-by-step setup guide).\n. Finished a live demo in the Widen/fine-uploader-examples repo under the s3-no-server branch.  This will be merged into that repo's master branch as part of the 4.2 release process.\n. Live demo is available at https://fineuploader-s3-client-demo.s3.amazonaws.com/index.html for early adopters.  Blog post and feature documentation are still pending.  Links to the source code of the demo are pointed at the master branch of the fine-uploader-examples Github repo, which does not yet have the s3-no-server code.  It will after we release, though.  In the meantime, if you want to look at the source of the demo, check out the s3-no-server branch in the fine-uploader-examples repo.\n. Blog post is complete and will be published with the 4.2 release.\n. @feltnerm When you get a chance, please prepare updates to the customizer to only pull in crypto and other client-side-signature-related code if the integrator expresses interest in this workflow.\n. Last item to finish here: Unit tests.  I'd also like to make this an excuse to write generic file-based S3 unit tests, similar to the traditional endpoint unit tests that I wrote in #1063.  The S3 tests will be covered in #1076.\n. Hi there @railsjedi.  Thanks for catching this.  I think your suggested fix is correct.  I'd also like to patch the css method in util.js so that it spits out a more specific error message if an attempt is made to style a node that is not in the HTMLElement prototype chain (and therefore does not have the style property).  \nNo need to open up a PR.  I'll mark this as a bug and will have a fix as part of the next release (4.1).\n. Another workaround would be to use the <body> element as your drop zone.  Out of curiosity, why are you using the document, instead of, say, <body>?\n. Hmm, that's odd.  I wouldn't expect that to be an issue.  I'll try to reproduce that myself tomorrow.  I'm involved in another project that uses Fine Uploader with a large drop zone, but it uses a <div> (inside the <body>) that contains the majority of the content as the drop zone.  I wonder if wrapping all of your content in a <div> inside the <body> and setting that <div> as the drop zone would work?  Again, though, I'm a bit surprised <body> is giving you issues.  I'll report back after I've had some time to investigate.\n. I'm not seeing any issue using <body> as a drop zone.  Most likely there is some issue in your code/environment.  I am fixing the document issue you reported though.\n. Another commit related to this fix can be found in 674a38f572c6450b7166a685a7ef203e6734af19.  My commit message failed to add this commit to this issue due to a syntax error in the commit message.\n. This is fixed in the develop branch, and will be part of 4.1.\n. Let's look into this more in 4.2.\n. We're never gonna do this, are we @feltnerm?\n. Yup\nOn Sun, Sep 21, 2014 at 6:16 PM, Mark Feltner notifications@github.com\nwrote:\n\nI can do it quickly. I'd story point this a 0. Forgot about this. Many editors parse .editorconfig and can automatically use spaces over tabs, indent 4 or 2, or w/e rules are setup inthe .editorconfig. I would assume those rules would match the style and lint rules we have established.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1053#issuecomment-56316459\n. Thanks Craig.  We'll look into this more during the next release cycle (4.2).\n. The contributed change creates a regression that prevents other default drop zone visible drop areas on the page (such as those contributed by other uploader instances) from disappearing after the drop.  Looking into this now.\n. @craigrbruce The change associated with your pull request prevented other drop zones on the page from being optionally hidden (since they only do this when handling a drop event).  So, when receiving a drop event, after preventing it from bubbling, I trigger a custom event observed internally that allows all other drop zones on the page to be hidden.\n. Please provide a working example of this so I can look a bit more.  I'm not sure I understand your setup.\n. I hope to have some time to reproduce in the next couple days.\n. Thanks for the update.  Nothing for me to do at this point, I assume.\n. Are you saying that you are explicitly setting the camera.button value to the default button?\n. I am not able to reproduce this issue in the develop branch.  What version are you using?\n. Ah yes, I'm seeing it now.  We'll fix that in the current release cycle, 4.1.\n. Fixed in the develop branch.\n. This was much less likely to be an issue in 4.1.0 with the iOS7 MOV file workaround I have included (#1039), but this is fixed nonetheless.\n. The feature allows you to change the name of the file sent with the request before the upload request is sent.  If you'd like to send other metadata along with each file, you can do so via the params option, or the setParams API method.  See the documentation for more details.\n. Can you please describe your application's specific need for this information a bit more?\n. You should be able to set any element as an \"extra\" upload button.  Please see the multiple upload buttons feature in the documentation.\n\nAs to your original request, we will discuss this internally.  If we move forward with this, we will likely provide an API method that will allow you to determine which drop zone element a specific file is associated with, similar to what is possible via the getButton method.\n. This will be part of 4.2.  I've added an API method for Fine Uploader UI and appended a dropTarget parameter to the processingDropppedFilesComplete event for DnD module standalone users.\n. TODO: Address skipped until tests in submit-validate-cancel.js after this is resolved.\n. Fine Uploader doesn't use or depend on jQuery internally.  Supporting any valid CSS selector would be a bit of a chore because of this.  It's not clear here what you would gain by passing in a selector string, instead of simply selecting the element yourself.\n. If you are talking about simply passing in a jQuery object, you can already do that if you are using the jQuery plug-in wrapper.\n. We need to discuss more internally.\n. Fine Uploader already handles resizing and rotation, in fact, it even parses the Orientation tag from the EXIF header.   This case will include native support for sending multiple versions of an image, ostensibly in the same request.  Are you expecting all sizes of an image (along with the original) to be sent in the same request?\nThere are no plans to parse any additional EXIF data at this time.  If you'd like to parse all EXIF fields, there are other libraries out that that will do this for you alongside Fine Uploader, such as Nihlogic's EXIF Reader.  You can grab the file object from Fine Uploader via the API, and feed it into a full client-side EXIF parser, or you can easily parse it server-side and return this information in the response to the upload request, making it available to your onComplete callback handler.\n. Currently, resized images are only for display.  The EXIF headers are\nlikely removed when the image is drawn onto a canvas internally.  Re-adding\nthese headers will likely not be a trivial task, but it is something we\nwill look into.  Essentially, we will have to grab the EXIF data from the\noriginal image and re-added it to the resized images.\nOn Tue, Nov 26, 2013 at 9:39 AM, Pierre notifications@github.com wrote:\n\nActually I don't want to upload the original photo, just the resized one\nto save bandwidth and uploading time.\nDoes your resize function keep EXIF datas in resized photos ?\nIn anyway I will re-parse EXIF datas on server-side to support old\nbrowsers, so uploaded photos (resized ones) have to hold EXIF datas\n(location, orientation, date).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-29302254\n.\n. @sayanb All files are always uploaded asynchronously by Fine Uploader, so that is not an issue.  I'm guessing you will want all sizes for an image uploaded at once.  Please comment if that is not the case.  Is preservation of the EXIF data important?  I suspect it is, and this is going to be perhaps the most challenging part of implementing this feature, but my intent is to ensure EXIF data is preserved.\n. If the user navigates away from a page that is hosting a Fine Uploader\ninstance, the instance will be destroyed and all in progress uploads will\nbe terminated.  If you'd like your users to interact with your site while\nfiles are uploading, you will probably want to host the upload component in\na popup window.\n\nOn Sat, Nov 30, 2013 at 5:01 AM, sayanb notifications@github.com wrote:\n\nYes, we would need to keep exif data for future usage for store.\nAs far as uploading all sizes are concerned,please consider this scenario:\n1. I need to upload 15 photos where each photo is somewhere around 5MB.\n2. Fine Uploader resizes the photos and starts uploading all at the\n   same time.\n3. Once all the resized small photos have been uploaded, my client\n   code should somehow be notified.\n4. Once the client \"knows\", it informs the user that photos have been\n   uploaded. This information is not accurate as the main photos are still\n   getting uploaded. However, the user can then navigate away from the upload\n   page to another page where she can use the uploaded smaller photos the way\n   she wants to.\nQuestion- if the user navigates away, will Fine Uploader stop the upload\nprocess for the larger main photos? If yes, uploading all at once might not\nbe ideal. The whole idea is to not make the user wait for large uploads and\nlet her move to other parts of the site while the large photos are getting\nuploaded. If Fine Uploader does not stop uploading the main photos once the\nuser navigates away to another page, uploading all at once shouldn't be a\nproblem.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-29550349\n.\n. No release date yet.  This will likely not be part of the current release cycle (4.2).  Perhaps next release cycle.\n. Hi there.  This feature was never planned to be part of the current\nrelease, which should go out on Wednesday.  We will be discussing the\nfollowing release late next week though.\n\nOn Thursday, January 9, 2014, sayanb wrote:\n\nHi,\nJust wanted to check if you are implementing this new feature for the\npresent release and if so, when can end users expect the present release?\nThanks,\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-32001109\n.\n. Sorry, this didn't make it into the 4.3 release cycle.  We're pretty booked in 4.3 with the upload-to-Azure feature (#1022) and supporting existing HTML forms on a page (#781).  Perhaps this will make it into 4.4?\n. Needs and requirements tend to change very quickly, so we don't usually make promises about future releases, as they are not planned far in advance.  This is consistent with the \"agile\" nature of this and other projects.  Features are prioritized based on perceived need/want by the community.  The complexity of the feature and available time to implement are a factor used to determine if a feature will fit into a particular release as well.  This particular feature is behind several others in that regard.  However, it is near the top of our list and is likely to be part of a near future release.  \n\nAlso, given the relatively low cost of the license fee, there are a limited number of resources assigned to this project, and there are only a finite number of hours in a day to complete features, fix bugs, and respond to support requests.  \nThe feature you are asking for may be fairly complicated to implement.  The main complexity involves ensuring the resized image contains appropriate EXIF data based on the original's EXIF data.  Generally speaking, Fine Uploader does not pull in any dependencies, except for a few workflows.  This might be a scenario where we pull in an EXIF library to speed up development, but it is still not clear if we need to adjust the EXIF data on the resized image based on the changes we have made.  So, either way, this will not be a trivial task.\n. You will need to get a handle on the image file via Fine Uploader's getFile API method, run it through an EXIF parser, ask Fine Uploader to create a scaled version of the file via the drawThumbnail method, convert the <canvas> it returns to a Blob via the toBlob method on the HTMLCanvasElement, then construct a new Blob that also contains the EXIF data from the original file.  That last part is going to be quite difficult.\n. Please also keep in mind that the creator of jquery file upload provides\nabsolutely no support for his library.  Support alone takes a good deal of\nour time and is one of the reasons we charge a license fee.  Also keep in\nmind that you can generate a resized preview using fine Uploader and upload\nit.  The proposed feature will just make that a bit easier and provide the\noriginal exif data alongside the resized file , something jquery file\nupload does not do.\nOn Sunday, January 26, 2014, Paolo notifications@github.com wrote:\n\n+1 on this feature. @rnicholus https://github.com/rnicholus, I\nunderstand that this feature is behind others in your list, but bear in\nmind that jquery-file-upload already implements it and it comes for free...\nWhile your S3 direct upload approach is much clean than that of\njquery-file-upload, at least this is my opinion, there is no much point in\nswitching and paying for the licence as per today. I bought a licence but I\noverlooked the presence of this feature, unfortunately.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-33321480\n.\n. I can see this feature being part of the 4.4 release, with original exif\ndata sent as a parameter alongside the resized image.  That will be much\neasier than attempting to insert and adjust the exif values into the\nresized image.\n\nOn Sunday, January 26, 2014, Ray Nicholus rnicholus@widen.com wrote:\n\nPlease also keep in mind that the creator of jquery file upload provides\nabsolutely no support for his library.  Support alone takes a good deal of\nour time and is one of the reasons we charge a license fee.  Also keep in\nmind that you can generate a resized preview using fine Uploader and upload\nit.  The proposed feature will just make that a bit easier and provide the\noriginal exif data alongside the resized file , something jquery file\nupload does not do.\nOn Sunday, January 26, 2014, Paolo >\nwrote:\n\n+1 on this feature. @rnicholus https://github.com/rnicholus, I\nunderstand that this feature is behind others in your list, but bear in\nmind that jquery-file-upload already implements it and it comes for free...\nWhile your S3 direct upload approach is much clean than that of\njquery-file-upload, at least this is my opinion, there is no much point in\nswitching and paying for the licence as per today. I bought a licence but I\noverlooked the presence of this feature, unfortunately.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-33321480\n.\n. Its tough to cover every workflow under the sun, but when we do add such a\nfeature to the library, our goal is always to do it better than anything\nelse out there in terms of completeness. The preview generation, s3,\nUploader, paste support, auto resume/retry, and the upcoming upload to\nazure and existing form support, among others, are all examples of this.\n Rest assured that this feature is on our radar and will be in progress\nonce we tackle the features scheduled for our current release cycle.\n\n\nOn Sunday, January 26, 2014, Ray Nicholus rnicholus@widen.com wrote:\n\nI can see this feature being part of the 4.4 release, with original exif\ndata sent as a parameter alongside the resized image.  That will be much\neasier than attempting to insert and adjust the exif values into the\nresized image.\nOn Sunday, January 26, 2014, Ray Nicholus >\nwrote:\n\nPlease also keep in mind that the creator of jquery file upload provides\nabsolutely no support for his library.  Support alone takes a good deal of\nour time and is one of the reasons we charge a license fee.  Also keep in\nmind that you can generate a resized preview using fine Uploader and upload\nit.  The proposed feature will just make that a bit easier and provide the\noriginal exif data alongside the resized file , something jquery file\nupload does not do.\nOn Sunday, January 26, 2014, Paolo notifications@github.com wrote:\n\n+1 on this feature. @rnicholus https://github.com/rnicholus, I\nunderstand that this feature is behind others in your list, but bear in\nmind that jquery-file-upload already implements it and it comes for free...\nWhile your S3 direct upload approach is much clean than that of\njquery-file-upload, at least this is my opinion, there is no much point in\nswitching and paying for the licence as per today. I bought a licence but I\noverlooked the presence of this feature, unfortunately.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-33321480\n.\n. @wavetronz This issue/feature is specifically about client-side image resizing and uploading.  The server-side code really has nothing to do with Fine Uploader, as this is a client-side library.  The server-side examples are stored in a different repo entirely, and are provided as a starting point for integration into an existing web app.  We can certainly look into making it easier to resize images server-side, starting with PHP, though, by augmenting the server-side example(s).\n. That would be much appreciated.\n. If you don't mind, I'm going to remove everything after and including your first message, since you've created an issue in the server repo with the same text.\n. This feature is now scheduled for the 4.4 release cycle.  Here are the goals:\n- New scaling option that will allow you to have Fine Uploader scale any supported image files, client-side, to a specified maximum size (in pixels).  You can specify an array of sizes, or a single size.  If an array is specified, a separate scaled image will be generated and uploaded for each specified size, per submitted file.\n- Optional quality values (image/jpeg or image/webp only) and suffixes for each scaled image may be included along with the each max size value via the new scaling option.\n- If the option is turned on, by default, the scaling will take place by Fine Uploader automatically.  The scaled image(s) will be sent with the upload request in place of the original image.\n- EXIF data will NOT be re-attached to the scaled image(s), nor will it be adjusted.  However, we will pull in something like exif.js to parse all EXIF data into an Object.  We will then send this data as a JSON parameter with the scaled file's upload request.  None of this matters if the original image does not contain EXIF data, of course.\n- An option to also send the original file as a separate upload request.  If this is set, Fine Uploader will send the original file in one request, programmatically generate a separate file record for the scaled image, and send this in a 2nd request.  The original file will, of course, include the original EXIF data in the image.  The name of the scaled image file/record will be augmented to include the word \"(scaled)\".\n- The scaled image will be a Blob.  The possible image types for output will be \"image/jpeg\", \"image/png\", or \"image/webp\" (Chrome and Opera only).\n\n\n\nThe following items are NOT goals of this feature:\n- Re-inserting EXIF data from the original image file into scaled image files.\n- Support for IE9 and older.\n- Scaling support for image types other than JPEG, PNG, GIF, and TIFF (Safari only).\n. We will include the EXIF data with the resized image upload request.  I'm not sure we should rotate the images, as this would invalidate the Orientation value in the EXIF header we send.  For integrators that actually want to manipulate the image server-side using the sent EXIF data, this may cause them additional problems.  I'll have to think about this.\n. Fine Uploader already has code to orient the previews it generates correctly based on the Orientation tag in the file's EXIF header.  This has existed since the thumbnail feature was delivered.  I even wrote my own EXIF parser to grab the Orientation value.  I can tell you that dealing with iOS is one of the most tricky parts of that feature as we have to account for the image subsampling that iOS performs.  \nI can see adding a flag that tells Fine Uploader if it should orient the scaled image before uploading.  It seems reasonable to \"fix\" the scaled image in this way, as I suspect the only acceptable use for the original image's EXIF data in the context of the scaled image will be the tags that describe data that is not a property of the image itself, but rather metadata such as data/time, and GPS-related tags (not information about the image itself, such as dimensions and bits per pixel).  In fact, a number of the EXIF tag values from the original image will not be valid in the context of the resized image.\n. Development on this feature has started.  Here are the tasks that must be completed:\n- [x] Create scaling option with the following properties: sendOriginal: false, orient: true, defaultQuality (number: 1-100), and type (MIME string), sizes: [].  The sizes property will need to be populated with one or more size objects.  A size object must contain the following properties: max (in pixels).  Optional properties for size are: name (string).\n- [x] When a file is submitted, generate a record for each scaled version.  It's probably not a good idea to generate these scaled blobs ahead of time as this might eat up a substantial amount of browser memory.  Instead, perhaps I should generate \"recipes\" for creating these scaled blobs.  The scaled blobs should probably be generated on-demand as part of the upload process, and not cached.  A call to getFile should probably just return the original file.  ~~Investigate using web workers to do as much of the scaling work as possible so we don't unnecessarily block the UI thread.~~ I would have liked to use web workers, but we can't pass Blobs to web workers, only ImageData, and you cannot create Canvas objects.  The 3rd-party code in Fine Uploader that scales images would have to be heavily modified to allow use of web workers here.\n- [x] Ensure the name value of the size object is appended to the original file name for scaled version.\n- [x] Upload scaled images before original, smallest version first.\n- [x] Orient images correctly for each generated scaled image if this is turned on in the scaling option and if the original image has an Exif tag.\n- [x] Ensure images/files that can not be handled natively by the browser skip this workflow immediately.  This will have to be done using the type property on the original file.  This is not as accurate as Fine Uploader's internal file identification module, but it's likely good enough.  Using the internal file ID module would make the initial sorting of the files submitted by the user an asynchronous operation, and this would break a lot of unit tests, and possibly cause problems for integrators that are not expecting addFiles or addBlobs to be an asynchronous operation.  In other words, the current behavior of addFiles or addBlobs is: return only after the files have been submitted to the handlers and the internal file tracker.  So, for example, getUploads would return results that include all files passed to addFiles if this is called immediately after addFiles returns.\n- [x] Ensure non-scalable files/images are treated as normal uploads (no error, no scaling).\n- [x] Ensure the resulting scaled blob is of the original images file type, unless the integrator has specified a specific file type that it should be converted to instead.\n- [x] Respect the defaultQuality property on the scaling option if the target image type is \"image/jpeg\". \n- [x] Handle instances where the reference file is too large to scale client-side.  Simply fail the scaled file uploads in this case.  The behavior here should be the same regardless of why the scaled image cannot be generated.  In any case, the scaled file should be listed as failed & not retryable.\n- [x] Allow the original file to be ignored (not uploaded and not displayed in UI).\n- [x] Option to hide all scaled file items in UI.\n- [x] Create an API method that generates a scaled blob, given a File ID.  This will have to be promissory.\n. Additional tasks split off into #1136 & #1139.\n. I've decided not to immediately support WebP for this feature.  See #1140.\n. This first phase of the feature is complete, but documentation remains.  #1136 & #1139 must also be completed.\n. This feature is functionally complete in the develop branch.  The plan is to release this with 4.4.  If there is anything missing from the implementation, please comment ASAP.  The documentation for this feature can be found at http://docs.fineuploader.com/branch/develop/features/scaling.html.\n. Yes, this feature includes all work in this issue, along with #1136 & #1139.  #1140, however, is not part of this feature.  #1140 may be completed in a future release, if there is enough demand.\nI should probably add something to the feature documentation, explaining that client-side image resizing and EXIF header insertion is potentially very processor & memory intensive, and may not be an appropriate feature to enable for all customers.\n. Looks like there are some issues on Android 4+ stock browser.  Chrome on Android looks OK though.  Looking into this now.\n. There are 2 issues in Android's stock browser that we will probably need to address here:\n1. canvas.toDataURL(\"image/jpeg\") returns an image/png data URI.  This is a known issue with Android's stock browser.  This will prevent us from generating JPEG scaled versions & including EXIF data with images scaled on Android's stock browser.\n2. An attempt to upload a Blob via Android's stock browser results in an empty payload.  This is also a known issue in Android that I'm aware of.  There may be a workaround here.\nI'll look into both Android problems in issue #1146.\n. The scaling options apply to all files and are not currently adjustable\nafter a Fine Uploader instance has been constructed.  You can choose to\nhave all originals uploaded, or only upload all scaled versions.\nOn Tuesday, March 11, 2014, sayanb notifications@github.com wrote:\n\nHi,\nA quick question- if I want to decide whether to send the original or a\nsmaller scaled version based on the file size of the original, is there a\nway to handle this on the client side?\nThanks,\nOn Tue, Mar 11, 2014 at 1:53 AM, Ray Nicholus notifications@github.com<javascript:_e(%7B%7D,'cvml','notifications@github.com');\n\nwrote:\nClosed #1061 https://github.com/Widen/fine-uploader/issues/1061 via\n0dd3acf<\nhttps://github.com/Widen/fine-uploader/commit/0dd3acf40afe0a9ca0d439526aadc8578738fc62\n.\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/Widen/fine-uploader/issues/1061>\n.\n\n\nSayan\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-37265694\n.\n. We will not expand the size of an image beyond its original size.  For the moment, another version of the image will be generated given your scenario, with the same dimensions.  Other properties of the scaled request will be applied to this version, such as orient, and type/defaultType and possibly defaultQuality.\n\nI thought about simply not generating \"scaled\" versions if the \"scaled\" version's dimensions would match the original exactly, but this would require a bit of refactoring of the internal validation code as this determination is an asynchronous one, and some thought would need to be put into making this determination more efficient for images with potentially multiple items in the scaled group.  This enhancement can certainly be added in the future, if requested.\n. Compression is handled entirely by the browser, specifically, by the <canvas> element.  Furthermore, the quality of an image can only be adjusted when the output image is a jpeg.\n. There is  a way to adjust the quality, via adjustable properties on the scaleImage API method, or the core scaling option.  Choose one or the other, depending on your intended use of scaling.\n. Note that I made a couple last minute edits to my above comment.\n. m not seeing any such issue, and no other users have reported this.  So, the issue is likely in your code.  If you would like assistance tracking this down, please open up a thread on stack overflow, tag it fine-uploader, and be sure to include your code and any console messages that might provide additional clues.\n. I'd like to close this & move on.  What say you, @feltnerm.\n. Thanks @daniellwu.  Note, while the build is listed a failing in the last commit here, that was an issue with Fine Uploader's beforeunload handler causing the tests to stall (in some cases) when run in a browser.  That event handler should be squelched as of 09cb7e4f4cf4ea6ac366b564ed7b2c88795937b3, with tests now passing.\n. Closed as a duplicate.\n. Closed as a duplicate.\n. Thanks for your report.  We'll schedule this fix for the currently in-progress release cycle (4.2).\n. I don't plan on passing a filename or an uploader instance as additional params.  The best solution here would be to ensure the context of the call to key function matches the context of the callbacks when they are invoked.  We'll consider this for the release after the current one (4.3) most likely.\n. Must uncomment portions of the chunking unit tests after fixing this.\n. No indication that CORS is supported.  Closing.\n. This seems like an 8.  I may or may not finish before we are scheduled to release 4.2, but I'll get as many unit tests in as I can at the very least.  My ability to complete this entirely as part of 4.2 depends largely on how quickly I can finish unit tests for #1047.\n. Why do you require this?  What are you trying to do exactly?  You shouldn't depend on the qq-file-id attribute in your application.  That is an internal unpublished implementation detail.  It may change or be removed at any time.\n. The qq-file-id will only reset back to 0 if you reset or re-initialize the uploader.  Are you doing this at some point?\n. Your approach makes some assumptions about the internal workings of Fine Uploader, and this may cause you other headaches in the future as well.  Internals may change at any time, potentially breaking your app (without notice) as it stands with even a patch version upgrade.  \nI suggest you change your approach.  If you open up a question on Stack Overflow under the fine-uploader tag and explain your app in a bit more detail (including some screenshots), we will be happy to suggest viable alternative (and safer) approaches.\n. What advantage does a content editable div have over a text input field in\nthe context of specifying a file name?\nOn Saturday, December 21, 2013, Alexandru Furculita wrote:\n\nThis is a suggestion. It will be nice to use Html5 at its whole power, at\nleast in the browsers that supports it. Maybe it's a nicer approach to use\ncontenteditable html5 attribute when the edit file names feature is on.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1079\n.\n. Ah, I likely replied a bit too early in the morning as I temporarily forgot\nthat Fine Uploader's edit filename feature requires an event/javascript to\nexpose the text input and hide the filename display element, and then\nreverse the visibility of these elements when the editing is complete.\n You're probably right - a contenteditable element may be a better choice,\nand I believe this will work in all supported browsers, including IE7.  If\nwe switch to CE elements in the future, we will need to be sure we continue\nto support the same conveniences as the current feature, such as tabbing to\nedit the next filename.\n\nI can see making this change in a future release, but I'm not sure when as\nthis is probably a low-priority adjustment with many higher-priority\nfeatures ahead.  We will discuss internally a bit more.\nOn Sat, Dec 21, 2013 at 9:35 AM, Alexandru Furculita \nnotifications@github.com wrote:\n\nTo obtain the same experience that a contenteditable div offers we have to\napply more CSS on the text input file.\nAlso i think we'll not need anymore qq.FilenameClickHandler if we have a\ncontenteditable div.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1079#issuecomment-31065549\n.\n. After some more thought, I don't think contenteditable is appropriate for this situation. A simple text input is best for renaming a file. As such, I'm closing this.\n. Waiting for results of some internal testing before releasing this as part of a 4.1.1 hotfix.\n. You are correct on both points.  Thanks for catching these and informing us.  They will be fixed on Monday.\n. This also needs to be fixed on the validation feature page.\n. After thinking about this some more, I'm doubting that an array of strings will work for the acceptFiles validation option.  We'll need to test in all browsers.\n. Please provide all the code required to reproduce your issue, and also\nmention which version of Fine Uploader you are using.\n\nOn Thursday, January 2, 2014, Nikolaos Michaleas wrote:\n\nWhen I try to cancel a file using this code:\n$('#fine-uploader').fineUploader('cancel',Id);\nthe uploader removes the file from queue! When I re-submit files for\nuploading, the uploader does not upload the files (without any error\nmessage), even if the files are presented in UI. If I try to cancel the\nfiles I get the following error for each file I tried to cancel:\n\" [FineUploader 4.1.1] 1 is not a valid item ID. \"\nSo, my question is: How can we cancel a file from queue by using the\nfine-uploader's api, and not only the internal event binding on class\n\"qq-upload-cancel\".\nThank you\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1083\n.\n. I'm going to have to ask you again to provide your client-side code, as I am not able to reproduce this. My guess is that you are constructing Fine Uploader using non-jQuery syntax, and then addressing it using jQuery.\n. @Kalisteus This is not the same issue described in the original post of this thread.  I'm not able to reproduce your issue either.  Submitting a file and cancelling it via the API works as expected.  The issue is likely in your code somewhere.  Please provide a link to a site where your issue can be reproduced live.\n. If someone can provide a live example of this, I will be happy to take a look.  Until then, this issue is closed.  At this point, I see no issue with Fine Uploader and highly suspect that your integration code is causing your issues.\n. @dlin-me That is by design.  Fine Uploader tracks all files submitted, even rejected/invalid ones.\n. Should be covered by #910.\n. Looks good.  Thanks!\n. I don't understand.  You are trying to upload a cancelled file?  Where/how is this upload attempt occurring?\n. I suppose you should simply pass the ID as an integer then?  The API documentation mentions that Fine Uploader is expecting a number, not a string, when you pass an ID.\n. The qq-file-id attribute is an implementation detail.  Your application shouldn't be aware of this attribute.  It may be renamed or removed at any time without any notice/documentation.  If you need to grab the ID of a file, given an element inside its associated file container, you will be able to use the getFileId API method of Fine Uploader UI added as part of 4.2.  This method is only available in the develop branch at this time, as 4.2 has not yet been released.  You can read more on the feature request that prompted this method by looking at #1033.  \n\nA better option in the meantime would be to annotate the file element container yourself and then retrieve that value when you wish.  You can get a handle on the file container element at any time (such as in a callback) via the getItemByFileId method.  Once you have this element, you can annotate it using jQuery.data or by setting your own attribute on the element.\n. Also, why are you doing this to cancel a file?  Fine Uploader UI already provides a cancel button.\n. I can look into throwing a qq.Error if the proper ID type is not passed into one of the methods.\n. Understood.  I've marked this as a bug so we will get to it in the near future.  Perhaps even in the current release cycle.\n. Note that you may want to consider using jQuery's data store for this type of thing, instead of messing with attributes.  It looks like you are already pulling in jQuery.\n. After more thought, it doesn't seem worth the effort to add code that ensures that passed ID is a number, and not a string.  The docs state that a number is required.  If you are passing in an ID stored in an element attribute, it will need to be converted to an integer first \u00e0 la parseInt(id).\n. Upon further inspection, I believe the \"delete feature is disabled\" portion of the message is sufficient.\n. No, there is nothing exposed that allows this.  What is your specific scenario?  Why do you need to adjust this value dynamically?\n. @atistler That won't work.  The ACL value from the options is cached inside of the S3 endpoint handlers (s3/handler.xhr.js & s3/handler.form.js) during initialization of a Fine Uploader S3 instance.  A small amount of refactoring will be required. \n. I've tagged this for internal discussion.  I'm not sure at this time if this will make it into the 4.3 release, or later.  The plan is to release 4.2 tomorrow and then spend a day or two discussing the 4.3 release cycle.\n. This feature is complete in the develop branch and will be part of the 4.3 release.\n. Prompted by a post on Stack Overflow.\n. ...we'll also need to include support for this in browsers where uploads via the REST API are not possible (IE9 and older).\n. After some thought, I don't see the need to set server-side encryption on a per-file basis.  It seems reasonable that a Fine Uploader S3 instance order all uploaded files to be encrypted server side, or none.\nIf someone can provide a reasonable use case for encrypting some files but not others during a particular session, we can add support for this.\n. Shedding a story point since this will be easier if we only create an option for it and apply it to all files associated with the instance.\n. This is complete in the develop branch and will be part of the 4.3 release.\n. http://docs.fineuploader.com/branch/master/api/options-s3.html#objectProperties.serverSideEncryption\n. Unless this can be wrapped up in under a day, I'm going to reassign and probably push this off to a later date\n. Sounds like you were working on this at some point @feltnerm.  Is this something we want to finish?\n. I don't see an obvious need to \"automate\" anything related to fineuploader.com ATM, other than maybe updating the version number. But that is a pretty easy variable to update manually.\n. It looks like Azure's Blob Store service requires that files be uploaded in chunks (blocks).  Each block must be 4 MB or less, and the total size of a combined blocks (the blob) cannot exceed 200 GB.  This fact and the apparent lack of support for uploading blobs via a multipart encoded POST request (and the per-request limit of 4 MB) suggests that there is no way to upload to Blob Storage directly from IE9 and older.\nRackspace and Amazon have necessary support for browser-based uploads in IE9 and older in their storage services.  Certainly Microsoft didn't exclude the majority of their own browsers from this workflow, did they?\n. Confirmed that this is not supported by Azure at this time.  Blocked until Microsoft makes this possible.\n. This still isn't supported by Azure, and probably never will be, especially since IE9 and older are no longer supported by Microsoft. Closing this as it's not really a priority anyway.\n. Blocked due to #1025.  This hardly seems worth the effort if #1025 can't be completed.\n. I closed #1025, so I'm closing this too for the same reasons.\n. How are you measuring the progress?  That is, how do you know the value is incorrect in these browsers?\n. Just tested with Firefox and Chrome on Windows 7 myself.  I'm not seeing any issues.\n. Thanks for the update & the workaround.  It looks like this is a 3rd-party bug, so I'll mark it accordingly.  There isn't much we can do to work around this.  The browser reports upload progress, and we simply format it.\n. There is nothing we can do about this, so, closing.\n. Will need to add an option to enabled this (default to off). \n. The simplest solution may be to modify the code that determines if an upload is a candidate for resuming.  There is code for this common to non-traditional handlers (S3 & Azure) and a different function for traditional endpoint handlers.  The duplication here is due to the fact that the traditional handler still uses cookies, and the non-traditional uses localStorage.  The next major release should move all handlers to a localStorage system.  See #1024. \nAnyway, we can modify the logic to reject a file as not resumable when we locate resumable data for the added file if a file with the same properties is already uploading.\n. Reproduced in S3 & traditional uploader.  Probably also present in Azure.\n. It looks like my initial plan is not going to work out as I hoped.  If a duplicate file is selected, not only do we need to ensure that we don't resume this file based on the existing persisted record, we also need to mark this duplicate file as ineligible for pause/resume so the existing record is not overwritten by the duplicate file.\n. This feature was never implemented.\n. Everything is working as it should, as far as I can tell. getInProgress is returning 0 if autoUpload is set to false before uploadStoredFiles is called and the uploads are in progress.  Once the files are in progress,getInProgress is reflecting these uploads.  This is consistent with the documentation and the name of the method.  \nIf getInProgress worked differently at some point in the past, then that was likely a bug that we fixed.  If you need to track files at any stage of the process, have a look at the getUploads method.  You can also read more about file status in the status feature documentation.\n. ... If you are not seeing the behavior I described, please provide a\nfunctional demo that reproduces your issue.\nOn Tuesday, January 21, 2014, Dino Krtanjek notifications@github.com\nwrote:\n\nUp until 4.x, getInProgress() worked correctly irregardless of autoUpload.\nNow it returns the correct number of files in progress only when autoUpload\nis true.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1102\n.\n. If there is something we can do to improve the documentation in that area,\nplease let is know.\n\nOn Tuesday, January 21, 2014, Dino Krtanjek notifications@github.com\nwrote:\n\nOh, ok...I understood the documentation wrong. I'll make the corrections\nin my wrapper code. Thanks\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1102#issuecomment-32887226\n.\n. Ah, I see.  I think we can improve that text.  \"Queued\" refers to a file that is waiting for an available connection to be uploaded.  By default, Fine Uploader will only send 3 files simultaneously.  The other files are \"queued\".\n. I've adjusted the description of getInProgress a bit.  Hope this helps.\n. There is no editFilename option.  That was removed in Fine Uploader 4.0 as part of the templating redesign (#867).  It looks like we need to remove that from the documentation as well.  \n\nIf you do not want users to edit filenames, your template must not include the related edit filename elements.  If you have two uploaders on the same page with different requirements in this regard, your best bet is to use different templates.\n. Yep, this appears to be a status reporting issue specific to manual-upload mode.  We'll look into this.  It's unlikely this will be part of a hotfix release as this isn't a major issue as far as I can tell, but it will be fixed in the next planned release.\n. What high-level feature/problem are you trying to implement/solve that requires this information?\n. I'm working on a fix now.\n. I am currently staging a fix in the hotfix/4.2.2 branch.  Could you integrate it into your app and let me know if it solves your issue before we release this as a hotfix?\n. No problem.  I'll hold back on releasing this until you have a chance to take a look.\n. This has been released as part of 4.2.2.\n. We should really update the documentation...\n. Why are you invoking uploadStoredFiles inside of a callback?\n. What are you trying to do here exactly?  Why are you using manual upload mode (autoUpload: false) in the first place?  Where is this file you want to add to the \"queue\" coming from?\n. Why don't you just set the autoUpload option to true (the default)?  Then there is no need to ever call uploadStoredFiles.\n. What logic are you using to determine when the files should be uploaded then?  It's not clear from your explanation why you wouldn't want the files to be uploaded automatically.\n. Please show me your uploader code.  I'm still not sure why you don't simply let Fine Uploader manage the uploads based on the number of open connections.\n. When autoUpload is set to false, Fine Uploader doesn't actually add the file to the internal list of \"stored\" files until after the onSubmitted callback is invoked.  I'd have take some time to examine the related commits to determine why that is.  \nIt probably makes sense to store the file internally if autoUpload is set to false before we invoke the onSubmitted callback (but after onSubmit).  The rules are a bit different when autoUpload is set to true though.  In that case, I think the current internal order of events is appropriate.\n. Will probably look into this as part of 5.2.3.\n. @KRTac @bjornbos The fix for this is currently being staged in the develop branch as part of 5.3.0-5. Please let me know if this fixes your issue.\n. Thank you for your contribution, and I can see these changes as potentially useful, but a couple problems:\n1. The PR is against master.  All development is done in the \"develop\" branch.\n2. There are some linting issues with your code.  I can take care of those though when I get some time to look over this proposal a bit more.\n. If you could, please do.  I hope to find some time this release cycle to take a closer peek at the proposed changes.  Thanks!\n. The build only rejects PRs targeting the master branch.  The build failed in this case due to linting issues.\n. After some more thought, I'm apprehensive about adding more complexity to the code when it's fairly easy to contribute your own custom validation rules via the submit or validate callbacks.  For example, if you want to reject any files that have a .txt extension:\njavascript\nvar uploader = new qq.FineUploader({\n    callbacks: {\n        onSubmit: function(id, name) {\n            return qq.getExtension(name) !== \"txt\";\n        }\n    }\n});\nAs far as calculating the file sizes using base 10 vs base 2, I can perhaps see adding that as an option in a future release, but this isn't something I'd like to look into anytime soon unless there are a number of requests from users.\n. Thanks.  We'll probably adjust this to include a link to the initial file lists feature page.\n. Docs have been updated (with the requested link as well).  This will be pushed out with 4.3 on Monday.\n. The first item in the list has not been fully addressed.  Please see this SO question for more details.  http://stackoverflow.com/questions/21362650/fine-uploaders-deletecomplete-event-hook.\nI was looking for a note indicating how event handlers should be registered in \"non-jQuery mode\", as well as in \"jQuery mode\".  For example, with OR without the jQuery plug-in wrapper, this is acceptable: \njavascript\ncallbacks: {\n    onDeleteComplete: function(id, xhr, isError) {\n        //...\n    }\n}\nThis syntax is only acceptable when using the jQuery plug-in wrapper:\njavascript\n$(\"#my_uploader\").on(\"deleteComplete\", function(event, id, xhr, isError) {\n    //...\n});\n. We don't maintain build archives, but every single version of the source since 2.0 is tagged and and available in the releases section of the Github project.\n. It looks like you are a license holder as well.  If you send an email to us from the address you used when purchasing the license, I'll be happy to build a 3.9 version and send it to you.\n. Please send a message to licensing@fineuploader.com.\nOn Tue, Jan 28, 2014 at 2:23 AM, kristoffernolgren <notifications@github.com\n\nwrote:\nSure! what e-mail should I use? I can't find one on your webpage.\n2014-01-27 Ray Nicholus notifications@github.com\n\nIt looks like you are a license holder as well. If you send an email to\nus\nfrom the address you used when purchaing the license, I'll be happy to\nbuild a 3.9 version and send it to you.\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/Widen/fine-uploader/issues/1111#issuecomment-33381405>\n.\n\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1111#issuecomment-33458953\n.\n. I'd love to improve the build file, but it's probably not going to happen anytime soon, due to time constraints.\n. :thumbsup: Glad to see this happening.  I'll also be glad to rid this repo of coffeescript.\n. I'll take a peek myself sometime this weekend.  Is the only difference between your machine and travis the node version?\n. BTW, we really should be linting the build files as well...\n. 3bfac4e46b4311d95779c829018104df5dcaf77c = sweet.  :fu: coffeescript\n. GTM => develop\n. @feltnerm What's left here, if anything?\n. This probably isn't ever going to happen due to the risk and complexity of the required changes, and the minimal benefit.\n. This was closed due to the lack of real benefit, in my opinion. Not to mention the fact that aggregating all files into a single request means you cannot utilize many of the advanced features including and associated with chunking. On top of this, you run the real risk of hitting server-side request limits with this approach. Is there some significant benefit of a single request for all files that you can report?\n. Consider using the form support feature, or extracting the data from these form fields yourself and then passing them along to Fine Uploader before uploads begin using the setParams API method. The form data will be included with every file upload request. \n\nIf you run into trouble implementing this, please consider asking for further help on Stack Overflow under the fine-uploader tag. Be sure to include all of your code and a specific question if you do this.\n. The easiest solution would be to use the form support feature to send all form field data with every file automatically. You can perhaps then contact your server in your onAllComplete handler just to let it know that all uploads are finished.\nThere is no real need to be concerned about how the files are sent, regardless of the browser. Fine Uploader creates a satisfactory layer of abstraction that gives the appearance of ajax uploads in older browsers by utilizing hidden iframes. If you have any further specific questions, please see our support page at http://fineuploader.com/support.html.\n. I think \"absurd\" is a bit strong here.  It's quite common and reasonable for a library to have conventions in place to make integration more straightforward.  You can already define the conditions for success in your server code.  The currently required success element in your server's JSON response is simply a signal to Fine Uploader from your server that everything is A-OK.   I can understand wanting to override this convention in some cases to allow more client-side control, or to support legacy systems where the server's response is not negotiable, and this enhancement is covered in #995.  Feel free to add your thoughts to that case as well.\n. Well, that depends entirely on the decisions that need to be made.  What sort of logic are you attempting to execute in this handler?\n. This type of very custom validation is indeed quite difficult with this limitation.  One workaround until this is adjusted may be to cancel the file in your submitted handler if it is invalid.  We'll discuss this internally on Monday.  At the very least, this will be adjusted as part of the next scheduled release (4.3), but the release probably won't happen for another couple weeks.  We generally like to avoid rushing out a hotfix unless the issue is critical to a majority of users, or the issue is generally severe, as rushing out anything increases the risk of regressions.  Another option would be for us to commit an adjustment to the develop branch, and you could use that with the understanding that this is pre-release code.\n. I'll look into a permanent adjustment during this current (4.3) release cycle.  This seems like 2 SPs at the moment.\n. This is complete in the develop branch and will be released with 4.3.\n. Fine Uploader also supports IE8 and older, none of which will accept this as a valid tag without ensuring createElement is executed first in IE8 and older.  So, to make all browsers happy, we would need to ensure Fine Uploader makes this call before rendering the template where appropriate.  Also the method of filling the progress element differs from the way Fine Uploader currently animates progress.  \nSo, in order to properly support this, internal code changes are required and we would need a fallback in place for older browsers.  Also, this would represent a breaking change to the UI and any custom css rules that integrators are already relying on.\n. Actually, the part about IE8 support in my message above is irrelevant since progress is not displayed in IE9 and older anyway.  However, the rest of what I said is still true.  \nI'll mark this as a potential feature for now, but it's unlikely this will be implemented in the near future due to it's nominal usefulness in a general sense.  You could replace the existing progress bar in the HTML with a progress element and drive it via callbacks yourself, and that is the recommended approach if you want your app to use the progress element at this time.\n. In order to properly implement this, Fine Uploader's template module would have to detect that the progress bar is a <progress> element, and update this element as the file progresses using the API specific to this element.\n. What should Fine Uploader do if the progress element isn't supported (i.e. Android and some older browsers that still support XHR2 progress reporting)?\n. No plans to add this to Fine Uploader UI directly. But react-fine-uploader includes a <ProgressBar /> component that does use the <progress> element. Still, even in that case, I may provide a fallback that resembles Fine Uploader UI's  custom progress bar, since the native <progress> element is not trivial to re-style cross-browser.\n. It looks like the ETag header is only returned in the response to multipart encoded POST requests that Fine Uploader S3 sends.  These requests are only sent for non-chunked uploads.  For chunked uploads, ideally, S3 would return an ETag in response to a Complete Multipart Upload request, which is sent by Fine Uploader S3 after the last part has been uploaded, asking S3 to combine these parts into a completed object.  No such header exists on this response though.  So, we can certainly include the ETag in the upload success POST, when available.  \nRegarding this comment:\n\nI'm handling this by prefixing the upload key with the username, and refusing to sign policy documents outside the user's namespace. This works okay, but requires integrators to configure objectProperties.key, and also requires that the front end have access to that username. It also makes anonymous uploads tricky to handle.\n\nNote that you don't need to include any key-determination logic client-side, if you don't want to.  The objectProperties.key option accepts a promissory function as a return value.  This is most appropriate if you want to delegate key name determination to your server, via an ajax request.\n. It should be quite simple to do this for non-chunked uploads.  In the develop branch, more of the code used to send this upload success request has been generalized during a refactor attached to the Fine Uploader Azure development.  The parameters passed to the upload success endpoint are determined for the S3 module in the override of the general _getEndpointSpecificParams function.  Currently, only the file ID is passed in.  The general code that calls this function will need to additionally pass the associated XMLHttpRequest object so the S3 module can extract the ETag header from the response and include it as a parameter with the upload success POST.\nSeems like, at most, 2 SPs.\n. Note that the client will not be able to extract any data from the signed policy without access to your secret key.\n. Yes, this could potentially be extracted from the base64-encoded policy, but not the signed policy.  Also, decoding the base64 encoded policy in IE9 and older will require us to pull in Crypto.js, since these versions of IE don't implement atob.\n. This has been implemented in the develop branch as part of 4.3.0-10.  As previously mentioned, an etag property will be included with the upload success POST request for all non-chunked uploads in all browsers.\n. That's correct.  That ExposeHeader rule must be part of your CORS\nconfiguration if you want the ETag passed to your signature handler for\nXHR-based uploads.  It's also required if you are using chunking with the\nS3 uploader.\nOn Thu, Feb 13, 2014 at 11:05 AM, Paul Melnikow notifications@github.comwrote:\n\nHi there,\nThis is working well when ETag is set on the\nbucket's CORS policy.\nWhen that header is not set the upload completes normally, but this\nmessage appears in the console:\nRefused to get unsafe header \"ETag\" s3.jquery.fineuploader.js:6995\nqq.extend._getEndpointSpecificParams s3.jquery.fineuploader.js:6995\nqq.nonTraditionalBasePrivateApi._onComplete s3.jquery.fineuploader.js:6626\nqq.uiPrivateApi._onComplete s3.jquery.fineuploader.js:4744\nqq.extend._onComplete s3.jquery.fineuploader.js:8870\noptions.onComplete s3.jquery.fineuploader.js:2041\nuploadCompleted s3.jquery.fineuploader.js:8392\n(anonymous function) s3.jquery.fineuploader.js:8327\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1118#issuecomment-35000457\n.\n. Yes.  There is no configuration option in place to tell Fine Uploader whether your server is interested in the ETag or not.  It attempts to grab the ETag in the response from AWS for all XHR-based uploads with the addition of this feature.  The CORS spec infers that the ETag header is not a \"simple\" one, and therefore can only be accessed by the client in the context of a cross-origin request if the server explicitly allows it.  When you add the ExposeHeader rule to your bucket's CORS XML configuration, this tells S3 to include an Access-Control-Expose-Headers header in its response, with the value of \"ETag\".  Only then can Fine Uploader read the value of this response header.\n\nWe probably need to update the documentation to mention that this CORS rule is now needed for all XHR uploads, even if chunking is turned off.  I suspect the vast majority of users already have chunking turned on if they are using Fine Uploader S3 (there is very little reason not to).  So, while this was another unintended breaking change, it's a small one.\n. Thanks for this suggestion Paul.  I think it does make sense to default to SSL unless the scheme is not explicitly specified via request.endpoint.  I'll schedule this for the current release cycle, and hope to work on this after the current feature I'm implementing, #781.\n. Looks like we simply need to adjust the logic in the S3 module's endpoint store override to make this happen.  Sounds like 2 story points, at most, with adjusted unit tests.\n. @feltnerm Is working on a response to your email as well.\n. This has been completed in the develop branch as of 4.3.0-11 and should be eventually released as part of 4.3.\n. This feature was reverted as part of 4.3.1 via 09cb5ef18eceb934171d36070f6cf4b10c1341d9.\n. I could see allowing both policy signature responses and REST header signature responses to include key property that overrides the key for that specific object.  This is something we can discuss for a future release, perhaps 4.4.  \nIn the case of non-chunked uploads, the server would have to modify the policy JSON (replacing the key) sent by Fine Uploader and then sign it.  Client-side, Fine Uploader S3 would have to adjust the key parameter before sending the MPE upload POST request.\nIn the case of a chunked upload, this is a bit more complicated.  A number of requests are required to upload a chunked file to S3.  Suppose we have a file that is to be split into 2 parts.  This will require 4 requests to S3: 1 Initiate Multipart Upload POST, 2 PUT requests (one for each chunk), and 1 Complete Multipart Upload POST.  A signature request precedes each of these as well.  The integrator's server would have to ensure that the key name is only changed when Fine Uploader S3 requests a signature for the Initiate Multipart Upload request.  Changing the key in the middle up a chunked upload would have unpredictable results.\n. @Venorcis It's unlikely that this will be completed anytime soon, if ever. There is very little cost in terms of integration work to use the chunking feature when uploading to S3, and the benefits are usually quite substantial. Building a feature that depends on non-chunked uploads is very low priority.\n. Thanks for reporting this.  Looks like a regression caused by work on the #819.  We'll fix this in 4.3.\n. This has been fixed in the develop branch, and will be part of the 4.3 release.\n. Fixed in the develop branch, to be part of 4.3.\n. getUploads returns an array only when there is a potential for the operation to return more than one file in the result set.  This excludes queries for a specific, single ID or UUID.  All other queries will return an array.  \nWe will update the documentation to point this out.\n. The getUploads method documentation has been updated, along with the feature page that discusses its use w/ examples.\n. What are the sizes of each file?\n. I suspected this was the case.  The file types have nothing to do with what you are seeing, instead, the sizes account for this difference in behavior.  \nWith chunking enabled, Fine Uploader S3 will chunk any file that is greater than 5 MB (the minimum chunk size allowed by S3).  Uploading a file in pieces to S3 is much more complex than uploading the entire file in a single request.  \nFor a non-chunked upload, we're just sending a POST with the file data.  For this request, we have to construct a policy, and then we POST this policy to your server for signing.  The signature, along with the base64 encoded policy must be included in the payload of the request containing the file.\nFor a chunked upload, we must use S3's REST API.  There is no policy document involved here.  Instead, the signature is created using properties of each REST call, such as headers and the endpoint.  For example, say a file is 9 MB.  If chunking is turned on, Fine Uploader S3 will send 4 requests to S3: 1 to initiate the series of requests (POST), 2 for each chunk (PUT), and then a final POST to ask S3 to combine the parts.  For each request, Fine Uploader S3 requires your server to generate a signature, which is part of the Authentication header for each request we send to S3.  A string containing all relevant data to be signed is sent to your signature endpoint in this case, instead of a policy document.\nFor more information, please see the S3 server-side notes documentation.  There are also PHP, node.js, Python, and Java examples in the fine-uploader-server repository that demonstrate handling of REST and non-REST signature requests.\nIf you don't want to handle both types of signature requests, you will need to turn off chunking, but that means auto-resume will no longer be available, along with a number of other features and efficiencies tied to chunking.\n. You don't need to generate policies at all server side.  Fine Uploader S3 will generate a policy for you for non-chunked upload requests, and send the policy to you.  Your server then signs the policy, returns the signature, along with a base64 encoded version of the policy.  \nFor chunked uploads (REST requests), there is no policy involved.\n. ...and yes, it would appear that your server simply isn't accounting for the signature Fine Uploader is expecting for REST requests it makes.\n. This message indicates that your signature server is not properly signing the headers string that Fine Uploader S3 is sending in its POST.\n. You are correct.  Fine Uploader S3 probably should lower-case these parameter names.  I'll make sure this adjustment is part of the upcoming 4.3 release.\nI'm going to re-name this issue appropriately.\n. This has been fixed in the develop branch and will be part of the 4.3 release.\n. The issue tracker is for bug reports and feature requests.  Please see the support page at http://fineuploader.com/support for information on obtaining technical support.\n. Looking a bit closer at the code, there are two causes:\n1. Removal of the <input type=\"file\"> in the common form upload handler's add method.  This is called when a new file is submitted to the uploader.\n2. The call that appends the <input type=\"file\"> element to the hidden form that Fine Uploader submits to trigger the upload.  This uses Element.appendChild, which removes the element from its current location, into the hidden <form> that Fine Uploader creates.\nSolving the first issue probably won't be difficult, but the second issue may be a bit tricky to work around.  We can't simply clone a <input type=\"file\">.  If we do, we lose the file attached to the original element, so that's no good.  Fine Uploader will probably have to move this <input type=\"file\"> back under its original parent after the form has been submitted or clone it and move the clone back under the parent of the original input.  I'm not sure if we need to wait until after the form submit is complete, or if we can do this immediately after triggering submit().  \nWith all of this in mind, it's not clear that Fine Uploader should event try to solve this \"problem\".  The integrator passing the <input type=\"file\"> to Fine Uploader's addFiles method will likely want to remove and re-add this element anyway (to clear it) if it is to be re-used for additional files later.  \nPerhaps the best solution is simply to advise integrators to clone or re-create the <input type=\"file\"> after submitting it via addFiles, or simply attach the input element to Fine Uploader via the button or extraButtons options.\n. You will need to build a copy of Fine Uploader, and include that JavaScript file.  See the building section in the documentation.\n. Without any code or real information here, I can only assume that the issue is most likely in your server code.  Fine Uploader doesn't have any issues with special characters that I know of.\n. I was just able to reproduce on our S3 demo on fineuploader.com.  I suspect the issue is a regression caused by work on #1119.  I haven't looked at the root issue yet, but I suspect it only affects installations that specify their S3 request.endpoint without a scheme.  Can you show your client-side Fine Uploader integration code?  What is the exact value of your request.endpoint option?\n. My guess is that you are using a custom domain/CNAME for your S3 bucket, and are also not specifying the scheme.  That seems to be the recipe for reproducing this.  I'll wait for more information about your situation.  If this does match your endpoint name, then simply changing your request.endpoint from \"mys3domain.com\" to \"http://mys3domain.com\" should fix this issue. I'm going to consider reverting the #1119 feature as it's usefulness is minimal and apparently will cause issues with custom domains.  I overlooked this situation.\n. That doesn't sound like something related to the SSL issue I just\ndescribed.  A status of 0 usually occurs in this context when there are\nCORS issues, so you may simply have a bucket configuration issue, or\nperhaps something is interfering with the reuqest between the client and\nS3.  You'll need to provide the actual request headers for the failed\nrequest (according to a proxy) along with your bucket's XML CORS\nconfiguration.\nOn Mon, Feb 10, 2014 at 8:56 PM, Shaun notifications@github.com wrote:\n\nOur request.endpoint is set to foo-bucket.s3.amazonaws.com. I'll try\nexplicitly setting the scheme when I get to the office tomorrow.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1129#issuecomment-34722209\n.\n. @paulmelnikow Yes, SSL will simply not work if you are addressing your bucket via a custom domain or if your bucket name contains a period, as you mentioned.  I knew this (at one time) but it escaped me while working on #1119.  \n\nI'm inclined to revert #1119 and leave it up to the integrator to determine if SSL is important/appropriate for them.  If it is, then they will need to explicitly declare this in the request endpoint value.  This seems reasonable.  The new default imposed by #1119 is indeed a (unintended) breaking change, which is something we avoid outside of a major version release, as it violates semantic versioning to introduce a breaking change (for the most part) in a non-major version release.  We like to follow semver closely.  \nEven as part of a major version release, I avoid breaking changes unless the changes bring about substantial improvement in some aspect of the library.  #1119 doesn't fit this definition, in my opinion.  We'll discuss the fate of #1119 internally tomorrow, and I will open up a new case if we intend to release a hotfix that reverts it.\nI'd like to point out that I don't really think the issue described in this case fits the issue we are discussing regarding SSL.  I don't think @simshaun's issue is caused by a Fine Uploader S3 regression, but I'll need to see request headers and CORS config on the bucket to confirm.\n. Ah, that was missing from your last response.  Yes, the default-to-SSL is the issue here, and you can resolve this even before we make any changes/reverts by simply specifying a scheme.  We'll be discussing a way to deal with this internally tomorrow, and I'll keep this issue updated.\n. Fixed in 4.3.1.\n. It doesn't look like that instance of qq.FineUploaderBasic is ever used in the standalone DnD module.  And, it probably should never have been constructed in the first place as the DnD module is not supposed to depend on Fine Uploader at all.  I'll take a closer look in an hour or two.  Does removing this one line fix your issue?  I'll need to figure out why this causes a failure either way.\nOut of curiosity, why are you using the standalone DnD module?  Are you utilizing Fine Uploader core instead of UI?\n. I agree that this line of code shouldn't exist, and it will be removed, but I'm a little confused as to why this would cause an exception.  As long as fine uploader is loaded on the page, there should be no issue.  Every version of Fine Uploader (S3, Azure, UI) inherits from qq.FineUploaderBasic, so this should always be available as long as Fine Uploader is on the page.  Is it possible that Fine Uploader is not loaded before the standalone DnD module is attached to an element?  \nWe are using Fine Uploader core with the standalone DnD module in one of our products at Widen as well, and haven't seen this issue.\n. It looks like this odd line of code has existed, undetected, since the wrapper for the standalone DnD module was created in 8fe94ae59874ff7507617fddac6473016fa68a73.\n. Ah, yes.  I think you are completely correct.  Nice debugging effort!  The project we are using the standalone DnD module in does not utilize Fine Uploader S3, which would also explain the lack of an issue on our end.  \nI'm not sure how many are using Fine Uploader S3 with the standalone DnD module with the jQuery wrapper, but this issue will certainly cause problems for them.  This issue has definitely existed since version 3.8 (August 16, 2013), and you are the first to report it.  This makes me think that very few individuals are utilizing the standalone jQuery DnD module with S3 (or Azure).  So, I'm not sure this qualifies for a hotfix release.  Instead, I'd like to fix this as part of the next scheduled release (4.4), due out in about a month. \nThoughts?\n. If we are forced to push out another 4.3 hotfix, this will definitely be part of it.  I try to avoid pushing out hotfixes unless the issue affects a large number of users, as hotfixes are generally released in haste, and that sometimes lead to more bugs.  The DnD-related code is notoriously difficult (impossible) to unit test, which makes it easier for bugs to slip through.  It's also quite brittle due to all of the browser-specific hacks in place, due to the nightmare that is the HTML5 drag & drop API.\n. These messages are generally not targeted at end users, as there is nothing the end user can do to solve this problem.  Instead, they are prominently displayed to make it easier for the end user to describe the issue to the integrator (you).  I can see providing options that make it simple to override these default messages for S3 in the future though.\n. BTW, the dfstudio.com home page is pretty sweet.\n. Valid point.  At the very least, we can update these messages, but it may be useful to provide overrides via options as well.\n. This will be adjusted in 5.1.0.\n. Yes, that seems reasonable.  In fact, the X-Mime-Type should probably be removed entirely, and the Content-Type should contain the MIME type of the file (for non multipart encoded requests).  For multipart encoded requests, the MIME type of the file is already provided in the header section of the file's multipart boundary.\n. I would also, personally, change if (file.type !== \"\") to if (file.type).  That new condition will evaluate to false if file.type is null, undefined, or an empty string, plus, it's a little easier on the eyes.\n. When completing this task, the code should also be updated to check the custom header array first. If any user-provided headers exist, such as Content-Type, we should refrain from setting that header with some default value anywhere else. Surprisingly, XMLHttpRequest.setRequestHeader will append the passed value if the header has already been set. This is a bit non-intuitive, and I wasn't aware of this behavior until today.\n. This will definitely be part of 6.0\n. Should have mentioned this issue in 0b94f39d412314bd88e856ac1d00d43b5b1eed97.\n. This 2nd part of scaling is complete.  On to the (hopefully) last step: #1139.\n. Regression caused by this feature caught and fixed in 366f15582b522bad94c97629c8233e5cd4a7de3c.\n. This enhancement is not targeted for 4.4.\n. No one seems to be interested in this, and support may not be trivial.  Closing.  We can re-open if users express interest.\n. We will look into updating the documentation, but the appropriate time to call onUpload is strictly a matter of personal preferences.  The event is consistently called whenever a file upload kicks off.  If an attempt fails, onUpload is called when the upload starts up again when it is retried at some point in the future.  onUpload is really very appropriate for a resume, since this generally happens when a previously submitted and failed/aborted file from another session is submitted in a subsequent session, and Fine Uploader picks up where it left off using the auto resume feature.  The logic for firing onUpload on a retry can be (and is) applied to a continuation of a paused upload.  \nWe'll discuss more internally and update.\n. ...I could see passing an additional parameter to onUpload that provides more context, such as a flag or flags that indicate this is associated with a resume oe retry.\n. A retry is not a resume.  Also, continuing a paused upload is only implemented as a resume.  As far as the user is concerned, it's a \"continue\".\n. The pause/continue feature itself is a higher-level abstraction that the lower-level upload handler code is (mostly) not aware of (which is nice).  When a user \"pauses\" an upload, the higher-level code asks the lower-level upload handler to abort the upload request.  When a continue is requested, the upload handler is simply asked to \"upload\" the file, and its internal logic ends up resuming the upload, since at least one chunk uploaded successfully and there is persisted data to represent its progress when it was interrupted.\nIn an attempt to keep each piece of Fine Uploader's internal code focused on a specific job, these sorts of leaky abstractions are bound to pop up from time to time.  I agree, a flag does seem like a reasonable solution to all of this, without creating any breaking changes.\n. We'll just update the documentation here to better clarify when this event is called.\n. Thanks for your request.  We'll discuss this internally at our next planning meeting.  Note that this feature falls pretty far outside of the job of a file upload library.  Unless a number of other users request this, it is unlikely that it will be completed in the near future.  In the meantime, you can update the DOM accordingly via javascript after the initial file list has been added.\n. No one else has expressed interest, and, as I said earlier, this is a bit outside the scope of an upload library.  Closing, but can be re-opened if others express interest.\n. Hmm, this seems to have fallen through the cracks when we updated our download/build system. I'll be sure to have this fixed when 5.3.0 is released. In the meantime, you can build all.fineuploader.js by following the instructions in the building Fine Uploader guide. \n@ayelkawar2 I'd be happy to build the version of your choice for you and send the combined version via email. If you're a license-holder, send an email to support and I'll get back to you with a zip file.\n. My plan is to simply publish an additional combined JS file that includes Azure, S3, and the traditional endpoint handler. This will essentially be the all.fineuploader.js file that is created (but not published) when the build is run. Not sure if I'm going to provide one w/ and one w/out the jQuery wrapper though. I'd love to just build one w/out.\n. Completed as part of 5.3.0. This is the last scheduled case for 5.3.0, so if testing goes well release will be next.\n. Does anyone know if this is an issue with recent Surface tablets?\n. Closing, but willing to re-open if this is still an issue.. \n. We can't really support scaling or blob uploads in Android stock.  The only way to upload a Blob in Android's stock browser is to convert the Blob into an ArrayBuffer and send it as the sole contents of the request body.  Unfortunately, you can't send an ArrayBuffer in a multipart encoded request as FormData.append doesn't accept anything other than strings, Files or Blobs.\n. Everything looks ok to me here.  Headers are only sent with REST calls.  The request you have referenced above is not a REST call.  Instead, it is a multipart encoded POST request.  AWS allows files to be uploaded in a single multipart encoded POST request, and Fine Uploader sends all files this way in IE9 and older, as well as if chunking is turned off, or for any submitted files that are below the minimum chunk size of 5 MB (even if chunking is turned on). \nIf a file is uploaded via a multipart encoded POST request, the appropriate location for this directive is inside of the request body.\nThe 403 you are seeing is likely caused by some other issue either with your bucket policy or the signature you are providing.\n. Another option is to simply not mandate encryption via your bucket policy.  Sure, a malicious user could rip off or modify the encryption header/param from the request, but:\n- The request will fail if they do this after your server signs the request\n- If you add some logic on your server that checks for the existence of this header/param in the policy/header string, you can reject the request/not sign it if this header/param is missing.  This will prevent them from attempting to get around this directive by removing this header/param before your server signs the request.\nIn the end, you are still mandating server-side encryption.\n. Any idea if this has been fixed by Amazon yet?\n. No problem. Thanks for the update just the same.\n. For consideration for a future major version release, due to breaking changes.  There is no immediate need for this now.\n. No real gain here, and breaking changes.  Closing.\n. Only 1 request for this.  Closing, but can be re-opened if more uses express interest.\n. What do you mean by \"path\"?\nOn Friday, February 28, 2014, sebastianzebrowski notifications@github.com\nwrote:\n\nAFAIK there's currently no way of setting path of uploaded file. To do\nthis Amazon needs 'starts-with' rule in Conditions object.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1150\n.\n. There is no need to worry about policy documents client side.  Fine Uploader will construct a proper policy document with the correct conditions based on the object key.  You can specify whatever key you like per file by providing a key function.  See the objectProperties.key option in the documentation for more details.  \n\nFurthermore, there is no need for a starts with condition if we know the exact key name, which we always do.\n. Is there any reason you can't use the request.customHeaders option?\n. I'll close this then.  Also, all pull requests need to be against the develop branch.\n. I just removed my last comment after some brief thought.  Is there any reason why you can't simply adjust this in your app via CSS?  It should be very simple:\ncss\nINPUT[name=\"qqfile\"] {\n    height: 100%;\n}\n. Setting the height to 100% will likely not be sufficient to overcome your specific issue in older browsers.\n. We can look into this for a future release.\n. We will likely look into this as part of 5.1 development.\n. This is likely going to be part of 5.0.5.\n. ...along with #1277\n. @max-mykhailenko and/or @raulferras are you interesting in testing out 5.0.5-4 to confirm that my adjustments address your issues?\n. Caught and fixed (in 5.0.5-5) an issue caused by the last fix.  Turns out that the file input is no longer clickable in IE7 if the height is set to 100%.  I simply don't set the height to 100% in IE7 now.\n. Hey, nifty tool!  We'll have to look into integrating that into our docs site.  \nWe'll fix that typo shortly.\n. I'm going to open up a case for us to investigate integration of proofreader into our docs site.\n. This is pretty much what Angular does for their docs.  See the \"Improve this doc\" button at the top-right of any doc page at http://docs.angularjs.org/api.\n. @feltnerm Any chance this will be done in the next week or so for 5.1.0?\n. pushed to 5.2\n. Doesn't look like this is going to happen any time soon, and I have more important cases to attend to.  So, I'm going to refrain from tying this to a release and hope it is completed someday, but I'm not sure this is critical.\n. Why do you want to disable client generated previews altogether?\n. It sounds like the real issue here is preview image quality.  Please attach some of the original images that are causing you a problem so we can look into the preview quality issue you are seeing.\n. No response after 8 days, closing.\n. Also, consider reporting the number of seconds left before the next retry in the UI.\n. Seems interesting, but unnecessary.  I'm going to close.  Let me know if you really want to do this @feltnerm.\n. @engagingcomms You can send the files to whatever location you choose, as the server is entirely under your control.  Fine Uploader is exclusively a client-side library.  You can use Fine Uploader's traditional endpoint handler to send files to your specific server, where you can then relay the files to Google Storage using the GS API.\n. It looks like GCS supports CORS, so it seems like we could upload directly to a bucket from the browser, \u00e0 la Fine Uploader S3/Azure.  Is this what you are wondering about?\n. It's something we can look into directly supporting in a future release.  Theoretically, it's possible without our intervention, but a specific Google Cloud Storage module for Fine Uploader would make it easier, so you don't have to worry about the details of the GCS API.  We'll discuss this internally.\n. We might be able to easily support this via the s3 compatibility layer provided by cloud storage.\n. The work completed in #1332 may make this possible, assuming the Google Cloud Storage S3 integration layer is enabled.  Any Google Cloud Storage users want to confirm with the pre-release of 5.1.0?  If you find issues, we'll fix them as part of 5.1.0.  Otherwise, we'll look into this more in a future release.\n. We plan to release 5.1.0 this week, so you will be able to give this a spin in the released version.\nOn Mon, Dec 29, 2014 at 5:57 PM, kngtr notifications@github.com wrote:\n\nHi - How can I get a copy of the pre-release of 5.1.0?  Thanks.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1158#issuecomment-68316969\n. @kngtr Have you downloaded 5.1?  If so, are you interested in using it to upload directly to Google Cloud Storage?\n. We have a number of Fine Uploader S3 PHP samples in the server-examples repo.  You'd use Fine Uploader S3 and setup Google Cloud Storage to use S3 compatibility mode.  The S3 feature page will provide some additional details, if you need them.  Uploading to Cloud Storage with S3 compatibility mode enabled would qualify as an \"S3-like\" endpoint, which, in theory, should be supported now after changes made in 5.1.\n\nWhen constructing Fine Uploader S3 client-side, you'd need to specify the Cloud Storage endpoint as request.endpoint and the bucket in objectProperties.bucket.\n. @bryangoldberg What, specifically, are you stuck on?  The Google Cloud Storage docs cover a \"simple migration\" from S3 to Cloud Storage, which allows a CS endpoint to be treated as if it were an S3 bucket.\n. Has anyone had a chance to test this out with Google Cloud Storage's S3 compatibility mode yet?\n. You'll need to ensure all access keys server side are your cloud storage keys.  Also, the credentials.accessKey client-side Fine Uploader S3 option must be set to your GCS access key.\n. Shelving this until sometime after 5.3, unless someone reports success using Fine Uploader S3 w/ CDN support in the meantime.\n. Can you describe the changes, or simply open up a pull request so we can discuss further?\n. If you could include that list in the PR or at least reference this issue, that would be helpful. I'm currently traveling, but will look closer once I get past a number of other items in my fine uploader queue first.\n. No build steps are needed for doc changes. I have a webhook setup that listens for pushes to each branch, and docs are updated for the associated branch at http://docs.fineuploader.com. Develop = \"in progress\", master = root, other branch docs can be seen at http://docs.fineuploader.com/branch.\nPull requests that only cover documentation can be made against master, otherwise all PRs should be against develop. What changes to Fine Uploader code, if any, are required?. >Will you have GCS as a supported endpoint in Fine Uploader \nI don't have any plans to implement this myself in the foreseeable future. Your best bet is to use GCS in S# compatibility mode and follow #1674. Once that is completed, it should be relatively easy to upload to GCS from Fine Uploader. . The templates do not cover alerts/messages.  The angular example that Mark referenced uses bootstrap 3 and provides everything you are asking for here, as far as I can tell.  Bootstrapping an uploader is a simple as adding the appropriate bootstrap CSS classes to the template elements.  The styling guide provides more information as well.\nWe can look into updating the bootstrap example on the demos page.\n. Task here is to upgrade demo bootstrap example to use v3.\n. No plans to do this anymore. In fact, I'd like to move away from boostrap entirely.\n. Total progress is not dependent on any server side module.  If you are a\nlicense-holder, simply make sure the \"total progress\" option is checked\nwhen you build your custom version of Fine Uploader, and the proper module\nwill be included in the combined JavaScript file.\nOn Tue, Mar 11, 2014 at 7:35 PM, Boris Reitman notifications@github.comwrote:\n\nOK, I now understand that Total progress module is something that must be\ninstalled on the server.\nI don't want to do that. I want a progress bar for individual file. Can\nyou point me to an example where your \"progress\" event is handled and a\nbootstrap 3 progress bar is updated.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1160#issuecomment-37363587\n.\n. The required module is included in all builds produced by the build\ninstructions on the contributing page.\n\nOn Tuesday, March 11, 2014, Boris Reitman notifications@github.com wrote:\n\nI am not a license holder yet as I would like to see try integrating it\nfirst. How can I build that module given that I cloned the project from\ngithub and followed your build instructions.\nhttp://docs.fineuploader.com/branch/develop/contributing.html\nI am asking because totalProgress is not working for me even thought I\nhave it in the template.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1160#issuecomment-37366412\n.\n. It looks like the total progress feature docs are severely lacking in specifics as far as templating is concerned.  Sorry about that,  I'll fix that in the next 12 hours.\n. I just enhanced the docs in b26401ea116ccdb5d9b9a5ea82f23c0e349b6664.  Note that the default template also contains a total progress fragment.\n. That would require making another call to the S3 API from the browser.  If you need this information for older browsers, you can make a HEAD Object request from your server to get details about an object.  We don't have any plans to make this call in the future from Fine Uploader.\n. Thanks for this.  Can you possibly contribute your exact changes via a pull request in the Widen/fine-uploader-server repo?\n. Thanks for reporting this Rob. We'll make sure those variable names are\nadjust in the next scheduled release.\n\nOn Friday, March 14, 2014, Rob Evans notifications@github.com wrote:\n\nWhen passing the script through Google Closure Compiler it gives errors:\nERROR - Parse error. identifier is a reserved word\nqq.each(bytes, function(idx, byte) {\nvar byteAsHexStr = byte.toString(16);\nqq.each(byteString, function(idx, char) {\nintArray[idx] = char.charCodeAt(0);\nThe words \"byte\" and \"char\" are reserved words in JS.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1163\n.\n. Ah, good catch.  The code GCC is complaining about will never run in a pre-ES5 browser anyway.  We should probably just change those variable names at some point just the same.  I've already scheduled this for 5.0, assuming I ever get past the monster that is #937.\n. Ok.  Please merge into develop, which is where 5.0 is being staged.\n\nOn Mon, Mar 17, 2014 at 5:36 PM, Mark Feltner notifications@github.comwrote:\n\nForgot to add that I fixed this in 59c66cehttps://github.com/Widen/fine-uploader/commit/59c66ce\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1163#issuecomment-37879806\n.\n. Also please version:build\n. This is explained in the comment at https://github.com/Widen/fine-uploader/blob/b26401ea116ccdb5d9b9a5ea82f23c0e349b6664/client/js/s3/util.js#L256.  We could adjust this to a smaller value, but it probably doesn't matter either way.\n. No response for 2 days, closing.  This can be re-opened in the future if new information is included.\n. Thanks for catching this Craig.  This issue has existed since 3.1.0, as far as I can tell.  Indeed we should be checking the length property of the DataTransferItemList here, as you have done in your PR.  \n\nCould you re-open this with a new PR against the develop branch?  We always stage non-doc changes in the develop branch, and only merge into master as part of a scheduled release, as we like to follow the git flow model.\n. It looks like @feltnerm fixed this in develop.  No need to open up a new PR Craig.\n. Craig.  Please open up a new PR against develop for this new issue.  Thanks.\nAlso, I'm not sure about your fix.  If we simply ignore a call with no files, an error will not be pushed out to the error callback handler(s).  I think we might need to look a different adjustment, depending on the exact problem you are trying to solve.\n. Re-opening as this change has caused a regression that prevents DnD in Firefox (and possibly other non-Chrome-based browsers).\n. @feltnerm Is this a problem we need to deal with?  If so, how difficult would this be to solve?\n. Docs will be moving to a GH repo or possibly S3, so there is no reason to keep this open.\n. Are you only seeing this in Safari, or other browsers as well?\n. Note that we do not support Safari for Windows.  \nWe'll take a closer look at this issue in OSX Safari.  Thanks for your report.\n. After glancing at versions of the CORS spec, my guess is that Safari 5.1 (and similar versions) were using a build of webkit that did not include support for the Access-Control-Expose-Headers header.  This wasn't added to the CORS spec draft until July of 2010.  Safari 5.1 was released in July of 2011.  According to this message thread, Access-Control-Expose-Headers support wasn't added to webkit until sometime after November 2011, which means Safari 5.1 definitely did not support this.  According to this webkit/safari bug support wasn't added until mid-January 2012, meaning that the earliest version to contain this support would be 5.1.4 (but possibly even later).\n. @cj if you are seeing this message in a current version of chrome, then the issue is with your bucket's CORS configuration.\n. Safari is on 7.1 at this point.  Not sure there is much we can or should do at this point.\n. Fine Uploader will not let you submit more files than you can possibly upload if the itemLimit option is set.  Is this clear?  If not, please provide more details about your issue so we can determine if this is a bug or not.\n. Are you saying you have only submitted one file, but you are unable to\nselect a second?  Please show your code.\nOn Saturday, March 22, 2014, Nikolaos Michaleas notifications@github.com\nwrote:\n\nSupposing that I need to upload multiple files. If the itemLimit is 2, the\nlibrary will not allow me to select more than 2 maximum files, which is\ncorrect. For some strange reason, if one of the files is uploaded, I cannot\nadd 1 more in queue. The library keeps that I always have 2 files in queue.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1169#issuecomment-38365924\n.\n. I am not able to reproduce your issue with the live demo at http://fineuploader.com/demos#list-number.  Please provide a link to a live version of your app where this can be reproduced.\n. No, this isn't the way the limit works.  As I said earlier.  The itemLimit will prevent you from submitting more files than you can possibly upload.  So, this feature is working as designed.\n. Your changes will cause errors in IE9 and older, as getFile will return a null value.  Also, pull requests must be against the develop branch.  \n\nI'm also wondering why these parameters must be hardcoded.  You can pass any additional params you like to your upload success endpoint via the uploadSuccess.params option or/and the setUploadSuccessParams API method.\n. The size issue has been fixed in the develop branch and will be released with version 5.0.  See #1161 for details.\nIf you want to determine parameters based on current context, you should do so via the setUploadSuccessParams method, inside of a callback.  For example, if you want to include the size of a file as a param, your code may look like this:\njavascript\ncallbacks: {\n    onSubmitted: function(id) {        \n        if (qq.supportedFeatures.canDetermineSize) {\n            var size = this.getSize(id);\n            this.setUploadSuccessParams({size: size}, id);\n        }\n    }\n}\n. You don't need to use that syntax when using jQuery.  You can use the code I provided if you are using the jQuery wrapper or not.\n. No need to use .on( unless you are binding your event handlers at some time after construction of the uploader instance.\n. There is no way to determine file size in IE9 or older.\n. Works fine for me.  There must be some issue with your code.\n. Note that the block you have in your gist will never run in IE9 and older, since qq.supportedFeatures.canDetermineSize will always evaluate to false in IE9 and older.\n. It sounds like you are focusing on the wrong problem here.  I'm hesitant to make any changes to account for fundamental server or network flaws.  If uploads are frequently failing, you might want to look into the root cause.  If it takes a large number of retries to successfully upload a single large file, surely your users must be inconvenienced already.\n. We haven't had any other reports of such an issue.  What version of Firefox, and do you have a set of steps to reliably reproduce?\n. What version of Fine Uploader?\nOn Tuesday, March 25, 2014, Shaun notifications@github.com wrote:\n\nI've reproduced this error 5/5 times on two different PCs under two\ndifferent ISPs/networks. Mine at our office, and through a VPN to a PC at\nour client's office.\n- Both PCs are running Win 7/Firefox 28.\n- For consistency, we are attempting to upload the same 1 GB file on\n  both PCs.\nTo reproduce, we:\n1. Open an S3 upload page 3 times (3 different tabs). Chunked uploads\n   enabled, Retry enabled (10 times max)\n2. Choose the 1 GB file on each page so that all 3 tabs are uploading\n   at the same time.\n3. Wait. We sometimes begin seeing retries near the beginning of the\n   upload, sometimes it takes a few minutes. It always happens\n   eventually.\nUpload speed does not appear to have any effect. Our office connection is\na meager 5 MB/s upload, but it errors. Our client's upload speed is pushing\n800 MB/s, it errors as well.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1172#issuecomment-38640517\n.\n. Thanks.  We will look into this further tomorrow.  This case will be\nupdated with progress and new info as it becomes available.\n\nOn Tuesday, March 25, 2014, Shaun notifications@github.com wrote:\n\nFineUploader 4.3.1\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1172#issuecomment-38642078\n.\n. Note that Fine Uploader doesn't set the Content-Length header, the browser\ndoes, so that's not likely part of the problem here.\n\nOn Wed, Mar 26, 2014 at 12:01 PM, Shaun notifications@github.com wrote:\n\nWe are receiving the error intermittently today just trying to upload a\nsingle file.\nSo, I've been researching the 400 RequestTimeout problem, and it seems\nwe're definitely not alone in having this issue.\naws/aws-cli#454 https://github.com/aws/aws-cli/issues/454\nSolution: They just retry upon receiving 400 RequestTimeout.\naws/aws-sdk-php#29 https://github.com/aws/aws-sdk-php/issues/29\nSolution: They just retry upon receiving 400 RequestTimeout.\nAdditional clue: If you continue to see this issue, please ensure that\nyou are not sending an incorrect Content-Length header in your requests.\nhttps://groups.google.com/forum/#!msg/jets3t-users/jr_8VXzSWU/3EWPjwrUoaYJ\n_Additional clues: S3 is pretty unforgiving about pauses during an\nupload and will return\nan error within a few seconds. But the most likely problem is simply an\nincorrect Content-Length value.\nhttp://www.plupload.com/punbb/viewtopic.php?id=3909\nNo solutions offered, but does give a little insight in to potential\nproblems with Firefox.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1172#issuecomment-38710189\n.\n. I just read the plupload thread, and didn't find anything useful in there.  It's not clear how Firefox is involved.  Do you have firebug open, or any other extension installed?  I've seen extensions and OS antivirus interfere with browser HTTP traffic on numerous occasions.\n. Firebug has been a source of constant pain for me.  I've found builds of it to be quite buggy and generally avoid using it.  Is firebug open when you reproduce these issues?\n. No, this is not something we can overcome. Every browser has some sort of a\nmaximum request size.  A 4.5 GB file is likely exceeding that max, perhaps\nresulting in a truncated request, which is causing AWS to complain.  We can\neasily get around this max request size in modern browsers via chunking, but\nchunking is not possible in IE9 and older.\n\nOn Wed, Mar 26, 2014 at 5:13 PM, Shaun notifications@github.com wrote:\n\nI think you've hit the nail on the head about Firebug.\nWe've uploaded 4 batches of 6 GB files (3 uploads at a time in each batch)\nwith Firebug disabled. The first one is described in the comment above. The\nnext 3 batches all completed without error.\nTried a 5th batch with Firebug re-enabled and the errors began appearing\nagain. Waited until each upload hit 30 errors at only ~20% through and\ndisabled Firebug again. Uploads quickly finished successfully without\nanother error.\nThis is definitely not a FineUploader issue as far as I'm concerned.\nHowever, we are receiving errors in IE9 as well. Log from IE9 console:\nLOG: [Fine Uploader 4.3.1] Received 1 files or inputs.\nLOG: [Fine Uploader 4.3.1] onSubmit - waiting for onSubmit promise to be fulfilled for 0\nLOG: [Fine Uploader 4.3.1] onSubmit promise success for 0\nLOG: [Fine Uploader 4.3.1] Submitting S3 signature request for 0\nLOG: [Fine Uploader 4.3.1] Sending POST request for 0\nLOG: [Fine Uploader 4.3.1] Sending upload request for 0\nLOG: [Fine Uploader 4.3.1] Received response for 0_17574c5e-5bee-4e8c-a8f3-8070f9281507\n[Fine Uploader 4.3.1] Error when attempting to access iframe during handling of upload response (Access is denied.)\nLOG: [Fine Uploader 4.3.1] iframe loaded\n[Fine Uploader 4.3.1] Amazon likely rejected the upload request\nUsing Fiddler2 to inspect the request, we see the response from Amazon:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nMalformedPOSTRequestThe body of your POST request is not well-formed multipart/form-data.5363D49F5B3E1150tyUziamtbIKB30oMbY+AVDeaDg4lL5vkr+r5AGeanX0fme/rWbUJhXRiwGI9lAHI\nIE9 succesfully uploaded a 1GB file then 2x 1GB files at once. It fails\nconsistently with a 4.5GB file. Should I open a new issue for this?\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1172#issuecomment-38747051\n.\n. Yep, I'd have to think about where to put it.  Can you open up a case so I remember to take care of this?  \n\nI guess we can close this one as well?\n. Sure.  I'll reopen this so we can discuss more internally.\n. This will be part of a future release.\n. This has not made it into a scheduled release yet. When it does, the case will be updated appropriately.\n. By the way, while I do agree that the retry count should be reset after a successful chunk upload, I do not agree that this should be reset on a manual retry.\n. This will be fixed simply by resetting the count once a chunk has\nsuccessfully uploaded.\nOn Wed, Oct 7, 2015 at 5:40 AM notken notifications@github.com wrote:\n\nI guess because it's not resetting after a successful chunk, it not\nresetting when you manually retry seems illogical. It just seems like it's\ntotally ignoring the settings.\nWhen testing it with built-in random failures, if I click Retry I'd expect\nit to suffer 3 more random failures before stopping again. But in\nactuality, the moment it's successfully done one after a failure I'd be\nquite happy for it to keep recovering from occasional failure until it's\ncompleted, and only fail if it really couldn't get through at all.\nIt just seems odd to ask for an auto-retry count in settings, and then\nignore it and go for a developer-decided number when you manually Retry.\nMaybe it all needs to be in the settings.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1172#issuecomment-146150028\n.\n. trivial - scheduled for 5.0\n. We use Uglify, which does not have a problem with these reserved words.  Furthermore, these words are only reserved in very old versions of the ECMAScript spec, and the code you are referring to will never execute in these browsers.  We are aware that Google Closure Compiler chokes on these, and a case has already been opened to address this.  See #1163 for details.\n. Yes, if you could provide a video, that would be helpful.  Also, please provide your client-side code.\n. Your markup is a central to your issue, as far as I can tell, as the total progress bar provided by Fine Uploader UI works as expected for me.  I would expect you to use the following markup if utilizing Bootstrap's progress bar instead:\n\nhtml\n<div class=\"qq-total-progress-bar-container-selector progress\">\n    <div class=\"qq-total-progress-bar-selector bar\"></div>\n</div>\nOf course the specific CSS class names depend on the version of bootstrap you are using.  There should be no content inside the qq-total-progress-bar-container-selector other than the qq-total-progress-bar-selector element as the progress-bar element is intended to consume all of the space in the progress-bar-container.\nIf you want to add other text that is dependent on the visibility of the total progress bar, you'd need to rethink your design a bit, and perhaps observe the totalProgress event to show/hide that label in the DOM.\n. I also tested with Fine Uploader S3, and was unable to reproduce.  I would imagine something else in your markup/CSS/javascript is causing an issue for you.  I'd also be happy to take a look if you give me a link to a live app that is able to reproduce.  \nThe line you are talking about is https://github.com/Widen/fine-uploader/blob/55166f33438e4915045f17d8c4e1adea008af19b/client/js/templating.js#L650.\n. Yes, it does indeed look like there may be an issue when a number of very small files are uploaded.    We may need to tweak the total progress calculation code.  I'll schedule this for 5.0 (the current release cycle) and we'll sort this out as part of the next release.\n. Thanks for the compliment @jetheredge.  We certainly try to keep Fine Uploader cutting edge and our users happy.  \nIt's only a tiny bug if it doesn't affect you :wink: .\n. @jetheredge I beleive I have this fixed in 5.0.0-10.  I also added some logic to ensure that progress/totalProgress updates are never repeated.  Furthermore, I normalized non-chunked progress callback arguments to account for the fact that the browser doesn't always return the same value for the total size of a file among all progress events for that file.  If you are interested in testing this out, please let me know as soon as you can,\n. I'll send you something.  Please reply to the last email you received from us.\n. Justin - are you still interested in testing this?\nOn Wed, May 7, 2014 at 4:13 PM, Justin Etheredge\nnotifications@github.comwrote:\n\nI'd be happy to test this out, is there an easy way for me to get a build\nfrom a future version of fine uploader? Currently I just grab it from\nhttp://fineuploader.com/customize.html\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1175#issuecomment-42483892\n.\n. Sure - just send it to my address...\n\nOn Fri, May 9, 2014 at 3:33 PM, Justin Etheredge\nnotifications@github.comwrote:\n\nYeah, I tried to send you an email, I sent it to the last email address I\ngot on a fine uploader email. I guess it did not make it through. Can you\npoint me to an address to email you at?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1175#issuecomment-42710378\n.\n. Due to the number of support purchases, this is likely not worth the effort right now.\n. A few problems with this approach:\n1. The jQuery wrapper is just that, a wrapper.  The internal core code has no knowledge at all of jQuery.  It always depends on these qq functions, regardless if jQuery is available.\n2. The qq namespaced util functions do not have a direct mapping to similar jQuery functions, in terms of API.\n3. There are functions in the qq utils that are not present in jQuery at all.\n\nWhile this sounds like a nice idea, utils.js is less than 9k minified.  Add gzip compression, and you're down to about 3k.  So, it's probably not worth the effort.\n. util.js does not make much of a dent in the size of the library.  And I'll have to disagree with you on the reason for a jQuery plugin.  Size was not a factor in that decision at all.  The wrapper provides convenience for jQuery users.  For example, you can pass jQuery objects to Fine Uploader methods instead of HTMLElements.  You will receive jQuery objects instead of HTMLElements in callbacks.  You can bind event handlers at any time after the instance has been constructed via jQuery.  You can create multiple instances of the library bound to the results of a selector, etc.\nCreating an entirely different version for jquery is definitely not going to happen.  That would add a significant amount of work required to maintain the library (2 versions instead of one).  The wrapper allows us to provide the conveniences of a jQuery plug-in without modifying the core library at all.  Even if we extended jQuery, that would result in additional code.  At that point, we are essentially dealing with a zero sum game since util.js isn't very large to begin with.\nThe library's size depends largely on what components you select via the build mechanism.  Uncompressed, yes, it can be 300k.  But no one uses unminified code in production.  Minified, you're down to about 130k.  Gzipped, we are down to about 35k.  And this hit only occurs on the first load for a user, as subsequent hits are 304's. \n. util.js does not make much of a dent in the size of the library.  And I'll have to disagree with you on the reason for a jQuery plugin.  Size was not a factor in that decision at all.  The wrapper provides convenience for jQuery users.  For example, you can pass jQuery objects to Fine Uploader methods instead of HTMLElements.  You will receive jQuery objects instead of HTMLElements in callbacks.  You can bind event handlers at any time after the instance has been constructed via jQuery.  You can create multiple instances of the library bound to the results of a selector, etc.\nCreating an entirely different version for jquery is definitely not going to happen.  That would add a significant amount of work required to maintain the library (2 versions instead of one).  The wrapper allows us to provide the conveniences of a jQuery plug-in without modifying the core library at all.  Even if we extended jQuery, that would result in additional code.  At that point, we are essentially dealing with a zero sum game since util.js isn't very large to begin with.\nThe library's size depends largely on what components you select via the build mechanism.  Uncompressed, yes, it can be 300k.  But no one uses unminified code in production.  Minified, you're down to about 130k.  Gzipped, we are down to about 35k.  And this hit only occurs on the first load for a user, as subsequent hits are 304's. \n. If you'd like more history on the decision to add jQuery support, and the reason for the implementation choice, you can look at #326.\n. We don't support opera pre version 15 at all.\nOn Tuesday, April 1, 2014, fens notifications@github.com wrote:\n\nLack of URL.createObjectURL support causes Opera 12.16 (Presto/2.12) error\nwhen resizing images. Yes, I know it's old, but we still have many users\nwith older browsers! Fallback to FileReader or feature detection?\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1179\n.\n. Sorry, you'll need to alert your users to either upgrade to a current version of Opera, or use a different browser.  Opera has historically been a difficult browser to work with, and the user base is so small, it has never been worth the effort to support it at all.  Since version 15, Opera is indistinguishable from Chromium (other than the user agent string) which is why it is now supported.  \n\nThere are likely a number of issues with older versions of Opera.  Your best bet is to look for a user agent string that matches older versions of Opera, and alert your users that they are using an unsupported browser.\n. Most available documentation suggests that chunking should be possible in Safari 5.1 (including caniuse.com).  All that is needed is basic File API support, and Safari 5.1 seems to have that.  However, it looks like the slice method is missing from the Blob prototype in some builds of 5.1, which makes chunking impossible.  \nWe'll look into this more and update our chart when we have a better understanding of this limitation in 5.1.\n. @feltnerm You'll also need to update the pause feature in the support matrix for Safari 5.1, as it is dependent on chunking.\n. Thanks @Snake85.  We'll discuss internally and perhaps makes this part of a future release.\n. TODO:\n- [ ] expose new scaling option to allow image to be scaled based on height OR width (don't scale if image is thinner or shorter than the specified value)\n- [ ] Determine height vs. width of image before scaling\n. After further consideration, I'm not sure this is worth the effort at this time.  If other users express interest, we can re-open.\n. Sorry, but I'm not seeing this issue in FF 28, and no one else has reported such an issue as well.  There is likely some issue with either your code, or perhaps you have an extension interfering with Fine Uploader.  I tested with the latest version of Fine Uploader.  What version are you using?\n. I'm not sure I understand your response.  Are you having an issue with progress reporting in 4.4, or an older version?\n. Ok.  I've tested in Firefox 28 on Windows 7 using the traditional endpoint uploader, which you seem to be using, and progress reporting is working as expected.  You'll want to take a closer look at your code and Firefox extensions.  Perhaps an extension is interfering with progress reporting.  It's also possible that another library you are importing is interfering with XMLHttpRequest.  I've seen a few instances of that in the past, such as with users who are importing dajaxice.\n. Sounds good.  This can be re-opened if you happen to uncover anything.\n. Please provide the version of Fine Uploader and specific steps required to\nreproduce.\nOn Saturday, April 19, 2014, Jonah Werre notifications@github.com wrote:\n\nIn Firefox an Error is thrown on line 549\nqq.toElement = (function(){\n    var div = document.createElement(\"div\");\n    return function(html){\n        div.innerHTML = html;\n        var element = div.firstChild;\n        div.removeChild(element);  <---- TypeError: Argument 1 of Node.removeChild is not an object.\n        return element;\n    };\n}());\nThis is not happening in Chrome or Safari\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1183\n.\n. ...also provide the version of firefox you are using.\n. Since we do not have any steps required to reproduce, I'm going to have to close this.  This can be reopened if new info surfaces.\n. Glad the issue has been resolved.  Templating was redesigned as part of 4.0 in #867.\n. What have you set the type attribute to on your <script> tag?. All of the demos on FineUploader.com, which use templates, seem to be working in Firefox. So, how does your code differ from what is at http://fineuploader.com/demos?. On hold until iOS8 madness is straightened out.\n. Even though #990 still applies to Chrome, I'm going to close this as the original issue will be sorted out, eventually, in future versions of iOS/Chrome.\n. Sorry, I'm not sure what you are asking.  I'd be happy to re-open once you have clarified your question.\n. Sure, that sounds like a neat feature.  We'll look into it.  Thanks for the feature request.\n. Duplicate of #1201 & #1202.\n. We'll look into this during the current (5.0) release cycle.  Such an option will only be available for traditional endpoint handlers, though.\n. This is now part of 5.0.0-11.\n. I plan to remove the jQuery wrapper in #1310 as part of 6.0, so this case is no longer needed. \n. Duplicate of #1196.\n. Current plan is to simply provide an API method.\n. @ludofleury & @alphestdev Can one or both of you commit to verifying that that API method I will add in this issue addresses your needs? \n. ...this would be pre-release testing. I'll make sure you get access to the pre-release version and will wait for your feedback before release.\n. I've pushed a pre-release - 5.6.0-1 which contains a new API method - addInitialFiles. Please let me know if this is working as expected. Upon verification, I'll formally release this as Fine Uploader 5.6.0.\n. You can get a list of all files tracked by the uploader (as well as each file's name, size, uuid, id, etc) using the getUploads API method.\n. Unless you are looping through thousands of files, there is likely no perf difference, but I'm really not clear why you are looping over anything. All you need to do is pass your initial file list via the addInitialFilescmethod. I'd advise stepping back and taking a close look at your code to see how it can be improved. Perhaps there is a much better approach to solve whatever problem you are trying to solve, given the available API. \n\nThanks for the update, I will release this new version next week.\n. Also if you post a question on stack overflow under the fine-uploader tag, explain what you are trying to do with all of these loops (taking into account use of the API method I just added), and show all of your code, I can help you find a better approach as well. This is an ideal use case for SO.\n. This has been released as part of 5.6.0.\n. The S3 demo actually does upload files to S3, and we maintain a signature\nserver outside of Github pages for this demo as well.  All other demos do\nnot send any actual bytes to the server since the server is Github pages\nand github pages rejects all requests that are not GET requests.\nWe've considered hosting the server side of the other demos elsewhere, but\nthat would add much more complexity to the demos pages, and it isn't clear\nthat this is necessary.  The purpose of the demos is adequately served with\nthe current setup I believe.\nOn Sunday, April 27, 2014, Mark Feltner notifications@github.com wrote:\n\nThis is intended. All the demos except the S3 demo (which is fully\nfunctional) are rigged to continue to work on GitHub pages where we can\nonly do GET requests.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1192#issuecomment-41503489\n.\n. > Every file, regardless of size, type, etc. will be shown as \"uploaded successfully\" instantly, even if the upload hasn't even begun.\n\nThis is not accurate, the uploads are certainly not completed before they start.  After the upload begins, it will be completed instantly for all demos except for the S3 demo.  This is due to the fact that we cannot send anything other than GET requests to the github pages server.\n. @panique We appreciate the offer, but lack of servers is not the holdup here.  There's a number of issues with hosting public servers that would allow up 2,000+ visitors a day to submit files.  We're not currently convinced that it is worth the time and resources to allow this.  The S3 demo does allow actual files to be uploaded to a real server.  The other demos serve various other purposes, such as demonstrating client-side thumbnail generation, client-side validation, etc.  Keep in mind that Fine Uploader is a client-side library.  The act of sending the file bytes is somewhat transparent to the user, apart from the unexpected immediate feedback and lack of progress bars.  \nWe can certainly look into adding a note to demos that do not send actual file bytes to a server.  This will likely happen when we spruce up the UI for the demos in the near future.\n. Thanks for mentioning this and for the kind words.  I'll keep this case open so we can ensure it is discussed and added to the schedule.\n. This will be mentioned in the demos section once 5.1.0 is released.\n. Thanks Craig.  We'll schedule this for 5.0.\n. @csquire This has been addressed as of 5.0.0-12.  Can you test to ensure the issue is fixed for you as well?\n. Your approach seems reasonable.  We can discuss internally what can be done in Fine Uploader to make this easier, but I'm not sure any changes are warranted.\n. We'll think about this some more and talk about it again next week.\n. It's not clear to be what we can add to the library to address this specific case.  The approach described here seems like a reasonable solution.\n. I imagine it would be tricky to pause all uploads when autoUpload is enabled.  You might need to simply monitor status via an onStatusChange handler and attempt to pause any file with a status that isn't qq.status.PAUSED.  I haven't tested that though, just a thought.  We'll keep this in mind for a future release.\n. Please see my comments on your PR. There are a number of issues that will need to be resolved before this can be considered to be made a part of the library.\n. This is likely a duplicate or at least very closely related to #1190.  I'll close that in favor of this case, since more real detail is provided here.\n. For some reason, the title of this case has diverged from the original description. The request was for Fine Uploader to clean up the DOM once the number of file representations became \"too large\". The title was changed, by me, to shift this focus to the internal upload history store. Each item in the upload history store should probably only take a very small amount of memory, and it doesn't seem to be worthwhile to expend any effort to auto-prune that list. If the DOM is the focus, then this is not Fine Uploader needs to tackle. Integrators are free to remove <li> elements that represent files from the DOM at any time. \n. As Mark mentioned, the best way to do this is to build these status elements into your custom UI using the data provided by Fine Uploader's getUploads API method.  This method provides information on all files submitted to the uploader.  #1160 originally was going to include these elements in the default UI, but I punted on that as it wasn't clear how to make these elements both generic and appealing.  It should be reasonably simple to create a status widget that mirrors the style of your app using the API.\n. This feature is now complete in the 5.1.0 pre-release branch (develop).\n. Yes, we've updated the addFiles API method documentation.  http://docs.fineuploader.com/branch/master/api/methods.html#addFiles\n. The documentation is pretty clear about the fact that a <script> is not required.  You can include your template in any element, as long as Fine Uploader is able to locate it in the DOM.  \nAs for the default value of the template option, we can certainly adjust the demos & docs to point that out better.  As it stands, the demos will work with modified templates, without changing any code, simply by replacing the template body in the examples with your own.\n. Also, I've edited your question as you failed to escape your <script>, cutting off the last half of your text.\n. From the top of the styling documentation:\n\nThe template does not have to be included in a <script> tag. For example, you may instead include the template in a hidden <div>. Fine Uploader simple needs to be able to locate the template element container in the document.\n\nTypo, though.  \"simple\" should be \"simply\".\nIn one of our projects that uses Fine Uploader, we are rendering our template in a hidden <div> as <script> elements are modified by a framework we are using.\n. Sure, we can certainly adjust the documentation here.  We expect that most integrators will simply drop this in a <script>, as that is how templates are commonly referenced in the DOM.\n. I'm not following your logic.  If you could provide some code to illustrate your scenario, that would be great.  Perhaps there is some misunderstanding about how templates work in Fine Uploader.\n. We'll make a few small changes to the wording for the template option in the docs.\n. Addressed in the develop branch, and this will be part of 5.0.0.\n. Looks like a browser bug.  Thanks for reporting.\n. Putting Fine Uploader on a CDN is not a bad idea.  I'm a fan of referencing CDN versions of libraries myself (at least in production).  But we'd have to determine which builds should be pushed.  There are a lot of possible Fine Uploader builds: \"everything\", S3, Azure, Traditional, S3 w/ jQuery, Azure w/ jQuery, Traditional w/ jQuery, all of the previous builds w/ or w/out the UI module, not to mention the customized builds that are possible.\nSee our build generator for all possible combinations.\n. Not in a position to act on this now.  Will setup an internal meeting to discuss Fine Uploader & CDNs.\n. We already distribute Fine Uploader via npm, which, in my opinion, is sufficient.\n. For a workaround (until this is fixed), see the Stack Overflow case the prompted this issue.\n. Please provide some information required to reproduce the issue, such as:\n- your client side code\n- the exact components that make up your custom build.  A screenshot of the build page will suffice.\n. You haven't actually included any code or a screen shot.  You will need to paste your code, properly escaped, and include information about your custom build.\n. You cannot simply attach files to an email when posting to github issues.  \nYou will need to paste your code, properly escaped, and include information about your custom build.\n. If you provide us with a link to your app, we can take a closer look.\n. Everything looks ok here, but it's hard to tell what the error is.  Please provide a link to your app where this can be reproduced.\n. I'll need a link to your live web app.  A custom build is just that.  I have no way of determining what code is on line 4060 in a custom build.\n. Another option, suggested earlier, is to provide a screenshot of the custom build page from the website (with the appropriate options selected), so we can re-create your build and test.\n. You can attach files via the github issues page.\n. Your last message contained no content.\n. I asked for a screenshot of the custom build form.  Please let us know when you have a site we can visit that will reproduce this issue.\n. It looks like you are having some trouble understanding me.  I'm sorry but I won't be able to help any further without a link to a live site that reproduces the issue you are having.\n. My guess is you triggered a custom build without a selected server type.  The traditional is selected by default, but you much have de-selected it.  You'll need to re-generate your custom build and pay careful attention to the server type section, selecting the one that suits your needs.\n. Can you provide a use case for this?  I'm not sure why another option is really necessary here.  This is just a low-level log message, for the most part.  Your callbacks will have access to the underlying XMLHttpRequest instance anyway.\n. As you have illustrated, your specific requirement can be dealt with in a couple lines of code in an error handler.  This is why the error handlers exist.  I'm not keen on adding more options to Fine Uploader unless there is really no other easy way to solve the associated problem, or if the problem is a common one that will need to be solved in almost every project.  Fine Uploader has, arguably, far too many options as it stands.  The events and API give you the power to address requirements specific to your application via the API and events, and I'd suggest that this is the best way to fulfill your requirement.  Thank you for your time and contribution anyway.\n. Not everything is namespaced, such as MegaPixImage, and some other optional dependencies.  All non-third-party components are namespaced under qq though.\n. to be dealt with as part of the current builder retooling\n. dealt with in 5.1.0\n. The value of that option must be the path to your signature server.  This is also explained on the doc site.  For technical support questions, please post on stackoverflow under the fine-uploader tag.\n. The job of a signature endpoint handler is described in detail in the Azure server side docs under the required server-side tasks section.  There is also a c# example in the fine-uploader-server repo which is referenced on the Azure server side documentation page.\n. Sorry, for some reason I assumed you were using Azure since you are making use of a .NET language.  We have S3 server-side examples in many languages, but .NET is not one of them.  Regardless, the required server-side tasks section of the s3 server side doc page should provide adequete details for handling signature requests.\n. Sorry, Fine Uploader is a client-side library, and while we do offer some server-side examples, we are not equipped to assist with server-side implementation in all languages.  The server-side documentation should detail, at a high-level, the tasks your signature server must perform.  There are implementations in a number of other languages as well in the fine-uploader-server repository that you can use as a reference. \nIf you have a specific question about the high-level details outlined in the server docs, please open up a thread on stack overflow under the fine-uploader tag.  Please be aware that your question must include attempts (in the form of code) to solve your problem along with a description of the specific issues you are having.\n. The request.endpoint option should always be the path to your S3 bucket.  Looking at your code above, you don't appear to be looking at a specific path for delete file requests.  Your signature.endpoint option should be set to \"s3/signature\", and your uploadSuccess.endpoint option should be set to \"s3/success\".  \nFor further technical support questions, please see our support page at http://fineuploader.com/support.  The issue tracker is for bugs and feature requests only.  Thanks.\n. For technical support questions, please see our support page at http://fineuploader.com/support. The issue tracker is for bugs and feature requests only. Thanks.\n. It's possible that I'm missing something (I didn't have time to look over the code closely) but it seems like all of this can be done in a very small amount of code, and FileReader shouldn't be necessary.\nTo compare two images, pixel by pixel, all you need to do is:\n1. Get an object URL for each Blob\n2. Convert those to 2 <img> elements\n3. Draw the <img> elements onto 2 <canvas> elements (you can resize them as part of this process).\n4. Iterate over the ImageData for each image (from the canvas' associated RenderingContext) and stop when you reach the last subpixel or find a difference.\n. Phew.  Seems like a lot of work.  Maybe in another repo, in another life.\n. You are correct, you can only set custom headers via the params method/option.  Fine Uploader will already set Content-Type for you via the x-ms-blob-content type header on the \"put block list\" request and Content-Type on \"put blob\" requests.  \nWe can certainly expose an option and/or method to allow other headers to be set, such as content-disposition.  The issue you opened here will server as a reminder for upcoming releases.\n. You are correct, you can only set custom headers via the params method/option.  Fine Uploader will already set Content-Type for you via the x-ms-blob-content type header on the \"put block list\" request and Content-Type on \"put blob\" requests.  \nWe can certainly expose an option and/or method to allow other headers to be set, such as content-disposition.  The issue you opened here will server as a reminder for upcoming releases.\n. Do we want to allow any headers to be set?  This may conflict with setParams which creates prefixed headers based on passed params.  Other option is to just allow specific headers to be set via API.\n. I think params should always be prefixed. I can see allowing creation of any headers via a setCustomHeaders API method for the Azure module though.\n. I just tested in Chrome 35 on a chromebook, and your image rendered\ncorrectly as a preview.  I'll look at more browsers when I am near a real\ncomputer later.\nOn Thu, May 22, 2014 at 7:19 AM, vsync notifications@github.com wrote:\n\nTested on Win7 / FF29\nSeems like the preview thumbnail is rendered completely black when I\nchoose a source image which is very wide. I've taken those photos myself\nwith my Nexus 5 phone. They are panorama. Here's a link to one of them:\nhttp://dropthebit.com/demos/PANO_20140427_191305.jpg\nIs it something that can be fixed by javascript or is it a browser bug?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1213\n.\n. Your issue says that you tested on Win7 / FF 29.  Nothing about\ntesting/results in other browsers.  If you mentioned that it worked in\neverything other than FF29, I would have not started to test in other\nbrowsers first.  And, as I said, I'll do more investigation myself once I\nam near a real computer.  Please try to be a little patient.\n\nOn Thu, May 22, 2014 at 8:04 AM, vsync notifications@github.com wrote:\n\nyes becuase it works on chome...I said my my issue, this is a Firefox\nissue.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1213#issuecomment-43884499\n.\n. Can you provide some more specific information about your setup, browser extensions, etc?  You are the first to report such an issue, and the previewing feature has been out for quite a while.  The image manipulation code is fairly non-trivial in order to support all of the features we offer, but, for the most part, we rely on <canvas>.\n. I should mention that video drivers are unlikely to be the culprit.\n Perhaps a browser extension is causing an issue.\n\nOn Saturday, May 24, 2014, vsync notifications@github.com wrote:\n\n[image: fine_uploader_demo_-_2014-05-24_21 04 16]https://cloud.githubusercontent.com/assets/845031/3075273/efc46262-e36d-11e3-8d07-4f8d4e786b3c.png\nIt might be anything...my graphic drivers even. who knows. I really hope\nit only happens on my machine and not on any other, but it's the only place\nI've ever seen this happens. with this script, so this is why I'm stating\nthat. I've tried this with other uploading solutions I've found on google,\nsuch as http://www.dropzonejs.com/ and they preview works ok. So, logic\nsuggests that this is a fineuploader issue.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1213#issuecomment-44094932\n.\n.  If you can provide us with a list of your extensions, that would be\nhelpful.\n\nOn Saturday, May 24, 2014, vsync notifications@github.com wrote:\n\nyes, it is probably an extension. I've just tried to restart Firefox in\nsafe mode and that black thumbnail hadn't occurred. As a developer, I have\n20 addons right now, I am too lazy to disable each one and then restart\nFirefox and check which one is responsible for the issue, it is too\ntime-consuming\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1213#issuecomment-44095642\n.\n. Thanks!  Once we determine which extension is causing the issue, we will\ntake the most appropriate action to work around or document the issue.\n\nOn Saturday, May 24, 2014, vsync notifications@github.com wrote:\n\nName version enabled  Adblock Plus 2.6 true  BrowserStack Local 5.2 true\nColorZilla 2.8 true  CSS Reloader 1.0.5 true  Download Status Bar 9.9.1\ntrue  Firebug 1.12.8 true  Firebug Autocompleter 1.4.1 true  Firebug\nPaint Events 0.1.8 true  FireFontFamily 0.1.2 true  FireQuery 1.4.1 true  Free\nMemory 0.95 true  Html Validator 0.9.5.8 true  Image Zoom 0.6.3 true\nMeasureIt 0.4.13 true  Screengrab (fix version) 0.97.24c true  SelectBug\n0.1a4 true  Tab Mix Plus 0.4.1.3.1 true  Text Font-Size Adjuster 0.94.18\ntrue  Web Developer 1.2.5 true  X-notifier 3.4 true  Adobe Acrobat -\nCreate PDF 1.2 false  Download Statusbar 0.9.10 false  YSlow 3.1.8 false\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1213#issuecomment-44100066\n.\n. Sounds like an extension is the culprit.  Nothing we can do about that.\n. We can probably add an easy way to set this header per-object, along with Expires and Content-Disposition.  We'll look into this in one of the upcoming release cycles.\n. We can probably add an easy way to set this header per-object, along with Expires and Content-Disposition.  We'll look into this in one of the upcoming release cycles.\n. Same concept (mostly) as #1212.\n. Work on this has not started.\n. Handled in #1258.\n. I'm sorry but I can't accept this change.  It is mandatory to call preventDefault on the drop and dragover events in order to allow users to drop files.  Your changes effectively break drag and drop.\n. Thanks for the report.  We will try to find an iPad 3 to reproduce.\n Perhaps there is an issue with a specific (early) build of ios6.\n\nOn Tuesday, May 27, 2014, vsync notifications@github.com wrote:\n\nTested with my iPad 3, iOS6 on your demos page. I get to browse my files\nand when I choose a file, it eventually does nothing.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1216\n.\n. Our only ipad 3s are running either ios7 or 6.1.  I just tested on an ipad running ios6.1 without any issues.  What specific build of ios6 are you running?\n. I located a few more ipads, but the oldest version of ios installed is 6.1.  So, I used a 6.0 simulator (10A403), and was also unable to reproduce your issue.  Let us know if the issue persists after upgrading to a more current build of iOS6.\n. Unable to reproduce on recent versions of iOS6.  If you are seeing issues on very old versions of iOS6, this may have been a bug that Apple fixed in subsequent versions.\n. What specific property/object is the failure related to?  You can determine this by setting appropriate breakpoints, such as asking the browser to break on a TypeError, or perhaps by adding a logging statement.  I realize that Safari is pretty awful when it comes to dev tools (and everything else for that matter), but you can remote debug a cable-connected iOS device via desktop safari.\n. That build of Fine Uploader is ancient. I'm not aware of any such issue with the current version.\n. What version of iOS?\nOn Sat, Oct 3, 2015 at 3:17 PM J\u00e9r\u00e9my Lal notifications@github.com wrote:\nDid i say 3.5.2 ? I meant 5.3.2 of course !\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1216#issuecomment-145285664\n.\n. Ah, I see. Thanks for the report!\nOn Sat, Oct 3, 2015 at 3:38 PM J\u00e9r\u00e9my Lal notifications@github.com wrote:\nLinux ! debian/stretch gnome 3.18 / epiphany 3.18.\nIt seems to be a well known bug in webkit, see\njrburke/requirejs@d09afa7\nhttps://github.com/jrburke/requirejs/commit/d09afa77cc956ae5062a76350bd4db6302c7e873\nand\nhttps://bugs.webkit.org/show_bug.cgi?id=49739\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1216#issuecomment-145287555\n.\n. No problemo\nOn Sat, Oct 3, 2015 at 3:52 PM J\u00e9r\u00e9my Lal notifications@github.com wrote:\nha damn, it was me passing button option instead of element. Sorry for\nthe noise.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1216#issuecomment-145288157\n.\n. This bug will require that we postpone the release of 5.0, as I'd really like to have this fixed in 5.0, even though the future of directory upload support in Chrome is in question due to the removal of the filesystem API from the spec.\n. Yes, it is certainly possible and quite easy to use Fine Uploader in any scenario without jQuery, as the library itself does not depend on jQuery in any way,  If you have specific questions about your code, please post a question along with the specific code you are inquiring about on Stack Overflow under the fine-uploader tag.\n. I edited your post to fix your code formatting.  You can find information regarding use of GitHub markdown on the markdown help page.\n\nIt's really simple to use Fine Uploader without jQuery in your situation.  Your code would look like this  without jQuery:\n``` javascript\nangular.module(\"myApp\")\n    .directive(\"fineUploaderS3\", function() {\n        return {\n            restrict: \"ECMA\",\n            controller: 'FaceCardEditCtrl',\n            replace: true,\n            link: function($scope, element) {\n            var uploader = new qq.s3.FineUploader({\n               element: element,\n                Fine uploader options...\n            });\n        }\n    }\n});\n\n```\nYou can find all documentation for options, events, methods, and more on the docs site.  Also, for future technical support requests, please see our support page.  We don't normally handle tech support in the GitHub issue tracker, this is reserved for bug reports and feature requests. For free technical support, post on Stack Overflow under the fine-uploader tag.  We also offer paid support.\n. Sounds good.  You left a lot out of your code, so if you are having issues, it's related to something that you omitted.\n. The signature of your link function is incorrect.  The third param is an object: attrs.\nFrom the angular docs:\n\nlink takes a function with the following signature, function link(scope, element, attrs) { ... } where:\n- scope is an Angular scope object.\n- element is the jqLite-wrapped element that this directive matches.\n- attrs is a hash object with key-value pairs of normalized attribute names and their corresponding attribute values.\n\nPlease post future tech support questions on Stack Overflow.\n. Seems like busy work after some thought.\n. All style rule validations are now cleaned up and this is part of the develop branch.\nNote that I decided not to enforce styles in unit tests.  There are far too many style issues in the unit tests, and I'm not sure it's worth the time to clean those up.\n. Thanks again for your help!\n. Please provide more detail, such as:\n- your markup that demonstrates what you have described\n- how you would like Fine Uploader to choose the specific duplicate file\n  container or duplicate file element children.\nAnother option is to use Fine Uploader core, and design the UI as you like.\nOn Saturday, May 31, 2014, Eugene Krevenets notifications@github.com\nwrote:\n\nI have case when I have different design for different screen's size. So\nI'm using http://getbootstrap.com/css/#responsive-utilities. And I have\nmore then one instance of qq-upload-retry-selector,\nqq-progress-bar-container-selector, and other for one uploaded item. And I\nhave too complex and very different design to reduce big screen to small\nscreen. But libs written in such way when only 1st instance is processed.\nCan you fix lib to process all instance inside uploaded item?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1222.\n. Why do you have these duplicate elements?  Why not simply use media queries\nto adjust these elements to fit the display size (if that is what you are\ntrying to do here)\n\nOn Sunday, June 1, 2014, Eugene Krevenets notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus\nI mean, for example we have such template:\n\n\n\n\n\n\n\n\n\n\n\n\n\nin this case only 1st progress bar will work, the same situation for other\ncontrols.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1222#issuecomment-44782270\n.\n. Fair enough.  The Fine Uploader team will discuss how we can support your\nrequirements, and we'll schedule work on this once that is done.\n\nOn Sunday, June 1, 2014, Eugene Krevenets notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus I have duplication elements\nbecause I'm using media queries (from bootstrap3).\nThe reason, because for different screen sizes I have completely different\ndesign and as follow different html structures. Sure it possible to squeeze\ndifferent designs in one html-structure, but it is differently bad practice\nbecause it this case html won't reflect design structure and it will be\nvery hard to make any changes.\nI just wasn't show whole pages because my example is enough to reproduce\nproblem.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1222#issuecomment-44783841\n.\n. In the meantime, since you are already apparently doing a lot of custom UI\nwork yourself for the upload portion of your web app, you can simply use\nFine Uploader core and drive your own custom UI with the help of Fine\nUploader's API.\n\nOn Sunday, June 1, 2014, Eugene Krevenets notifications@github.com wrote:\n\n@rnicholus https://github.com/rnicholus thanks\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1222#issuecomment-44785720\n.\n. Are you trying to create a styled upload button without Fine Uploader UI?\n. This is documented on the extra buttons feature page.\n. Makes no difference.  You simply point at an element (anchor, button, div, etc) and Fine Uploader will attach a file input to that element.\n. There isn't an API method for that, but you can certainly create your own file input element and pass it to Fine Uploader via the addFiles API method whenever you want to submit user-selected files.\n. Story pointed and added to the \"do\" list.\n. @Hyzhak That would be part of a different case.  Please move your comment to a new case and we will look into adding it to the schedule.\n. I say give sub modules a shot.\n\nOn Tue, Jun 3, 2014 at 2:55 PM, Mark Feltner notifications@github.com\nwrote:\n\nI've been working on the side on a server implementation for Fine Uploader in node.js. It has a few benefits:\n- Pluggable endpoints (can upload to disk or S3; trivial to add more via pluggable middlewares)\n- Good logging\n- Runnable via command-line / installable via npm\n- Command-line arguments for various options (port, static folder, uploads directory -- if using traditional, bucket -- if using S3, ...)\n- Can host static files or not\n- Runnable via command-line (no reliance on another IDE -- just need node)\n- Updated express and other libraries\n  It has been very useful when I need to quickly deploy a Fine Uploader server, but I'd like to a) determine where it should reside and b) get it tested and have CI going before officially releasing it. \n\nAs for issue a), where it should reside, we have the fine-uploader-server repo, which is full of various server implementations. Would this replace any or all of the other node servers? Also, would it exist in the same repo?\n  My initial thought is to create a separate repo for this particular server, and have it as a submodule of the fine-uploader-server repo -- probably replacing the previous node servers. @rnicholus -- what issues with submodules would hold this back? I know previously parent repos could not have their submodules track branches, but this has been added to a recent git version.\n\nReply to this email directly or view it on GitHub:\n  https://github.com/Widen/fine-uploader/issues/1223\n. Looks like you've already done this @feltnerm.\n. Thanks for the request.  We will discuss at our next planning session.\n. @feltnerm I added this to the 5.1 milestone.  I think this is important to get a handle on this soon.  Let's discuss and SP tomorrow.\n. pushed to 5.2\n. This will hopefully happen as part of 5.3 along with a rewrite of the getting started guide.\n. I think the docs will simply have to evolve into the docs site over time.\n. Also see #1178 for some discussion on why JS file size is mostly irrelevant.\n. Looks like this is a regression that affects traditional endpoint handlers, and only if chunking is enabled.  S3 and Azure do not appear to be affected.  We'll look into a fix for this starting today and push out a hotfix release once that's done.  Thanks for the report.\n. - [x] Ensure the server response is passed to the complete handler in all cases\n- [x] Add unit tests for this\n- [x] Improve \"finalizing...\" log message(s)\n. Fixed in 5.0.1.\n. Which build/version of iOS? \u00a0Which version of Fine Uploader?\n\nOn Thu, Jun 5, 2014 at 8:06 AM, Bjorn Bos notifications@github.com\nwrote:\n\nTry to upload the following photo on iOS:\nhttp://auto-expire.s3.amazonaws.com/bug/uploadBug.JPG\nAnd set the following scaling options on your FineUploader:\n    scaling: {\n        sendOriginal: false,\n        sizes: [\n            { name: \"full\", maxsize: 2480 }\n        ]\n    }\nIf we then check the content length of the upload request at the server, the filesize is 0.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1228\n. Since this is not a bug, closing.\n. Create a new issue, describe the error in detail, and include all of your code.\n\nOn Fri, Jun 6, 2014 at 2:56 AM, Bjorn Bos notifications@github.com\nwrote:\n\nI would like to reopen this issue. Even without the typo, the following photo has issue when using the scaling functionality:\nhttp://auto-expire.s3.amazonaws.com/bug/upload.JPG\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1228#issuecomment-45311848\n. Currently, the partSize chunking option must be defined when the instance\nis constructed, and is not modifiable after construction.  Perhaps it could\nbe modified to also accept a function that is invoked by passing in the\nfile ID.  With this, you could write a function that returns a partSize\nbased on the file size.\n\nNote that the blog post you referenced is out-of-date.  The current limits\nare here: http://docs.aws.amazon.com/AmazonS3/latest/dev/qfacts.html\nOn Thu, Jun 5, 2014 at 5:08 PM, Eugene Krevenets notifications@github.com\nwrote:\n\nMy users will upload very wide range of files from 0 and up to 3T (rarely).\nBecause s3 has upper bounce of number of parts\nhttp://aws.amazon.com/blogs/aws/amazon-s3-multipart-upload/\nIs there any way to define max number of parts and let fine uploader\nadapts partSize to the file size?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1229.\n. 3 TB is a pretty large browser-based upload.  What sort of files are you dealing with?\n. Even animated cat gifs?\n\nOn Thu, Jun 5, 2014 at 5:38 PM, Eugene Krevenets notifications@github.com\nwrote:\n\nany type of files\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1229#issuecomment-45284147\n. Even animated cat gifs?\n\nOn Thu, Jun 5, 2014 at 5:38 PM, Eugene Krevenets notifications@github.com\nwrote:\n\nany type of files\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1229#issuecomment-45284147\n. covered by #1697. Status text is updated automatically by Fine Uploader based on the current state of the file, and these state messages are configurable via options.\u00a0What sort of logic are you using to determine what the status message should read? \u00a0What status messages are missing?\n\nOn Thu, Jun 5, 2014 at 5:42 PM, Eugene Krevenets notifications@github.com\nwrote:\n\nI need to receive status text to show it by myself. Right now I use monkey patching of fine-uploader to get it:\njavascript\nuploader._templating.setStatusText = function(id, text) {\n}\nIs there any way to get same result without monkey patching?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1230\n. Status text is updated automatically by Fine Uploader based on the current state of the file, and these state messages are configurable via options.\u00a0What sort of logic are you using to determine what the status message should read? \u00a0What status messages are missing?\n\nOn Thu, Jun 5, 2014 at 5:42 PM, Eugene Krevenets notifications@github.com\nwrote:\n\nI need to receive status text to show it by myself. Right now I use monkey patching of fine-uploader to get it:\njavascript\nuploader._templating.setStatusText = function(id, text) {\n}\nIs there any way to get same result without monkey patching?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1230\n. You are doing a lot of custom UI work it seems. \u00a0Why not just use Fine Uploader core and build your own UI around the API? \u00a0Fine Uploader UI is not appropriate for every single project. \u00a0If you find yourself monkey patching the template module or other related UI code, that is a signal that either you should use the API to drive your own custom UI, or perhaps there is a better way to solve your problem with Fine Uploader UI. \u00a0If you really want to use Fine Uploader UI, in this case, just omit the selector class on the status element and update the text when appropriate for this element via the dom.\n\nOn Fri, Jun 6, 2014 at 7:19 AM, Eugene Krevenets notifications@github.com\nwrote:\n\n@rnicholus I try to decapled from template engine inside of Fine Uploader and done everything by angularjs. The reason - that my case can't be covered by current template engine of Fine Uploader and I think there is no a lot of sence to try to set on all chairs. So If you can decaped Core of Fine Uploader and give posibility to handle setStatusText, it can be much easier to customize visualization.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1230#issuecomment-45330494\n. No.  As I mentioned, there are several much better ways to contribute your\nown status text.  To recap:\n1. Contribute appropriate values for the associated message/text options\n2. Build your own UI driven by Fine Uploader's API\n3. Omit the qq-upload-status-text-selector element from your template, and\n   update the file element in the doc with whatever status text you desire.\n\nI would suggest you not \"monkey patch\" the code.  The internals can change\nat any time, without announcement.  And, they often do change as\nrefactoring is a regular part of development.\nOn Fri, Jun 6, 2014 at 8:59 AM, Eugene Krevenets notifications@github.com\nwrote:\n\n@rnicholus https://github.com/rnicholus\nIf you really want to use Fine Uploader UI, in this case, just omit the\nselector class on the status element and update the text when appropriate\nfor this element via the dom.\nbut is there any way to get callback of setStatusText, without monkey\npatching?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1230#issuecomment-45339357\n.\n. Have a look at the statusChange event.\n. You can keep track of the number of retries via callbacks.  Also, terminal errors will be passed to your onComplete handler via the error property of the response param.  Fine Uploader UI already includes these exact status messages.  It's still not clear what you are trying to do.  If you are looking to  contribute translated forms of some of the error messages that appear in the UI, admittedly, this is something we can improve, especially for S3 and Azure handlers.  Please see #1133.\n. I spent some time looking into this today, and this appears to be a browser bug that I can only reproduce with the specific image you provided.  Looking at the EXIF data, it appears as if the picture was taken on an iPhone 5.  Can you provide more information about how this photo was created, and why it may differ from others in your collection?\n\nI was able to observe an issue simply by taking the File representing the image, converting it to an object URL via the browser's native URL.createObjectURL, rendering this URL in an <img> tag, and then drawing that <img> onto  a <canvas>.  Up to this point, everything seems normal, even the ImageData representing the <canvas> seems reasonable at a glance.  However, when converting the <canvas> to a data URI via the RenderingContext method's toDataURL, an empty data URL is returned.\n. I spoke too soon.  Upon closer inspection of the ImageData provided by the <canvas> RenderingContext, the values do appear to be invalid.  Looking closer now.\n. Well, I would definitely expect disabling scaling to be an effective workaround for this issue.  The image is not processed at all if scaling is turned off.  I'm investigating more now.\n. I'm still not entirely sure why the image you provided is creating issues.  I can tell you that dealing with images and canvas in iOS is extremely difficult due to some of the architectural decisions Apple has made.  Fine Uploader (and every other library I am aware of) delegates to a library called MegapixImage to render images from iOS onto a canvas.  This is to overcome some issues specific to iOS:\n1. There are very strict memory limitations in iOS in place when dealing with canvas elements, for example.  This is overcome by drawing an image onto a canvas in small pieces.\n2. iOS \"subsamples\" images.  When these images are drawn onto a canvas, they are rendered incorrectly in iOS.  A complex set of operations is required to detect and overcome this.\nBoth of these issues are difficult ones to overcome, and this problem has been mostly solved by the MegaPixImage library.   However, issues continue to crop up as Apple adjusts their algorithms.  Unfortunately, Apple has not done a great job of keeping their documentation up to date either, which makes it difficult to adjust the algorithm to overcome the memory limits and the subsampling as the Safari codebase changes.  \nIt's likely that later versions of iOS have made adjustments to subsampling, added more processing operations, or perhaps broken the canvas implementation in Safari even further (there are already other serious long-standing canvas-related bugs in Safari that Apple has shown no interest in fixing).  \nPerhaps some adjustments can be made to MegaPixImage to overcome some of these new issues.  It's also possible that these issues are native browser bugs that we will not be able to work around.  We'll do some more investigation internally and keep this case up to date.  The first step will be to see if MegaPixImage logic can be adjusted to overcome these issues.  \nIf you can provide me any more information about the images you are having problems with, that would be very helpful.  It looks like your images are fairly large and complex compared to images I am able to take on an iPhone 5 running iOS 7.1.1.\n. Yep, it most likely is due to size/dimensions.  If you downsample the image a bit, does it work?\n. Hmm, maybe the issue only occurs if the maxSize exceeds both the width and the height of the natural image.  Looking closer at that now.\n. I just noticed in Apple's documentation that the max size of a <canvas> varies between 3 MP and 5 MP, depending on the device's memory.  This means that the size of a <canvas> on an iPhone 5, for example, cannot exceed 2289x2290, or 2000x2620, etc.  In other browsers with such memory limitations, the canvas will still render, but will be truncated.  iOS just throws away the entire image and leaves you with an empty canvas backed by a properly sized but zeroed-out ImageData typed array and no error.  \nIt looks like I'll need to adjust either our code or our (modified) copy of MegaPixImage to ensure that we never attempt to render a canvas that exceeds 5 MP on iOS devices with more than 256 MB of RAM and 3 MP with devices less than 256 MB of RAM.  I'll have to resort to user agent string parsing to identify the iOS device and maintain a map of devices with their memory limitations.  I think that we only really need to worry about some of the older iPods as far as devices with less than 256 MB go.\n. Yep, and incrementing it by one more (to 2290) results in an empty image/file again.\n. We'll start on a workaround and release as a hotfix to 5.0, even though this is not a regression.\n. I'm thinking the latter. \u00a0This is only an issue for scaled versions of submitted files.\nOn Fri, Jun 6, 2014 at 12:02 PM, Bjorn Bos notifications@github.com\nwrote:\n\nSo what will be the workaround? Upload full size, or scale to maximum allowable dimension for device?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1231#issuecomment-45360192\n. If the full image is desired, then the sendOriginal option should be set to true. \u00a0As far as scaling is concerned, I believe we should fulfill that request as best we can.\n\nOn Fri, Jun 6, 2014 at 12:12 PM, Bjorn Bos notifications@github.com\nwrote:\n\nWould be nice to have both choices as an option. I can see cases where you rather have the high resolution (full) image than the (extra) scaled image.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1231#issuecomment-45361164\n. Understood.  I'll ponder that for a while before I commit a final fix for this issue.\n. If we provide an option to send the original image in place of a scaled version that cannot be rendered, we will likely send the original image in place of the expected scaled version for every scaled version that cannot be generated due to device limitations.  \n\nFor example, for the image you provided in the initial description of this issue (2448x2448), given the following scaling option:\njavascript\nscaling: {\n    sendOriginal: false,\n    sizes: [{name: \"small\", maxSize: 2300}, {name: \"medium\", maxSize: 2400}]\n}\nThe original image will be sent twice.  Taking a more intelligent approach (only sending the original image once) would be fairly complex due to the design and asynchronous nature of the scaling feature.\n. It would likely be more complicated than that.  For example, the maximum scaling size is not 2289 px, it is 5 MP.  So, with that limitation in mind, we can only proportionally scale a 5000 x 5000 image to 2289x2289, but we can scale a 3264x2468 image to a maximum scaled size of 2560x1920.  \nTo keep the workaround simple, and to make life easier for integrators, how about we just make a best-effort to send a scaled version.  The scaled version may be smaller than the maxSize in iOS, but you can adjust the value of the sendOriginal option like so by utilizing qq.ios().  \nFor example:\n``` javascript\nscaling: {\n    // only send the original if we are on iOS, otherwise, just the scaled versions\n    sendOriginal: qq.ios(),\n// slightly smaller scaled versions will be sent on iOS for a 2448x2448 image, for example\nsizes: [{name: \"small\", maxSize: 2300}, {name: \"medium\", maxSize: 2400}]\n\n}\n```\n. There are a number of functions available that attempt to identify the browser based on the user agent string.  Fine Uploader uses them internally as a last resort (for example to work around browser-specfici bugs).  They are undocumented as I don't really want to encourage others to use them and they are really only meant for internal use.\nThere is already a feature detection module, and I will likely add a unrestrictedCanvasSize or limitedCanvasSize flag as part of this bug fix.  The implementation will likely need to parse the user agent string though, but I think a higher-level approach like this has a lot of benefits.\n. Looks like all devices capable of running iOS6 or newer have at least 256 MB of RAM.  So, we just need to enforce the 5 MP canvas restriction on all devices identified as running iOS.\nNote that Fine Uploader is not supported in iOS5 or older.\n. iOS apparently subsamples all images larger than 2 MP when they are \"decoded\".  I believe this applies to all images of this size that are rendered.  Fine Uploader must render image files to a hidden <img> tag, then draw them onto a <canvas> as part of the scaling process.  iOS likely subsamples larger images as part of the first render.  There is a long-standing bug (as I understand it) that causes these subsampled images to render incorrectly when drawn onto a <canvas>, hence the need for some funky code to overcome this.  So, yes, per my understanding, larger images will be subsampled by iOS as part of the scaling process, and, as a result, subsampled versions will be uploaded.\n. @bjornbos I have a fix for this staged in a hotfix branch.  Please let me know when you are ready to grab a copy and verify that this fixes the issue with all of your images.\n. Ugh, please hold on.  I left something in the code that must be removed...\n. Ok, I'm fairly confident in the code now, but if you see any issues, please make a note of the image so I can determine if the internal max pixel value needs to be adjusted.  While Apple's docs claim that the upper limit is 5 MP, that does not appear to be completely accurate in practice.\n. Eh, not easily.  Quite frankly, I'm not even sure how to do it myself.\n Your best bet is to use one of the versions that the grunt package task\ncreates.  I can just send it to you as well.  Send us an email...\nOn Thu, Jun 12, 2014 at 10:17 AM, Bjorn Bos notifications@github.com\nwrote:\n\nIs there a way to create a custom build from this branch?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1231#issuecomment-45905136\n.\n. Great to hear.  We're going to walk through some internal integration testing, partially due to the fact that I changed the structure of part of the source tree while working this case (not an entirely necessary action, but I couldn't help myself).  After all tests check out, we'll release this next week as 5.0.2.\n. Included in 5.0.2.\n. Very true.  Thanks for the update.  I decided to namespace our custom\nversion of MegaPixImage since we've modified it so much.\n\nOn Wed, Jun 18, 2014 at 4:47 AM, Bjorn Bos notifications@github.com wrote:\n\nNote: For everyone using the MegaPixImage library that is included in\nFineUploader, you should now use qq.MegaPixImage (we reuse the library for\ncanvas drawing).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1231#issuecomment-46415589\n.\n. Yes, you can certainly do this by utilizing the drawThumbnail API method and then adjusting the margins on the returned preview container/image appropriately.  In fact, I am doing just that in an internal project that utilizes Fine Uploader.  \n\nThere is already a feature request open to build this additional functionality into the preview feature.  See #1181 for more details.\n. You might want to comment in the original case instead.\nOn Fri, Jun 6, 2014 at 10:00 AM, Eugene Krevenets notifications@github.com\nwrote:\n\n[image: :+1:] waiting for this features\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1232#issuecomment-45346254\n.\n. Your onValidate handler will be called for each selected file.  If you'd like to ignore a specific file in your onValidate callback, return false in your callback handler.  In your code above, you are attempting to cancel a file that hasn't even been successfully submitted yet.\n. ``` javascript\nonValidate: function(file) {\n    var matches = $.grep(this.getUploads({status: qq.status.SUBMITTED}), function(recordedFileItem) {\n        return file.name === recordedFileItem.name && file.size === recordedFileItem.size;\n    });\n\nreturn !matches.length;\n\n}\n``\n. If you don't want to depend on jQuery, you can use the [filtermethod available onArray.prototype](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/filter) instead of$.grep.  Your validation won't work in IE9 or older anyway, and the arrayfilter` method is available in versions of IE as early as 9.\n. I would consider this a high-priority documentation bug.  The menus should be scrollable I suppose/\n. The menu itself should be scrollable.\nOn Wed, Jun 11, 2014 at 10:20 AM, Mark Feltner notifications@github.com\nwrote:\n\nNot sure how that'd work, as the page needs to scroll as well...\nI haven't come up with a better idea yet, though... maybe we could\ncategorize features, and offer sub-menus?\n/cc'ing @joshuaArd https://github.com/joshuaArd and @avo\nhttps://github.com/avo to see if they have any ideas\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1234#issuecomment-45756010\n.\n. 2 questions: Does the actual file name end in \".jpg\"?  Is the file is being rejected due to a validation rule that limits submitted files to specific extensions?\n. Ok, please let us know when you have the exact file name.  Fine Uploader will report the name according to the browser, and if it is being rejected due to an extension validation rule, it most likely is lacking the expected extension.  You can also check by creating a jsfiddle with a simple file input and examining the name reported by the browser.\n. This does not appear to be a Fine Uploader issue, but can certainly be re-opened if evidence is available that illustrates an issue with the library.\n. Would your problem be solved simply if you could reset the item limit counter via the API?\n. We don't have such an API method yet.  If you are interested in this, you can watch case #1169.  In the  meantime, it's fairly easy to enforce your own item limit (or any other custom validation rules) via the onValidate or/and onValidateBatch callbacks.  That may be your best bet.\n. I would strongly suggest you not modify the Fine Uploader instance at all.  In other words, add methods to an object/namespace you control, and not to Fine Uploader.\n. There is no such version.  After 4.4, the next version was 5.0.  Also, folder selection and dropping has been supported in chrome and opera for some time now.  Have a look at the features menu on the docs site at http://docs.fineuploader.com\n. Folder uploads are only possible in Chrome and Opera without the use of flash or java.\n\nOn Mon, Jun 23, 2014 at 6:52 AM, Manidipa notifications@github.com\nwrote:\n\nThanks for your quick response. I have checked the features in the document and you have added drag and drop of folder support for Chrome and Opera which is good. But we are looking for folder selection in all the HTML browsers. I did not find the folder selection feature for all the browsers in the feature list. Can you please help me on this.\nThanks in advance for your help.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1237#issuecomment-46834514\n. Please provide your Fine Uploader related client-side code so we can attempt to reproduce the issue you are describing.\n. Ugh, thanks for reporting this.  Definitely a bug in Fine Uploader.  We should, of course, only prevent \"originals\" from being uploaded if the file is scalable in the current browser.  We'll fix this in an upcoming 5.0.3 hotfix release.\n. James - I believe I have a fix for this in a hotfix branch.  Before we\nrelease a hotfix, we'd like to give you the opportunity to test this\nyourself to verify that it fixes your issue.  I needed to write some tests,\nand fix other code that was dependant on the original faulty logic.  Send\nus an email when you'd like to get a copy for testing.\n\nOn Mon, Jun 23, 2014 at 2:31 PM, James Scott, Jr notifications@github.com\nwrote:\n\nThanks, I will watch for the update.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1238#issuecomment-46890613\n.\n. Glad the fix worked for you.\n\nI'm assuming the PDFs always showed up in the file list UI, regardless of the settings, correct?\nWhat you are seeing - nothing in the file list with hideScaled: true and sendOriginal: false for scalable images - is expected.  If you don't want scaled versions to be represented in the UI, and don't want originals to be uploaded, there isn't anything left to display in the UI.  I suppose we could display a list item to represent the batch, but it's not clear what that would look like and what actions would be available, if any.  That is certainly open for discussion.\n. Good to hear James.  Thanks for the update.  We'll probably do a hotfix\nrelease today or tomorrow.\nOn Mon, Jun 30, 2014 at 9:28 AM, James Scott, Jr notifications@github.com\nwrote:\n\nI've covered all my bases, everything I need it to do is working as\nexpected. Thanks for the quick turn around, and a great package.\nJames,\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1238#issuecomment-47538073\n.\n. This is part of the 5.0.3 release.\n. Windows Safari is not supported.  For future reference, we have a page that goes into detail regarding browser and feature support at http://docs.fineuploader.com/browser-support.html.\n. Again, windows safari is not supported.  Only OSX Safari.\n. I see you have posted this same question on stack overflow.  I'll close this issue and it can be addressed on SO from this point forward.\n. It looks like you are upgrading from a 3.x version.  Please see the upgrading guide in the documentation.\n. What is your question?\n. Are you sure you want scaled versions of an image to be indistinguishable? Won't your users be confused when they see the same file duplicated multiple times in the UI?  Why is this behavior desired?\n. Ah, you must have sendOriginal set to false.  \n\nWe'll address this in the next hotfix release by ensuring nothing is appended to the original file name if the scaled version's name property is an empty string or null/undefined.  \nIn the meantime, you can adjust the name of any file via the setName API method. \n. Sorry, I missed it due to the formatting issues in your post.  I'll fix the formatting issues in your initial post now...\n. Sure thing.  You can read more about GitHub-flavored markdown at https://help.github.com/articles/github-flavored-markdown.\nWe'll plan on releasing a fix for the issue you reported in 5.0.4.\n. This will probably be the last bug fixed as part of 5.0.4.  We'll be working on this shortly.\n. This completes planned work for 5.0.4.  @markryder53 Would you like to confirm that this adjustment addresses your requirement?\n. I'll send you an email Mark.\n. Thanks for the update.  This will be part of 5.0.4.\n. You can include this or any other parameters with each upload request with the setParams API method.  The ID itself is probably not something you want your server to be dependant on.  It is only unique for a particular uploader instance.  The UUID is entirely unique, and that is sent with every request.\n. I strongly suggest you not modify any of the Fine Uploader code.  You'll find upgrades to subsequent versions to be difficult.  This is a general rule that should be observed with any 3rd-party software.\nIf you want additional parameters to be sent, simply call setParams on a \"submitted\" or \"upload\" handler, passing in the ID of the file and whatever key/value pair you want to include as a parameter.\nFor example:\njavascript\ncallbacks: {\n    onUpload: function(id) {\n        this.setParams({\"fileId\": id}, id);\n    }\n}\n. :thumbsup: \n. Note that you do not need to use the above jQuery syntax, even if you are using the jQuery wrapper.  The code in my comment is usable in any case.\n. Which settings are you referring to?\n. Please show your code and provide logs with a clear explanation of the problem.\n. Are you saying that failed uploads automatically retry despite the specified autoRetry value?\n. If you can provide a link to a place where this can be reproduced live, I can take a look on Monday.\nOn Fri, Jul 4, 2014 at 9:14 AM, PauloCelso notifications@github.com\nwrote:\n\nThe thing is we do not see it failing, it looks like we possibly do not get the \"Success\" response in a timely manner due to server side processes,  at that point it uploads the file several times  I have only been able to prove this via iis logs, where i can see the request made in intervals of 5 minutes.\nSimilar to the following, \nhttp://stackoverflow.com/questions/16631078/fineuploader-restarts-the-upload-in-case-of-delayed-server-response.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1245#issuecomment-48048235\n. Closing, but we can re-open if a live example required to reproduce is made available.\n. Looks like you opened up a question at http://stackoverflow.com/questions/24600925/fine-uploader-how-use-table-as-file-list.  We can discuss further there.\n. Actually, even though this was a known limitation for the life of Fine Uploader, it's probably something we should look at adjusting.  I think you are the first person in a long time (that I can remember) who has tried to use <table>s in a Fine Uploader template.  \n\nIs there any particular reason you want/need to use a table?\n. Hmm, the files are already displayed in a list format by default, and your only changes involve wrapping these elements in table tags. \u00a0It's not clear what additional benefit you will get from a table here. \u00a0What issues with the default layout are you looking to address?\nOn Mon, Jul 7, 2014 at 3:22 AM, Alex Antonov notifications@github.com\nwrote:\n\nTable is the most convenient way of presenting information without any cost vrmena writing a new style for displaying information.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1246#issuecomment-48151930\n. It's unlikely that we will pull in a mandatory dependency. \u00a0Currently, the library has no such dependencies.\n\nOn Mon, Jul 7, 2014 at 7:17 AM, Alex Antonov notifications@github.com\nwrote:\n\nI load additional data for each selected file to upload, and for me to be more practical use for this tables... \nMaybe you think about replacing template engine to mustache (or another) and fix handler of templates?...\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1246#issuecomment-48171001\n. I would say that the size is irrelevant.  Fine Uploader has been a no-dependency library since its inception, and I hope to keep it that way.  We'll look into a possible fix for the templating issue and address this in 5.0.5 if possible.\n. @bjornbos Are you able to get more details from the customer, such as what \"does not work\" means, specifically?\n. We are not able to reproduce (due to lack of such a device) but will keep\nthis open in case someone else is able to verify or more details become\navailable in the future.\n\nOn Wed, Jul 9, 2014 at 4:39 AM, Bjorn Bos notifications@github.com wrote:\n\nThe customer told us that the 'file picker window' opens fine, but after\nselecting the file, the file picker closes but nothing happens (no upload\nstart). Note that on that same device it did work with Chrome....\nBtw: we are using FineUploader 5.0.2 with S3, previews and scaling.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1247#issuecomment-48449195\n.\n. Not sure we will ever have such a phone in our inventory, and no one else has reported the same issue.  Closing, but if anyone else runs into this, we can re-open.\n. Most likely there is a browser extension interfering with the button.  What sort of extensions are installed on the browser where this is reproducible?\n. Closing, but we can re-open if more information becomes available.\n. What is the bug you are seeing?  Just a log message, or is the uploader behaving incorrectly as well?\n. There are a number of places in the code that will lead down that path.  It's likely that the entry in requestData is being removed before that call, perhaps due to an explicit call to abort the request (via pause or cancel).  We'll have to look into this further.\n. I haven't looked yet, but I plan to look into this as part of the 5.0.5 release.  5.0.4 will likely go out shortly. I commented on the possible low-level cause a few messages above.  Let me know if you find anything out, otherwise I will look closer after 5.0.4 is out. \n. Are you noticing any actual issues?  Are you registering callbacks that are not being invoked?  Are files failing to upload, etc?\n. Great. \u00a0Thanks for the update!\n\nOn Sat, Nov 8, 2014 at 10:08 AM, Bjorn Bos notifications@github.com\nwrote:\n\nI have not yet seen any occurrences of this error on iOS8, so it looks like this only applies to iOS7\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1249#issuecomment-62263088\n. Closing unless this resurfaces in iOS8.\n. :thumbsup: My limited experience with jekyll has been positive.\n. Sems docfu is working well enough for us.  Any plans to overhaul it, @feltnerm?\n. Only the build file is written in coffeescript, and that will be ported over to plain 'ole javascript shortly, thanks to #1112.  It's not particularly useful to push compiled files to bower, IMHO, especially for a project like Fine Uploader, where your built version can vary greatly depending on the features you are interested in.  Also, it's unlikely that this bower package will remain up-to-date as we don't plan on maintaining something like that at this time.  \n\nIf you'd like to build your own version, we've described how this can be done in the building section at http://docs.fineuploader.com/contributing.html.\nIn the meantime, we are actively discussing ways to make it much easier to obtain a copy of Fine Uploader.\n. You could perhaps access and dynamically change one of the underscored \"private\" properties that controls this endpoint.  Another option is to fork Fine Uploader and add the appropriate API method.  We'll flag this issue and schedule it for a future release.\n. This will be part of 5.1.0.  Documentation added as well.\n. If the chunking.partSize value is greater than or equal to the size of the file, no chunking will occur.  Note that a chunked request is different from a non-chunking request due to differing headers, and the fact that the message-body of a chunked request contains a Blob, while a non-chunked request message-body contains a File (assuming the file is not a scaled version and the original file is not a Blob itself).  \nPre 5.0, all traditional endpoint upload requests would be chunked (if the feature was enabled), even if the entire file was smaller than the desired chunk size.  This was an inconsistency that I finally fixed in 5.0 (it existed since the chunking feature was introduced by me in v3.2).\n. This issue is pretty easy to work around: simply call getName in your progress handler, passing in the ID of the file.  This should be suitable until this issue is fixed in a future release.\n. Starting work on this as part of 5.0.4.\n. Fixed in the hotfix/5.0.4 branch.  To be part of the upcoming 5.0.4 release.\n. @xzyfer Any interest in verifying the fix, since you reported the issue?\n. Pause/resume is not available for files of that size (less than 4 MB, by default).  How are you initiating the pause?\n. Ah, ok.  Yes, you shouldn't be able to pause an upload until after the first chunk has successfully completed.  A pause operation aborts the in progress chunk and a \"continue\" will resume the upload starting with the aborted chunk.\n. @sixlettervariables Can you re-open using a branch based off of the develop branch?\n. Thanks for this.  We'll sort out the build failure in the develop branch and take a closer look at this when we begin work on the next release.\n. No apparent merge conflicts.  So, this is still clean.  When we get around to this, we'll likely just merge it into develop anyway and make any required adjustments before making it live.\n. @stevenringo Your comment doesn't appear to be related to this case.\n. ...except for the last point\n. Regarding URL encoded params: this is necessary.  In some cases, these params are sent as headers (when the S3 REST API is used).  You can't have non-ascii chars in headers.  Also, even when these params are sent in the message-body, any special characters are ripped out by S3 anyway, since these params are included as headers when S3 responds to a request for the object.\nAll custom params are prefixed with x-amz, per the S3 API specification.\n. Also, not sure what this comment means:\n\nThese seem never to get caught, as the name is munged into content-disposition for example:\ncase \"Cache-Control\":\ncase \"Content-Disposition\":\ncase \"Content-Encoding\":\n\nThe code looks correct to me.\n. I think you are misunderstanding the context of this code.  Custom headers in the context of Fine Uploader are any headers that the user/integrator specifies via the customHeaders option or API methods in Fine Uploader.\n. Not seeing where the header name's case is changed.  Can you reference that line number?\n. There isn't anything on that line or in that function that changes the case of the header name.  And I explained earlier why parameter values are URL encoded.\n. I do however see your point about encoding the values of the non x-amz params. \u00a0We will ensure that is examined closer before this is merged in. \u00a0Thanks.\nOn Thu, Aug 28, 2014 at 5:00 PM, Steven Ringo notifications@github.com\nwrote:\n\n@sixlettervariables They should also not be URL encoded.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/pull/1258#issuecomment-53807939\n. I'm going to work on integrating this change as I wrap up the 5.4.0 release.\n. Changes are being staged in the develop branch as part of 5.4.0-9. I had to make a few small adjustments to address linting errors. Please let me know before the release (which is coming up soon) if anything is missing.\n. @arnoldad You should be able to set any of the headers listed in the commit diff. Let me know if anything is not working as expected.\n. @arnoldad Thanks for the update. Can you submit a pull request against develop with your change? Do the unit tests pass with your change as well?\n. Thanks! Note that the unit tests cannot be run in Phantom anymore due to the age of Phantom 1.x and the serious issues with binaries in Phantom 2.x. So, Firefox is the suggested way to run them.\n\ngrunt clean dev test:firefox\nI hope to remove grunt and simplify the build a lot as part of 6.0.\n. @arnoldad Looking at the pull request I merged in, it's clear that there is a lot missing, unfortunately. I also noticed that the \"header\" values are being unnecessarily URL encoded.\nAt this point, I don't intend to tackle this issue or #1387 as part of 5.4.0 anymore. Instead, I'm going to push them to a 5.5.0 release. 5.4.0 has been in progress long enough. I'd like to move to the testing phase followed by a release. 5.5.0 will, hopefully, be released in less than a couple months. \n. Remaining work moved to #1494.\n. Please see http://fineuploader.com/support\n. Support is handled on stackoverflow.  The issue tracker is for bugs and feature requests.\n. Thanks for reporting this.  We will attempt to reproduce and look into an appropriate solution if this is reproducible by us.\n. I'm not able to reproduce on Win7 IE10 using the buttons on the demo page at http://fineuploader.com/demos.  Please provide specific steps and/or a link to a site/instance where this can be reproduced.\n. That data object is only ever supposed to contain name and size properties.  We'll look to see why it differs in some cases.\n. The initial call to the onValidate callback includes only the name and size properties, as documented.  This is a simple Object with only two properties, based on the underlying Blob.  \nonValidate calls for subsequent files pass the underlying Blob.  This will include the name and size properties, along with all other properties native to a Blob or File object.  This was not the intention.  Instead, we should be passing a simple object with name and size properties to ensure that the container for this data parameter is consistent, regardless of the browser (since some browsers don't have support for the File API and File/Blob objects).  \nThe bug here is that we don't pass a normalized data parameter (containing name and size props) in all cases.  This means onValidation callback handlers in IE9 and older receive an undefined data param in some cases.  This is the bug that we intend to fix here in the next release.  It's important to know that this bug will never naturally occur in IE9 and older, since multiple files cannot be submitted at once via a file input element in these browsers due to a lack of support for the multiple attribute.  However, this could be an issue if multiple file input elements are submitted via the API in these browsers.  So, we'll make of note of this and fix in a future version.\n. Working on this now as part of 5.0.4.\n. This should be fixed with my last commit (with an additional unit test).  I also detected (and fixed) a related issue: associated buttons (if avail) are not passed as the last param to onValidate for all but the first file in a batch as well.\n@KratosGemini Any interest in verifying this fix, since you were the original reporter?\n. Test fixed in f849952abf04ddb48deccaa61eb29fb42be7a49c.\n. Excellent.  Thanks for the update.\n. This is a confirmed regression, likely caused by 5.0 work.  The only workaround would be to obtain a list of files via the getUploads API method and call the cancel method for any cancelable files.\n. For the most part, a file can be cancelled unless the status is CANCELED, REJECTED, DELETED, or DELETING.\n. Yes, this is an issue that will affect all builds of Fine Uploader.\n. Starting work on this as part of 5.0.4.  In fact, I think I have it fixed in the hotfix branch, but I really would like to ensure we have some better cancelAll unit tests as part of this case (since the existing tests didn't catch this glaring issue).\n. Turns out that unit testing this is tricky due to the timing required to properly execute the cancelAll in order to reproduce.  Tests that rely on careful timing/setTimeouts are usually bad news.  I've performed some manual tests in a few browsers, and all looks good.  @dmichael and @PaulParker Are you interested in verifying this fix in your apps, since you both reported this issue?\n. Simply re-running whatever application/code you ran when detecting this issue, with the updated code, will be helpful.  I'll send you an email, Paul.\n. Anyone get a chance to test this out?  I'd like to release as part of 5.0.4 soon.\n. I'll look into this next. \u00a0Thanks for the report. \u00a0Concurrent chunking is a mysterious beast.\nOn Tue, Aug 19, 2014 at 8:17 AM, Paul Parker notifications@github.com\nwrote:\n\nIt looks like there is an intermittent issue with the currently-uploading file not getting cancelled when chunking and concurrent uploads are enabled.  WIth those settings, if I drag a bunch of files and cancel them, sometimes the first one will not be cancelled.  It seems like it's probably a timing issue or something.\nIf I disable concurrent, the issue seems to go away.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1262#issuecomment-52631549\n. I'm guessing you mean \"for a file < 5 mb, the 'cancel all' seems to work\nfine\"\n\nOn Tue, Aug 19, 2014 at 10:43 AM, Paul Parker notifications@github.com\nwrote:\n\nYeah I figured. Note that I am only seeing the issue when the\ncurrently-uploading file is big enough to be chunked for S3 upload. For a\nfile > 5mb, the 'cancel all' seems to work fine, even with the concurrency.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1262#issuecomment-52653656\n.\n. Ah, I see.  Odd that a non-chunked upload fails to cancel in concurrent chunking mode.\n. The complexity associated with concurrent chunking is a bit overwhelming.  Hopefully the implementation can be improved/simplified over time to avoid these types of regressions from cropping up.  I'll take a look at this issue sometime this week.\n. Looks like cancelAll won't cancel any files that are not eligible for chunking if concurrent chunking is enabled.  This was an oversight in the concurrent chunking logic.  I'm looking into a fix.\n. Good catch @PaulParker.  I think I have the issue fixed in 5.0.4-5.  Care to confirm?\n. I'll send you an email @PaulParker \n. @PaulParker were you able to verify the fix?\n. Great. \u00a0Thanks for verifying Paul.\n\nOn Sat, Aug 23, 2014 at 7:34 AM, Paul Parker notifications@github.com\nwrote:\n\nOk I think the fix worked and I haven't seen any other issues.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1262#issuecomment-53151606\n. Hmm, that's an interesting request.  Fine Uploader and other similar libraries generally embrace progressive enhancement.  There are certainly a number of other similar inconsistencies between browsers (such as IE9 and older versus Chrome/Firefox/Safari/IE10+) due to the differing capabilities associated with each browser.\n. I'm guessing that Craig was referring to the fact that support for this feature across browsers is inconsistent. \u00a0Did I understand this correctly?\n\nOn Mon, Aug 4, 2014 at 6:12 PM, Mark Feltner notifications@github.com\nwrote:\n\n\nusers complain that dragging folders gives an inconsistent experience.\nWhat is inconsistent?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1263#issuecomment-51130448\n. I've never seen the issue with uploading that you have mentioned.  How can this be reproduced?  If you are using an older version, you may be experiencing #1217, which was fixed in 5.0.0.  Otherwise, the issue you described hasn't been witnessed or reported before to my knowledge.  The only time this would be expected is if some of the files failed validation, but this is no different than dropping a batch of files where some fail validation.\n\n\nWe can certainly make a note of a request to allow folder dropping to be disabled, but we can't even detect if a folder has been dropped in any browser other than Chrome or recent Opera.\n. No guarantee that this will be removed. Only if chrome removes support for the filesystem API. \u00a0There are no specific plans to do that AFAIK, but is is possible since the spec was killed by W3C.\nOn Mon, Aug 4, 2014 at 6:46 PM, Craig Bruce notifications@github.com\nwrote:\n\ninteresting comment you made about directory D&D potentially being dropped (https://github.com/Widen/fine-uploader/issues/1217)\nsounds like we just need to live with this for now. Thanks.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1263#issuecomment-51133034\n. Most likely, the issue is in your server code/environment.  Since this case lacks information required to reproduce, I'll have to close it.  However, it can be reopened if you provide your client and server-side code, along with browser log messages with the debug option set to true.\n. Are you positive that this happens when a new file begins to upload, and not simply when a new file is submitted to the uploader?\n\nOn Tue, Aug 12, 2014 at 4:18 AM, Kajan notifications@github.com wrote:\n\nHi,\nI am using FineUploader 5.0.2 in core mode, with the AngularJS framework.\nI make requests with the scaling options, sendOriginal set to false and maxConnections set to 1.\nAnd I got a strange problem : the totalBytes parameter of the totalProgress event increases  each time it starts to upload a new file. Making my computation of the percentage of upload wrong.\nI couldn't find any issues related to that, let me know if I missed something or if you need more infos.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1265\n. Ah yes.  Unfortunately, there is nothing that can be done about this.  We don't generate scaled versions of original images until just before they are uploaded (we then delete the scaled versions from the browser after the upload completes).  This is done to conserve memory and processor cycles.  Therefore, we don't know the size of these scaled versions until just before they are uploaded.\n. Sure thing.  In this case, you'll need to live with the occasional resizing of your total progress bar, due to the way scaling is implemented.  So, you'll need to re-calculate the percent complete whenever you receive a new \"totalProgress\" event.\n. Of course, I can see why that may be a problem when your instance is set up to only allow 1 upload at a time.  \n\nCan I ask why you are setting maxConnections to 1?\n. A better way to preserve \"order\" would be to associate specific parameters\nwith each file, so you can easily sort this out server side.\nOn Tue, Aug 12, 2014 at 11:00 AM, Kajan notifications@github.com wrote:\n\nBecause we will mainly use the uploader for images, and we want to keep\ntheir order while uploading the images. And apparently, on the previous\nversion of the website I am working on, they had some order issues when\nthey used a maxConnections superior to 1.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1265#issuecomment-51935425\n.\n. We will keep this in mind for a future release.  Thanks for your suggestion.\n. If we implemented this feature, it would only apply to Chrome, and only for dropped directories.  I'm not sure this is worth the effort required to make this happen.  I'm going to close this case, but we can re-open if more users express interest.\n. No, the web specification tied to this feature has been deprecated, so browser support is forever limited to Chrome.\n. You'll need to provide more information if you'd like us to investigate.  Specific steps required to reproduce, etc\n. Ok. Without any specific information regarding circumstances of the error, we will have to close this issue.  If more information is uncovered later, we can certainly reopen.\n. Ok. Without any specific information regarding circumstances of the error, we will have to close this issue.  If more information is uncovered later, we can certainly reopen.\n. What is the status code of your server's response?\n. A failed chunking.success response must include an appropriate response code (non-200).  \nFor successful responses, you may return an empty body with a status of 200, 201, or 202. Any other status code is determined to be a failure. You can also return a JSON response with any data your would like passed to your onComplete handler. Furthermore, you can include an error property in your response with the error message you would like to have displayed next to the failed file (if you are using Fine Uploader UI).\n. http://docs.fineuploader.com/branch/master/features/concurrent-chunking.html#expected-response-for-the-chunking-success-post\n. We'll keep this open so we remember to update the docs.\n. Thanks for your report.  Testing against iOS8 beta will start shortly, now that it is presumably close to release-candidate stable.  I'll keep this updated with our findings and adjustments.\n. Just tested myself with a simulator.  Looks like a pretty serious bug in iOS8 beta to me.  Apple historically has had a number of serious issues in mobile Safari with file input elements when the multiple attribute is present.  This appears to be another such issue.  \n\nI was able to reproduce with a simple <input type=\"file\" multiple>, no Fine Uploader involved.  If you remove the multiple attribute, you are able to select a photo.  \nCan you confirm my observations?\n. First off, can you confirm my observations regarding the issue you initially reported ?\n. After a very simple test, with the multiple option set to false, uploads seem to work in iOS8 using Fine Uploader.  I didn't try a form submit, as Fine Uploader doesn't upload files this way in modern browsers.\n. Which device (running iOS8) are you using?\n. multiple=\"false\" is no different that multiple, since it is a boolean attribute.  \nI've filed a bug with Apple regarding the initial issue you reported.  Hopefully this will be fixed before iOS8 releases.  If not, we'll consider forcing the multiple option to false in Fine Uploader for iOS8.  This is similar to the approach we take to work around the bug in iOS7 that results in a 0-sized file uploaded when a video is selected with the multiple option set to true.  In that case, if a video can be selected, we force the multiple option to be false in iOS7.  #1039 \n. After some reflection, I think it is best to go ahead and incorporate a workaround for this bug in v 5.0.5 of Fine Uploader.  \nWith the workaround, worst case is Apple fixes the bug before iOS8 releases and users can only select one file at a time (which is already the case in most instances, such as if the possibility of selecting a video isn't prohibited due to #1039).  \nIf we don't include this workaround and Apple doesn't fix the issue before iOS8 goes live, worst case most users won't be able to select any files in iOS8 without re-deploying their apps that depend on Fine Uploader with the multiple option to set to false.  \nMy hunch is that this bug will not be addressed by Apple before iOS8 releases, based on past experiences.  I don't want to hold up 5.0.4, so this can be a 5.0.5 release.  Any thoughts @feltnerm?\n. The bug I filed with Apple was closed as a duplicate of another.  What that other bug looks like, I don't know.  There is no way to access any bugs that you have not personally filed.  This is a well-reported & noticed bug and that might result in a fix from Apple before release.\n. I'm going to wait to release 5.0.5 until just after iOS8 releases.  If the final version has this issue, I'll go ahead and release 5.0.5 immediately.  Otherwise, I'll revert bca3f13 and then release 5.0.5.\n. iOS8 doesn't release until the 17th. \u00a0The gold master build was just made available, but I haven't looked at it yet. \u00a0Nothing in the release notes though.\nOn Wed, Sep 10, 2014 at 2:50 AM, Bjorn Bos notifications@github.com\nwrote:\n\nDo you know if it has been solved by Apple?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1269#issuecomment-55082048\n. It's not clear if this issue is fixed due to a more serious regression in iOS8, described in #1284.\n. Thanks for the report. We'll look into this early next week and likely include a fix as part of 5.0.5.\n. I'm not able to reproduce this issue.  Using Fine Uploader 5.0.3.\n. Sure.  Just reply to the last email you received from us, such as your receipt email.\n. Are you trying to add params to a request sent to azure, or to one sent to your signature server?\n\nOn Sun, Aug 24, 2014 at 4:27 PM, angelsix notifications@github.com\nwrote:\n\nI might be using it wrong, but for Azure, inside the on submit function I use a promise to ask the server for some information that I need to pass to the signature url. The promise works fine and everything else works, the signature gets called, and I can use setName to set the name which comes through to the signature url so I know the basic setup is all working.\nNext to the setName I also call setParams (and I have tried setCustomHeaders too although I don't think thats for Azure), but nothing I set adds headers to the signature URL. I need to pass some information I get from the server call in the submit function to the signature call.\nHere is what I try inside the submit function, where id is the id of the file passed into the submit function by FineUploader. I have also tried it without an id to be global to all calls but that doesn't work either.\nfu.fineUploader('setParams', { 'some-header': 'some-value' }, id);\nNo matter what I do I cannot get any custom headers or information to be sent to the signature function.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1271\n. Currently, you can specify custom headers when the upload is constructed via the signature.customHeaders option.  The ability to specify additional parameters for the signature URL via query parameters is a requested feature not yet implemented.  Please see #1224.  We can probably include the ability to dynamically specify headers in that case as well.\n. You are correct.  As mentioned previously, we can include the ability to dynamically set/change headers for signature endpoints in #1224.  This was not included in the initial development as the initial beta testers didn't seem to have an issue with the absence of this feature, and we didn't want to prolong the release of Fine Uploader Azure.  As with Fine Uploader S3, we expect to evolve the Azure module over time as users request additional features.\n. http://docs.fineuploader.com/branch/master/api/methods.html#getUploads\n. There is definitely some issue with your code, but I can\u2019t tell what that issue is from one line. \u00a0You\u2019ll need to either share all of your code, or a link to a site where this can be reproduced.\n\nOn Mon, Aug 25, 2014 at 9:55 AM, angelsix notifications@github.com\nwrote:\n\ngetUploads always returns undefined. Wherever I call it I just get undefined.\nIt is called like this:\n            console.log('getUploads: ' + uploader.fineUploader(\u2018getUploads\u2019));\nI have tried calling it inside progress, totalProgress, complete, and allComplete. Everywhere returns undefined.\nOn Aug 25, 2014, at 3:49 PM, Ray Nicholus notifications@github.com<mailto:notifications@github.com> wrote:\nhttp://docs.fineuploader.com/branch/master/api/methods.html#getUploads\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53273557.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53274384\n. @EZWrighter since you reported this bug, are you interested in verifying the fix in your app?\n. This has been part of the DnD module since the beginning.  It is needed to expose initially hidden drop zones when a dragged object enters the page.  It exists to serve the default UI, and the standalone DnD module, which is not necessarily used with the Fine Uploader CSS file.  \n\nWe can investigate ways to more easily override this style without breaking existing standalone DnD workflows.\n. Yes, perhaps.  If the DZ isn't hidden initially, that line is not needed if I recall correctly.  In the default case, it is.  Apparently, it's uncommon for drop zones to not be block-level elements, yours is the first request we've received to adjust this.  \nWe'll look into this internally and keep this open as a reminder.\n. @angelsix I've made this adjustment as part of the 5.1.0 pre-release.  If you're interested in verifying before the release, let me know.\n. We're getting away from these very customized builds due to the associated complexity required to maintain, troubleshoot, and document.  Also, it doesn't scale well.  \nI can send you a jQuery Azure build.  Also, since you are using jQuery it seems, please take a peek at #1310.\n. I would disagree that it's \"not an error\".  It is indeed an error.  The fact that it will be retried doesn't mean that the previous attempt did not end in error.  The purpose of this event is simple: notify you whenever any error occurs, which it does.  We definitely won't be creating another event for this, there are arguably too many already.  \nIf you want to notify your user only when a file has not not uploaded after all auto retry attempts, register an onComplete event handler, and look at the value of the success property in the responseJSON param.  http://docs.fineuploader.com/branch/master/api/events.html#complete.  You can notify your user that a retry is pending by looking at the statusChange or autoRetry events.\n. The complete event will be called only after the file has uploaded successfully, or all retries (if any) have been exhausted and the upload is a failure.\n. It should triggger onError. But you should also (and more properly) be able to access the status of the request in an onComplete callback. If you are seeing a specific issue, please open up a new case.\n. There is no specific timeline to complete this. Reasons:\n- Azure is much less popular than S3 or traditional endpoint support. The S3 and traditional/custom endpoint modules of the code are given priority attention\n- I am the only developer allocated to Fine Uploader, and my time to work on this project is unfortunately quite limited as well. I spend most of my time answering questions and providing support.\n. Thanks for that. I'm working on a plan to get more eyes on Fine Uploader and Modern Uploader.\n. Then don't specify an href attribute, or use \"#\" as the href.\n. As Mark stated, you should not be programmatically clicking a file input.  Some browsers will prevent this one way or another.  Also, extra buttons aren't treated any differently than the \"default\" button.  In both case, click events are not \"canceled\".  Again, if you really want to include an href, set the value to \"#\".\n. May work in some modern browsers depending on the version, certainly not IE9 and older.  In those browsers, the underlying form submit will be rejected by the browser if the chooser is invoked via JS.  At any time, browsers may prevent this from working, as has been the case in the past.  I encourage you to read up on the history of limitation on the file input element.  Programmatically clicking a file input is a hack and generally discouraged.  \nFurthermore, you cannot simply preventDefault, as this will, of course, prevent the chooser from being displayed as this is the browser's default behavior, and the click event will initially target the file input and not the anchor. \nFinally, you certainly can use \"#\" to prevent page reloads.  The browser will not attempt to GET a resource if a hash is added to the URL, thus no page refresh.  This is the case in all browsers.  Your best bet is to do this, or omit the href and style the anchor however you please.\n. Are you able to reproduce this issue on our demos page?  For the most part, I'm not seeing the issue there.  Is this specific to your site or your use of the styled file chooser button?  I'm not able to sign into your site in a Windows VM today, but I'll take a look next week.\n. I was able to reproduce this on your site by reverting the font-size on the opaque <input type=\"file\"> to 118px.  Very interesting.  I don't think this has come up before.  The only solution that I'm aware of would be to change the font-size to a very large value, as you suggested.  If there aren't any regressions associated with that change, it's looking like that will be the fix for this, kludgey as it is.\n. @yairEO Will you be interested in giving a pre-release with a fix for this issue and #1152 a spin?\n. Caught an fixed an issue with IE8 caused by this fix.  It turns out that setting the font-size to a value that is \"too large\" causes the file input to become visible in IE8.\n. This issue seems to affect all versions of IE, so feature detection won\u2019t be of any use.\nOn Wed, Sep 10, 2014 at 9:04 AM, vsync notifications@github.com wrote:\n\nBetter to set the font-size using feature-detection so the right value will go to the right browser\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1277#issuecomment-55119346\n. It may be best to simply limit this arbitrarily large font-size to all versions of IE.  This requires user agent string parsing, but that is acceptable to work around peculiarities such as this one.\n. Reading over your comment again, it's not clear what issue you are describing.  The cursor in Chrome seems to render the same with or without a large font-size.\n. Ok.  We don't plan on rendering buttons of various sizes as part of our testing.  So, the safest bet is to limit this \"fix\" to IE.\n. Programmatically clicking on a file input will cause IE9 and older to reject the eventual programmatic form submit used to upload each file.  Other browsers have, at one time or another, prevented/ignored programmatic clicks on file inputs as well.  \n\nIt's a moving target, and it's unlikely that these types of small quirks can (or should) be resolved.\n. Looks like the issue you discovered had nothing to do with font-size.  It was caused by the addition of a width: 100% style to the underlying <input type=\"file\">.  I'll remove this as it is probably unnecessary.\n. Should be fixed in the 5.0.5-6 pre-release.\n. ugh, it just occurred to me that the width: 100% may be needed in IE to complement the large font-size.\n. I just created a huge chooser button, and it seems to be clickable w/ one click in IE8+ without the width: 100% after all.\n. I will be reverting this change for IE8 due to a regression found in #1306.  If you really want a large upload button in IE8, you'll need to fiddle with the font-size via your own CSS rules, based on the size of your upload button.  You can target the opaque file input via a INPUT[name='qqfile'] CSS selector.  \nIE7 support for a large button is blocked by a (IE) bug that makes most of the visible button unclickable when the height of the opaque file input is set to 100%.  If you plan on supporting IE8 and older, you should consider sticking with a normal-sized upload button for those browsers.\n. Working on this next as part of 5.0.5.\n. I'll be tackling this bug next as part of 5.0.1.\n. er, 5.1.0\n. After more investigation, this appears to be an issue where the browser runs out of memory prematurely due to intensive preview generation. It looks like the browser's garbage collector doesn't free up memory quick enough when a number of large images are generated at once, and the tab crashes.  Decreasing the number of simultaneous preview generations seems to address the problem, but this is a tricky workaround to automate.  There is no way to monitor memory usage from JavaScript, so we may be forced to limit preview generations to occur only one at a time and/or space the preview generations a few seconds apart or so.\n. Even more investigation shows that this is only an issue in Chrome, and seems to happen after enough large images are previewed without fail.  It might make sense to simply provide an option to limit the total number of generated previews.  Integrators can set a limit in Chrome only, if they want, by making the option value conditional based on the browser's user agent string (or simply by checking for folder drop support via qq.supportedFeatures.folderDrop.\n. This may be explained by an existing Chromium bug.  Sounds like some have had luck turning on the \"impl-side painting\" flag, but I didn't see any improvements myself.  \nThis case will likely include other adjustments to the preview image feature.  I noticed that a large number of complex images can cause any browser to hang for a while during preview generation, so I'm also working on a preview generation queue that will ensure preview generation is limited to 1-at-a-time, with a period of time between generation jobs to ensure the CPU isn't continuously pegged.\n. Ready for integration testing.\n. duplicate of #1294\n. I believe we are already going to account for this in #1258.\n. No idea\n. Here's the Chrome issue I filed: https://code.google.com/p/chromium/issues/detail?id=412847.\nUnfortunately, Apple doesn't expose issue links, or allow anyone outside of Apple to see issues filed, other than the filer.  So, I can't provide a link to the iOS bug I filed with Apple.\n. A new release of Chrome that addresses this issue before iOS8 launches on Wednesday seems like a longshot at this point.  \nWe should probably work around this issue, since a browser crash is a significant problem for users.  The only way to prevent this is to force the multiple option to false in iOS8 Chrome.  The side effect here is that we will need to disable another workaround (described in #1039), so videos will be uploaded as empty files due to another outstanding bug in iOS, described in #990.  Still, this is better than a browser crash.  Once this issue is fixed, we can release a new hotfix that disables this workaround.\n. Sounds like this will be fixed in Chrome 38 based on the changes to the issue I filed.  I'm not sure yet if this will release before iOS8.\n. Since the Chromium team won't give a release date, we'll have to code a workaround into Fine Uploader 5.0.5, forcing a multiple attribute on the underlying <input type=\"file\"> element.  This means that videos will upload 0-sized, but there's not much we can do about that.  At least users will be able to upload images in one iOS browser.\n. Workaround added to 5.0.5-7 pre-release.\n. @ChaplinWang  That is expected behavior for iOS and is unrelated to any Fine Uploader code.  iOS will not permit access to the camera when the underlying file input element contains the multiple attribute.\n. The logic in place in Fine Uploader appears to be correct to me.  The crash issue is specific to Chrome or any app that launches UIWebView, and may occur in any version of iOS8, depending on the installed version of Chrome or the version of the app using UIWebView.\nYou can disable this workaround if you are certain your users are using a current version of Chrome or a current version of your app in iOS8 that was compiled using the iOS8 SDK.\n. Yes, it seems Apple knew about all of these bugs, chose to ignore them and release a gold master anyway.  Hopefully they come to their senses and fix this before release.\n. As you suggested, UIWebView does not seem to suffer from these issues.\nRegarding your suggestion to encourage users to switch to Chrome - keep in mind that video uploads are not possible in Chrome iOS8 at this time due a bug described in #1283.  \nI've outlined all new and existing browser-based-upload issues present in iOS in a blog post published yesterday.\n. Not sure what we are going to do yet, but it will likely be a decision we finalize shortly before iOS8 releases, just in case Apple fixes these issues and issues a new pre-release build.\n. I'm going to have to explore the pinning workaround a bit more.  It may be tricky or even impossible to distinguish between a page traditionally loaded in iOS8 Safari and one loaded via a home screen icon.   If we can, we will have to display some sort of message for Fine Uploader UI integrations when using iOS8 on Safari.  Maybe something similar to what we did in #680.\n. @bjornbos Adding the site to your home screen does not appear to work around the issue for me.\n. Yep. \u00a0On an iPad w/ iOS8 GM. \u00a0Seems like this is not a reliable workaround.\nOn Tue, Sep 16, 2014 at 3:14 PM, Bjorn Bos notifications@github.com\nwrote:\n\nWorks for me on an iPhone with iOS8 GM. Did you start it from the home screen icon afterwards?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1284#issuecomment-55806342\n. 5.0.5-8 is likely to be released tomorrow.  It will include code to alert iOS8 Safari users to the fact that uploads are not possible due to outstanding bugs in the browser.  Users will be directed to use Chrome instead.  This alert will only display for apps that run in iOS8 Safari.  UIWebView containers are excluded from this alert, since they are not affected by this bug.  \n\nFor Fine Uploader UI, the uploader container will be replaced with text explaining the limitation and directing users to Chrome.  This is same approach we take for iOS5 users.\nFor Fine Uploader core/basic, or for any attempts to upload files via the addFiles or addBlobs API methods, an alert is displayed indicating that uploads are not possible in iOS8 Safari, and the user is directed to Chrome.\nThere are also new options in place to turn off this (and other) workarounds.  See the blog post on iOS issues for more details.\n. Here's the latest (and only) update from Apple regarding the bug I filed almost 2 weeks ago:\n\nHello Ray,\nEngineering has determined that your bug report (18293405) is a duplicate of another issue (18016794) and will be closed. \nThe open or closed status of the original bug report your issue was duplicated to appears in the yellow \u201cDuplicate of XXXXXXXX\u201d section of the bug reporter user interface. This section appears near the top of the right column\u2019s bug detail view just under the bug number, title, state, product and rank. \nAn example of the duplicate section from the bug reporter user interface with your bug and the duplicate bug info is included below:\n18293405 file input element does not allow files to be read client-side or uploaded to server\nState: Closed                   Product: \nRank: No Value\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\nDuplicate of 18016794 (Open/Closed)\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\nIf you have any questions or concerns, please update your report directly here: http://bugreport.apple.com/.\nApple Developer Support\nWorldwide Developer Relations\n\nSince radar is a closed bug tracker system, I have no way of knowing what the status of 18016794 is.  If anyone happens to see this case and have any info/updates on 18016794, kindly post here.  As it currently stands, this bug is still not repaired in iOS8.\n. Yes, that's true.  I noticed that in the gold master.\n. Twitter thread from a WebKit person re this issue: https://twitter.com/xeenon/status/513569772957466624\n. Haven't tested 8.0.1 yet.  Unless there is a new issue, video uploads should work fine in Safari, provided the multiple attribute is omitted from the file input element.\n. Looks like 8.0.1 fixes this issue and #990.  Only tested on Safari w/ iPhone 5.\n. @karpitsky Video uploads are working fine for me in 8.0.1 iPhone 5 w/ or without the multiple attribute on the file input.  If you are still seeing an issue, please provide more info about your environment.\n. Note that you will want to disable the workarounds coded into Fine Uploader 5.0.5.\n. Wow, that was a really quick turnaround on 8.0.2. \u00a0I thought for sure it would be weeks before another release. \u00a0We\u2019ll take a closer look at 8.0.2 in the coming days. \u00a0The workaround is tied to 8.0.x, but can be easily disabled via the workarounds option.\n\u2014\nSent from Mailbox\nOn Thu, Sep 25, 2014 at 8:04 PM, Mitch Flindell notifications@github.com\nwrote:\n\nHey everyone, looks like 8.0.2 has been released, tested on my device and it all seems back to normal. They're also providing 8_0_2 as the userAgent so it will be a good idea to keep up the warnings for people stuck on 8.0 still.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1284#issuecomment-56907559\n. @bjornbos Is this a new issue as of iOS8?  What features do you have enabled on your uploader?\n. I just uploaded a handful of files and a video in iOS 8.0.2 on an iPhone 5 w/ scaling turned on (using Safari).  Everything looks ok at first glance.  Going to confirm on an iPad as well.\n\nWe'll release 5.0.7 that locks this workaround to anything older than iOS 8.0.2.\n. I'm not able to reproduce.\n. I'll see if I can reproduce next week. \u00a0Unfortunately, iOS8 in general is a train wreck, and this is becoming more common with apple software. \u00a0You might want to encourage users tied to Apple devices to stick with iOS7, or, better yet, iOS6.\nOn Sun, Sep 28, 2014 at 3:46 PM, Bjorn Bos notifications@github.com\nwrote:\n\nLooks like there is difference between iPad and iPhone. On iPhone everything works smoothly, but on iPad the upload process crashes the browser frequently. I'm also getting this feedback from my users now...\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1284#issuecomment-57099492\n. No ETA at the moment.  You can disable the workaround via the new workarounds option.  http://docs.fineuploader.com/branch/master/api/options.html#workarounds\n. No ETA at the moment.  You can disable the workaround via the new workarounds option.  http://docs.fineuploader.com/branch/master/api/options.html#workarounds\n. Fine Uploader 5.0.7, released today, will only target iOS 8.0.0 safari for this workaround.\n. Fine Uploader 5.0.7, released today, will only target iOS 8.0.0 safari for this workaround.\n. We will look into the iPad specific issue you have mentioned in the near future.\n\nOn Sun, Oct 5, 2014 at 10:26 AM, Bjorn Bos notifications@github.com\nwrote:\n\nI found out that it is not the upload process that crashes the browser on the iPad with iOS8+, but it's the image scaling. I now change the scaling option parameter to false for iPad iOS8+ users, but you might want to build this into the iOS8 workaround feature as default.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1284#issuecomment-57939459\n. This particular issue was resolved in iOS 8.0.1.\n. Yep, this will be fixed in 5.0.5.  The fix was introduced in 83aeb9cf1fcfbc6b644764a3aac37dc0f4bc6ab8.\n. So this is only an issue when the reset API method is called, correct?  If so, we'll fix in the next hotifx release: 5.0.6.\n. Right, and this is only called when you invoke the reset method in the API.  Are you seeing this only after you call the reset method in Fine Uploader's public API?\n. Hmm, it seems to happen after selecting a batch of files.  After submitting a batch of files, the second attempt only allows single-file selection.  \n\nThanks for the report.\n. Confirmed.  Regression caused by #1283 via d6cb1ac31a3bffab0467ae2db132575e194cff0c.\n. fixed in 5.0.6\n. Just to be clear, the original issue is reproducible only with display.prepandFiles set to true, correct?\n. Also, can you clarify what you mean by \"upload tray\" and \"update\" in this context?  Looking at the code, it's not clear to me how the situation you describe could occur.  It seems like the specific cause of the issue you are describing is something we need to investigate further.\n. Thanks.  We'll look into this.  I'd love to get to the bottom of the issue and make sure this isn't a symptom of a larger problem.\n. Thanks.  We'll look into this.  I'd love to get to the bottom of the issue and make sure this isn't a symptom of a larger problem.\n. Only 20-30?  Hmm, that's odd.  We are using Fine Uploader in an internal product with the prependFiles option turned on.  It's not uncommon for a large number of files to be submitted via this interface, and I can't recall running into this.\n. In this particular project: no, not for the upload section.  We do have other products that use Fine Uploader as an angular directive though, but they do not use the prependFiles option*.\n*except for one, which is a mobile web app, but it's uncommon for a large number of files to be submitted via a mobile device\n. Could be.  We'll keep this on our radar though.\n. Just out of curiosity, are you still seeing this issue as of Fine Uploader 5.4.1?\n. Thanks for the update. I'm going to close this then, but will consider re-opening if anyone is still seeing this on a recent version of the library.\n. Guess you should turn off \"Scanner Surf-Shied\" then.\n. Nothing we can do about it.  The progress information is supplied directly by the browser.  Sounds like your AV is intercepting the request and indicating that the entire file has been sent before actually sending to its final destination.\n. Sounds like you are looking for the validation.acceptFiles option.\n. If you'd like to remove a specific file after it has been added to the list, you can always cancel it via the API. \nBut, I'm confused.  multiple: false should only allow one original file to be selected/submitted.\n. > I now see that the uploader retains the invalid submissions, but only sends valid ones to the backend\nCorrect.  Fine Uploader accounts for all files submitted, whether they are valid or not.  These records are available via the getUploads API method.  There is a status property (among others) for each record.\nPlease see http://docs.fineuploader.com/branch/master/features/statistics-and-status-updates.html for more info.\n. Not able to reproduce in 5.0.6.  Please upgrade and try again.  If you are still seeing an issue, please post your code and HTML so we can investigate further.\n. Sorry, I'm not able to reproduce.  Perhaps some other library in your app is causing the issue, perhaps via a rebroadcast of the paste event?  Just speculation.  If you provide a live demo, I can take a closer look.\n. on completion of....?\nDestroying the uploader doesn't sound like it will solve your problem.  You've said that the first paste of an image results in one file, and the second results in two, etc.  Is there anything specific, other than pasting the same image multiple times, that needs to be done to reproduce?\n. Doesn't sound like destroying the uploader will solve anything, otherwise the issue would appear on the first paste, and the number of pastes would not be a factor.  Since we're not able to reproduce, I'm going to have to assume that something in your stack is affecting the paste event, causing this issue.  \nIf you have more details surrounding the issue, feel free to report back.\n. That is drop-zone code, unrelated to paste code.  The event is fired when the drop zone is setup, and when a drop event is handled in some cases.\n. Looks like there is a bug in the paste handler.  We are expecting to populate a variable when the paste event handler is registered that allows us to unregister the handler, but that is not happening.\nWe'll fix this in a future release, but you can work around this simply by ensuring that the element the paste handler is bound to is removed from the document when your dialog is closed.\n. I believe you can attach a paste handler to any element, but the element must have focus (or you must click on the element) for it to be the target of paste actions.\nOn Mon, Oct 6, 2014 at 9:16 AM, Scot Wittkamp notifications@github.com\nwrote:\n\nThank you. That's explains it. I've been using a targetElement of window or document as I have not been able to get paste to work using any other DOM elements. By that I mean pressing Ctrl-v does not create a paste event when bound to any other element. Any ideas?\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1293#issuecomment-58022819\n. We'll fix this and #1306 as part of the 5.0.8 hotfix release.\n. @dswittkamp I believe I have this fixed in a pre-release build of 5.0.8.  Would you like to try it out to confirm?\n. @dswittkamp ...note that you will have to call the reset API method after you are done with a particular Fine Uploader instance.\n. I don't think there is a pressing need to auto-generate these. The current practice of writing up a blog post explaining the new release is probably sufficient. We could (and arguably should) include a list of changes in the release section of the GitHub project as well though.\n. @allegrem We don't have a formal CLA at the moment, but do you have any issue with us merging your code in and releasing it under either GPL and/or our commercial license?\n. This will be part of 5.1.0.  Documentation added as well.\n. Anyone interested in trying this out before release?\n\nOn Tue, Nov 11, 2014 at 6:32 AM, Hugo Cordier notifications@github.com\nwrote:\n\nNice! Thanks\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/pull/1296#issuecomment-62540491\n. There is no concept of a success endpoint outside of the S3 or Azure uploaders. \u00a0You can make use of the onComplete event.\n\nOn Thu, Dec 18, 2014 at 8:46 AM, Alexander Skrivanos\nnotifications@github.com wrote:\n\nThis method should be available in the traditional uploader API as well.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/pull/1296#issuecomment-67494953\n. @skrivanos That exists due to the nature of concurrent chunking, and is only really necessary if concurrent chunking is enabled.  It is important  for your server to know when the last chunk has been sent, so the server can remain stateless.  Fine Uploader has access to this info, so it makes sense to fire a POST to the server so it can combine the chunks.  \n\nThe onComplete event is more than sufficient for all other traditional endpoint uploads.  Your server already has access to the file and all metadata associated with it.  This is not necessarily the case with S3/Azure uploads.\n. We can perhaps tie this to the upload endpoint, or allow an alternate endpoint to be specified dynamically in a future version.  Please open up a new feature request for this.  \nOtherwise, you can make the request in onComplete quite easily via XMLHttpRequest.  Also, if you rely on the chunking success endpoint, this will, of course, not be called if the browser does not support chunking, or if the file is not chunked.  onComplete is what you really want here if you need your server to be notified when the file has been uploaded successfully.\n. This is being staged in the css-updates branch.\nRemaining items to complete/adjust for 5.2.0:\n- [x] Fix disproportionate CSS scaling of gallery/tile images.  Some images appear to be stretched.\n- [x] Ensure all tiles are the same height\n- [x] Icons for delete/retry/pause/continue buttons\n- [x] Move JS code that shortens file name & failure message to CSS.  This will affect all UI views. This will make the failedUploadTextDisplay.maxChars option redundant.\n- [x] Thin images are not horizontally centered. This should be examined and fixed.\n- [x] Update styling docs with info needed to use this template/css.\n- [x] Update 5.2 site branch with a gallery view demo.\n. This is done, other than updating the docs (in progress)\n. Substantial updates to Fine Uploader's UI in this case and #843 are now complete. If anyone is interested in using this before the release, let me know.\n. The addCanvas branch contains my progress on #1198.  \nLet's put this on a feature branch until we get a chance to fix the violations and do some quick manual tests, just in case.  We'll merge into develop after that.\nThanks for the time you put into this @mrjoelkemp, we really appreciate it.\n. I moved this into the feature/jscs-integration branch.  We can start to fix the violations there and then merge into develop when everything is green again.\n. @mrjoelkemp If you're ever in the Madison area, or if we're ever in the NY area, we'll be sure to spring for that beer :beer: (or :beers:).  Until then, if you're looking for some assistance on one of your projects, let us know.  Perhaps one of us can spare a few of our own hours as well.\n. Forgot to tag my last commit, so here it is: 2682f74c09e3675d1bfd10714e335ec4f61c2dc7\n. :+1: \n. duplicate of #789\n. Already exists: http://docs.fineuploader.com/branch/master/api/methods-s3.html#setUploadSuccessParams\n. nope\n. Re styling the alert message:\u00a0http://docs.fineuploader.com/branch/master/api/options-ui.html#showMessage\nOn Wed, Oct 1, 2014 at 7:30 AM, vsync notifications@github.com wrote:\n\nwhen validating an upload, there are a number of validations that a person can set, like dimensions, file size and type. \nWhen using the validation event callback, it does not include the reason of the failure, so I, as the developer, cannot act differently to different failure scenarios. I would expect it as a parameter.\nAlso, I would like the ability to bypass the ugly alert messages when a validation has failed. (do my own custom popups instead). but the major thing it knowing the reason of failure. it's very important to an app's different flows.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1301\n. Seems like this should be a hotfix.\n. Develop should be fine.\n. We don't plan on exposing individual modules as part of the official API.  The logic associated with validating image dimensions is fairly straightforward.  If you require more complex validation for your project, you can make use of the onSubmit or onValidate callbacks.  These callbacks also accept a promise as a return value, so you can perform async operations to determine if the file is valid or not.\n. Please show your code.\n. It sounds like you are talking about server handling of the request.  Custom names for uploaded blobs will be included as a \"qqfilename\" param in the request.\n. I'm going to re-open this so we can update the docs to make this clearer.\n. The issue isn't form elements, since there are no (visible) form elements on the demo page.  Are you only seeing this on the demo page?  Are you able to demonstrate this anywhere else?\n. I suspect this is a regression caused by some work on #1277.  I'm able to reproduce the issue on the demo site in IE8, but I'm only seeing it in my local test page if I hover over the file chooser buttons.  \n\nA quick workaround, until we get a hotfix pushed out, would be to add this to your document:\nhtml\n<style>\n   INPUT[name='qqfile'] { font-size: 118px !important; }\n</style>\nI will likely exclude IE8 from the fix committed in #1277 if I can't find a reasonable workaround.  Overlaying a styled button on top of file inputs is extremely difficult to get right for all use cases in IE, unfortunately.\n. Note that I am seeing another issue specific to IE8 on the demo page only.  It looks like the uploader isn't being instantiated for some of the demos in some cases.  Appears to be a race condition of some sort as a refresh produces different results sometimes.  We'll take a look at this as well, but I suspect that is something very specific to the demo page.\n. We'll get this fixed as part of a 5.0.8 release.  Work on 5.1.0 will shift to this issue in order to get it resolved in a short period of time.\n. @rylwin Can you perhaps check to see if a font-size of 3000px causes any issues in IE8 for your app?  Looks good to me, but want to confirm.\n. @rylwin scratch that - After more investigation, the best thing to do is to exclude the font-size hack for IE8.\n. Fine Uploader really must be \"built\".  There are a lot of source files, and you likely don't want to simply pull all of them in individually.  The best course is to use one of the build tasks to create a concatenated version with the packages that you need for your scenario.\n. What version of Fine Uploader are you using, so I can attempt to reproduce the issue you have described tomorrow?\n. You aren't using a serverless upload workflow.\n. Please show the exact code you are using that results in policy issues.  Your initial question talked about use of the serverless workflow, but you appear to be using a server based workflow instead.\n. Sorry, I'm not able to reproduce any issue.  If you'd like to include a link to a live site where you have been able to reproduce this, I'll be happy to re-open the case.\n. I think this broke in 5.0.5 as a result of the change to qq.ie().  Before this change, qq.ie() returned false in IE11.  The DND module depended on this odd behavior.   b80ebef804ee47da5dfd29195ce70fc0264a1145  #1277\n. Note that the jQuery plug-in registry was taken down a couple days ago.  I take this as confirmation that the registry is dead.  \nJust to reiterate a bit, while it is clear jQuery is still used in many web sites/applications, I feel that this trend will not continue as the Web API evolves.  Also, and most important, wrapping the library in a jQuery plug-in doesn't have any obvious benefits for users of the library, and in fact makes integration more complicated and awkward.\n. @PaulParker There shouldn't really be any rewriting involved if we were to remove the jQuery plug-in wrapper.  There are only a few adjustments you'll need to make, at most (possibly only 1 or 2 in reality):\nConstructing\nInstead of $('#fineUploaderContainer').fineUploader({...});, you'll need to construct like this: \njavascript\nnew qq.FineUploader({\n   element: $('#fineUploaderContainer)[0],\n   ...\n});\nPassing elements into Fine Uploader's API\nYou'll need to pass in an HTMLElement instead of a jQuery object.  So, just add a [0] to the end of all portions of your code that construct a jQuery object that interfaces directly with Fine Uploader.  For example, if you are setting the button option now as button: $('#myButton), you would simply change this to button: $('#myButton')[0].  \nCallbacks\nIf you are using jQuery event handlers for Fine Uploader events/callbacks, you'll need to refactor a small amount of logic.\nFor example, the jQuery way:\njavascript\n$('#myFineuploaderContainer').on('complete', function(event, id, name, response, xhr) {\n   ...\n});\nWithout relying on jQuery event handlers, you'll declare your callback handlers during construction, like this:\njavascript\nnew qq.FineUploader({\n   callbacks: {\n      onComplete: function(id, name, response, xhr) {\n         ...\n      }\n});\nThe latter approach is recommended over jQuery event handlers anyway.  Why?  Well, it's more intuitive and efficient.  You can (and should) be using the 2nd approach now, even if you are using the jQuery plug-in wrapper.\nAPI calls\nThe jQuery way looks like this: $('#myFineuploaderContainer').fineUploader('getName', fileId);.  Pretty awkward, IMHO.  \nThe native JavaScript way looks like this: uploader.getName(fileId);.  I really prefer this syntax.  The jQuery syntax is odd and unnecessary.  \nIn the long run, no longer depending on jQuery is a good thing for everyone.  When you look at jQuery critically and compare it with what's already provided by the Web API in modern browsers and other micro libraries, jQuery seems unnecessary.\n. I've started writing a series of blog posts that will hopefully be of use for those who want to move away from jQuery. There are a couple posts already, and I have specific topics I plan to cover in additional posts over time.  Maybe this will be of some use to Fine Uploader users.\n. No worries.  There are no specific plans to move forward with this in a near-future release.  It's possible that we will never remove the jQuery wrappers, in fact.  We'll probably take other actions (such as emphasizing the vanilla JS API/syntax over the jQuery one) long before we even consider tackling this case.\nI agree that AMD/ES6 module/UMD support is much more important.\n. Plan is to remove the jQuery wrappers in Fine Uploader 6.0, provided CommonJS/ES6 module support is completed as well. \n. CommonJS support is set to be released in 5.8.0 (in progress). See #1562 for details.\n. You beat me to it :wink: .\n. I can see this being a useful enhancement for many users, and I think it can and should be applied to Fine Uploader Azure as well.  We'll aim to make this part of 5.1.0.\n. @Biggytv I've added this enhancement to the 5.1.0 version being staged in the develop branch.  Are you interested in testing to make sure it satisfies your requirements before we release?  If the format is not quite to your liking, and this is discovered after the release, any changes will have to wait until a major release.\n. Ok.  Plan on building yourself?  Otherwise, you can email us at the licensing address.\n. Looks like you're trying to use Fine Uploader as a jQuery plug-in.  I sent you the non-jQuery wrapper version, just change the first few lines to this:\njavascript\n$(function() {\n   var uploader = new qq.s3.FineUploader({\n      element: document.getElementById('fineuploader-s3'), \n      request: {\n         accessKey: \"\"\n      },\n...\nIt's not clear how deeply your application depends on jQuery, or what browsers you support.  If the answers are \"very little\" and IE9+, you can replace the first line with document.addEventListener(\"DOMContentLoaded\", function() {.\n. Looks like you haven't defined a template in your markup.  Have a look at the default templates included in the zip file I sent you.\n. Thanks Kyle.  You can read about the CDN integration for Fine Uploader S3 in the S3 feature docs for the develop branch.\n. Is there some reason why you cannot simply return a 200 from your server?  In this context, the only other possibly reasonable status codes are 201 and 202.\n. 5.2.0-4 in the develop branch will accept 200-204 for all upload and generic POST requests.  This will be part of the upcoming 5.2.0 release.\n. 5.2.0-5 adds the same support to PATCH and PUT requests.\n. This was a known regression in 5.0.5.  It was fixed in 5.0.8 via #1309.\n. Thanks for fixing this!\n. Thanks much for your proofreading effort.  Looks like you landed on that page via our recent tweet re the delete file feature.\n. I've asked you close to half a dozen times across your two stack overflow questions  to include code required to reproduce.  \nI'm unable to reproduce the issue by any means.  As it stands, we have the sortable plugin and fine uploader on a single page with text inputs in an internal app: no issues. Something in your code or environment is causing the issue.  Or perhaps you haven't configured the sortable plugin correctly, or...?  Can't say for sure as you haven't provided any useful information to aid in troubleshooting.\nThere isn't much else I can do to help if you don't provide specifics and code.  \nI'll be happy to reopen this issue if you oblige.\n. For anyone else that comes across this issue, the question-asker posted the following on Stackoverflow:\n\nThe problem was that we are using a jQuery Slider plugin and if keyboard navigation is enabled (which unfortunately is on by default) for this control, it stops all input activity. FineUploader IS WORKING PERFECTLY\n. The build failed as we only accept PRs against the develop branch.  \n\nThe function in question here is used in some code that attempts to ensure that a cross-origin request isn't unnecessarily preflighted.  We'll make sure this is fixed as part of an upcoming release.\n. Keeping this open for tracking.\n. Sure.  Also noticed that your branch is quite far behind.  May want to fetch first.\n. I'm a bit unclear on your requirements.  What, specifically, are you doing now that isn't working consistently?  Illustration w/ code would be best.\n. Looks like you've declared a chucking configuration option.  If this is an exact copy of your production setup, you'll want to correct that to be chunking instead.  \nI can see other benefits to allowing for an endpoint to be determined on-demand asynchronously as you have illustrated.  So, I'll keep this open for future consideration.\n. I would expect the promise to return a URL to the endpoint. Is this what you are suggesting?\n. Ah I see. I think I misunderstood the intent of this case, looking back at my earlier comments. \nI can see implementing this for everything other than upload requests (for all endpoint types, not just S3). There would need to be some agreement as to what the resolved promise would \"return\". Should it return an XMLHttpRequest object, or some other object with conventional properties? The former seems to be the simplest choice, but I suppose this makes the solution less flexible for integrators.\nThis seems interesting, but it probably isn't going to happen any time soon. There are several non-trivial higher-priority enhancements ahead of this in the queue, such as support for S3 v4 signatures (#1336), and substantial updates to the documentation. I'd also want to hear a few other users express support for this.\n. I don't see this making it into 5.5, as that is currently intended to be a small, focused release. 6.0 is also quite full at the moment (overfull even). Still I can see that it is a desired feature, and I'll keep it in my periphery when planning releases.\n. After looking at this a bit closer, it seems as if there is still an issue here.\nThe param passed into the containsNonSimpleHeaders function is an object.  Properties are header names, values are header values.  The qq.each is iterating over this object, but examining the header values instead of the header names.  The logic in the qq.each loop shows that the original assumption was that this param is an array of header names, but that is not the case.  Note that the param (which is tied to the customHeaders option, can also be a function.  This is also not accounted for.  \nI'll continue to keep this open so we can ensure it is truly fixed.\n. Please show your code and explain what you mean by \"loaded images\".  If you are talking about previews, Android 2.3 is not capable of rendering file previews entirely client-side due to lack of File API support.\nAlso,  which version of Fine Uploader are you using?\n. Sorry, I'm afraid I don't understand your last set of comments.\n. Please let us know when you can provide more details.  At that point, we'll be happy to re-open.\n. LocalStorage is used to support the resume feature. \u00a0I\u2019m not seeing any issues on my end. \u00a0Sounds like an extension or some other item in your environment is at fault.\nOn Tue, Dec 2, 2014 at 8:12 AM, Fabian Schwahn notifications@github.com\nwrote:\n\nThe same happens in Safari 8.0 (and probably other versions), though here it is SecurityError: DOM Exception 18: An attempt was made to break through the security policy of the user agent.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1324#issuecomment-65235737\n. Ah, ok.  Sounds like disabling cookies may also disable localStorage.  In that case, if you want to use the resume feature, you'll need to keep cookies enabled.\n. Ok, that is the issue here then.  You should have lead off with \"uploading files is impossible if cookies are disabled\".  I'll update the title of this issue and schedule this for a hotfix release.\n. That isn\u2019t a standard property, and may not work in all cases. \u00a0We\u2019ll probably address this by wrapping the reference to window.localStorage in a try/catch block in the check.\n\nOn Tue, Dec 2, 2014 at 9:31 AM, Fabian Schwahn notifications@github.com\nwrote:\n\nI solved this by rewriting the check for the resume option as:\n    supportsResume = supportsAjaxFileUploading && supportsChunking && navigator.cookieEnabled && !!window.localStorage;\nThis allows me to use fineuploader when cookies are disabled.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1324#issuecomment-65248194\n. Is this a response to an upload request?\n. The requirement has always been that a successful upload response must contain JSON in the payload with a success property with a value of true.  This is only really necessary for IE9 and older (along with any other browser that does not support the File API) but has always been a requirement for all browsers for consistency.\n\nThe change you're suggesting seems reasonable, but it is indeed a breaking change and will have to wait for the next major release. (6.x).\n. Sure, I'll tag this appropriately.  \nIn your endpoint, you'll definitely want to avoid returning a non-200 response for upload requests if you plan on supporting IE9 and older.  Here's a snippet from our docs explaining why:\n\nIf the response code is not 200, and the size of the response is less than 512, or, apparently, sometimes, less than 256 bytes, IE replaces the response with a \u201cfriendly\u201d error message. If you insist on returning responses with a status code other than 200, you can work around this by instructing IE users to uncheck the \u201cshow friendly HTTP error messages\u201d setting or by padding the response JSON with whitespace as described\n. Moving this into the 6.0 milestone. With Microsoft dropping support for IE9 and older, I think it makes sense to focus even more on modern browsers going forward. Plan is to treat 2xx as successful, unless the JSON response indicates failure with success: false, just in case any existing integrations utilize this approach, or if integrators want to always return 200 but use the response to indicate failure for easier cross-browser support. IE9 and older will have to always return a 200 but can signal failure with a success property with a value of false in the JSON response.\n. Working on this next as part of 6.0.0.\n. This is complete and being staged on the release/6.0.0 branch.\n. Finally getting around to this in #1917. I expect this to be a non-breaking change (5.16.0) with the addition of a new option: request.requireSuccessJson.. Yes, that seems like a possible workaround.  I think allowing the signature endpoint headers to be adjusted on-demand via the API is useful though, so we'll look into adding this in a future release.  The adjustment will apply to Fine Uploader Azure as well.\n. Can you set a cookie with the token?  Cookies will be sent to your endpoint automatically.\n. No, there is no good way to do this.  It's possible that this adjustment will make it into 5.2.0.  We are currently finishing up 5.1.0.\n. Looks like I did account for the signature.customHeaders option to handle a function value, but forgot to  reflect that in the docs!  Looks good to me, but be aware of this bug #1321.  \n\nI'll update the docs in 5.1.0.\n. This seems to be a regression created, possibly as a result of work on 5.0.  CancelAll seems to expect a file either be waiting for an open connection, or be currently consuming an open connection.\n. The change required to address this issue is quite risky, and the benefit is marginal in my estimation.  If you'd like to prevent a file from being submitted, there are a number of other opportunities to do so, such as in your submit or validate event handlers.  Ok, you can cancel the file once it has been submitted.\n. Why would you cancel the file here, instead of just returning false?\n. Oh, onSubmitted, I read onSubmit mistakenly.  What is your workflow exactly?\n. I'm not able to reproduce this in Fine Uploader 5.0.9 (the latest version).  Calling the cancel API method inside of an onSubmitted callback cancels the file.  Can you provide a full code sample?\n. Not at the moment.  That is something we plan to support/maintain in a near-future version.  If you include a sample fiddle with you HTML and JS, I can run that locally.\n. I'll re-open this if/when a live example is available showing a way to reproduce.  I'm not able to reproduce myself, so I'll close for now.\n. The file input button should be reachable via keyboard (tab) in all browsers, with the possible exception of the current version of Safari.  Safari seems to have accessibility issues on all sites, so not much we can do here.  \nIn IE, two tabs are required to navigate past a file input element.  This is due to the fact that IE treats the file input element as two separate elements.  The first tab hits the file input's text box and you cannot invoke the chooser via keyboard at this point.  The second tab hits the file input's button.  To invoke the chooser, you must hit the space bar.  All other browsers only take one tab to navigate past the file input, and the enter key will invoke the chooser.\nPreviously, keyboard access to the file input was disabled in IE due to the two-tab issue.  I removed this condition as I believe flawed keyboard access is better than no keyboard access.  \nThere are other potential solutions to ensure consistent keyboard access across all browsers, but all of them involve using JavaScript to either focus the file input, or click it.  The former trips security checks in Firefox, and the latter prevents the underlying form from being submitted via JavaScript in IE.  So, the current behavior is as good as it's gonna get.\n. Our website certainly needs some work (JavaScript embedded in <script> tag, global vars everywhere, inline styles everywhere, etc) but the site is much more accessible after my changes.  The templates, demos, and examples have been updated as well.  All that's left is the docs site: up next.  \nChanges to the docs site, main site, and code will go out with the next scheduled release, which is 5.2.0 at this time.\n. Docs site has been updated.  Once our doc generator is fixed, I'll verify and this will be done and ready for 5.2.\n. No a11y errors on the develop docs site according to wave.  I'll need to run the same tests on the website and an uploader instance as well before declaring Fine Uploader WCAG compliant.\n. Fine Uploader's a11y work should be complete at this point!  Staged in the develop and site/5.2.0 branches.\n. Please discuss your need for this feature more, such as how your workflow requires this.  Seems like this type of determination can accomplished with the existing API.\n. Yes, it would be useful to include this error message as well.  Thanks for the report.\n. It's working fine for me in Win7, Fine Uploader 5.0.9, IE 11.0.9600.16428.  I verified using the http://fineuploader.com/demos page.  If you are seeing anything specific in the console, please let us know.  This may be an issue specific to your environment.\n. Perhaps the #selectionhldr element doesn't exist in the DOM when the fineUploaderDnd module is initialized.  Your next step will need to involve looking closer at initialization of the DnD plug-in to determine why the drop zone isn't being registered properly in your environment.  Fine Uploader uses that plug-in internally in UI mode.\n. Fine Uploader doesn't depend on jQuery internally.  In fact, I'm toying with the idea of deprecating/removing the jQuery wrapper in a future version, see #1310 for details.\nSeems like it wouldn't be difficult to add an API method to update/set the bound form, which could be called anytime after init.\n. Well you know how it is.  First step is to say something is trivial.  Second step is to start working on it and realize that you've opened a can of worms.  \nThat said, this doesn't appear to be an overly difficult adjustment.  I would imagine a new public method would be added to the API: setForm.  The parameter would be either an HTMLFormElement or an ID selector string for the form (once we officially drop support for IE7 in 6.0 #637 these selector strings can be much more complex since we can utilize querySelector/querySelectorAll) .  \nWhen the new API method is called, Fine Uploader will run the _initFormSupportAndParams internal method, passing in the new form selector/element.  Some modifications will be required to this private method.\n. Looking into this now as part of 5.3.0 work.\n. This is complete in the develop branch - 5.3.0-7.\n. The issue has been addressed in #1043 in v4.4.0.  DnD is much more tricky to support cross-browser than it sounds due to the inconsistent implementations among browsers.  In some browsers, the when the drop zone highlight happens to stick around after an aborted drop attempt, it will disappear once the mouse re-enters the drop zone.  I believe this is the case in Safari, and IE10+.  See #1043 for details.\n. Interesting.  It's not clear how this affects multipart encoded POST uploads that bypass the REST API.  This workflow is critical to supporting IE9 and older.  In that case, there is no Authorization header (since there is no way to specify headers when uploading files in IE9 and older).  \nSome things for us to do and investigate:\n- [x] Ensure that v2 signatures are supported by default (for backwards compatibility) OR introduce a breaking change and require all signatures returned from the signature server are v4.  The latter is obviously a potential annoyance to integrators and must wait for a major version release of Fine Uploader.  If we go the non-breaking-change route, we'll need to add a version property to the signature option. For v4 signatures, we'll need more information from the server, such as the bucket region.\n- [x] How do v4 signatures work for multipart encoded POST uploads that bypass the REST API?  Is the format of the signature field value for signed MPE POST uploads identical to the format of the Authorization header for v4 signed REST uploads?  \nThis change will need to include code adjustments, documentation updates, and server-side example updates.\nWe'll look into this for a future release.\n. The more I think about this, the more I'm fairly sure that we may never be able to remove the ability to accept v2 signatures.  Fine Uploader S3 is used against some S3-like endpoints.  Also, if we are to support uploads to Google Cloud Storage via the S3 compatibility layer #1158, I assume v2 signatures must be used.\n. We will support v4 signatures in a future release, most likely 5.3.\n. For those who don't know (including myself) please describe this \"KMS\".\nOn Wed, Mar 11, 2015 at 7:57 AM, Justin Etheredge\nnotifications@github.com wrote:\n\nI would also like to chime in and say that fine uploader cannot be used (in any region) to upload to S3 using keys from KMS until signature V4 is supported.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-78257651\n. For those who don't know (including myself) please describe this \"KMS\".\n\nOn Wed, Mar 11, 2015 at 7:57 AM, Justin Etheredge\nnotifications@github.com wrote:\n\nI would also like to chime in and say that fine uploader cannot be used (in any region) to upload to S3 using keys from KMS until signature V4 is supported.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-78257651\n. Supporting v4 signatures will be investigated as part of the 5.3 version of Fine Uploader. 5.2 is currently in development.\n. Supporting v4 signatures will be investigated as part of the 5.3 version of Fine Uploader. 5.2 is currently in development.\n. Yes, thanks for the info. Please see my list of TODO items related to this case. \n\nI'd like to introduce this as a non-breaking change. In fact, I think it is imperative that both v2 and v4 signatures are supported. As reflected in my TODO list, I'm not sure how v4 signatures work for non-REST uploads (MPE upload POST requests used in older browsers). If anyone happens to have more information about this, that will save me some research time.\n. Yes, it does, thanks. I wasn't able to locate that document after a brief search earlier.\n. Starting work on this as part of 5.3 now.\nTODO: \n- [x] Ensure that v2 signatures are supported by default. Will need to add a version property to the signature option.\n- [x] Support v4 signatures for REST uploads.\n- [x] Support v4 signatures for non-REST uploads.\n- [x] Support v4 signature for client-side signing workflow.\n- [x] Update all server-side examples to include support for V4 signatures.\n- [x] Update docs with all V4-related signature info.\n- [ ] Start working on #1225. This will involving moving any code-specific stuff out of the blog post and into the docs site on an S3 feature page. Any server-specific elements should exist on the S3 server docs page.\nUnfortunately, we won't be able to send the expected signature version to the server in the signature request. This would require a breaking change for non-REST uploads, since the signature request message body, in that case, consists solely of the policy JSON.\n. Looks like the hardest part of this, as expected, will be attempting to understand Amazon's convoluted new signing policy. It is, unfortunately, vastly different than the process required to generate V2 signatures. I'm currently attempting to generate a simple V4 signature based on the (disorganized) signature docs on the AWS site. No luck just yet. The example code in their docs is riddled with syntax errors, so that's of no help.\n. Phew, finally made some headway on generating a V4 signature in PHP. JS may be a bit more complicated, due to my lack of knowledge of CryptoJS and AWS's invalid CryptoJS example code.\n. Wow, the new V4 REST request signing algorithm is substantially more complicated than the POST upload request method. The devs at Amazon really went out of their way to make this difficult to implement, and the complexity of the algorithm seems to be mostly unnecessary. It almost seems as if they created an unnecessarily complex signing process as an additional layer of security, which is of course a bad idea, but I can't fathom how the design of V4 signatures came about any other way. It's going to take some time to get this right, not to mention all of the server-side examples that will need to change. \n. @jetheredge That is part of the signing process of POST uploads. The process for REST (multipart PUT) uploads is much more complex. One concerning requirement of the signing process for uploads to the REST API involves hashing the entire request body. This will require reading the contents of each file into memory browser-side and generating a hash. The performance implications of this are substantial. I'm going to open up an issue in the S3 forums to ask them if they have any plans to allow payload hashing to be bypassed for upload PUT requests, and will report back when I know more.\n. Issue/question posted in the S3 forums at https://forums.aws.amazon.com/thread.jspa?threadID=179762.\n. Received a confusing response from AWS, claiming that the documentation does not indicate the payload needs to be hashed (even though the opening paragraph of the v4 signing docs explicitly mentions that this is required). \nThe V4 signature docs are a bit of a mess and there appears to be contradictory information in various areas. On top of this, it seems as if they are not consistent with their terms throughout the docs. The rep from AWS mentioned that the payload does not have to be hashed for multipart upload PUT requests, but this is not reflected in the documentation, and the rep did not link to such any documentation that backs up this assertion. \nI followed up with a request for a specific link that points out that multipart upload PUT requests do not need to take into account the message body when generating the string to sign. The closest thing I can find is this signature v4 signing document, which mentions PUT requests, but also refers to \"streaming\" PUT requests, which is a confusing term in this context. \nI'm hoping someone will shed some light on this. Until then, work on this case is blocked. Feel free to prod AWS on Twitter or via the forums. That may result in a better response than the one received so far.\n. The requirement you are describing is not documented anywhere, and I am\ndefinitely hoping that file bytes do not need to be hashed, due to the\nrelated complexity and performance concerns. According to this \"chunked\nupload\" document at\nhttp://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-streaming.html, it\nsounds like you can get away with only signing headers, provided one of the\nheaders is \"x-amz-content-sha256\" with a value of \"\nSTREAMING-AWS4-HMAC-SHA256-PAYLOAD\". Even though this document refers to\nthese uploads as \"streaming\" (which is confusing and probably not the\ncorrect term). I'm likely going to attempt to implement v4 signatures with\nthe model described in the document I just linked to in mind.\nOn Thu, May 14, 2015 at 9:11 AM, Justin Etheredge notifications@github.com\nwrote:\n\nI've been meaning to follow up on this for a few days, but I think you are\ndefinitely correct in that at least the first piece of the file upload\nneeds to be hashed, but then subsequent pieces look like they can be hashed\nusing the returned hash from the previously uploaded part by looking at the\n'X-Amz-Content-Sha256' header. Here is a link to the line in the v4 signer\nin the Amazon Javascript SDK which shows where they do this:\nhttps://github.com/aws/aws-sdk-js/blob/master/lib/signers/v4.js#L175\nThe license for this library is Apache, so you should be safe in looking\nat the implementation.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-102047733\n.\n. I did receive (somewhat of) an update from AWS today:\nHello rnicholus,\nI do apologize if it appears that we have left this thread to languish--I can assure you, we are still working on getting clarification for you. I have pressed on our team for some expedience in this matter and I do apologize for the troubles you are seeing here.\nBest regards,\nJustin G.\n. I wonder if I can follow the model in http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-streaming.html to send all requests with payloads in the multipart upload workflow (upload part and complete multipart) without hashing any payloads.\n. After really pouring over the \"streaming\" upload document referenced above, I'm almost convinced that this is not the signature formula to follow when using the multipart upload REST API. In fact, a \"streaming\" upload appears to be quite different from a multipart upload. After reading through the entire document, this becomes clear. I'm afraid I'll just have to wait until I hear back from Amazon regarding the documentation specific to multipart uploads.\n. still waiting for a response from AWS, even though they have assured me they are working on it. Seems no one at Amazon understands how to send multipart upload requests with v4 signatures.\n. Another award-winning response from the crack staff at AWS, this time informing me that each file chunk must be hashed.\n\nLet's go over a quick summary of the thread I opened in the AWS forums:\n- May 4: Me - \"Hashing each file chunk will (substantially) negatively impact performance when uploading to S3, especially directly from the browser\".\n- May 6: AWS -  \"You don't have to hash the file chunks. Nowhere does it say you have to do this\".\n- May 6: Me - Points out multiple places in the docs where it says message body hashing is mandatory. Also asks about a streaming doc, which suggests there may be an alternative. Unsure how this relates to the multipart upload API.\n- May 14: AWS - \"No one here seems to understand our own API or documentation. We're looking for someone who does, please wait\".\n- June 1: AWS - \"Yes, you must hash all file chunks.\"\n. Take 2: https://forums.aws.amazon.com/thread.jspa?threadID=189207\n. Work on this feature has resumed. I've successfully implemented the non-streaming v4 signing algorithm. This will be used for all non-PUT/upload requests when communicating with S3's multipart upload API. The streaming v4 signing process is a bit different, and will be the next to tackle. \nWithout a doubt, implementing v4 signing has been the most challenging task to date.\n. ...pretty sure I will need to make a few changes to my existing code, such as sending the canonical request and the string to sign to the signature server. This way, the signature server can verify that the canonical request contains expected values. The server would also want to encode the canonical request to make sure it matches the last line in the string to sign.\n. May have to revisit the format of the content to be signed sent to the signature server to properly account for #1406 at a later date.\n. I'm currently in the process of implementing the logic required to sign multipart upload PUT/chunk requests. The only way to avoid hashing the entire chunk payload is to make use of their \"streaming\" v4 signature process. Unfortunately, it looks like this will prevent us from sending multiple chunks of the same file simultaneously, which means we can't support the concurrent chunking feature if the v4 signature process is used.\nFrom the streaming doc:\n\n...the chunk signatures are chained together; that is, signature of chunk n is a function F(chunk n, signature(chunk n-1)). The chaining ensures you send the chunks in correct order\n\nThe order of the chunks should not matter - I'm not sure why Amazon insists the chunks be sent sequentially, as this was never a requirement pre-v4 (and is the reason why Fine Uploader's unique concurrent chunking feature is possible w/ the S3 module).\nI'm going to open up a case with AWS and see what they have to say about fixing this.\n. https://forums.aws.amazon.com/thread.jspa?threadID=215652\n. Sigh, sorry about this everyone. It hasn't been possible for me to concentrate on this for more than a couple hours a week or so as of late. The constant context-switching combined with the extreme technical difficulty of implementing AWS' v4 signature algorithm is making this very tough to complete in a reasonable amount of time.\nShortly into implementation of the \"streaming\" algorithm I was pointed to by AWS, I started to realize that this process literally requires all chunks be streamed. I take that to mean one request that remains open until all chunks are sent. It is not currently possible to \"stream\" data from the browser in this manner using XMLHttpRequest. I have been looking for a way to support V4 signatures using the multipart upload API, which allows each chunk to be sent in a separate request. In hindsight, the requirement that all chunks be streamed in a single request in order to avoid signing the payload explains why each chunk must be sent in order.\nI'm going to have to reach out to AWS in hopes that there is some way to utilize the MPU API w/ v4 signatures without having to sign each chunk. If this is not possible, that I'll have to go back to square one with chunked uploads and evaluate the feasibility of hashing each chunk browser-side.\nIf anyone has a reliable contact at AWS, it would help me get to the bottom of this much quicker.\n. After looking over the issue tracker in the AWS S3 SDK, it appears that I will indeed need to hash the payload of each multipart upload chunk request. I opened yet another thread in the S3 forum asking for an explanation regarding the inconsistency in V4 requirements between chunked & non-chunked uploads, but I'm not optimistic I'll receive a good answer.\nI'll have to move forward with the plan to hash each chunk browser-side. I'll probably want to do this in a web worker to avoid tying up the UI thread for long periods of time, though this will add more complexity.\n. Thanks! It'll be slow going though. This is a major undertaking.\nOn Fri, Sep 25, 2015 at 7:08 PM Adam Arnold notifications@github.com\nwrote:\n\nKeep up the good work- I spent several hours today going through the same\nstruggle. My team is waiting to buy a license when the v4 signatures are\nsupported.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-143380466\n.\n. Chunked upload requests via the S3 multipart upload API using V4 signatures is now working in the features/s3-v4-signatures branch. I still have a bunch of TODOs to clean this up though. See the commit message of bf5ede4a229972ce21195c7bb2dba174a7d6853b for details.\n. Thanks! We're not out of the woods yet - still a few things to take care\nof, including doc updates and updates to as many of the server examples as\nI can address myself.\n\nOn Mon, Oct 5, 2015 at 5:56 PM Justin Etheredge notifications@github.com\nwrote:\n\nCongrats! I know this has been a looooong time coming. Maybe you can send\nsome documentation over to the AWS team? :-)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-145692075\n.\n. After some testing in multiple environments, it's not clear that the work and added complexity required to hash file chunks in web workers is important in terms of responsiveness. So, I plan on hashing chunks in the UI thread for the moment. If a need for this becomes clearer later, I will consider moving chunk hashing into web workers in a later release.\n. Please let me know, anyone, if you are interested in testing V4 signature support. The code is usable at this point. All that remains is:\n- [x] update docs\n- [x] publish new PHP server example that handles v4 signatures\n- [x] multipart upload API unit tests w/ v4 signatures\n- [x] client-side signing workflow is support for v4 signatures\n- [x] client-side signing v4 unit tests\n- [x] update Java server example to handle v4 signatures\n- [x] update node.js server example to handle v4 signatures\n. All S3 PHP server examples have been updated to support v4 signatures. These are currently sitting in a feature branch in the fineuploader/php-s3-server repo, but the changes will be merged into the mainline as part of the 5.4.0 release of Fine Uploader.\n\nUntil then, you can pull in the v4 signature version of the PHP example server (which also supports v2 singatures) via composer. A sample composer.json might look like this:\njson\n{\n  \"minimum-stability\": \"alpha\",\n  \"repositories\": [\n    {\n      \"type\": \"vcs\",\n      \"url\": \"https://github.com/FineUploader/php-s3-server\"\n    }\n  ],\n  \"require\": {\n    \"fineuploader/php-s3-server\": \"dev-v4-signatures\"\n  }\n}\n. I'll update the node.js example next, and then I'll release. Speak now if you want to test this out, as I don't plan to make any behavior changes to V4 signing once it's released.\n. Node.js updated in https://github.com/FineUploader/server-examples/commit/5fe77403732d58f3c5144e75b9a8deeb2c2a89d2. This feature is now complete, and is scheduled to go out with a few other changes in 5.4.0.\n. After I finish the other tasks scheduled for 5.4. I also may make another\nadjustment to the S3 v4 implementation.\nOn Mon, Nov 2, 2015 at 9:28 AM kaurranjeet12 notifications@github.com\nwrote:\n\nHi rnicholus,\nWhen are you planning to release fineuploader version 5.4?\nThanks,\nRJ\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-153052778\n.\n. I don't usually provide specific planned release dates. Keep checking back\nfor updates.\nOn Mon, Nov 2, 2015 at 10:02 AM kaurranjeet12 notifications@github.com\nwrote:\nDo you have any timeline as we are planning to buy the licence.\nThanks,\nRJ\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-153062565\n.\n. What issues are you having\nOn Tue, Nov 3, 2015 at 8:29 AM e-tip notifications@github.com wrote:\nHi, i've used the develop version and i can confirm that, for non chunked\nversion, it works perfectly.\nI 'm facing issues with chunked upload but i guess it's because i still\nhave to understand how it works ! thanks\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1336#issuecomment-153371043\n.\n. I've described how to handle these requests in the docs, and have provided pre-release versions of PHP, Java, and NodeJS server-side examples that handle all v4 (and v2) requests. Have a look at these for more details.\n. @e-tip If you'd like me to assist, you'll need to provide a little more than an error message, such as information required to reproduce the issue.\n. Please do not send me the whole project. I'm simply looking for a set of steps and conditions with focused/relevant code fragments needed to reproduce your issue.\n. Which browser is this failing in? Is it succeeding in any? What type of file are you uploading?\n. Seems to be working for me on those browsers, with large chunked files. Could be one of several issues on your end:\n- using wrong Fine Uploader JS file\n- browser extension causing issues\n- some other JS code causing issues\n\nIs the failure happening on the first PUT request to S3, or the first POST request?\n. whoa, why are you doing all of this? You should only be importing one of the built files. grunt clean build, then use one of the files created in the _build dir.\n. Yes, grunt is garbage and I wish I wouldn't have used it in the first place. I may be able to remove it with some of the changes scheduled for 6.0. \nYou can also access this build at http://releases.fineuploader.com/develop/5.4.0-5/s3.fine-uploader-5.4.0-5.zip\n. Good to hear. There may be an update to chunked support for V4 before I release. Currently, Fine Uploader S3 sends the hashed header data to your signature server. This make verifying some aspects of the request server-side impossible. I'm going to see if I can simply send the canonical request w/ the hashed payload to the signature server instead. This will require a bit more work by the signature server, but allow signature servers to better verify the request before signing it.\n. I made some changes to Fine Uploader S3, reflected in 5.4.0-6. Instead of sending the hashed canonical request to the signature server, I'm now sending the \"raw\" canonical request. This will allow signature servers to more definitively validate the request before signing it. Docs have been updated as well, along w/ Java, NodeJS, and PHP examples.\n. @e-tip It looks like this is not necessarily a new issue, but your change is likely to cause other issues. I'll look into ensuring that forward slashes in key names are not encoded.\n. Chunked uploads to S3 have worked in Fine Uploader for years now. This feature only adds support for v4 signatures. \nI've added a patch to Fine Uploader to prevent forward slashes from being encoded in key names. You can find this update in 5.4.0-7.\n. Note that there was also a regression introduced into the PHP s3 server example yesterday (on the v4 sigs branch in that repo). I've also fixed that - it only applied to v2 sigs.\n. I'll take a look. The ( and ) characters don't need to be escaped. I'll look into this further though.\n. The complexity and silliness of the logic AWS engineers employ when designing their systems never ceases to frustrate me. It is perfectly valid for S3 keys to contain ( and ). But, the \"canonical URI\" portion of the canonical request used to generate a signature, which, in part, contains the object key, must contain escaped versions of (, ). I've made adjustments to account for spaces and brackets in 5.4.0-8. \n@e-tip You're a pretty effective tester!\n. There are are couple things remaining before release of 5.4:\n- [ ] Verification of work on #1258.\n- [ ] Completion of work to address #1387\nI'll also need to type up a blog post, as per usual. If #1387 isn't able to be completed within a few days, I'll push it to a future release. I'm aiming to release by 18 Nov. I am hesitent to release after the 18th since this is close to the U.S. Thanksgiving holiday, followed by a couple weeks of vacation by me at the start of December.\n. That sounds like a configuration issue with your CF distro. The best place to inquire further about that is the AWS forums. Unfortunately, the AWS support people manning those forums know very little about their products. Hopefully a user knowledgable in CF will provide some guidance.\n. Just a thought - I believe you will have to setup an Origin Access Identity in your CF distro. I think this will result in CF signing its request before then relaying it on to S3. Otherwise I can see how the signature calculated by S3 would be wrong due to the changing host header due to CF's involvement in the process. CloudFront may not support uploads to S3 using a version 4 signature in combination with an OAI though, due to lack of support for POST requests in this scenario.\nAgain, I'm not the correct person to ask about this stuff as my knowledge of CF is very limited.\n. @e-tip I'm a bit confused here with all of the \"xxx\"s\n1. What is the URL of your S3 bucket?\n2. What is the URL of your CF distro?\n3. What is the value of the host header in the original version of the code block above?\n4. What is the value of the host header after your changes?\n. @e-tip There isn't anything I can do to help further without answers to the above questions. If you backtrack a bit, you will be able to uncover the necessary info.\n. It sounds like, with your current config, you need to specify the bucket as your host header instead of the actual host of the CF distro. I would expect this to only be necessary if OAI is not setup on your CF distro. Again, the best place to inquire further is the AWS forums. I would hope that the request can be sent through CF without any special adjustments. \n. All tests are passing on all browsers and we're ready for the 5.4.0 release. I expect to push this out no later than mid-next-week.\n. closes #1495 \n. Just noticed that uploads via a CDN are broken when using V4 multipart uploads. I'll have to add a new objectProperties.host option that must be filled out with the hostname of the S3 bucket when sending V4-signed uploads through a CDN. This will look very much like that objectProperties.bucket option added for initial CDN support. Work on this is in progress now.\n. CDN support is now fixed for V4-signed uploads.\n. Your bucket should indeed be named \u201cmybucket.s3.mydomain.com\u201d.  Take a look at the S3 docs regarding CNAMEs buckets for more info: http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html#VirtualHostingCustomURLs.\n. > We're not using AWS in the backend but ceph's S3-compatible API\nThat was an important piece of information that only surfaced in your last comment.  Fine Uploader 5.1.0, in development, has support for S3-like endpoints, and uploads to S3 via a CDN in #1332 .  In that version, you can explicitly specify a bucket name via a new objectProperties.bucket option.  \nIf you were uploading to S3, your bucket would have to be named \"test.mydomain.com\".\n. Ah, you've already pulled down the development version of 5.1.0 and verified that it works in your case?  Excellent.  Thanks for the update.\n. Looks like there is only one such typo in the docs.  We'll fix this when 5.1.0 is released.\n. I'm fine removing the java stuff, once we have a server that handles everything the java server currently handles\n. I'm going to remove all the Java stuff in 5.2 and replace it with PHP.  This seems like the best choice, since PHP is likely the most common server-side language for integrators.\n. The develop branch is now Java-free!  No more IntelliJ!  Yay!\n. We'll consider this, but we'll want to arrive at a solution that will work for non-UI and UI mode.  We'll discuss this at our next planning meeting.\n. Once #1301 is complete, you will be able to more easily react to a specific validation error. That should address this case, so I'm closing as a duplicate.\n. First off, Fastly (or any other CDN) will need to be configured to point at an S3 endpoint (or endpoints).\nAfter you setup your fastly account, make sure you set Fine Uploader S3's request.endpoint to your fastly endpoint, and the objectProperties.bucket to your bucket (or a function that can dynamically determine the bucket name per file).\nThe related changes to Fine Uploader should also allow uploads to S3-like endpoints, that is, endpoints that use the S3 API but are not actually S3.  Google Cloud Storage offers an S3 compatibility layer, which may work perfectly with these changes #1158.\n. Can you provide a bit more information, such as your code and specific steps required to reproduce?\n. Will work on this and #637 in parallel as part of 6.0 work, since they are closely related.\n. This appears to be complete and is currently being staged on the release/6.0.0 branch.\n. This should be covered by #637 . Thanks for catching this.  Can you please sign the CLA?\n. Ah, so you have.  I'll take a closer look at this tomorrow.\n. While writing tests for this issue, I believe I may have encountered another somewhat related issue, which I will track down as well.  Once that is all straightened out and tests are passing, I'll probably release all of this as a hotfix: 5.1.3.\n. This has been fixed and released as Fine Uploader 5.1.3.\n. The check you linked to is specific to folder-based DnD uploads.  I don't see how simply exposing this interface allows us to determine at load time if the browser supports DnD folder uploads.  It seems the only way to determine this is by inspecting the DataTransfer instance associated with a drop event.\n. The webkitGetAsEntry method on a DataTransferItem is a Blink-specific prefixed method to access the associated Entry for the dropped item.  The Entry interface is part of the Filesystem API, which used to be part of the HTML5 spec, but was recently dropped.  No other browser will ever support the Filesystem API or any associated interfaces, and it is certainly possible that Chrome will remove support in the future.  Handling a dropped folder in a drop event handler requires support of these interfaces.  Users of other browsers can certainly drop folders, but there is no way to parse them (or even determine that a folder has been dropped).  \nThis is a big gap in browser-based file support that only Chrome (and other browsers using Blink such as recent Opera) have addressed.\n. Awesome!  We'll have to decide when to remove the UA string parsing code here.\n. I can't remember at the moment.  I believe that the issue was the presence of the appropriate APIs in other browsers, but incomplete implementations.  I'll update once I get a chance to go over some history.\n. I think the issue is that Chrome allows a copied image (in the clipboard) to be pasted into any element, and other browsers require that element to be a contenteditable element.  There are some other issues as well, described in #774.  Not sure if this can be detected without UA string parsing.\n. The Clipboard API spec says the following in the paste action section:\n\nIf the cursor is in an editable element, the default action is to insert clipboard data in the most suitable format supported for the given context.\nThe paste event has no default action in a non-editable context, but the event fires regardless.\n\nBlink-based UAs fire paste on editable and non-editable elements.  Others only on editable elements.  So, it seems as if other browsers have not completely implemented the spec.\n. The initial file list is an array returned by your server.  The files will appear in the order represented by the array.  If you'd like a different order, this can be accomplished by adjusting the order of the items in the array returned by your server.  Another option is to implement a widget in your UI that sorts the way the items appear based on whatever characteristics are most important to your project.  This would involve moving around the list items in Fine Uploader UI's file list.  Or, you can implement your own UI entirely using Fine Uploader's API.\nIf there is an issue specifically with the way Fine Uploader interprets the initial file from your server, we can discuss further and re-open this if necessary.\n. Note that the gzipped size of the minified file is less then 40 kB total.  The difference between the gzipped size of the all-inclusive fine-uploader.min.js vs a custom build is much smaller in this case.\n. I think we can oblige in a future version by including seperate  builds of core and UI for traditional, S3, and Azure endpoints.  It occurred to us that we should also throw the DnD module on npm, as that can stand on its own as well.\n. We will look into this as part of the release after 5.2 (likely 5.3).\n. This will be covered by #1607.\n. It's likely that someone has, but I'm not aware of a specific implementation.  Is there something in particular you're struggling with?\n. I'm going to close this for now, but if you and others comment on specific integration issues with meteor, I'd be happy to consider re-opening.\n. What isn't working?  Where is your code that isn't working?  What version are you using?\n. The setItemLimit API method seems to work fine.  I just tested to verify (and there are unit tests as well).  There must be some issue with your code that you are not showing here, or perhaps you have made changes to Fine Uploader.  I would suggest setting a breakpoint to see what the value of this is in that method, and go from there.\n. Hi there.  For now, I think the best place to open up a Fine Uploader PHP issue is in the fine-uploader-php-docs repository's issue tracker.\n. Instead, style based on presence of :hover pseudo-class (IE7+) and :focus pseudo-class (IE8+).  Since we'll be removing any IE7-related code as part of 6.0 to complete our removal of support for IE7.\n. duplicate of #1344 \n. This will be covered in #1314 and #734.  We'll be sure to deal with this as part of the upcoming 5.2.0 release.\n. Is this for a simple upload request, or for one of the requests sent by Fine Uploader S3/Azure (signature and success)?\n. Based on the issue you files, #1354, I'm guessing this is related to the uploadSuccess POST sent by Fine Uploader S3/Azure.\nYour pull request is against master, which only contains released code.  Regardless, we'll be sure to make this adjustment in #1314 as part of 5.2.0.\n. This is not broken.  Please see the discussion in #804 for more information.\n. Hello there.  We only handle bug reports and feature requests in this issue tracker.  If you are looking for help solving a problem involving Fine Uploader, please post in Stackoverflow under the fine-uploader tag.  Also be sure to explain your exact problem clearly and include code to illustrate your problem.  Thanks.\n. You can generate thumbnails at will, for any <img> or <canvas> via the drawThumbnail API method.\n. Glad you were able to get this working.  May I suggest that you avoid using the jQuery plug-in wrapper?  It really doesn't add any value, and just clutters up your code.  \nYour code sans that wrapper looks like this:\njavascript\n$(document).ready(function () {\n       var uploader = new qq.FineUploader({\n            template: \"qq-simple-thumbnails-template\",\n            element: document.getElementById(\"file-upload\"),\n            thumbnails: {\n                placeholders: {\n                    waitingPath: \"/scripts/js/fineuploader/placeholders/waiting-generic.png\",\n                    notAvailablePath: \"/scripts/js/fineuploader/placeholders/upload-success.png\"\n                }\n            },\n            request: {\n                endpoint: '/Handlers/FileUpload.ashx'\n            },\n            multiple: false,\n            validation: {\n                allowedExtensions: ['jpg', 'jpeg', 'png']\n            },\n            text: {\n                failUpload: 'Error'\n            },\n            callbacks: {\n                onComplete: function(id, fileName, response) {\n                    this.drawThumbnail(id, document.getElementById(\"preview\"), 400);\n                }\n            }\n        });\n});\n..also, the last parameter to drawThumbnail can be omitted entirely instead of explicitly passing false.\n. Lots of info and examples on the website, http://FineUploader.com, and the documentation site, http://docs.fineuploader.com.\n. We generally don't accept pull requests against master, unless we are dealing with a hotfix.  This falls under the category of refactor as this is just a rename of an internal variable.  Thanks anyway though.\n. Yes, this seems to be a duplicate of the above mentioned case.\n. Sounds like an issue specific to your phone.  We'll keep this here in case anyone else runs into the same issue.\n. Closing this, but am willing to re-open if this is still an issue on newer versions of Android.. I'll need more information to track down that specific line (if it differs from the block of code pasted into your question).  There are many different types of combined fine uploader JS files.  \nThe error message is specific to Safari/webkit, which is what PhantomJS is based off of.  This error suggests that the proper uploader namespace does not exist when you are running your tests.  For example, if you are trying to test Fine Uploader S3 or Azure, the qq.s3 or qq.azure namespaces are missing. Or if you are testing traditional Fine Uploader, the qq.traditional namespace is missing.  \nYou haven't provided any detail about your tests or even the type of build you are trying to test, so I can't give you any conclusive answers.  You'll need to look closer at the file or files  you are making available to your tests, and perhaps how Fine Uploader is being initialized.\n. No, there were no breaking changes, unintentional or otherwise.  Breaking changes are always represented as a new major version (i.e. 5.0 vs 6.0).  \nIf you are having the same issue with the traditional uploader outside of your unit tests, then there is definitely an issue with your code or environment, because all uploaders are working as expected.  In fact, we have our own (large) suite of unit tests that hit S3, Azure, and the traditional uploader. \nIf this is reproducible in Chrome simply on page load, please post all relevant code needed to reproduce your issue (markup and JS), and we will take a look.\n. Yes, that's correct.  If you want the traditional uploader, you need to download the traditional package.  All uploaders share common core components, but the low-level uploading logic differs depending on the endpoint type.\n. Sorry about that.  Fine Uploader PHP is a separate product from the traditional library.  You're right, it's unacceptable for us to have let your support requests go unanswered for so long.  At this time, due to resource limitations, we are not able to provide the same support for Fine Uploader PHP that we have consistently provided for the JavaScript library.  Fine Uploader PHP is in a beta state at the moment.  We have decided to shelve Fine Uploader PHP until we are able to secure enough developers to provide consistent support and evolution of that product.  We will link back to the project on our website once this happens.\nFine Uploader JavaScript (the library represented here) will continue to grow and be supported as it always has been.\n. Absolutely.  They have been updated.\n. I'm not seeing the issue on our live S3 demo at fineuploader.com, which is also using 5.1.3.  Please show your fine-uploader related JS code.\n. What is your request endpoint?  Where does that value live in your code?  It's not clear how your code differs from the demo, which is working properly, so something is missing here.\n. Something is missing from your example code.  You are pulling in v5.0.5, not 5.1.3.  The demo on our site is working as expected, so I have to assume that there is some issue specific to your setup.  I'm also unable to reproduce locally.  \nIf you provide a link to a live site where this can be easily reproduced (with non-minified code) I can take a closer look.\n. Closing as not reproducible.  If you can provide a live example where this is reproducible, I will be happy to re-open.\n. Nice catch!\n. Fixed as part of 5.2.0.\n. :+1: \n. It would be fairly easy to prevent files from being scaled based on file type (i.e. exclude all gifs).  Detecting an animated gif client-side is possible, but much more work.  We'd need to read the gif file and look for frames.  This may result in a read of the entire gif, assuming we don't find more than 1 frame.\n. > So maybe start simple and allow a field of types to exclude from scale.\nI'm not sure that is a useful feature. But I do see the need to prevent scaling of animated GIFs since the scaled version will not be animated.\n. This feature is not yet planned for an upcoming release. You can see the plans for the next few releases at https://github.com/FineUploader/fine-uploader/milestones.\n. @shiningdracon that is a not something I would advise doing, and this change will break the source map. a pull request might get this case pushed through into the next release though. I see an option on thumbnails and a matching one on scaling, in addition to the code changes needed to enforce the new options. Probably wouldn't be too hard...\n. @LusciousPear This is currently low on my priority list, but I'd be happy to review and provide advice for a pull request.\n. What version are you using, and what noticeable issue does this error cause (other than the log message)?\nOn Sun, Feb 22, 2015 at 11:41 AM, thomas83 notifications@github.com\nwrote:\n\nThis happens only when chunk is enabled, on S3 mode.\n            chunking: {\n                enabled: true,\n                concurrent: { enabled: true }\n            },\nTurn on debug mode, then try to upload a big file, then disconnect wifi in the middle.  Wait for a bit, until 3 retries are over.\nThen, there will be an error:\n Uncaught TypeError: Cannot read property 'upload' of undefineds3.jquery.fine-uploader.js:5594 qq.extend._registerProgressHandlers3.jquery.fine-uploader.js:9434 chunked.put.chunked.initHeaders.then.promise.failure.errors3.jquery.fine-uploader.js:1109 (anonymous function)s3.jquery.fine-uploader.js:659 qq.eachs3.jquery.fine-uploader.js:1108 qq.extend.successs3.jquery.fine-uploader.js:9418 (anonymous function)s3.jquery.fine-uploader.js:1109 (anonymous function)s3.jquery.fine-uploader.js:659 qq.eachs3.jquery.fine-uploader.js:1108 qq.extend.successs3.jquery.fine-uploader.js:8494 handleSignatureReceiveds3.jquery.fine-uploader.js:3804 onCompletes3.jquery.fine-uploader.js:3909 (anonymous function)\nI've investigated a bit on this...\nOn line 5560, this gets called: _registerProgressHandler()\nOn line 5561, it will try to use the handler to get xhr.  Unfortunately, it fails to get the xhr.\nOn line 5594, without checking xhr variable, it tries to assign a new function on top of xhr.upload, and boom, \"Cannot read property 'upload'\".\nI advise to resolve the issue by making a check right before definition of the function.\nSomething like... if( xhr === undefined || xhr.upload === undefined) return;\nBtw, I do notice that while most of the time this happens, everyone once a while this does not.  I'm not sure about the whole flow of the code, or how the threading works here, but yeah, that's how I see the bug currently.\nLast but not least I thought this whole fineuploader thing was really well made.  Really love it a lot. \nThanks guys!\nCheers,\nThomas\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1372\n. I believe I have seen this log message in the past. \u00a0As you suggested, it is only noticeable when concurrent chunking is enabled. \u00a0It can be reproduced when an in progress concurrently chunked upload is canceled. \u00a0When an upload of this type fails, fine uploader cancels all chunks (internally), so that is why you are seeing the issue. \u00a0I believe the error log message is benign, but I'll look closer before 5.2 is released.\n\nOn Sun, Feb 22, 2015 at 11:48 AM, thomas83 notifications@github.com\nwrote:\n\nWow that was some quick response.\nThere are no noticeable issues.  I'm making a wrapper on top of this, so I wanted to make sure every single point goes clear and working the way it's supposed to be.  It could be my problem, but I kinda doubt it this time.\nI'm using the latest version I downloaded today.\n/!\n- Fine Uploader\n  \n- Copyright 2015, Widen Enterprises, Inc. info@fineuploader.com\n  *\n* Version: 5.1.3\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1372#issuecomment-75447478\n. I'm not able to reproduce this issue in the develop branch as of 5.2.0-20, so I'm going to assume this has been fixed somehow. If you're able to reproduce in the dev branch w/ 5.2.0. please let me know.\n. Can you elaborate on \"didn't work\"?\nOn Wed, Feb 17, 2016 at 8:55 PM Andreas Venturini notifications@github.com\nwrote:\nI noticed this error today after a user reported that uploads didn't work\nfor them\nUser agent Mozilla/5.0 (Linux; Android 5.1; LG-H815 Build/LMY47D)\nAppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/38.0.2125.102\nMobile Safari/537.36\nFineUploader Version 5.5.0\nTypeError: Cannot read property 'upload' of undefined\n1\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 345 col 4327 in qq.extend._registerProgressHandler\n2\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 346 col 27382 in v.initHeaders.then.s.failure.error\n3\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12351 in [anonymous]\n4\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 8057 in Function.qq.each\n5\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12328 in qq.extend.success\n6\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 346 col 27172 in [anonymous]\n7\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12351 in [anonymous]\n8\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 8057 in Function.qq.each\n9\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12328 in qq.extend.success\n10\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 346 col 14732 in Object.t\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1372#issuecomment-185213397\n.\n. Can you paste your fine uploader initialization code here?\n. Seems to be related to #1519. Have a look at that case for a possible solution.\n. Why not just set the endpoint, per file, in the onSubmit callback handler?\n. The onSubmit callback allows you to return a promise.  So, you can return a promise, make your call, update the endpoint, and then resolve the promise.\n. This was answered on Stackoverflow a while back.  The code in that example can perhaps be a bit simpler by making use of the qq.getExtension utility method.\n. You are explicitly only passing one extra button element in your fiddle, so I don't see any issue there.\n. You are explicitly accessing only the first element returned by the jquery selector in your fiddle. \u00a0That is what $(...)[0] does.\n\nOn Sun, Mar 1, 2015 at 9:53 AM, thomas83 notifications@github.com wrote:\n\nOh, I have 3 DIVs with class=\"file-trigger\".\nIn my JS script, I did $('.file-trigger').  So I guess that should query all 3 DIVs correct?  But only one gets captured.\nPerhaps, did I misunderstand anything about its usage?\nCheers,\nThomas\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1375#issuecomment-76603380\n. Yes, of course it does. \u00a0You cannot pass a jquery object into fine uploader without the jquery wrapper. \u00a0You'll need to pass a separate extra button array item for each actual button element.\n\nOn Sun, Mar 1, 2015 at 9:57 AM, thomas83 notifications@github.com wrote:\n\nAh yes you're right.  However, it returns JS error if I remove the [0].\nSo I can't do this in a bundle for some reason.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1375#issuecomment-76603691\n. Yes, that is correct. \u00a0\n\nNo real benefit to using jquery if you are only selecting elements. \u00a0It just gets in the way, as you can see here. \u00a0If you'd like to get more comfortable with the web and JavaScript outside of jquery, for instances such as this, have a look at my blog on the subject at\u00a0http://blog.garstasio.com/you-dont-need-jquery/.\nOn Sun, Mar 1, 2015 at 10:07 AM, thomas83 notifications@github.com\nwrote:\n\nAh, I think I got what you mean.  So you mean I cannot expect FineUploader to be iterating over my jquery object on either versions.  And I would have to first build something like this, and t:\nvar myExtraButtons = [\n                {\n                    element: $('.file-trigger')[0]\n                },\n                {\n                    element: $('.file-trigger')[1]\n                }\n            ];\nand then passing this into the FindUploader options:\nFineUploaderS3({\n            ...\n            extraButtons: myExtraButtons,\n            ...\n});\nIt seems like the above is working for me.  But just to make sure, did I get your point correctly?\nCheers,\nThomas\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1375#issuecomment-76604430\n. Sure. \u00a0I'll investigate further during the workweek.\n\nOn Sun, Mar 1, 2015 at 11:22 AM, thomas83 notifications@github.com\nwrote:\n\nThanks Ray!  All good now and cleared out now.\nJust one thought though, it might be nice to show an example or two on the documentation, especially for users who are using the JQuery wrapper, as they may tend to think they can simply just put in a JQuery object (of multiple elements) into that area.\nThanks again!\nCheers,\nThomas\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1375#issuecomment-76616156\n. Looking again at the jQuery plugin wrapper code I wrote, only array elements that are also jQuery objects are expanded to take into account all elements that match the selector.  In all other cases, the first element that matches the selector is used, and all others are discarded.  I'll update the documentation to make this more clear.\n. This marks the last planned task for 5.2.0. Integration testing will begin next, and once all is looking solid, 5.2.0 will be released.\n. It doesn't look like you are using an actual Android device.  I've found the virtual devices to be unreliable. Have you verified on an actual device?  You are the first to file such an issue.  I would expect that such a significant bug on Android would have been reported by now if it existed outside of a virtual environment.\n. Sounds like it was fixed in a hotfix release after 4.4.2. I'll mark this as a browser bug and keep it open so others with a similar issue will be able to easily locate the cause. Thanks for your report.\n. Thanks!. 1. Not sure why are you specifying an itemLimit of 0 instead of simply omitting the validation?\n2. You haven't actually described the problem. What happens when you try to select more than 900 files? Are you simply not able to select, or does the submit to fine uploader fail. \n\nSince you haven't provided any details about the issue, I have to assume that you are simply unable to select more than 900 files in the file chooser dialog of whatever operating system you are using. In that case, fine uploader is not to blame as it has little control over the file chooser modal.\n. You need to build it, or you can download one of the various versions from the home page and try it out by following the getting started guide in the documentation.\n. http://docs.fineuploader.com/contributing.html\n. Sorry, without more information regarding how fine uploader may be at fault, there is no advice I can provide. Looks like an issue with windows at this point.\n. Thanks for reporting this. Looks like a regression, created in 5.0.0 during work on #937, which was a major refactor of the library. This one slipped through. The bug was introduced in 05a25f9b2881a6a2631e7bde6661859e554ca75, and the bug appears to be caused by an improper evaluation of the file size in the upload-data module. We'll fix this as part of 5.2.0.\n. Fixed in 5.2.0-21\n. I'm curious as to how this would help users, since there is nothing they can do about this type of error.\n. This type of error is generally unrecoverable. We can consider making the message customizable, instead of reporting the message from S3, but I would suggest detecting the error in your code and automatically reporting it instead of relying on the user to do so.\nOn Tue, Mar 10, 2015 at 11:50 AM, Studio Republic\nnotifications@github.com wrote:\n\nIt could ask the user to report the error at a certain email address, try again later and just generally be more user-friendly.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1382#issuecomment-78096162\n. Via an onComplete handler. The response object will contain an error property w/ the message text, and a code property with the S3 error code.\n. Via an onComplete handler. The response object will contain an error property w/ the message text, and a code property with the S3 error code.\n. Should be solved in #1724. If not, let me know.. Please see my response to all of the other duplicate cases you previously opened.\n. You can contribute an onComplete event handler to deal with the result of any upload attempt.\n\nFrom the S3 server-side documentation:\n\nYou can also pass any data to your Fine Uploader complete event handler, client-side, by including it in a valid JSON response to the uploadSuccess.endpoint POST request. In fact, the S3 demo server-side code on FineUploader.com is passing a signed URL to the complete handler which allows you to view the file you've uploaded.\n. It looks like you posted the same question on Stack Overflow. I'll paste my answer from SO here:\n\nThe log messages suggest that the issue is with a clock drift on the user's machine. It's not clear how this is related to Norton. If the clock on the user's machine drifts too far from the actual time, then AWS will reject the request. You'll need to be sure that the machine clock is reasonable accurate.\nA similar question was asked at http://stackoverflow.com/questions/18520108/fine-uploader-getting-policy-expired-message-sending-to-s3-for-some.\n. Looks like this won't be happening as part of 5.2. I'll try to balance this and S3 v4 signatures as part of 5.3 instead.\n. Yes, this is correct and by design, and you'll really want to ensure that client machines have reasonably accurate time, not just for Fine Uploader or S3.\nWe can consider adding such an option in a future release. In the meantime, you can probaby update the expiration server-side as part of the policy signing process.\n. I don't see how we will be able to consider server-time, without some breaking changes or complex code adjustments. This is especially true as we look into support for v4 signatures. However, we will consider allowing the 5 minute expiration time to be adjusted via a client-side option.\n. You have at least a couple options, all are fairly easy to achieve since Fine Uploader is a JavaScript library.\n1. Override the qq.s3.util.getPolicyExpirationDate function with your own logic. This can perhaps be simply done by keeping a copy of the original implementation in scope, updating the passed Date to reflect your desired expiration date, and then calling the original function with the modified Date.\n2. Modify the code locally to change the + 5 minutes part of the expression in getPolicyExpiration to your desired value. \nIn both cases, you'll need to be conscious of changes to these methods when Fine Uploader is updated, but I don't intend to make any breaking changes to this API. I intend to make this possible either as part of #1336 or shortly thereafter in Fine Uploader 5.3.\n. I moved this into the schedule for 5.4.0. In order to account for user time issues, I intend to provide a new option that will allow you to specify the relative policy expiration date. It will default to 5 minutes from present, which is the current hardcoded value that has caused some problems for all who have weighed in on this case.\n. @mikesherov You're correct, I forgot about x-amz-date. Too much time has passed since this issue was created, and I must have forgotten about that detail. Thanks for reminding me. I'm certainly open to a patch. It would be great if you have a unit test as well, or at least passing unit tests after the change. But if not, I'll take care of that as part of my review of the code. If you submit a pull request, please do so against the develop branch.\nI still hope to get this in as part of 5.4.0, which is nearing completion, and already S3-themed.\n. Just deleted my last comment after thinking it over some more.\nI can see it being a standalone option property (root-level) or on the request object option. Either way. Are you expecting this value to be a date? If so, it should be in ISO8601 format to make parsing easier. Fine Uploader will need to reformat it and generate future dates in order to properly support POST and multipart upload API requests across v2 and v4 signatures.\nDon't worry too much about the tests if they take up too much of your time. I'll make sure they are in there either way.\n. Yes, I think that should work.\n. @mikesherov Due to scheduling obstacles that would prevent a release until the end of December, I'm aiming to release no later than 18 Nov. Will you possibly have a PR ready within the next few days? If not, I'll do my best to implement this feature as we have discussed so I can get this in for the 5.4.0 release.\n. I'm pushing this, along with additional required work described at the bottom of #1258, to a 5.5.0 release. I don't think I can get out 5.4.0 in the next couple weeks if I include these cases. After 5.4.0 releases, I expect there to be other requests that pop up after some start to make use of v4 signature support. Any of those non-critical issues will also be part of 5.5.0.\n. work on this case has started for 5.5.0\n. This feature is now complete and on the develop branch. Can someone pull down 5.5.0-1 and verify that this fixes your clock drift issues? Once this has ben verified by at least one user, I'll consider it complete and ready to be released with the rest of 5.5.0.\n. ...note that the documentation has been updated as well. See http://docs.fineuploader.com/branch/develop/features/s3.html#accounting-for-browserclient-clock-drift and http://docs.fineuploader.com/branch/develop/api/options-s3.html#request.clockDrift for more details.\n. @schmuhl @mcorrigan @alexsaveliev Are you still interested in this feature? If so, can you verify that this change addresses the issue for you?\n. Since I haven't received any further feedback, I'm going to call this done and ready for 5.5.0. After I complete #1422, I plan on cutting a new release.\n. Thanks for the request. We'll consider this for a future release.\n. completed in 5.2.0-20\n. This is the issue tracker for Fine Uploader, not angular-file-upload.\n. The issue is with your vm or your environment. As I mentioned in the other case, I am able to upload a 10mb file to s3 on the demo page via a fresh ie8 vm without issue.\nOn Thu, Mar 26, 2015 at 5:48 AM, joebtron notifications@github.com\nwrote:\n\nHello, this is a continuation of this ticket which you closed https://github.com/FineUploader/integration-examples/issues/2\nWhen uploading the 10.7mb file c:/windows/system32/ieframe.dll to http://fineuploader.com/demos.html#amazon-demo in a Windows 7 Virtualbox VM running IE8 the upload never finishes, the green window progress bar fills up. I've also tried an 8.9 mb file and after 20mins got a red upload failed notification, clearing the cache everytime, a 1.9 mb file was fine. As far as I can see, this behavior is common to all files over 6 MB as I also tried a 6.9mb mp4 file after that on the same page load which never finished uploading after around 20 mins. It seems to try to go to the page http://fineuploader.com/server/success.html?bucket=upload.fineuploader.com&key=.... and never finishes loading.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1393\n. Also, the success url you are listing is a static html file. If that is not loading quickly and the upload of such a small file is taking 20 mins, then most likely your vm network configuration needs some tweaking. I'm sorry, but that sort of support is far out of scope for this issue tracker.\n. This seems to be caused by network issues between your client and S3. Most likely something is interfering with the request and the response never comes back. Pausing the upload aborts the request. On continue, a new request is created and the upload resumes starting with the last failed chunk offset.\n. The issue is almost definitely caused by network issues. Doesn't have to be on your end, could be some other point between you and S3, or even S3. S3 is not the most reliable endpoint, unfortunately. If you look at the network tab in your dev tools when this happens, you'll likely see the request in question in a \"pending\" state. That means the browser is waiting on a response.\n. We are making very heavy use of Fine Uploader S3 internally here at Widen, and do notice this type of behavior, but only occasionally. It's caused by temporary network issues at some point. Fine Uploader S3 is pretty heavily used by other customers as well, and I'm not aware of any issue in Fine Uploader that would cause this to happen.\n\nWe've discussed setting the timeout property on XMLHttpRequest in the past to deal with this issue, see #743 for an example. At that time, Chrome and Safari did not support this property, but that is no longer the case, so we may revisit.\n. ...I would also ensure that you don't have any rogue Chrome extensions OR antivirus messing with HTTP requests. I can't tell you how many times that has caused these types of issues with other customers.\n. Strange. Looks like the final chunk succeeds. The next step is for Fine Uploader S3 to send a \"Complete Multipart Upload\" POST request to S3, but that is not happening.\nDid you say this happens every time? Do you have a live example site (without minified code or with sourcemaps) where this can be reproduced for me to examine closer?\n. Hmm, very strange indeed. I just uploaded a 300 MB file to S3 (split into 54 parts) without issue. I'll try out your site now.\n. I'm going to have to spend some more time looking into this today. You have concurrent chunking enabled, so multiple chunks are sent at once for a file. The problem here is that the first two chunks are never marked as completed. This means that these consume 2 of the 3 slots in the queue throughout the entire upload, only allowing one chunk to upload at once. When the last file's chunk has been uploaded, it hangs because there are still two chunks that have not yet completed (the first 2). I'm using concurrent chunking myself and haven't seen this problem. My next step is to figure out what is happening with these two chunks in your case. \nI'll keep you posted.\n. Found the problem - it appears to be a bug in Fine Uploader after all. This is only reproducible with concurrent chunking enabled AND an an asynchronous objectProperties.key function. I suspect that is not a popular configuration, which is why you were the first to report it. The issue has likely been in place since 5.0.0, when concurrent chunking was introduced, but I'm not sure yet. I'll need to do some more investigation to best determine how to fix the async key checking logic in the context of concurrent chunking. Concurrent chunking is an incredibly complex feature (which is probably why all other upload libraries have punted on implementation). \nWhen I have a fix, I'll either push it out as a hotfix release, or as part of the upcoming 5.2.0 release.\nThe workaround for you is to disable concurrent chunking. Regular (one-chunk-at-a-time-per-file) chunking should be unaffected by this bug. Concurrent chunking should also work fine with anything other than an async key function. Please let me know if that fixes it for you, and stay tuned for updates on this issue.\n. Great to hear. That is definitely the best workaround since you will be able to continue to benefit from concurrent chunking.\nI am able to reproduce the issue locally simply by enabling concurrent chunking and \"simulating\" an asyc key determination function, like so:\njavascript\nobjectProperties: {\n    key: function() {\n        var p = new qq.Promise();\n        setTimeout(function() {\n            p.success(\"abc123\");\n        }, 1000);\n        return p;\n    }\n},\nchunking: {\n    enabled: true,\n    concurrent: {\n        enabled: true\n    }\n}\nSo this makes fixing the issue easier. It sounds like you won't need a fix though, but I'll still be sure to fix this in the next release (hotfix or otherwise).\nYou may also want to delete your site user/password comment above.\n. Should be fixed in 5.2.0-19. Appears to be caused by a simple oversight/typo in the key handling code of the S3 xhr upload module.\n. Reproduced myself. We'll fix this as part of 5.2.0.\n. Workaround is to turn off the resume feature until 5.2.0 is released if you are concerned about supporting large uploads in a Safari private browsing session.\njavascript\nresume: {\n   enabled: false\n}\nNote that this is the default value, so you can simply omit the resume option from your configuration to achieve the same effect.\n. Fixed in Fine Uploader 5.2.0-22. If you'd like to try this out before the release, please let me know. I'm hoping to release 5.2. in the next few weeks, provided no issues come out of integration testing.\n. The IEEE is pretty clear that 1 MB = 1000000 bytes. While some OSes don't follow this definition, such as Windows, others do, such as OS X. Here is one such reference: http://physics.nist.gov/cuu/Units/binary.html. It is clear that there are those in both camps (powers of 2 and powers of 10) that are willing to argue their side. That said, I'm for not changing the code as it follows a standard/codified definition.\n. That seems fair. We will put this in our backlog and discuss adding such an option for a future release.\n. Server-returned images are nothing more than a URL which must be rendered and potentially resized in the browser. With this in mind, it's unlikely that we will add such an option. \nThe current setup should prevent the browser from being continually stressed, since there is a pause between generation of previews. This pause allows other tasks to be completed in a timely manner, such as scrolling. \n. Yes, that is the intention of the maxCount option.\n. Yes, you are correct. We will adjust the docs before releasing 5.2 this week.\n. You have access to the server response via an onComplete event handler. From there, you can get a handle on the thumbnailUrl and render the images however you require.\n. It looks like you are trying to pass in an array of an array, which is definitely not valid. \n. A FileList is a pseudo-array, and an array of an array is not an acceptable value for this method. The docs do seem to suggest that this is acceptable, but that is a typo. I'll update the docs to clarify how FileList should be passed.\nIt does look like there is one bug here - file input elements cannot be passed into addFiles. This is an uncovered area of our unit tests at the moment (passing in file inputs). I'll fix this and release a hotfix release probably today or tomorrow at the latest. \n. Just to clarify, should pass in the raw FileList by itself, not inside of another array. I'll fix the issue with passing in an  next.\nOn Tue, Apr 21, 2015 at 8:17 AM, Jarda Kot\u011b\u0161ovec notifications@github.com\nwrote:\n\nOk, makes sense. Thanks!\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1398#issuecomment-94790980\n. Note that this bug only applies to <input type=\"file\"> elements passed into addFiles on browsers with File API support. Older browsers are unaffected. It looks like this particular issue has been in place since 5.1.0 and was introduced in eb5b396aed127f2c4285e0a2d05eb10345a07b1d during work on #1198.\n. Fixed in 5.2.1 (just released). I'll update the blog, download page, and npm shortly.\n. Everything has been updated. Thanks for the report.\n. We aim to please. I added a unit test for this code path as well to hopefully prevent this from happening again.\n. Fine Uploader doesn't utilize AppCache. I just uploaded several 200+ MB files without issue in Chrome myself, so if there is a Fine Uploader specific issue here, it must have something to do with this specific file type. I'm not familiar with a \"sparsebundle\". Perhaps this is actually a folder disguised as a file? What happens if you attempt to upload this same file in other browsers? What about other sparsebundles or other large files in Chrome?\n. If this is truly a folder instead of a file, then you will not be able to upload it outside of Chrome.\n. Fine Uploader definitely does not zip anything. Do you have a sample file I can attempt to reproduce with?\n. :+1: \n. I built a sparsebundle and was unable to reproduce the issue. So, without further information or a test file to examine further, I'll have to close this. If more information is added in the future, this can be reopened.\n. While waiting on more information from AWS on #1336, I'll begin work on this one, followed by other non-S3 cases, such as #1196 and #1334.\n. After some more thought, I'm not going to implement this. An extra UI option seems like noise in an already crowded API. If these alerts are \"annoying\" then one option is to present them in a less annoying way, such as via a slide-down message. Another option is to override the showMessage function via a configuration option with something that, for example, logs the message to the console.\n. Thanks for the report. We will begin investigating further tomorrow and will update once we know more, after some attempts to reproduce.\n\nCan you confirm that you are only seeing this behavior on iOS Chrome, and not on any other browsers?\nPlease post your Fine Uploader JS code as well.\nOn Wed, Apr 22, 2015 at 8:30 PM, Dallin Scherbel notifications@github.com\nwrote:\n\nI just uploaded 3 files under the \"Upload Files Directly to Amazon S3\" in the site demo. The first one was a snippet I recorded for around 45 seconds and it uploaded successfully (it ended up being 5.7MB). The second one was a video around 2 minutes and it did not work the first time. The uploading indicator icon just spun for a while. After waiting a bit, the retry button showed up. After clicking retry, the same file uploaded successfully (13.8MB). The third one went just like the second attempt, I recorded a 1:45 second clip this time, after finally getting the retry button again, it worked instantly (8.5MB). Can replicate this same experience on iOS 8.3 in Chrome?\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1401\n. I was just able to reproduce in the latest version of Chrome on an iPhone 6+ running iOS 8.3. Chrome on iOS has been plagued with issues in general, especially since iOS8 was released. I've noticed fairly serious issues outside of Fine Uploader as well. I'll look into this further today.\n. The issue, unfortunately, appears to be a(nother) fundamental flaw in iOS Chrome. I can reproduce the issue with the following code, cutting Fine Uploader out of the picture entirely:\n\n``` html\n<!DOCTYPE html>\n\n\n\n\n\n\n\n\n\n    document.querySelector('input').addEventListener('change', function() {\n        var xhr = new XMLHttpRequest(),\n            formData = new FormData();\n\n        formData.append('qqfile', this.files[0]);\n        xhr.open('post', '/test/dev/handlers/traditional/endpoint.php');\n\n        xhr.onload = function() {\n            alert('sent');\n        };\n\n        xhr.send(formData);\n    });\n\n\n```\nWith a small file (around 100 kB or so), the alert is triggered, indicating that the upload has succeeded. For larger files (800 kB), the alert is only occasionally triggered. I've never seen a video upload successfully. In all cases of failure, the server reports a truncated (or possibly) empty request. Using weinre to debug iOS Chrome, I noticed that the request is stuck in the \"pending\" state.\nI guess I'll have to file a Chromium bug.\n. Chromium bug filed at https://code.google.com/p/chromium/issues/detail?id=480506.\n. Based on recent activity in the bug I filed, Google may be planning to address this issue in an upcoming hotfix release of iOS Chrome.\n. Doesn't look like Google is going to fix this. Note that I plan on dropping support for iOS Chrome in Fine Uploader 6.0. See #1482 for details.\n. This should be \"fixed\" in 6.0.0 when I remove support for iOS Chrome. Follow #1482 for further updates.\n. What version of Fine Uploader?\nOn Sun, Apr 26, 2015 at 3:33 PM -0700, \"Christopher Smith\" notifications@github.com wrote:\nI tried returning ACCEPTED (202) from my success endpoint, since I don't have anything to say, but Fine Uploader considers that a failure code. Anything in the 200 series is supposed to be treated as success; in particular, it's entirely likely that a 201 is appropriate.\n\u2014\nReply to this email directly or view it on GitHub.\n. Acceptance of these statuses was added as part of 5.2.0 in #1314. If you are using 5.2.x and still seeing an issue, please include all details needed to reproduce and this can be re-opened.\n. Noted, and we'll consider this for a future release. Looking at the issue history, this was mentioned previously by another user, but it was in the context of an unrelated case. I asked them to open up a new case, but the user did not follow though. I referenced the workaround employed by this user for reference, but I would strongly suggest not utilizing it, as it makes use of internal properties which can change at any time without documentation.\n. This has not been a priority as there are at least a couple workarounds. One that comes to mind involves creating your own <input type=\"file\"> and then submitting it to Fine Uploader via the API once a user selects one or more files. For example:\nhtml\n<input type=\"file\" name=\"extraButton\">\n<script>\ndocument.querySelector('input[name=\"extraButton\"]').addEventListener('change', function(event) {\n   uploader.addFiles(event.target);\n});\n</script>\n. Have you built and tested to make sure this functions exactly as you expect it to?\n. Thanks, I'll merge this into develop to be part of the next scheduled release just as soon as I get some time to write a unit test or two, schedule permitting. If you're able to write a test instead, I'll be able to guarantee that this makes it into the next release.\n. @Korijn Looks good now! Can you take a peek at the contributor agreement and indicate here if you agree to its terms?\n. Thanks, this looks good. I may end up rolling the hotfix/5.2.3 branch into develop and release this, along with everything currently tagged as 5.2.3 as part of a new 5.3 release (pushing all existing 5.3 stuff to 5.4).\n. This is the first such request we have received. I don't anticipate integrating anything like this into Fine Uploader at the moment. The library is already quite complex and diverse in its support of workflows and endpoints. The library you referenced seems interesting, and I will certainly keep it in mind should someone ask about this type of support in the future.\n. All properties of the credentials option, other than accessKey are only intended to be used by client-side signing workflow. If you'd like to sign requests on your server, do not supply any credentials property other than accessKey in your options, and provide a path to your signature server.\n. You can read more about the client-side upload/signing process on the associated feature page in the documentation. If you do not want to handle signing client-side with short-lived credentials, use the server-side signing workflow.\n. It's not clear why you would like to provide temporary credentials when your credentials are stored safely on your server and never exposed to the client. \nIf you'd like to change your credentials with the server-side signing workflow, you'll need to re-initialize Fine Uploader with a new access key. We can consider a method to update your access key via the API in the future though.\n. @Jud Not being familiar with this workflow, it sounds like this could be solved simply by allowing the server to return this token as part of its response to Fine Uploader's signature request with the expectation that Fine Uploader will then include this token as a request parameter when communicating with S3. Is this correct?\n. I think this will be quite complicated to deal with server-side, as your server code will then need to reconstruct the policy document (for older browsers) or the headers string (for newer browsers that utilize the multipart upload API) in order to provide a correct signature, since x-amz-security-token must be accounted for when generating a signature. \n. ...and the complexity of dealing with this server-side once v4 signatures are supported by Fine Uploader is much greater.\n. > Since the secret key and access key should change in tandem would it make sense to have the signature endpoint return the accessKey?\nYes, I think that is feasible. I'm less familiar with how this session token affect the signature. If it must be considered when signing the request and included as a header on the request to S3, that makes all of this more complicated. I'll need to look into this further before I start implementing a solution.\n. I don't know if this will be completed as part of 5.7.0, but I will certainly begin researching and planning changes to the library to address the workflows described here. This has become more of a priority as of late. The need to allow for a constantly changing STS token and access key is something we are looking at for our apps that use Fine Uploader internally as well. Associating an EC2 server with an IAM instance profile that contains a set of temporary credentials for signing the request does seem to be a best practice that is being adopted by others. Fine Uploader could very well be sending requests to a cluster of EC2 instances, each with a different set of temporary credentials. This means each signature request for a single file could require different set credentials for each chunk/request. It seems important for Fine Uploader to support this workflow.\n. Just to confirm - the workaround detailed by @eugenebond in the case description does not work for you, @trauts2? There's an open pull request - #1549 - that aimed to address this to some degree, but it needs some attention and refactoring, and I'm not sure if it elegantly supports temporary tokens to the degree that I'd like to see. \n. I'd very much like to have proper STS support in Fine Uploader, or support for temporary credentials with a server-side signing workflow. Unfortunately, I'm pulled in many different directions these days, and simply responding to support requests and bug reports takes the majority of my time. Also, I'm in the process of (slowly) creating a React wrapper library for Fine Uploader UI, so that is accounting for all of my FU dev time at the moment.\nOn top of that, I feel I need to make time to understand STS a bit better so that I am able to properly test support for this once the feature is complete. I see this as being a fair amount of work. Another dedicated maintainer would make this all go a bit faster.\n. > it would be great to get the plumbing working with temporary credentials since this is arguably weakening the security to put static credentials on boxes\nCompletely agree. Unfortunately, there are quite a few other feature requests that have yet to be completed, in addition to this one. And, for the most part, I'm the only dedicated maintainer for this project. If this changes and someone else would be willing to come onto the project as a dedicated maintainer, we can make better progress. But being a maintainer is not a trivial amount of work, and requires an excellent understanding of HTML, CSS, JavaScript, HTTP, and S3, along with enough free time to make reasonable progress.\n. Thanks for the kind words @trauts2. It's always good to hear that my work on this project has been helpful to users. My employer will likely need support for temporary credentials w/ a server-side signing workflow in the near future as well, so this feature will likely make it into the library in due course.\n. @mgoodness I'm guessing/hoping your knowledge of STS/AWS temp credentials is greater than mine. Perhaps we could coordinate on implementation of this feature, since @Widen will likely need this support for all of our their products at some point anyway.\n. Cool, thanks Mike. I'm mostly interested in being sure that I understand how to use STS properly in a real-world scenario, using AWS best practices. Let's talk next week. If anyone else in this thread is interested in contributing information about their intended use of STS/temp credentials, please let me know ASAP. Perhaps we can all chat at once.\n. Sorry everyone, it is taking longer than I thought to simply take some time to write up a list of requirements for this feature. I promise I'll add something here in the next week. Stay tuned.\n. Mostly time. I won't have time to participate in any features of this size for the next few months or so due to commitments that are popping up.. Perhaps my work on #1939 will be of some use here.. If anyone has any idea at all how to file a bug or report an issue against facebook's in-app browser, please let us know. The support maze on their site appears to lead nowhere.\n. Anyone know if this is still an issue?\n. Closing, but will consider re-opening if someone reports that this is still an issue.. You haven't provided any information here that would help us to reproduce or even look into the issue. Useful information would include the browser, version of fine uploader, properties of the file causing the issue, or any steps at all required to reproduce.\nIt does indeed sound like a browser extension is causing your problem. I suggest you start removing or disabling extensions until you locate the offending extension.\n. This header was added to overcome a bug in introduced by Apple into iOS6 browsers. See #396 for more details.\nI suppose this can be changed to only append the header for POST, GET, (and probably DELETE requests). I'd have to give that some thought though.\n. I don't anticipate changing this. The best course of action is to ask Vimeo to add Cache-Control to the Access-Control-Allow-Headers preflight response.\n. You can either build your own ui from scratch or extend the ui that fine uploader provides. You can't convert a non-ui instance into one that contains the extendable ui. Either way, this is more of a support question, and belongs on stack overflow. When you post there, be sure to show your code and ask a question specifically about a problem you are having with that code.\n. The UI instance simply extends the basic instance. If you want to extend the default UI, then construct a qq.FineUploader instance. If you don't, construct a qq.FineUploaderBasic instance. \n. See http://docs.fineuploader.com/quickstart/01-getting-started.html or one of the many live demos at http://fineuploader.com/demos.\n. Before you open up any more issues, please read https://github.com/FineUploader/fine-uploader/blob/master/CONTRIBUTING.md.\n. please don't post the same issue in two places (here and stack overflow).\n. The issue is most likely on your end, and since you have provided no indication that the issue is with fine uploader, it should be worked through on stack overflow. If you want help solving this, you haven't provided key information required to help, such as your server and client side code.\n. Are you talking about a situation where you drop a lot of image files, and then remove one of them, which causes previews to not be generated for the remaining files?\n. I suspect this is a bug, and will look closer soon.\n. Looking into this now.\n. Easily reproducible, probably some logic in the templating.js module that is causing the process that generates previews from the queue to prematurely end when a file or img element associated with a queued item no longer exists.\nRegression caused by work on #1279 during 5.1.0 development. \n. Fixed in the hotfix/5.2.2 branch, to be part of the 5.2.2 hotfix release, along with #1417.\n. Most likely due to the close button lacking a type=\"button\". Adding that should fix the 2nd issue. Not sure what is causing the first issue for you. You'll have to show your code.\n. Issue 2 will be addressed by updating the default templates to include type=\"button\" on all <button>s in the upcoming hotfix release. I'm unable to reproduce the first issue though, so without your code and some ability to reproduce it, I will be unable to look into it any further.\n. Working on this now as part of 5.2.2. After the second issue in the report is addressed, 5.2.2 will be pushed out as a hotfix release.\n. I'm unable to reproduce either issue. Please provide your code, a list of steps required to reproduce, and the specific issue(s) you are seeing.\n. Nevermind, I am able to reproduce by uploading a file and then clicking the delete icon. I mistakenly thought you were removing images with autoUpload set to false before triggering the upload process.\n. Are you saying that you are using the 5.1 version of the JavaScript file with a gallery template and the 5.2 version of the CSS file? If so, that is completely unsupported and you likely will have issues. The gallery view requires you use at least v5.2 of the JS file, since it wasn't introduced until 5.2.\n. ...more specific to your case, one of the changes in 5.2 included an adjustment to th click handler code, which was needed for the gallery view. That might explain your first issue. As a matter of course, the JS and CSS/template files should be of the same version.\n. Ok. So the first issue is expected, and should be resolved by using all 5.2 components in your project. All other issues you filed should be fixed in the hotfix/5.2.2 branch and will be released in the very near future, possibly today or Monday.\n. This is an interesting positioning error that I am not able to easily reproduce, but I can see it happening every once in a while. It seems like the easiest solution is to include the following style in in your document:\ncss\n.qq-gallery .qq-upload-size {\n   float: left;\n}\nThis should prevent the file size element from pushing the trash icon (which is floated right) onto the next line. Does this fix the issue for you without causing any other obvious issues in other browsers?\n. Great. I'll include this as a default style in the gallery css file in v5.2.2. \n. Likely a duplicate of #1416. If you are still seeing the issue in 5.2.2, I'll re-open.\n. Are you able to reproduce this with the 5.2.2 version? The upload status of the file should not be relevant here.\n. Yes, 5.2.2 hasn't been released yet. Regardless, I was finally able to reproduce this in firefox using the 5.2.2 code. I'm looking into this further now.\n. I'm able to reproduce in any modern  browser that is capable of client-side preview generation, and the gallery template is not required as far as I can tell. Only a \"preview\" element in the template. \nThis also uncovered another issue which is fairly minor but I will fix as well. An attempt is made to \"update\" the preview after a file has uploaded successfully, even if there is no thumbnailUrl in the response and client-side preview generation is possible.\n. I think I have a fix for this. If you'd like to verify that I've fixed all of the issues you've reported in the last couple days (#1416, #1417, #1418, and #1419) before I release 5.2.2, I can get you the pre-release.\n. S3, azure, or a custom endpoint you control?\nOn Mon, Jun 8, 2015 at 3:03 AM micmicovich notifications@github.com wrote:\n\nOk, I'm waiting for pre-release.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1419#issuecomment-109896979\n.\n. http://releases.fineuploader.com/hotfix/5.2.2/fine-uploader-5.2.2.zip\n. I plan on releasing 5.2.2 tomorrow morning (Central Time) unless I hear that there are additional issues caused by these fixes. I didn't see any.\n. This does not sound like a new issue, nor does it sound like one that will\nbe easily reproduced. I'll see if I can reproduce, and if I am unable to do\nso in a reasonable amount of time, I don't see this holding up the hotfix\nrelease.\nOn Tue, Jun 9, 2015 at 4:14 AM micmicovich notifications@github.com wrote:\nAll issues (#1416\nhttps://github.com/FineUploader/fine-uploader/issues/1416, #1417\nhttps://github.com/FineUploader/fine-uploader/issues/1417, #1418\nhttps://github.com/FineUploader/fine-uploader/issues/1418, and #1419\nhttps://github.com/FineUploader/fine-uploader/issues/1419) - \u043e\u043a.\nWhen I begun to test, I faced the problem,\nthat later was hard to reproduce.\nProblem:\nthumbnail generation stops at some item (more often closer to the end of\nlist).\nHow to reproduce:\n- Firefox 38.0.5\n- a lot of open tabs (~30)\n- number of images: 36\n- image size: 1-2 Mb\n- Fine Uploader element outside of form\n- a little of system memory\n- CPU: high loaded (not necessarily)\nBut if thumbnail was not generated for even one item,\nafter deleting all items and uploading them again,\nno thumbnail is generated.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1419#issuecomment-110285974\n.\n. Also you'll need to quantify \"a little of system memory\".\n. Please move all of this to a new case\nOn Tue, Jun 9, 2015 at 7:44 AM micmicovich notifications@github.com wrote:\nI've edited the post: \"a little of FREE system memory\"\n~350 Mb on Windows 7 Ultimate\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1419#issuecomment-110345165\n.\n. I was unable to reproduce after a few rounds of testing. We'll keep an eye on this and, if we see it, are able to reasonably reproduce it, and are not convinced that this is an extreme edge case, we will investigate further in a future release.\n. Closing as I am still unable to reproduce. We can consider re-opening if the situation changes.\n. I just tested Spartan/Edge/whatever via a Windows 10 Insider Preview against Fine Uploader 5.2.2. Brief tests suggest that everything obvious is working well except for file dropping. This is not a big surprise as each new version of Explorer in the past has required adjustments to Fine Uploader's DnD module.\n\nThe next task will involve fixing DnD for Spartan. Then, I'll spend some time on more in-depth testing.\n. It looks like Spartan may not yet support dropping of files from the desktop. I assume that will be ironed out before release.\n. Official word is that dropping of files will not be supported by Edge in the initial release. https://twitter.com/morris_charles/status/611997674460479488\n. pushing this to 6.0.0 since Edge still does not support file dropping, AFAIK.\n. I'm dropping this from the schedule as Microsoft doesn't seem to have any specific plans to support this feature.\n. According to the Edge changelog, support for this feature was added in build 10565. Assuming this passes verification, Edge will be supported as part of Fine Uploader 5.5.0.\n. This is the last task scheduled for 5.5.0. I'll begin work on this next week.\n. When attempting to test out the DnD feature in Edge, I noticed that the available Windows 10 VMs only support Edge 10240. I reached out to the Edge team, and they informed me that indeed there is no support for 10565 in Windows 10 VMs at the moment. No known date for release of a VM with this build of Edge. So, I'll need to remove this from the schedule yet again.\n. Edge is not yet supported by Fine Uploader. This has not been possible for various reasons (all on the Microsoft side). Edge didn't even support file dropping until a few months ago, and then there was no VM available with the build of edge that included support for file dropping. I'll check again to see if there is an updated VM. If there is, I'll try to add edge support again.\n. Thanks for looking into this! I'll take a closer look and add support for edge in a near future release.\n. Sorry, still blocked on this. Microsoft has still not released a VM with a current build of Edge. The latest one available is 10240, which does not support file dropping. Without that VM, there isn't much I can do here. I'd suggest pinging someone at Microsoft about this. I'm going to mention this to them again, as I did a couple months ago. Until a VM with Edge build 10565 or later is made available by Microsoft, Edge remains officially unsupported by Fine Uploader.\nThread on Twitter at https://twitter.com/kylealden/status/684893112355794945.\n. Microsoft tells me an updated VM will be available in a couple weeks.\n. I now have a VM to work with, so I'll begin investigating support for Edge. Once this is complete (assuming I don't run into any more blockers) this will be released as 5.7.0.\n. PR to release Edge support is #1557. Anyone here interested in giving it a whirl to verify before I release?\n. This is completed and Microsoft Edge is now supported as of Fine Uploader 5.7.0.\n. Why?\n. Ah, I just noticed the link in your description. Regardless, all pull requests must be against develop, as mentioned in the contributing doc. I'll remove this property in the next release though.\n. I understand. Thanks for the heads up though, and like I said, I'll remove this in the near future.\n. Sorry, I'm not seeing an issue. You'll have to be much more specific about the conditions needed to reproduce, and the specific issue you are seeing. Also, what version of Fine Uploader are you using?\n. Thanks. We will look into this further.\n. Can you elaborate on how you are retrying two files \"simultaneously\"? I'm not seeing how this is even possible with the current API. Brief testing shows the total bytes being updated correctly when the second file is retried.\n. As you can see from my post, I am still unable to reproduce this. If you are confident an issue exists, please share the exact line or lines that are causing the issue, along with a proposed fix.\n. Closing as I am unable to reproduce. I'd be happy to consider re-opening if this changes.\n. It sounds like you are reporting three unrelated issues in the same case. If this is true, please split them up. \nYour first issue (I think) - only able to submit one file - is expected as you are setting the fileLimit option to 1.\nI'll have to investigate the getResumableFilesData() issue a bit.\nRegarding the callback issue or auto retry issue you are reporting (not sure exactly what issue you are having here) - retrying and the associated callbacks definitely work without any issues that I am aware of. If you are seeing something different, you'll need to provide specific reproduction steps and a clear description of the issue.\n. Thanks. I'll look into this further and will update when I have a question or resolution.\n. Sorry, haven't had a chance to look into this yet. I should be able to get\nto this on Thursday.\nOn Mon, Jun 15, 2015 at 1:32 AM Tim Daubensch\u00fctz notifications@github.com\nwrote:\n\nGood morning,\n@rnicholus https://github.com/rnicholus Any updates on the issue yet?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1425#issuecomment-111949516\n.\n. I found the issue with getResumableFilesData(). Indeed it is not returning any results, but this issue is localized to the logic associated with looking up resumable file records for the user-facing API method and deleting them after they have expired. The resume feature itself works and is not affected as far as I can tell.\n\nIf you are having retry or resume issues, the problem is elsewhere, perhaps specific to your environment or integration code. There is a bug in the getResumableFilesData public accessor method though, and this will be fixed in the next release, perhaps even a hotfix release. The issue with this API method is caused by an error in the internal _iterateResumeRecords method of the xhr.upload.handler.js file. The start of the localStorage key does not end with a '-', which is resulting in zero records. Two things call this internal method - the API method that returns resume records, and the code that attempts to remove all old records from localStorage.\n. This fix is currently staged in the hotfix/5.2.3 branch - version 5.2.3-1.\n. We can look into explicitly returning a status value from this method, specifically a promise, in some future release.\n. The internal promise impl probably accounts for about 500 bytes gzipped. Hardly noticeable.\n. No, it is not compliant, but more than sufficient for the purposes here. qq.Promise predates the spec, or at least my awareness of the spec. This is outlined in the promise module docs. For more info please read http://docs.fineuploader.com/branch/master/features/async-tasks-and-promises.html.\nI imagine that the library will evolve to make use of an external promise library if detected, at least when returning promises through the api.\n. Fine Uploader will accept files, file input elements, or canvas elements from any location you desire, provided they are passed into the addFiles API method.\n. Sorry, I'm not sure what specific problem you are trying to work around. If you can provide a clear description of the problem followed by a series of steps required to reproduce along with any code required to reproduce, that would be great.\n. Ah, I see. Then this appears to be a duplicate of #1106. Let me know if I've missed something.\n. I ran into #1431 (a regression likely caused by work on 5.2.0) when trying to reproduce this. So, once I fix that, I'll look closer and try to ensure this is also fixed in 5.2.3.\n. @josefloreschura This should be fixed as a result of my work on #1431. Instead of not adding \"hidden\" scaled files elements to the DOM, the corresponding elements are now added as of 5.3.0-6, but they are hidden and annotated so that Fine Uploader will never make them visible or return a reference to them via the public API.\nPlease confirm that this fixes your issue. I'm currently staging 5.3.0-6 on the develop branch. You can access the jQuery S3 version at http://releases.fineuploader.com/develop/5.3.0-6/s3.jquery.fine-uploader-5.3.0-6.zip.\n. Please cite the specific section of the spec that mandates custom attributes be prefixed with \"data-\".\n. I'm going to close this as there is no need to rename all of Fine Uploader's contributed custom attributes. You could very easily open the same case in, for example, the angular project, which also makes use of non-data attributes. \nThe primary reasons for using the \"data-\" prefix are:\n1. Access to the value on the element object via the dataset property.\n2. Prevent clashes with other native attributes.\nFine Uploader namespaces all custom attributes, so there is no chance of collision with native attributes. Also, we don't currently make use of the dataset property, mostly due to the poor browser support (IE11+). \n. Seems like we can just include the qqparentuuid param on all scaled images in all cases. Arguably, that should have happened from the start. Unsure if this should go in 5.2.3 or 5.3. It may be bumped.\n. You could perhaps append the UUID to the filename as a temporary workaround\nusing setName.\nOn Sat, Jun 27, 2015 at 9:37 PM MikeSmith01 notifications@github.com\nwrote:\n\nDid a little more testing today, and found out that name won't work as a\nunique link for resized images because if I upload the same image twice,\nthe name is the same for both uploaded images and code breaks. Will have to\nwait for the enhancement:)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1432#issuecomment-116185244\n.\n. Looking into this now as part of 5.2.3. Perhaps I can sneak this in...\n. @MikeSmith01 I've made an adjustment, which is currently being staged in the hotfix/5.2.3 branch. Please let me know if this will address your issue.\n. Sorry, I just merged the hotfix branch into develop as I plan on skipping the hotfix release and making this part of 5.3.0.\n\nYou can access zips of anything on the develop branch by following a little convention we have in place. For example, to grab the azure build of 5.3.0-4 (currently the latest build on develop): http://releases.fineuploader.com/develop/5.3.0-4/azure.fine-uploader-5.3.0-4.zip.\n. @MikeSmith01 Great, thanks for verifying. This will go out with 5.3.0, hopefully in the next few weeks or so.\n. I'm not sure what the issue is or what you mean by \"not keeping track\". Is something specifically falling? What is the observable issue? I doubt that requesting a key for one file will cause an issue when attempting to delete another file. I'll attempt to reproduce at some point though.\n. I'm not able to reproduce this, but I'd be happy to reopen if more details are made available.\n. Hi Mike, and thanks for your comments. You are correct that Fine Uploader's UI is not as flashy as it could be, but if you compare us to some of the other libraries, the difference in quality and support is pretty clear.\nLet's take dropzone.js for example, developed by Matias Meno. Now, dropzone has a pretty flashy UI, and a super nice looking website, but the feature set and support is laughable. Also, Enyo is a bit out of his element as he is clearly lacking sufficient web and JavaScript knowledge to handle this type of library. Another competitor - jQuery File Upload, which has a great feature set, though not as comprehensive as Fine Uploader, and absolutely zero support or library evolution. No one can touch Fine Uploader's feature set, code quality, or support. And I hope that users see this and use Fine Uploader as a result.\nThe original demos you have linked to were provided by a friend of the library, and were once used as the demo page. But the demos you have linked to are quite old and I have since moved on and updated the site quite a bit, as you can see. The code examples are not missing, in fact, I have more of them. Take a look at http://fineuploader.com/demos (notice the \"view code\" link at the bottom of each demo). We even have a gallery view template packaged with the library that is demonstrated on this very page in two places. I used to have more demos, but then users complained that the demos were too hard to navigate. I use to have more complex demos, and users complained that the demos were too complex. So, I decided to pare down the demos to a set of simple but common use cases. There are a few others to be found in the integration examples repo. There is also a standalone repo that demonstrates integration with another library I wrote, frame-grab, that shows how to generate video previews and upload specific video frames.\nWe do have some work in progress to attract more customers and make Fine Uploader more appealing. You should see this happen during July, so stay tuned!\n. Thanks for your support, as always, @andrew-kzoo!\n. Thanks for your input Mike. You've given me something to think about, and i\nwill use the case you have opened to document any changes/additions we\nshould make to the demo page. Perhaps i can take some additional time to\nreexamine the demos. Stay tuned as I'll update as i put together a plan and\nsome more ideas.\nOn Thu, Jul 2, 2015 at 10:47 PM MikeSmith01 notifications@github.com\nwrote:\n\nHi Ray, thank you for your reply.\nI absolutely agree with you that the code quality, documentation quality,\nand support quality is very crisp with FineUploader. I am very proud of\nhaving to work with it:)\nI was not aware that the demos were old, they very well might be, you\nwould know better:) I just wanted to provide an example of the demos that I\nwould personally expect to see, as these types of demos with\ncode/functionality side by side tend to be the best. I did see the code\nlink at the demos page. At the time I wrote this there was no demo for\nbasic..so I guess that's why I wanted to see more demos. (p.s. that demo of\nthat flashy image gallery might have primed me also;)\nIt's really weird that some users would ask for less demos, I as a\ndeveloper, would never ask for less demos or complain that they are too\ncomplex. Why would anybody ever do that? Demos are on take what you need\nbasis, it's not like one tries to cram demos in the developer's head. The\nmore examples the better, saves time on reading documentation right? When I\ndevelop I might copy/paste code snippets from this and that demo and put\nthings together pretty fast, I find this pretty convenient to work like\nthat. With all honesty, I am having a thought now that those users might\nhave been bogus and tried to intentionally undermine FineUploader's\nsales/reputation. While a flashy demo is subjective, a plain vanilla is\ngoing to look plain vanilla to everyone.\nIt's nice to hear that you have something in the works, I'm looking\nforward to it:) Honestly, putting up good demos and polishing them up can\nbe quite exhausting and tiring work, it would probably feel like that last\n10% of the way, which are the hardest. But they have to be there. As I\nalready suggested, maybe trying to put FineUploader in context with image\ngallery, video gallery, and file gallery would be good. More updated code\ndemos like the ones composed by a friend would be super nice. I am having a\npicture come up in my head now of a chest of jewels that's being\nunfortunately closed with only a few jewels shown on the top. I want to see\nit all so I can look no further from the start.\nThank you,\nMike\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1434#issuecomment-118223634\n.\n. For the love of god, can someone please step in and help update fineuploader.com?! \n\nIn addition to better demos, I'd like to:\n- remove jQuery and bootstrap\n- update the look\n- improve page load times\n. Wouldn't this be something you would track server-side? Fine Uploader can send a POST when each file has been uploaded successfully.\n. I understand that this may be useful for your specific use case, but I don't see a general use for this, and I'd like to avoid cluttering up the API any further. However, I would be glad to consider re-opening if other users show an interest in this.\n. There is no live demo for Azure, as there are not many customer utilizing Azure. S3 is heavily used, which is why it is represented with a live demo.  If you would like help troubleshooting your code, please see our support page for details on how to properly do this. The issue tracker is for feature requests and bug reports.\n. Please open up support questions on stack overflow. See our support page for more details. \nBe sure you include your code. As it stands, you haven't provided any useful info to troubleshoot your issue.\n. Which browsers are you using to reproduce this? If I'm able to reproduce\nmyself, I'll look into a fix for 5.3.0.\nOn Thu, Jul 23, 2015 at 5:42 AM Mohit Suman notifications@github.com\nwrote:\n\nIn the demo page :- http://fineuploader.com/demos\nI tried to upload near about 1800 files all pretty small less than 1 MB.\nOnce I click on Upload button it started uploading, but after 840 files\nthe progress bar disappears and for the rest of the 760 files I have to\nclick \"Upload\" button again.\nWe are also facing similar problem in our end.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1439.\n. It's tough to reproduce something that requires 1800 files to be uploaded. I'm not seeing any issues in the develop branch. There were a couple potentially related issues fixed there, and they will be part of 5.3.0. Please let me know if the 5.3.0-8 build fixes your issue.\n. 5.3.0 is in develop. The latest build is 5.3.0-8. For information on how to\ndownload the latest dev build of your choice, see my comment at\nhttps://github.com/FineUploader/fine-uploader/issues/1432#issuecomment-118995654\nOn Fri, Jul 24, 2015 at 7:07 AM Mohit Suman notifications@github.com\nwrote:\nWhen are you guys releasing 5.3.0 as it is in dev branch? Because till\nthen it is a production bug for us.\nOne more thing what problems are you facing in uploading 1800 files?\nWe just copy pasted a bunch of files and were able to test it 5 mins.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1439#issuecomment-124500145\n.\n. 5.3.0 will likely be released in the next week or two. In the meantime, you will want to ensure your issue is fixed in the pre-release before we actually release.\n. Everything is looking fine on my end on develop. Closing for now. I can re-open if you're able to reproduce on develop and have more specifics regarding reproduction.\n. After a few more attempts, I am now able to reproduce, though only after about 2700+ files. \n. After further investigation, the issue occurs when a very large number of files is submitted and the uploadStoredFiles method is called before Fine Uploader has finished verifying all the files submitted. The files are only eligible for upload after various internal checks are run during a processing phase for each file that is submitted. \n\nWhen uploadStoredFiles is called, it simply loops over an internal array of verified files and submits them to the upload controller to be queued or uploaded. When the issue described here occurs, this internal array does not yet contain all submitted files as not all submitted files have been verified. This also explains why calling uploadStoredFiles again later uploads the remaining files.\nI think a reasonable solution may be to check if any files are still in the qq.status.SUBMITTING state once we finish iterating over the array of verified \"stored\" files to upload. If there are any files in this state, then we probably want to wait a bit and attempt to process items in the stored files array again.\n. This is now fixed in the develop branch. Please verify on your end before release @mohitjee15.\nPre-release build number incremented to  \"-9\" in b7053e5b2dc56bdc2e803936c1856e8d0cd1765e. \n. I just pushed the release candidate to npm: \"fine-uploader@5.3.0-11\".\n. Sorry, the bug tracker is for bug reports and feature requests. This is a support question. If you'd like support, please open a question on stack overflow under the fine-uploader tag. You'll also need to include more information about the issue other than \"uploader failed\". \nMy guess is that you haven't started an actual server and are trying to reference the files directly from the filesystem. You need an HTTP server of some sort.\n. Thanks for the suggestion. We'll consider this for a future release.\n. Duplicate of #1422. Edge doesn't currently support dropping of files - not a Fine Uploader issue and there is no workaround. Please see 1422 for details.\n. Please see https://github.com/FineUploader/fine-uploader/issues/1422#issuecomment-212513830.\n. Most likely an issue with the signature server, or perhaps something is intercepting the request or response to the signature server on your network. Possibly even a browser plugin.\n. Just glancing at your page I can see that you have failed to include fine uploader's CSS file. Either that or you have heavily modified the template such that the rules in the CSS file are no longer able to target the proper elements. Also, this error is different then the last. Now it appears as if you have improperly configured the CORS rules in your S3 bucket.\nThe examples work fine and are demonstrated live on the home page for further inspection. If you have a specific technical support question, the best place to handle that is on Stack Overflow under the fine-uploader tag. But you'll have to provide much more information than you have provided here, such as your actual code. \n. Looking into this now...\n. Site is back up now. I'm guessing Dreamhost (which hosts a shared instance housing our docs site) had some sort of outage, at least on our shared instance. Looks like it was out for several hours, nothing noted on their status page or twitter feed. I'm going to follow up with them to find out what went wrong.. Note that we will still need to require IE9 & IE8 to return a 200 response with {\"success\":true} due to issues with handling of non-200 responses in those browsers when an iframe is involved.\nI don't want to make this a configuration option. Instead, 6.0 would mandate that endpoints declare the status of the upload request via the response status code, unless the request comes from IE9/IE8. All of this becomes a bit more complicated in a cross-origin environment. \nHonestly, I don't expect to to implement this given the scope of the change and the potential edge cases that may suffer.\n. Duplicate of #1325.\n. Any custom headers you set for the upload request will be sent with the chunking success request.\n. The multipart boundary header included in your question is representative of a JSON file. Of course, you can include JSON in an input field, or pass JSON to the setParams API method, but there will be no Content-Type, as that is reserved for files/blobs.\n. Please post support questions that are not bugs or feature requests to Stack Overflow under the fine-uploader tag.\n. I was hesitant to expose the ability to upload folders via the file chooser, since this is generally a bad idea due to the fact that the UI thread can lock up for long periods of time and cause the browser to crash. With this in mind, I don't forsee adding any further enhancements to support this workflow. You can always access the underlying File via the getFile API method.\n. Your best bet is to set autoUpload mode to false, allow them to drop all their files, and then instruct them to click a button that calls the uploadStoredFile API method once they are done providing whatever information you are looking for.\nFor any further non-feature or non-bug reports, please post on Stack Overflow under the fine-uploader tag.\n. You should already be able to do this by calling the retry API method. You can add this call to an onComplete or onStatusChange event handler.\n. And you can add exponential backup by making use of window.setTimeout.\n. No, but you can certainly keep track,\n. Looks like a bug. \n. The easiest solution is probably just add a call to the hideRetry method of the templating module to the qq.status.UPLOAD_RETRYING check in the _onUploadStausChange method. You can then remove any other code that duplicates this logic on retry.\n. The easiest solution is probably just add a call to the hideRetry method of the templating module to the qq.status.UPLOAD_RETRYING check in the _onUploadStausChange method. You can then remove any other code that duplicates this logic on retry.\n. No, 1000 is the correct value.\n. No, 1000 is the correct value.\n. Seems to be working fine for me - just tested on 5.3.0. If you are still seeing the issue and are using the latest version of Fine Uploader, I'd be happy to re-open if you are able to provide your code and any additional info required to reproduce.\n. Seems to be working fine for me - just tested on 5.3.0. If you are still seeing the issue and are using the latest version of Fine Uploader, I'd be happy to re-open if you are able to provide your code and any additional info required to reproduce.\n. I don't see ever adding that sort of fine-grained control. However, I can see updating the code to perhaps delete all hidden scaled images when the reference image is deleted. This would be exposed by a new  scaling option property. \n. should be available via getUploads().\nOn Wed, Aug 19, 2015 at 10:50 AM Anton Sarov notifications@github.com\nwrote:\n\nHaving a global scaling option to delete scaled images along with the\nreference image would be super cool!\nMeanwhile, is there any way to force the deletion of the hidden scaled\nimages? Getting the ID would help here.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1457#issuecomment-132645488\n.\n. Yep, looks good. Were you also able to verify that this works as expected for you?\n. Great. I'll push this out as a hotfix release very soon. It will be 5.3.1.\n. Not sure offhand. A quick trace of the code should provide a definitive answer. If you see anything, let me know and I can potentially re-open with a scheduled fix. In the meantime, a timeout of 0 is reasonable. \n. Not sure offhand. A quick trace of the code should provide a definitive answer. If you see anything, let me know and I can potentially re-open with a scheduled fix. In the meantime, a timeout of 0 is reasonable. \n. Unlikely that this will be part of the API, but I can see a blog post that explains how to calculate current or average transfer rate. \n. Thanks for the code @rmckeel. I don't have a specific date for this blog post, as there are a number of other items ahead of this in my queue. But I don't expect it to be very difficult to throw something together once I am able to do so.\n. @JHGitty Please do submit a pull request against the docs with a solution that works for you. I am also considering opening up the wiki so these sorts of things are easier to contribute.\n. I think it would be great to publish something like this as a small library, published to npm. This follows the lodash model, which I appreciate. Then, Fine Uploader users could pull it into their project and easily integrate it for upload speed reporting. I don't see any need to use jQuery here though, or any dependencies for that matter.\n. You are the first to report such an issue. Are you able to provide more information? In particular:\n1. Please elaborate on \"freezing\". What specifically is happening once the upload reaches 99%?\n2. What request or requests are in progress when this \"freeze\" occurs?\n3. How easily reproducible is this issue? Does it occur 100% of the time with files of this size?\n. Unless you had the dev tools console open the entire time, I would expect the logs to be empty. Logs will only be recorded after the console is opened.\n\nWere you able to see what specific request was in transit at the time it became stuck on processing?\nRegarding \"onAllComplete\" - this does not correspond to any calls to your backend/signature server. Figuring out exactly what request is in transit when this happens is the key to solving this issue. If you have any further information in this regard, that will be helpful.\n. How easily are your customers able to reproduce? Is there something common among all customers reporting this issue?\n. I'm going to close this until more information regarding reliable reproduction of the issue pops up.\n. You want Fine Uploader to make the entire XML response available to you? The messages sent to these callbacks are meant to be generic. If you'd like to tap into all details logged by Fine Uploader, you should consider intercepting calls to qq.log.\n. This indicates an issue with your onComplete callback handler. It appears as if you are attempting to reference an undefined variable.\n. I'm not seeing this issue with 5.3.1. If you still are after upgrading, let me know and provide all of your client-side configuration code for easier reproduction.\n. Yes, this is most likely the cause. While I can certainly understand a max size limit, enforcing a minimum size limit seems uncommon. May I ask why you are using this restriction? In the context of image scaling,  this restriction can be problematic we are including this limit in the policy/REST headers for all files.\n. > Pictures with less than 3Mb are considered low quality which I want to avoid.\nThis really isn't true in a general sense, and I would suggest re-evaluating this logic. The size of an image does not necessarily describe its quality. \nIn light of this, unless there is a reasonable use for limiting minimum size of scaled images, I'm going to close this case as the uploader is behaving as designed. \n. The button is not tracked until the file is officially submitted. That is, all validation checks have passed and the file has been associated with an upload handler. Your best bet is to move your logic to an onSubmitted callback. \n. The first step to fixing this would be identifying where the perf problem lies. Your case is very much on the outer edge of normal use, so it may be a little while before I am able to look at this further. There are a number of other questions/requests in the queue at the moment that I must attend to first.\n. Good detective work! Yes, this perhaps can be improved by batching all UI updates to ensure they happen all at once instead of staggered. I suspect this will be a bit tricky though, and this likely does not just affect stored files. Instead, you will probably see the same issue if you select/drop thousands of files in IE10/11.\n. What, specifically, are you looking to temporarily remove from the DOM? Fine Uploader looks for elements given a reference element. That reference element is usually the file list container element - .qq-upload-list-selector. It does not use document as a reference element after the template has been initially rendered. So, that seems like it would work without issue.\n. Typical of the jQuery docs, the exact reason why you should perform many\noperations on a set of orphaned elements is missing. But yes, I believe\nthat this will likely solve the issue as this should drastically limit the\nnumber of reflows/repaints.\nOn Mon, Sep 14, 2015 at 11:49 AM morgunder notifications@github.com wrote:\n\ni had a function that recalculated things and reapplied classes on a\ncouple of hundred elements and it was slow. then i found a few articles\nthat said that i should detach the dom element manipulate it then reattach\nit once i was done. this sped up that function considerably. i forget the\nexact amount, but at least 2x and maybe 5x.\nsome other articles on that basic concept\nhttp://desalasworks.com/article/javascript-performance-techniques/ <\nhttp://desalasworks.com/article/javascript-performance-techniques/>\nhttps://learn.jquery.com/performance/detach-elements-before-work-with-them/\n<\nhttps://learn.jquery.com/performance/detach-elements-before-work-with-them/\n\nOn Sep 14, 2015, at 12:16 PM, Ray Nicholus notifications@github.com\nwrote:\nWhat, specifically, are you looking to temporarily remove from the DOM?\nFine Uploader looks for elements given a reference element. That reference\nelement is usually the file list container element -\n.qq-upload-list-selector. It does not use document as a reference element\nafter the template has been initially rendered. So, that seems like it\nwould work without issue.\n\u2014\nReply to this email directly or view it on GitHub <\nhttps://github.com/FineUploader/fine-uploader/issues/1466#issuecomment-140128997\n.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1466#issuecomment-140141850\n.\n. Caution: we probably do not want to remove the entire file list from the DOM whenever new files are added. This will be a jarring experience for users. Instead, perhaps the new set of file elements can be built-up in a detached state, and then added to the DOM once they are all in place. Don't think this will be trivial though.\n. @rmckeel Do you know where the bulk of these calls to getByClass are coming from? I'm interested in the stack for that particular call.\n\n@Korijn IDs are, in most cases, to be avoided. They are an anti-pattern. There are a lot of ways to shoot yourself in the foot with IDs. Determining what is \"unique\" in a document that you do not have full control over is tough. I would also suggest not caching any of these results, as we could potentially run into memory issues. Optimizing theses selectors is probably the best course.\n. @rmckeel Thanks for your response. Even with your custom JS/profile data, I'll still want to reproduce locally so I can be sure this is properly fixed. I've updated this case and I'll begin looking into this perf issue ahead of everything else once I have a bigger break in my time this week.\n. I spent an hour yesterday investigating further. I was able to reproduce the issue. I'm using a Macbook Pro late-2014 model w/ 16 GMB RAM, i7, etc, etc. I setup my endpoint to return an initial file list of 3000 entires, consisting solely of name and uuid properties. Initial load of the list on Chrome 45 took about 10-15 seconds. During this time, I was able to scroll, but the browser did not respond to any other actions. \nUsing Chrome's profiler, I identified a huge number of calls to qq.getByClass. These calls seemed to account for the bulk of the work. I ultimately identified 4 issues here:\nToo many DOM elements\nEach file entry in the DOM is made up of at least 20 elements. If the initial file list consists of 3,000 entries, this means 60,000 extra DOM elements! That is a huge number of elements, and this will likely have a noticeable perf impact on most selectors. Putting performance aside, you can't expect your users will want to scroll through 3000 files. IMHO, your initial files endpoint should never return anything close to 3000 files. Instead, consider providing a small subset of these files. If you really expect your users to page through all of the files, you should return them in pages. I realize this is not very easy with the current API, but this could be much easier if I added an API method that allowed you to add more initial files to the list. You could then pull the first set on load via Fine Uploader's built-in code, and then request subsequent pages yourself on-demand, passing these into the new API method for Fine Uploader to render.\nToo many elements selector calls\nFor each file added to the list, there are perhaps a dozen calls to the document to select various parts of the file or file list. For a \"normal\" amount of files in a batch, this is likely not an issue. But at scale, this has noticeable perf consequences. The best solution to this is probably to determine when we are handling a batch of files, and maintain a cache of file IDs to file HTML elements. The internal templating module selectors can grab from this cache instead of hitting the DOM. This cache will be cleared after we are done processing the batch. \nInefficient element selectors\nThere were quite a few calls like this: fileListEl.querySelectorAll('.someClass')[0]. All we want is the first match, but instead we are querying for all matches and throwing all but the first away. A simple fix would be to use fileListEl.querySelector('.someClass') instead.\nTo many page reflows/repaints\nIn a batch of 3000 files, each file is added to the DOM separately. This results in a huge number of reflows/repaints, which is a perf issue. Instead, perhaps the code can be adjusted to build up this list of file elements detached from the document, and then add the entire batch at once when we are done processing the batch of files.\nI am working to make the changes described above now. This will be a bit of work, but progress will be reported here as it happens. After all of the changes are complete, I'll make a new pre-release available for testing.\n. > you might end up dropping a few elements and possible finding how to do some of the js logic in pure css for even more wins\nI have no plans to do this at the moment. These types of changes could be considered breaking changes, and I intend to make this a hotfix release.\n\ni wondered if making a version with font awesome icons vs the images you are currently using\n\nNo plans to tie Fine Uploader to any specific 3rd-party dependency. If you wish to use different icons, you can certainly do this via CSS overrides.\n. I just pushed some changes up to the hotfix/5.3.2 branch. Without these changes, a 5,000 item initial file list pretty much crashes Chrome/Firefox - spinners + constant long-running-script warnings, etc for quite a while. With my changes, the file list loads in a few seconds. That's a pretty substantial improvement. Profiling suggests that there are no obvious JS-specific or DOM-specific bottlenecks that can be further improved.\nThe last piece of this solution is to simply not load 3,000+ files for your users to sort though. And if you must do this, do so in pages. The work remaining in this case:\n- [ ] Provide API endpoint to pass in additional \"canned\"/initial files\n- [ ] Update docs\n- [ ] Consider using perf enhancements for dropped/selected file batches too.\n. Is there any interest in an API method that allows you to pass in additional \"initial\"/canned files after Fine Uploader has loaded? This will add a bit more complexity, but has already been requested in #1191.\n. Hi everyone. Just a reminder that this new proposed api method isn't meant\nto pass ALL of your initial files. It's purpose is to allow you to \"page\"\nthem. For example, your initial set on component load return 100, and you\ninclude a \"more results\" button. When this is pressed, you request 100 more\nand then pass the results into this new api method, appending them to the\nexisting list.\nOn Wed, Sep 16, 2015 at 11:44 PM Ryan McKeel notifications@github.com\nwrote:\n\n@rnicholus https://github.com/rnicholus Ray, my vote (on behalf of\nseveral clients sites that use FineUploader) is no interest in passing in\nlists of files after load. There is no change that would warrant it in the\nsingle session. I suppose group uploading would be a good reason to add\nthat feature in, I just wouldn't expect group uploading to be that common!\n:) Thanks ~\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1466#issuecomment-140969211\n.\n. In order to get this out sooner, I'm narrowed the TODO list to:\n- [ ] Update docs\n- [ ] Consider using perf enhancements for dropped/selected file batches too.\n\nI may drop the last item as well if it proves to be too complicated or risky relative to the benefit. If the last item does need to be addressed and it is not addressed in this hotfix, I'll open up a new case.\n. I don't think any change to user-submitted files is in order at this time. And since I plan to leave the work mentioned in #1191 for another time, I don't think there is much else to do here. Has anyone interested in this fix tested it out? If not, do you need more time? I plan to release my changes in a 5.3.2 version tomorrow otherwise.\n. great, thanks for the confirmation\n. This is expected, as zip files are not previewable.\n. Neither of these are issues either. The chunks folder is where file chunks\nare temporarily stored. And the itemLimit, of course, is a strict limit of\nthe number of files you can upload/submit.\nPlease do not create one thread and the post several unrelated issues under\nit.\nOn Mon, Sep 14, 2015 at 3:20 AM standus notifications@github.com wrote:\n\nAnd next trouble:\n{ \"validation\": { \"itemLimit\": \"1\", \"allowedExtensions\": [\"jpeg\",\n\"jpg\",\"avi\",\"png\"] }, \"scaling\": { \"sendOriginal\": \"false\", \"sizes\": [\n{\"name\": \"sized\", \"maxSize\": \"1900\"} ]} }\nand with sessions setting:\nsession : { params: { files: uploaded }, endpoint:\n'/libs/scripts/uploaded.php', refreshOnRequest:true }\nAfter reload page I have one already uploaded file which I see in UI of\nFU. But after try to upload next image I got error: Too many items (3)\nwould be uploaded. Item limit is 1. But I have only one. OK, I deleted that\none image, soo in UI is no image, I try upload newone, but with message:\nToo many items (2) would be uploaded. Item limit is 1.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1467#issuecomment-139995482\n.\n. The issue is in your configuration. \"false\" is not a valid value for the scaling.sendOriginal configuration property. That property expects a boolean, not a string. I would suggest taking a look at similar configuration options on your end. Be sure you are respecting the expected types according to the documentation. http://docs.fineuploader.com/\n. I'm not seeing this issue at all. I tested with a validation.sizeLimit of 10000000 and a chunking.partSize of 2000000. Files greater than 10MB were rejected as expected. If this were as you described, there would have been a large number of bug reports already, as this is a commonly used feature. I suspect you have either misinterpreted your issue, or perhaps there is some problem with code on your end, outside of Fine Uploader's scope. \n\nIf you are able to provide all of your Fine Uploader related configuration code, your Fine Uploader version, and specific steps required to reproduce, I can re-open this issue.\n. Then the issue is in your server code, so this does not involve Fine Uploader. \n. You did not mention this either. If there is a specific bug in the example PHP server code, please file that in the php-traditional-server repo.\n. I'm not sure what you mean by \"1000 concurrent uploads\". Please provide details.\n. Closing this due to lack of information.\n. Fine Uploader is a client side JavaScript library, not a server. I suggest you take a break from github until you figure out how to use the issue tracker. You opened up 2 exact copies of this issue today, which I've closed. \n. Looks like you've posted the same question on stack overflow. I'll answer there.\n. I'm not seeing a problem. Fine Uploader internally makes use of data URIs when displaying scaled thumbnails. Subsequent attempts to access the same URI come from the cache, as expected. But either way, there is no round-trip to the server.\n. I guess I don't really see the need to clutter up the api with another method in this case. If you are using the default showMessage impl, this would be nothing more than an alias for window.alert. If you provided your own impl during initialization, then it would be an alias to a function you already should have access to.\nAddressing your second question; allowing any configuration option to be changed at any time adds unnecessary complexity to a library that is already complex.\n. copy of #1470\n. copy of #1470\n. This is not a Fine Uploader issue. Instead, the issue seems to be in rendering of umlauts using the \"Maven Pro\" font provided by Google Fonts in Firefox. You can verify at http://typecast.com/preview/google/Maven%20Pro. The next best course of action is to either file a bug with Firefox and/or Google Fonts. \n. It is a Google Fonts or Firefox issue. Please look at the link I sent you and paste in a word containing an umlaut. The templating engine does not have any concept of character encoding.\n. I've attached pictures of a word with an umlaut entered into the google fonts typecast demo page on FF and Chrome - no Fine Uploader involved. You can see there is a clear rendering issue in FF. You'll need to contact either the Fonts or the Firefox team for further support.\nFirefox:\n\nChrome: \n\n. I can see adding a new configuration option for this, such as confirmBeforeUnload with a default value of true.\nIn the meantime, you can turn the function that adds this handler into a NOOP with the following code:\nqq.FineUploader.prototype._preventLeaveInProgress = function() {};\nMake sure you do this before you construct a new instance of Fine Uploader, but after the script has loaded (of course). As with access to any underscored property, this is not part of the official API and may change at any time, but is probably a reasonable workaround for now.\nI'll update this case when an option is added.\n. Thanks for the request. We'll consider this for a future release.\nOn Sat, Oct 3, 2015 at 5:02 AM Anton Sarov notifications@github.com wrote:\n\nIt would be really useful to have the following functionality: be able to\ndelete the scaled images when the original has been deleted. Right now in\norder to achieve this, one has to retrieve the ID of the scaled image and\nmake an additional request (deleteFile). This can be simplified by having\nsome configuration property (see below) which is then evaluated by Fine\nUploader and the scaled image is deleted as well. See #1457\nhttps://github.com/FineUploader/fine-uploader/issues/1457 for more info\nscaling: {\n    sizes: [\n        {name: \"small\", maxSize: 100},\n        {name: \"medium\", maxSize: 300}\n    ],\n    deleteWithOriginal: true\n}\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1478.\n. Can you describe the steps needed to reproduce?\n. Ah, that's the critical piece that is missing from your PR and issue - Azure. I'll update both cases. \n. No problem. I'll probably release this as part of 5.4 instead of a hotfix release. Use of Azure, compared to S3, is very small, so this likely doesn't affect many users.\n. I forgot to ask you this in previous PRs, but do you agree to give up any future claims you may have to the code in this PR, since it will become part of Fine Uploader for which Widen holds a copyright?\n. Thanks for the fix. I just merged into develop and added a unit test to cover this.\n. As in the SO question you referenced, I am unable to reproduce this issue. Were this a Fine Uploader issue, I would have expected other reports by now, as this is a fairly significant one. The code in your SO question was a bit hard to follow and overly complex, so I suggested you start over and gradually re-introduce that complexity (when necessary) until you are able to reproduce the issue. Once you are at that point and are able to provide a concise set of code and steps to reproduce, I'd be happy to re-open and look further.\n. The problem is in your code. The cancel method, as the documentation states, requires a Number (Integer) parameter to be passed in as the file ID. You are passing a string. You could have avoided this by making use of Fine Uploader's API to get the file ID, instead of sniffing DOM attributes.\n\nFor example, your click handler could be rewritten as:\njavascript\n$(\"body\").on(\"click\", \".customcancel\", function () {\n   var $li = $(this).closest(\"li\"),\n       id = manualUploader.getId($li[0]);\n   manualUploader.cancel(id);\n   $li.fadeOut();\n});\n. yes, this is not the first time someone has tried to pass a string as an ID and experienced strange results.\n. This is not a bug, rather it is intentionally in place to work around bugs in video file uploading present in current iOS Chrome and previous versions of iOS Safari. See #990 for details.\n. It's possible though that this should only be in place for Chrome. I'll keep this open so I remember to ensure this isn't affecting any version of safari newer than ios7.\n. If you set the workarounds.ios8EmptyVideos option to false, it should allow the multiple attribute to be added to the file input in iOS.\n. In Fine Uploader 6.0, I plan on removing this workaround, even though iOS Chrome may still have this issue. Along with removing the workaround, we'll probably pull support for iOS Chrome. Google doesn't seem to be interested in maintaining Chrome for iOS and there is little reason to use it anymore, especially as serious bugs remain unfixed for 1+ years.\n. TODO here for 6.0:\n- [x] Remove workarounds.ios8EmptyVideos option\n- [x] Remove support for iOS Chrome\n- [x] Remove workarounds.ios8BrowserCrashoption. This should not be an issue anymore.\n- [x] Remove workarounds.ios8SafariUploads. This was only for iOS 8.0.0.\n. No problem. That's one of the (many) things that makes Fine Uploader a better choice than any of the other upload libraries.\n. Working on this as part of 6.0.0 now. Again, Chrome on iOS will no longer be supported after this is complete.\n. Completed and staged in the release/6.0.0 branch.\n. I've not run into this myself, and this is the first such report. How exactly does one reproduce this issue?\n. Thanks for the information. Do you have a pull requests to offer that addresses this issue?\n. Thanks for the update. This looks like a reasonable change. I'll be sure to include it as part of the next scheduled release.\n. This is how the concurrent chunking feature is supposed to work. Please read the feature doc at http://docs.fineuploader.com/features/concurrent-chunking.html for more info.\n. Your question is a little hard to follow. If I have misinterpreted, please take some time to clarify.\n. Thanks, I understand now. This is a known \"limitation\" of concurrent chunking. Implementing the feature was exceptionally challenging. In order to keep the complexity at bay, I opted to implement the feature such that it simply moves from one file to the next, uploading as many chunks as possible for one specific file. The target workflow is one that uploads a single very large file, and this also works fine for many large files (though there is no benefit of concurrent chunking in this context).\nI'll look into enhancing the feature to accommodate other workflows as well in the future.\n. Can you provide specific steps needed to reproduce? I haven't encountered this issue myself, and I don't recall any reports either. I'll need other information as well, such as your client side code and version of Fine Uploader.\n. Ok, can you tell me what specific issue this message is causing, other than a log message in the dev console?\n. That sounds like a pretty serious issue, but this is the first I've heard of it. Have you tried using a more recent version, such as 5.3.2?\n. Without any information to go on or a way to reproduce, I'll have to close. Could be a browser plug-in on some user's machines that is causing the problem. If not, and you see a pattern, let me know and I can re-open.\n. There's a great getting started guide at http://docs.fineuploader.com. That should give you a head start.\n. Present in at least 5.3.2, likely other versions as well. Will investigate when this regression occurred soon.\n. Appears to only be an issue for the traditional endpoint uploader (not S3/Azure).\n. After closer inspection, I am not able to reproduce this issue. I became suspicious when I remembered that there are extensive unit tests covering this feature. In my own development setup, I was actually calling the setDeleteFileParams method in a callback, which made it appear as if the deleteFile.params option was being ignored by Fine Uploader, until I looked at my code closer. I suspect you might be in a similar situation.\n. Looks like you've already asked this question on stack overflow, and received a good answer. If you have additional questions of this type, the proper place to post them is on stack. The issue tracker is for feature requests and bug reports.\n. The GitHub issue tracker is for bug reports and feature requests. For \"how do I do this\" type of support questions, please post a question on Stack Overflow under the fine-uploader tag, as described on Fine Uploader's support page. Be sure to read the community rules for Stack Overflow before you post a question.\n. Fine Uploader has an auto-retry feature. By default, it will wait a few seconds between attempts, and then auto-retry up to 3 times. The time between attempts and number of attempts is configurable. You can also manually initiate a retry via the API or the UI. \nIf you are using the chunking feature, which is turned on by default in the S3 module, Fine Uploader will attempt to retry only the failed chunk, not the entire upload from byte 0.\nNote that chunking is not supported in IE8 or IE9.\n. I don't think there is a one-size-fits-all answer to that question. The chunk size is configurable so you can adjust it based on your results. Large chunks = less efficient retries. Smaller chunks = more HTTP requests.\n. This sounds pretty complicated, and I don't see it being an appealing feature for most. This becomes even more complicated with the concurrent chunking feature enabled. I don't plan on implementing something like this.\nIf you are having issues with the time required to combine all chunks, you have a number of options to mitigate this:\n- Use Fine Uploader S3 or Fine Uploader Azure. Chunk combining seems to be very quick.\n- Send larger (fewer) chunks. In my experience, this reduces some of the overhead.\n- Combine the chunks in a separate thread, and simply return a 202 to the chunking success request.\n- Faster disks (SSD) and/or more RAM on your server\n. I'm not sure the path options above are appropriate for this type of value. But I certainly can see the need to use HTML (especially <svg>) elements in place of images. Instead of including options with an HTML string, I would expect these to be defined in the Fine Uploader template, and tagged with a -selector class such as qq-img-not-available-selector. The templating module would be used along with the image generation module to show/hide these elements at the proper time (if they exist in the template) This approach is more consistent with post-3.x Fine Uploader. \n. Regarding header values of custom headers, I think the best approach is to simply leave these alone. If encoding is needed, the developer integrating with Fine Uploader S3 will need to properly encode these values before forwarding them on to Fine Uploader.\n. This has been completed and is available in the develop branch as 5.5.0-2. I plan to release this with 5.5.0.\n. @neilchaudhuri I will be on a short vacation for most of this week, and I plan to release 5.5.0 mid-next week, perhaps around the 20th or 21st. If I run into issues during final testing, I'll aim for a release the following week, provided the issues encountered are not significant. \n. All tests are passing in all supported browsers, so the release of 5.5.0 next week is likely.\n. I'm afraid I don't understand your first request at all. Perhaps you can attempt to explain a bit differently?\nAs for your second request, that's not something I plan on implementing. Changing the method depending on the chunk index doesn't make a whole lot of sense to me, and I doubt it would be generally useful. \n. No, Fine Uploader won't change the endpoint. It will send all requests to the endpoint specified. Or perhaps you are asking for the behavior to be changed such that Fine Uploader follows some sort of endpoint convention based on the type of request? That's what methods are for, so I dont expect to implement that.\n. Yes, if you change the endpoint via the API, of course Fine Uploader will respect that change.\n. Sorry, this is really confusing. It sounds like you are now filing a bug instead of a feature request. Is this accurate?\n. Ok, I think I understand now. You want more control over when each specific chunk is sent. Not something I plan on adjusting in Fine Uploader. Processes like concurrent chunking are complex enough as it is. I wouldn't suggest changing the endpoint for an upload while that upload is in progress, as the results will be hard to determine.\n. You can't currently turn on/off concurrent uploads dynamically via the API. Your questions are a bit all over the place and hard to follow. If you have a good idea as to what code should be changed, feel free to open a pull request and I will take a look.\n. > Also, another pointer is this success true thing is kinda not a good idea.\nIt's necessary for cross browser compatibility. The docs cover this in several places, and there are a number of issues explaining this as well. \n\nsuccess true is an easy on to eliminate because success can be based on header response just as easily. \n\nNo, it can't. Not for IE9 and older.\n. We're going in circles at this point. As mentioned before, if you would like a specific change made to the library, feel free to illustrate with code or a pull request. The specifics of your request are still murky to me. Keep in mind that this library has evolved over years of time, and design choices in place that may not make sense to you are likely frustrating simply do to your lack of knowledge in this domain. The goal for Fine Uploader has been consistency and progressive enhancement, as long as that progressive enhancement does not place a burden on users interfacing with the library. Keep this in mind as you explore changes.\n. Comment in that case, not in a new one.\n. Can you either close this issue or delete the Stack Overflow question? \n. Actually, since this is a bug report, this should only be filed here, and not on Stack. Please delete the duplicate question you opened on Stack.\n. > Do you think it's safe to make the changes I suggested?\nNo. This is likely a regression caused by work on #1466. The trick will be to fix this without re-introducing the issue addressed in #1466. The solution involved building up the initial file list disconnected from the document and then adding everything at once in one operation. I'll have to give this some thought.\n. After a few moments of reflection, I think the fix will be simple and appropriate.\n1. Instead of building up the initial file <li>s in a disconnected <span>, build them in a DocumentFragment\n2. appendChild the DocumentFragment of <li>s when all initial files in a batch are ready.\n. > Any ETA on the fix?\nI'd like to push this out as a hotfix release in the next day or two. I'd much rather do so only after verification that the fix works and that it doesn't negate the work done to address #1466. Will you be available to verify the fix in the next day or two?\n. Ok, If the fix goes as easy as I hope, I think I'll be able to push this out in the next couple days. If anything goes wrong, I'll have to wait until mid-December, as I'm out of the office for a few weeks starting at the end of this month and I don't want to cause problems for those monitoring the project during my absence.\nIf you are comfortable adjusting the code on your end and letting me know if you run into any issues, that will be helpful. Either way, it's late here and I'm offline for the next 8 hours.\n. Fix is being staged on branch hotfix/5.4.1. Let me know if you need any help verifying. \n. Sounds like you've tested this well enough. Normally, you could either pull down the built JS files from S3, or build yourself using grunt. I don't think the build process pushes anything up to S3 on any branch other than develop or master though. \n. fixed in 5.4.1\n. what version of Fine Uploader?\n. Sounds very similar to #1481.\n. No problemo.\n. Is there any particular reason why you don't want all scaled images to show up in the list? Barring something very compelling, I don't see this type of adjustment making it into a future release.\n. We'll consider this for a future release, but I'm not exactly sure when. 5.5 and 6.0 are already full at this time.\n. Looks like Azure maintains a node sdk at https://github.com/Azure/azure-sdk-for-node.\n. You are looking to upload server to server correct? Fine Uploader is a browser/client-side tool. Your best bet is to do some research or open up a well-formed question on Stack Overflow, but Fine Uploader is not the tool for this job.\n. @skvale These changes look appropriate at first glance. Why did you close this?\n. Thanks for these fixes Sam, and welcome to the Widen team! \nI'll update master as well.\n. We can probably address this by adding checking for a maxWidth or a maxHeight option if maxSize does not exist. However, we will have to take into account the image orientation based on the EXIF data before acting on either of these new options. Seems like this won't be terribly difficult, but the scaling feature is complex enough that a lot of other issues could appear as a result of this change, along with other unexpected challenges. \nAt the moment, this is a low-priority feature as it has only been requested by one user and I don't see this as an exceptionally important adjustment. As such, I don't have a planned release date or version at the moment.\n. Can you link to the exact comment where this was mentioned in #937?\n. > I feel like the concurrent chunking might be causing some issues\nHave you turned off concurrent chunking and attempted to reproduce?\n. > will usually not happen on the second upload attempt\nFine Uploader, by default, will auto-retry. By \"the second upload attempt\" do you mean the next auto-retry? If not, please explain further.\n. So auto retries do not solve the issue? What specifically must the user do to complete the upload? \nThe issue you linked to was specific to Safari, caused by a bug in the browser. This sounds different. \nI'll take a look at the code later in an attempt to determine how this might happen. Do you have browser console logs to match one of these incidents, or at least error logs by chance?\n. This doesn't sound like a Fine Uploader issue, in that case. More like an issue with the user's file system. I'm going to close this then, unless you have any alternate theories. \nThe error message is from AWS, and is not something we can customize. It seems to outline the issue pretty well though, without being overly specific about the root cause.\n. This is likely out of the control of Fine Uploader. In fact, Fine Uploader doesn't \"read\" the file before it is uploaded, this would be highly inefficient. It simply passes a handle to the file off to the browser's request transport, and then asks the browser to send it off. Also, the file path is not available. \nPerhaps we can log a message that is more presumptuous, but this will inevitably backfire when our assumption doesn't match the reality in some case. Either way, there isn't much the user can do about this issue. If your users are experiencing this issue fairly regularly, you will want to consider mentioning this in your application's support area.\n. You can set custom headers/params using the setParams API method or the request.params option. In most cases, Fine Uploader S3 will include an x-amz-prefix to this params.\nThere are a few enhancements planned for the next release, along with a dedicated documentation section on the S3 feature page. These enhancements likely don't pertain to your case, but you can see the updated docs for the next scheduled release (5.5.0) at http://docs.fineuploader.com/branch/develop/features/s3.html#headers.\nYour request makes it sound like there is no way to set custom headers, which I've answered, so I will close this case. If you were actually looking for something else, let me know and I can consider re-opening.\n. You mean calculate the MD5 hash client-side and include it with the request?\n. No response after 8 days, closing.\n. The best way to handle this situation is to use version 4 signatures with Fine Uploader S3. With version 4 signatures, the entire chunk is hashed and included as part of the signature. AWS re-calculates the hash/signature server-side, and if there is a mistmatch, the upload fails. The blog post that talks about version 4 sigs in Fine Uploader S3 can be found at http://blog.fineuploader.com/2015/11/16/fine-uploader-5-4-aws-s3-version-4-signature-support/.\n. You're quite welcome. Version 4 signature support was added to Fine Uploader in version 5.4.0. The blog post I linked to (which I wrote) explains how to get up and running with that workflow. There are sections on the docs site that deal with version 4 (and version 2) signature generation server-side as well, such as http://docs.fineuploader.com/branch/master/endpoint_handlers/amazon-s3.html.\n. @psusmars A pull request into the server-examples repo would be most appropriate. If your code works and you are sure to include it in a ruby dir, I'd be happy to include it there.\n. Instead of opening a new PR each time, you can simply push fixes to your branch.\n. There are a lot of changes here, many of which I don't agree with. Allowing the chunk to be potentially modified (made smaller or larger) adds quite a bit of complexity to the library, which itself is already more complex than I'd like it to be. However, I think this can still be accomplished for traditional endpoints by extending the onUploadChunk event/callback. Currently, Fine Uploader passes metadata about the chunk to the callback handler, just before it is uploaded. The code could be modified to include the chunk Blob as well. Furthermore, internal code that handles onUploadChunk calls could be modified to support a promissory return type that, when resolved, includes the new chunk Blob. I don't think this will be a terribly difficult modification to make. \nI'm going to close this pull request, but if you'd like me to consider this for a future release with my proposed solution, please open up a feature request, or, better yet, a pull request with minimal changes that implement my proposal.\n. > ...the problem is that it wouldn't support asynchronous code within onUploadChunk\n@ericmackrodt Yes, it would. As I mentioned in my comment, the internal code would need to change to handle a promissory return value from the callback handler.\n. If you feel comfortable making an attempt, by all means. But this is likely a pretty complicated change for anyone not familiar with the codebase. Otherwise, just open up a feature request.\n. Yes, this may very well be a bug. I'll look into this further and if I am still able to reproduce on develop, I'll hold up the 5.5.0 release and include this as a fix as well.\n. I tested on master and on develop, and am not able to reproduce this issue. I tested using two different filenames with at least one + in the filename, both chunked and non-chunked. Both uploads completed without issue using the PHP signature server 1.1.0 included at https://github.com/FineUploader/php-s3-server.\n. Sounds like it could be a bug. Could be that when a chunk fails with concurrent chunking enabled, there is a bug that results in an unordered list of parts in the digest request sent to S3 after all chunks have been uploaded. After all parts are uploaded, Fine Uploader sends a \"complete multipart upload\" request. The body of that request contains IDs (ETags, to be specific) for each chunk, and they are supposed to be in order. I'll look into this in the near future.\n. @jfpaulin Can you provide me with Fine Uploader JS/browser logs for the point when the chunk upload fails and then successfully retries? I'm also interested in the request body for the Complete Multipart Upload POST request that Fine Uploader sends after all parts have been uploaded. \nI don't see how the parts could be out of order, as they are explicitly ordered just before the Complete POST is sent. Perhaps something is going wrong with the numbering of the parts. I suspect that, after an out-of-order chunk fails, when its index is added back to the \"remaining chunk indexes\" array, something unexpected is happening before that chunk is retried. The logs I have requested from you may shed some light on this.\n. 5.1.3 is quite old. I'll either need to recreate myself or get access to the logs mentioned in my last post in order to get to the bottom of this. I'll take a closer look sometime next week.\n. @rushimusmaximus The error message in your comment above seems to be related to the network connection issue on your end, and is otherwise benign as far as I can tell. I suspect that the original issue reported here is related to assigning part indexes to retried out-of-order chunks. \n. Chunks 1344-1347 initially failed due to issues on S3 (these are surprisingly common), but then recovered. Looking at the complete POST request, part number 1349 is duplicated:\nxml\n<Part>\n   <PartNumber>1349</PartNumber>\n   <ETag>\"ea1968a50c26c099597724727c36abc8\"</ETag>\n</Part>\n<Part>\n   <PartNumber>1349</PartNumber>\n   <ETag>\"ea1968a50c26c099597724727c36abc8\"</ETag>\n</Part>\nSeems like this is causing S3 to reject the complete POST.\nIt's not clear why that specific part number was repeated. That chunk did not fail, but it is close in range to the chunks that did and were retried. I'll have to look closer.\n. Not sure. I don't see anything unusual in the logs. May have just been a pending request to S3 that fine uploader was waiting for.\n. @jfpaulin and @rushimusmaximus Is this something that can be easily reproduced by you or one of your customers? If yes, I'd like to consider giving you an updated version with some more logging so I can have an easier time determining why a part/etag is duplicated in a failure scenario. Otherwise I'll just push out a pre-release with some code that removes the any duplicates before multipart e \"multipart complete\" REST call to S3.\n. You can disregard the last message, after looking at the logs even closer, I think I see what is causing a duplicate part number in the manifest. When an error on S3 forced a batch of concurrent upload requests to fail, one of those requests actually succeeded. \nThe batch consisted of part 1344 - 1348 as far as I can tell. This makes sense @jfpaulin since you have the maxConnections option set to 5. Parts 1344-1347 failed but 1348 somehow succeeded (or at least this is what the logs indicate). I mentioned that the manifest contained a repeated part number of 1349. Amazon, for inexplicable reasons, decided that part numbers must start at 1 instead of 0. So while Fine Uploader's core logging code reports this part as 1348, AWS sees it as 1349. Anyway, due to some apparent error in Fine Uploader's concurrent chunking code, 1348/1349 was uploaded again when the batch of files was retried. I'm not certain why this happened, but this is what resulted in a duplicate entry, since the same part was uploaded twice. \nUploading the same part twice in itself isn't a problem, but reporting the same part twice appears to be. I should probably determine why a seemingly successfully uploaded part was re-uploaded, and that will result in a solution to this problem I imagine.\n. This is looking to be caused by a very unusual race condition. I'm not entirely certain about the chain of events, and reproducing looks to be difficult. I have not had any luck yet. The concurrent chunking feature is complex, as is the code. I'm hesitant to make any changes to the logic in this code unless I am 100% certain of the outcome and am certain that the change needs to be made. I also thought about simply checking the internal array that maintains the part numbers yet to be uploaded for a match before adding a new part number, but this check would occur often, and for very large files, this array could be quite large and examining it for a duplicate could be costly.  Unless someone has some thoughts or insight regarding reliable reproduction, I may just opt for an easy \"fix\" that involves removing a duplicate entry in the \"complete multipart\" manifest just before this request is sent.\nI really don't think this has any relation to the size of the file (6GB vs 500 MB), but I can see how the issue would be frustrating when a very large file fails to upload at the last step and is not retryable. Just out of curiosity, how often are your customers seeing this issue?\n. If this truly does take that large of a file to reproduce, then I will have difficulty reproducing myself due to limited bandwidth at my current location. I'm still not convinced that file size is really a factor. A request error is required to reproduce, and this is more likely to occur with much larger files somewhere along the way. That is probably why you are seeing this with larger files. Did you say you are able to reproduce yourself very easily? If so I'd like to be able to send you updates for testing/verification in order to get to the bottom of this as quickly as possible. Will that work for you? \n. It will probably be easier to continue via email then. Can you contact me at [redacted]? I'll have you a build with some more logging and a first naive attempt at a fix sometime on Monday.\n. Yes, I did. I'm currently GMT+7, so I will be sure to respond with details in the morning. Thank you for your patience.\n. This issue now has my full attention, and as soon as I fix it, I'll push out a 5.5.1 release. This is a tricky one, so bear with me.\n. 5.5.1-3 may have the fix for this issue. I have one person already testing, but was wondering if anyone else is interested in verifying as well? Since this change touches the most complex code in the library, more testers is a good thing.\n. This has been released as 5.5.1, now on npm and also available via the website.\n. closing this as plans for 6.0 have changed a bit. I'll track changes elsewhere once 6.0 gets started again.. The option name declares the intent pretty clearly, but the description is a little hard to follow. I'll push a clarification soon. Thanks for the report.\n. Understood. Since I don't plan on renaming the option forceTheConfirmationDialogToAppear, this will be addressed with updated documentation, unless you have another preference.\n. Fixed in 5.5.2.\n. Including my initial suggestion for implementation from #1516 here...\nI think this can be accomplished for traditional endpoints by extending the onUploadChunk event/callback. Currently, Fine Uploader passes metadata about the chunk to the callback handler, just before it is uploaded. The code could be modified to include the chunk Blob as well. Furthermore, internal code that handles onUploadChunk calls could be modified to support a promissory return type that, when resolved, includes the new chunk Blob. I don't think this will be a terribly difficult modification to make. \nThat said, version 6.0 is already in progress, and that is quite an ambitious release already based on the cases still yet to be completed. So earliest version would be sometime post 6.0.\n. duplicate of #1525.\n. Duplicate of #1524. I'll close that one if favor of this, since your description is more detailed.\n. Cool. Thanks much for your answer on SO and for opening this issue. This approach looks great and seems like it will solve a long-standing issue with image quality of the thumbnail feature and the image scaling feature.\n. if this type of message appears to be needed once I've investigated further, I'll look into an appropriate solution. Thanks for bringing this up\n. Usually, a message is not appropriate as Fine Uploader users don't always use the built in UI\n. You can follow this case for progress updates and commits.\n. I'm not sure about integrating this library into the core Fine Uploader code, but perhaps Fine Uploader could be modified to allow this or any other scaling library to be integrated, replacing the internal module. This sort of extreme flexibility is an area where Fine Uploader is lacking a bit. While Fine Uploader has been continually evolved to solve a great number of problems and workflows, extensibility was not a concern. I have been writing up plan for a new uploader library that would follow a vastly different architecture, focusing on extensibility (among other things) and make this sort of integration much easier (ideally). Let me know what you think. Note that this is still very early on in the design phase.\n. I would say that Modern Uploader is not around the corner just yet (since I'm still writing up the design docs). I'll make it a point to look into either documenting or making adjustments to Fine Uploader to allow the image generation code to be swapped out with something else.\nIf you can comment more on the \"hacks\" you've employed to fit the scaling and S3 uploader to your needs, that would be helpful, particularly for future development, such as Modern Uploader.\n. Thank you for sharing this information.\n\nScale images when added to upload queue, not when the upload starts.\n\nThe current behavior is intentional. It would be very easy to crash the browser (due to lack of memory) or freeze the page (due to the scaling effort) if all files are scaled as soon as they are added to the queue. The current approach waits until just before the file is to be uploaded, at which point the scaled Blobs are created, and then thrown away after the upload completes. This means that, by default, only three files have scaled image Blobs consuming memory at any time. Changing this would have potentially devastating consequences for most users. It's not clear to me what the issue is with the current behavior. Can you explain?\n\nSend Base64 encoded scaled image\n\nWhat use do you have for this?\n. > We embed base64 images in HTML to use as a placeholder while the actual, larger image loads.\nAre you talking about the scaling feature or the thumbnail preview generation feature? First I thought you were talking about the latter, but now it seems like you are in fact talking about thumbnails. If you are, the thumbnails used to be generated all at once after they were submitted, and in a sense they still are, but there is code in place to prevent too many from being generated at once due to issues with garbage collection that effected image generation in Chrome. See #1279 for details. \nI'd like to see your Fine Uploader integration code, out of curiosity. Can you send me a link? \n. I'm starting to look into this now as one of the primary features of v5.10.0. Any help or offers to review code or test solutions will be much appreciated.\n. To allow for freedom in choosing a resizing algorithm/library, I expect to create a new option or callback that accepts a function value. This function, if provided, will be called by Fine Uploader, passing an HTMLCanvasElement containing the image, the expected new width and height, and the associated file ID. This is expected to be a promissory function. The promise returned by this function should be fulfilled w/ the resized HTMLCanvasElement once the resize operation is complete (or rejected on error).\nIf a resize callback function is not provided, Fine Uploader will continue to use the internal scaling code. I'm not sure, at the moment, how well limby-resize and pica account for image subsampling in iOS. If they do not properly account for this, that may be an issue for Fine Uploader users, and I may want to also provide a way to easily switch to the internal scaling code (which does handle iOS image subsampling) on-the-fly.\n. Follow progress in #1576.\n. Looking for testers before I release. Please comment in #1576 if interested.\n. @keyeh The primary focus of this issue, and what will be part of 5.10.0, is the ability to easily substitute Fine Uploader's internal image scaling algorithm (for thumbnails and scaled uploads) with any other library of your choice. I now you mentioned some other items on your wish list. Perhaps the most important ones can be opened up as separate feature requests. I noticed a number of +1s under that comment, so if anyone else sees benefit in specific items in your wishlist, please feel free to comment and/or open up a case.\n. @davidtgq Currently, the solution that is a candidate for 5.10.0 (please see the code in #1576) passes a <canvas> with the original image drawn onto it, and a <canvas> to receive the resized image. As long as the resulting image can be placed onto this target <canvas>, you can do whatever you want as far as image processing. While I would have preferred a more pure functional approach (pass in a <canvas> and expect either a <canvas> or Blob as a return value) that would have required more widespread changes to the internal code of Fine Uploader, and the two JS scaling libraries I am aware of offer this same exact API (pass in a source and target <canvas>).\n. This feature is set to be released tomorrow as Fine Uploader 5.10.0.\n. Perhaps a title on a containing element that exists in the template will be sufficient. If not, that attribute can be transferred programmatically to the file input.\n. Moving this to 5.6.0, and I'll start work on this at once.\n. In order to properly address this, I'll need to add a new text option, such as text.fileInputTitle. Here, you will be able to optionally specify a title attribute to be used when Fine Uploader created the <input type=\"file\">. \nYou can't specify this yourself on the file input (easily) since it is removed and re-created whenever files are submitted to the uploader. This is the only way to \"reset\" the file input element. Another option would be to leave the title off of the file input and specify one on the parent element instead (such as the one in the template), but this will not work cross-browser. For example, Firefox defaults to the native hover tooltip when the file input title attribute is omitted. As a result, the text.fileInputTitle option appears to be the best solution.\n. I'm starting work on this feature this week, and once it is completed and verified by someone in this thread, I'll release 5.6.0. \n. This has been completed and is part of build 2 of 5.6.0. Please verify that this solves your issue. If it does, I'll formally release this as part of 5.6.0 next. You can download this pre-release build at http://releases.fineuploader.com/develop/5.6.0-2/fine-uploader-5.6.0-2.zip.\n. Note that I added a text.fileInputTitle option, and the extraButtons option also accepts a fileInputTitle.\n. Yes, this is the expected behavior. I kept the default value as I try to avoid any unnecessary changes in default behavior outside of a major version release.\n. There is no jquery version. Fine Uploader offers an optional thin jquery wrapper around the library, but the wrapper provides no real value (#1310).\n. @deviprsd21 Look good on your end? If so, I'll release 5.6.0 today.\n. This has been released as part of 5.6.0.\n. Can you please list the messages that are not currently replaceable?\n. Thanks for the update. I'll keep this in mind for a future version.\n. This won't have any affect on CSP, since that code path is only executed in IE7.\nPlease have a look at the milestone 6.0 case list. You'll see that j have plans to remove a number of legacy code artifacts. There is also an open case in that milestone to address any CSP violations (wherever possible).\n. CORS/XDR is completely irrelevant here, unless your signature server is on a different domain. If you are seeing an issue where Fine Uploader reports an unexpected response to an upload request, you'll need to provide the complete headers for the request and response payload/headers as well.\n. S3 will redirect to the localBlankPath endpoint you specified of the upload succeeds. If this is not happening, then the upload has not succeeded or this endpoint is not valid. If it is happening, then there is some issue with with specified bucket in the redirect URL. In order to troubleshoot I'll need the relevant request/response info.\n. Yes, this does appear to be a bug, caused by some rigid logic in the S3 form upload handler. Like other S3 code in Fine Uploader, the form upload handler needs to use a shared function that determines the proper bucket given a specific file ID. I'll look into fixing this in 5.5.2. If you could make yourself available to test the fix, that will make this a bit smoother.\n. Great! Today is my last day in the office until March 2nd, so I'll start working on a fix shortly after I return.\n. s3.fine-uploader-5.5.2-1.zip\nPlease see the attached build of Fine Uploader S3 5.5.2-1 with the proposed fix for this issue. Let me know if this works for you (and does not cause any further issues).\n. Thanks for the confirmation. I'll release this fix as part of 5.5.2 on Monday or Tuesday.\n. Fixed in 5.5.2.\n. In order to access the camera in older versions of iOS, you must ensure the underlying <input type=\"file\"> does not include the multiple boolean attribute. To ensure this attribute is not included on the underlying file input, you'll need to set a multiple property of false for each extra button.\n. Your report includes an error in the console, but what it the actual issue here? What specific problem are you seeing here?\nIt's unclear why you can't simply use the itemLimit option, as this should accurately reflect the non-deleted files successfully uploaded in that session. \n. Again, itemLimit does correctly account for deleted files and not count them towards the limit. So, it seems like itemLimit is the proper solution here.\n. I think you're misunderstanding how the itemLimit validation option works. It's quite simple:\n1. itemLimit initialized to 8\n2. User uploads 8 images. Validation prevents any more from being uploaded.\n3. User deletes 2 images. 2 more images may now be uploaded.\nThis will all work as described assuming you are using Fine Uploader's delete file feature.\n. Why not?\n. You're working against the library by deleting an uploaded file without using the built in delete file feature. Keep it simple and work with the library. This is a general suggestion, applicable outside of Fine Uploader. I haven't myself seen any issues with the cancelAll API method. But even if there are in this scenario, it's a scenario that is overly complex and can be replaced by utilizing built-in features that are meant to support the very workflow you have described above. \nIf you run into any issues with itemLimit or the delete file feature, please let me know. Questions regarding proper use should be posted on Stack Overflow under the fine-uploader tag. Thanks!\n. Before initializing Fine Uploader, make a call to your server to determine the proper itemLimit for that use (or provide this value on page load from your server), Then, use this value when constructing a new Fine Uploader instance.\n. In that case, make use of Fine Uploader's initial file list feature to display the previously uploaded files, with thumbnails (if desired). You can delete these files through Fine Uploader's delete files feature, and the itemLimit will be tracked as expected.\n. It sounds like you want Fine Uploader to support your workflow without using built-in support for that workflow, and it's not clear why. Your current approach is at odds with the features already provided by the library to suit your requirements. Of course, you don't have to use these features, but you run the risk of exposing issues associated with what I would describe as an unsupported or edge-case use of the library. I'm sorry I don't have an answer that pleases you here, but the reality is that there is a much better and more standard way to support your requirements through heavily requested features that a good number of users are already utilizing to solve the same exact problems. I would suggest you seriously consider updating your app to make use of these features to make your life easier.\n. Addressing your concerns:\n\nthe level of courtesy that I have received in regards to this issue, is unsatisfactory\n\nI have given this issue a significant amount of attention, responded to your comments promptly, and have provided guidance as to how to properly support your requirements using built-in features. \n\nSupport hasn't even attempted to reproduce the issue\n\nQuoting from a previous comment of mine \"I haven't myself seen any issues with the cancelAll API method\".\n\nyou should have posted this on stackoverflow\n\nI mentioned that any further questions that are not bug reports should be posted on Stack Overflow.\n\nWe are not going to take a look at this even if this is a bug, try some other functionality that seems to work in most cases.\n\nI do not classify what you are seeing as a bug, as your use of the library appears to be non-standard and this is easily remedied by making use of built-in features described above.\n\nI think the approach I am describing here is the most simplistic of all, it requires no tight integration with Fine Uploader and requires no additional server calls to pull any data from the server.\n\nWhile you may see your approach as ideal and simplistic, I see it as overly complex, brittle, and a bit confusing. By making use of features built into the library (which you have already tied your application to) you can likely avoid all of this.\nI'm sorry I wasn't able to resolve this issue to your satisfaction, but I am unfortunately not seeing any issues with this API call, and have recommended a more standard approach for you to follow that may give you better results going forward. It seems like we are going in circles at this point, so I'm going to close this case for now. Please feel free to open up a new issue if you have any bugs to report, or use Stack Overflow for questions regarding use of the library.\n. There isn't much that can be done about the CPU usage here. This is a fundamental problem with the version 4 signing algorithm created by AWS. It requires Fine Uploader to hash each file chunk sent via the multipart upload API. This requires reading each chunk into memory and then calculating a SHA256 hash given the file bytes. For underpowered machines, this will have a noticeable impact on the CPU.\nI'm not seeing the level of non-responsiveness that you've described, and I suspect this is only an issue on slow machines. To prevent the UI thread from being affected by this hash generation, I can explore pushing the hash calculation into a web worker. However, this may not solve the issue you are seeing in IE10/11, since IE does not support passing an ArrayBuffer into a web worker without explicitly copying each byte over the wire.\nYour best bet may involve one of the following workarounds:\n- Don't use version 4 signatures\n- Use a small chunk size (5 MiB) to avoid pegging the CPU for long continuous periods of time\n- Ensure your users are utilizing more performant machines.\nSorry that there isn't a better answer to this. I am quite unhappy with Amazon's v4 signature algorithm myself, but there isn't much that can be done about it. \n. Curious: why are you disabling concurrent chunking in IE?\n. As long as you aren't uploading to any v4-exclusive regions, then there is no need to use v4 signatures. There aren't many v4-exclusive regions at the moment. Frankfurt is one though. Also, concurrent chunking is not a factor here. If you're seeing the issue with one file and concurrent chunking enabled, you'll also see it with multiple in-progress files with concurrent chunking disabled.\nYou can also eliminate the entire cors section of your config. It's not needed unless your delete/signature endpoints reside on a different domain (yours don't).\n. Which headers? It seems a bit odd that you must use XDomainRequest to send a request to a same-origin endpoint. The fact that it is proxied server-side shouldn't effect the request sent by Fine Uploader.\n. I'm not seeing an issue in IE11 or Safari 9 locally. Any idea how this can be reliably reproduced?\n. After looking into the web application that is experiencing this issue, I have determined that this is caused by that app overriding Date.now with another function, specifically Date.now = function() {return new Date()}. So, closing as this is not a Fine Uploader issue.\n. I'd suggest either not using Kaspersky, or contacting Kaspersky support to further troubleshoot this issue. There is nothing Fine Uploader can do to prevent another application from intercepting the HTTP requests it sends.\n. The issue is, without a doubt, caused by Kaspersky. I've seen this more times than I can count. As you mentioned yourself, this issue goes away when Kaspersky is closed. \n. Looks like an issue with your server response. Please re-open and fill out all required fields in the template if you think this is a bug in Fine Uploader. Thanks!\n. I'm sorry, but without seeing the actual response, there's not much more help I can offer. In the future, please reserve the issue tracker for Fine Uploader bug and feature requests. Stack Overflow is to be used for support questions (under the fine-uploader tag). Also, please do not ignore the template that appears when you open a new issue.\n. This is already possible by examining the proposed files and either returning true/false or a Promise inside of an onValidate, onValidateBatch, or onSubmit callback. All of this and more related to file validation is detailed at http://docs.fineuploader.com/branch/master/features/validation.html. \n. Please show the request headers for a chunked request, according to your browser's dev tools.\n. According to the request headers you just posted, the parameters are being sent to your server. The issue appears to be with your server-side code. The PHP example at https://github.com/FineUploader/php-traditional-server handles chunked and non-chunked requests correctly. You might either want to pull that down using composer, or model your code according to that example.\n. Nothing Fine Uploader can do to fix that. The browser makes that determination.. I'm sorry, but Fine Uploader does not store blobs in memory any longer than absolutely necessary. In fact, I was extra careful about this when writing the scaling feature as well. If you can point to a specific bug in the code where I am caching blobs by accident, I'll be happy to re-open and fix, but I would be very surprised to find that this is happening. \nKeep in mind that blobs that reference files selected or dropped by the user do not take up any memory, they are just pointers to bytes on a file system. The only time blobs consume memory is when they are created, such as with the scaling feature.\n. Can you please open up a new issue with your above finding? Fine Uploader really should call revokeObjectURL once the scaled Blob is created. I'm not sure if this can be done for thumbnails as well, but it merits investigation.\n. This indicates that chunking is not supported in whatever browser you are using. \n. Sounds like a bug in the slice method of your browser then. I'll keep this open for others to discover, but there's not much else I can do as far as I can tell.\n. Thanks for the report. This is likely caused by Fine Uploader's failure to check the status of the response before attempting to parse the response. In this case, it is likely hitting a request for one chunk in a batch of concurrent file chunks that has been cancelled internally as a result of another chunk failure. The status is most likely 0, which indicates cancellation and therefore this request will not have a response. The issue appears to be benign. I'll look into including a patch in a future release.\n. Thanks for this. I'll look into addressing this in a future release.\n. You can use built-in validation using some of the built-in validation options, or even write your own custom validation by registering an onValidate or onValidateBatch handler. See the validation feature page for details.\n. As it stands, your configuration options are not valid (minHeight and maxHeight validations options are supposed to be part of an image configuration object). In fact, the JavaScript posted in your code block above is not valid either (extra closing bracket). This is likely the source of your issue as I am not able to reproduce myself given your steps. Please see the validation option on the documentation site for information on how to properly structure this option.\n. I wasn't able to reproduce using your code, or even the modified code with the correct options set. The validation logic worked as expected. What version of Fine Uploader are you using?\n. Given the fact that all browsers that would benefit from this feature are no longer supported by Microsoft, I doubt this will make it into any future release as there are far more pressing issues to be dealt with. That said, I'm going to close this accordingly, but I do thank you for the request.\n. Duplicate of #1422. Please follow that case for updates.\n. Please see https://github.com/FineUploader/fine-uploader/issues/1422#issuecomment-212513830.\n. Please show your HTML template and the rest of your JavaScript code, along with any log messages printed to your browser's dev tools console. As it stands, with what you have provided, this is not reproducible, so there is something specific about your environment or code that is causing this issue to occur.\n. Thank you for the detailed explanation!\n. Looks like the whitespace JSCS failures are not false positives. After I look get a chance to look closer at your code and proposal, I'll fix the whitespace issues.\n. This will also need some comprehensive unit tests. If you can add those, that will speed up this process. Otherwise, after reviewing, I'll write tests when time allows.\n. Cool, thanks for doing that. Your pull request introduces a lot of changes, which will take me a bit of time to work through. There are a dizzying number of workflows to consider, some of which are sadly not completely covered by unit tests.\nYour changes point out a deficiency in Fine Uploader. It's a solid library, but not terribly extensible. And adding more hooks for a particular feature set requires making changes to the entire library. This adds more risk to the changes, and makes it harder for those outside of the project (like yourself) to contribute. I'm very slowly working on the next version of Fine Uploader, which I'm currently calling \"Modern Uploader\". The goal is to address this issue of extensibility, among other things.\n. > I added a fourth parameter to the onSigningRequestComplete callback which is to be used as a return parameter\nWhy not just check the return value from the callback handler?\nI'm going to go through a first pass review now. I'll need to take some time later to look at the changes a bit more closely, write some tests, and take some time manually testing these changes. Documentation will also need to be updated. Please follow this case for progress & comments.\n. This sounds eerily similar to the feature requested in #1406. That case requires an STS token to be passed to S3 along with each request. This STS token may change/expire at any time, and the associated access key may also change as a result. Thoughts @jfwblog?\n. I can see eliminating the 4th param you added and instead checking for a credentials property in the response. This would allow the server to include a credentials property w/ a new STS token and/or a new access key, each as sub-properties of credentials. I don't see the client making these types of changes to the credentials when the request is signed server-side.\nI also do not think setCredentials should be called at all, to be honest. As you noted, there are potential race conditions that can surface, especially with concurrent chunking enabled. Instead, I would expect Fine Uploader to use the credentials provided during uploader initialization for every request unless the server returns a new set of credentials for a specific request. If a new set of credentials is to be used for the next 10 requests, then the signature server must return these credentials as part of the signature response for each request, otherwise Fine Uploader will use the initial set of credentials. \nYour PR has made me think about this quite a bit, and the need to allow for a constantly changing STS token and access key is something we are looking at for our apps that use Fine Uploader internally as well. I think the issue that will ultimately dictate changes to Fine Uploader is #1406, as this describes an enterprise workflow that is becoming increasingly common as it is seen as a \"best practice\". That is, associating an EC2 server with an IAM instance profile that contains a set of temporary credentials for signing the request. Fine Uploader could very well be sending requests to a cluster of EC2 instances, each with a different set of temporary credentials. This means each signature request for a single file could require different set credentials for each chunk/request. It seems important for Fine Uploader to support this workflow.\nI'm going to keep this PR open, but ultimately I see myself making changes that mirror the specific uses outlined in #1406 once I have taken some time to research this a bit more thoroughly. \n. I'm fairly sure that this second parameter was mean to be for internal use only. \n. As long as you have chunking enabled, and you are using a browser that supports chunking (anything other than IE9 and older), then Fine Uploader will retry the upload starting with the last failed chunk. In the case of a finalization error, it will only attempt to re-finalize. This behavior is standard across Fine Uploader S3, Azure, and the traditional endpoint uploader, and reflects one of the big advantages of chunked file uploading. If you are seeing an issue with this expected behavior, I'd be happy to re-open.\n. > So you mean that Fine Uploader will retry the finalize call one time and if that fails I'll just have to manually retry the upload?\nNo, every retry attempt will repeat the same logic, whether it is manual or automatic. The only instances where the upload will restart from byte 0 is if you cancel the file, or if Fine Uploader determines that there is no way for the upload to ever succeed.\n. What do you mean by \"store the uploader instance\"?\n. Looks good to me!\n. Glad to hear it. If anything else comes up, you know where to find me! Also, you can follow @FineUploader on Twitter for product updates and new releases.\n. Everything seems to be working fine for me with a 30MB file with that exact name. Most likely there is either an issue server-side on your end, or perhaps your page is missing a <meta charset=\"utf-8\"> tag. I was using the 1.1.0 version of the Fine Uploader S3 PHP server code on my end (which is currently the latest). \n. Since you have a meta tag, then the issue does seem to be server-side. I was able to upload a file using the exact name in your issue report without issue (using v4 signature support). Note that I am using Fine Uploader 5.6.0, so perhaps there is an unreported bug in the version you are using? Upgrading may shed some more light on this.\n. I guess I'm not certain if the issue is the data sent by Fine Uploader, or the signature generated by the server. If you are still unable to upload the file after upgrading, then there is most definitely something specific to your environment that is resulting in the error. The tough part may be uncovering that.\n. The escape sequence generated by Fien Uploader that you have posted for that filename is correct. The canonical URI is not URL encoded, it is escaped. The process required to properly handle v4 signatures is described more in #1336, but this logic appears to be required based on discussions at the end of that issue, and is handled correctly by the example PHP, Java, and Node.JS signature servers maintained in this organization. So it seems the issue is indeed with your server code. \nProperly encoding requests to satisfy AWS is a continual source of headaches, as you can see.\n. Did this involve changing internal Fine Uploader code? If so, we'll want to find a better solution as this will make upgrading a problem for you.\n. Yes, that is my understanding as well. I was unaware of a better way to address the AWS-specific requirements that came out while working on #1336. I believe AWS' JS SDK made use of escape as well, but perhaps there is a better solution. I'll keep this case open to remind myself to look into this again.\n. If you use Fine Uploader's form support feature, all form fields will be sent with each file. If you have questions during implementation, please post on Stack Overflow under the fine-uploader tag. Be sure to include all of your code and information about the specific issue you are having.\n. Thanks for the update! Can you share your Fine Uploader S3 config/options code? Have you run into any specific issues?\n. Great, then it does seem to work as I expected. This seems on track for official support in 5.8 w/ accompanying doc updates. Thanks again for your information!\n. @SohKai Thanks for the update! Anything special required on your end to get this working? I'm asking in terms of Fine Uploader config and AWS config, other than turning on transfer acceleration in the associated bucket(s)?\n. If anyone is up for updating the S3 features page in the documentation to describe S3 Transfer Acceleration support, I'd be happy to review & merge. This PR can be based off of master since it's only a doc update.\n. Hmm, what you're describing here is a very serious issue that likely should affect a large number of users. But this is the first such report I've seen. I would be surprised if the issue was entirely with Fine Uploader and not something specific to your environment or more likely an issue with your server response. Perhaps some other JavaScript on the page is conflicting with Fine Uploader, or your server is returning an especially odd response that is causing an unexpected issue with response parsing. I'm not seeing this issue myself locally, so if you'd like me to look closer to rule out any specific issue with Fine Uploader, providing me with a link to a site where you are able to reproduce this will be most helpful. It will also help if you either provide a sourcemap for any minified code, or perhaps just switch all of your minified code for non-minified versions for easier debugging.\n. BTW I see you're from UW. Fine Uploader is developed and maintained right here in Madison!\n. I did just attempt to reproduce in the latest version of Chrome (it's my primary development browser). Can you direct me to one of your applications where you have been able to reproduce this? If you are apprehensive about posting a link in public, I'd be happy to provide you with an email address or a twitter account to receive this link. This will definitely be the easiest way to get to the bottom of this issue.\n. I'm afraid I don't have any way to run an ASP.NET project.\n. I ran a simple PHP server using your included PHP file, navigated to the index page, dropped a 30 MB  ZIP file, and the upload completed successfully in the latest version of Chrome. The issue you are seeing is almost definitely a result of something specific in your particular environment. With this being fairly clear and me being unfortunately unable to reproduce your error, I'm going to close this case, but would certainly consider re-opening if you are able to provide a sure way to reproduce your issue.\n. The only errors I'm seeing are 404s for the success/loading/failure images. Everything is functioning as expected.\n. Nice catch and thanks for the PR! I'll look at this a bit closer tomorrow, and if everything checks out, I'll release Fine Uploader 5.7.1 with the fix.\n. This seems unrelated to your pull request, am I correct?\n. That specific issue can be solved with Fine Uploader's clockDrift feature, introduced in 5.5. I'll post more details as an answer to your question on SO shortly.\n. You are mistaken - all that needs to be returned from a chunking success endpoint is a status code.\n. All that's left ATM is docs and the actual release. In addition to allowing Fine Uploader's qq object to be exported via AMD or CommonJS (or global var if neither are available), I also created a \"lib\" directory as part of the build output that allows all project files to be much more elegantly imported. For example:\nNote: This already assumes you are pulling in Fine Uploader via npm.\njavascript\n// use Fine Uploader core (non-ui) for traditional endpoints\nvar qq = require('fine-uploader')\nvar uploader = new qq.FineUploaderBasic({...})\n``` javascript\n// use Fine Uploader UI for traditional endpoints\nvar qq = require('fine-uploader')\n// You may replace \"rows\" w/ \"legacy\" or \"gallery\" depending on your needs\n// This assumes you have a loader to handle importing css files, such as Webpack css-loader\nrequire ('fine-uploader/lib/rows.css')\nvar uploader = new qq.FineUploader({...})\n```\njavascript\n// use Fine Uploader core (non-ui) for s3 endpoints\nvar qq = require('fine-uploader/lib/s3')\nvar uploader = new qq.s3.FineUploaderBasic({...})\n``` javascript\n// use Fine Uploader UI for S3 endpoints\nvar qq = require('fine-uploader/lib/s3')\n// You may replace \"rows\" w/ \"legacy\" or \"gallery\" depending on your needs\n// This assumes you have a loader to handle importing css files, such as Webpack css-loader\nrequire ('fine-uploader/lib/rows.css')\nvar uploader = new qq.s3.FineUploader({...})\n```\n...etc\n. Beta published to fine-uploader@5.8.0-beta1.\n. CLA Assistant seems to be working out well for now. \n. First, please don't delete all of the template that appears when you open an issue. I expect that to be followed. Second, I have no plans to integrate any libraries for any reason directly into Fine Uploader. It is large enough as it is, but you are of course free to integrate what vet you like, and this should all be possible without changing any source.\n. Updated and simplified FineUploader/video-frame-uploader as part of this as well.\n. Version 5.9.0 has been released, and Fine Uploader is now MIT licensed! The article is currently in-progress and I hope to have that published next week.\n. I just published an article on Medium. I'll link to it on the Fine Uploader blog as well.\n. I updated your question to fix the formatting and syntax issues. Please let me know if anything is missing.\n. The issue appears to be in your code. Fine Uploader is behaving as expected. You are naming the 2nd parameter to your onDeleteComplete callback xhr, but then you are attempting to reference a variable in the body of this method named xhrOrXdr. This appears to be a typo in your code. Either rename the callback parameter xhrOrXdr, or change the referenced variable in the function body to xhr. In other words, your callback should look like this instead:\njavascript\n            onDeleteComplete: function(id, xhr, isError) {\n                if (isError) {\n                    console.log(\"Error in delete!!\");\n                    if (typeof xhr != 'undefined' && xhr != null) {\n                        console.log(\"resp text=\" + xhr.responseText);\n                        var t = JSON.parse(xhr.responseText);\n                        console.log(t['errorMessage']);\n                    }\n                }\n            }\n. No worries. Glad I could help you resolve this.\n. Wow, that's a lot of typos. Thanks for doing this! Can you update your branch based on my suggestion? After that, I'll merge this into develop.\n. Great, thanks for your help! This will likely be part of v5.10.\n. I have this mostly working at this point. Even though I have some more tasks to complete before calling this \"done\", it's certainly ready for someone to attempt to test out their favorite resize library alongside Fine Uploader. If anyone is interested in being a tester for this feature, please let me know. Of course, you will also be able to influence the feature before it is completed.\n. Core code on this feature is now complete. However, I'm unable to come up with a way to fix large image subsampling in iOS and still make use of one of the suggested third-party image resize libraries. I'm not sure this is even possible, or at least something that can be accomplished without integrating this complex logic into one of the third-party resize libraries. However, Fine Uploader will be able to properly orient all images before passing them off to a third-party resizer. On iOS, the internal resize/scaling code should be used instead of a third-party image resize plug-in. Documentation will include a way to easily implement this behavior.\n. Should be ready to test now. I've updated some docs, but not all (see the checkboxes in the pull request description for more details). Assuming you are using pica (and not supporting iOS), want to use pica both for resizing displayed thumbnails and for resizing images to be uploaded, your Fine Uploader initialization code will look like this:\njavascript\nvar uploader = new qq.FineUploader({\n    element: document.getElementById(\"uploader\"),\n    request: {\n        endpoint: \"/upload/endpoint\"\n    },\n    thumbnails: {\n        customResizer: function(resizeInfo) {\n           return new Promise(function(resolve, reject) {\n                pica.resizeCanvas(resizeInfo.sourceCanvas, resizeInfo.targetCanvas, {}, resolve)\n           })\n        },\n        placeholders: {\n            waitingPath: \"/client/placeholders/waiting-generic.png\",\n            notAvailablePath: \"/client/placeholders/not_available-generic.png\"\n        }\n    },\n    scaling: {\n        customResizer: function(resizeInfo) {\n           return new Promise(function(resolve, reject) {\n                pica.resizeCanvas(resizeInfo.sourceCanvas, resizeInfo.targetCanvas, {}, resolve)\n           })\n        },\n        sizes: [...]\n    }\n})\nThe scaling and thumbnails option documentation have been updated at http://docs.fineuploader.com/branch/feature_1525-better-scaling/.\n. @keyeh Have you had a chance to verify on your end? I'm hoping to finish updating the docs and get this out the door within a week.\n. This is ready to be released, and I plan on pushing out Fine Uploader 5.10.0 tomorrow unless I hear back from anyone regarding issue or requested changes.\n. This is a known limitation, and it is only an issue in IE10+ since we must serialize the form ourselves to take full advantage of the File API. The form support module that does this should be modified to account for the fact that the form may contain multiple fields with the same name, allowing it to behave more like a natural form submit.\n. Can you explain how you worked around this? Did you just rename your form\nfields such that there are no duplicates?\nOn May 31, 2016 at 8:10:16 AM, Jason M (notifications@github.com) wrote:\n\nI modified my server logic when handling the uploads so I can support the\narray params in the POST request. This will do until a proper fix is in\nplace in fineuploader. Thanks!\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1577#issuecomment-222683104,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AAkNoJCG7IEUcgH3S3fftQP_uPWtnhYGks5qHDM4gaJpZM4IqCJV\n.\n. > It's not just an issue in IE10 though. I've been using Firefox for my development and it still serializes the arrays improperly.\n\nThese really aren't arrays though - they are just individual form fields with matching name attributes. And yes, the issue you are seeing occurs with any browsers that support the File API (IE10+, Chrome, Firefox, Safari, Edge, iOS browsers, Opera).\n. > Fineuploader needs to not assume all form inputs have unique names.\nAgreed. This was my suggestion a bit earlier. Unfortunately, this will not be a trivial change. At the moment, I am a bit busy working on #1576. Once that is done, I can look into this, but that may be a week or two away. A pull request will likely speed things up. If you are interested, I can outline all of the changes needed to complete this.\n. Looking at this closer, I think IE9 and older may be affected as well, since Fine Uploader must reconstruct the form in an iframe in older browser to give the effect of an \"ajax\" upload.\nThe simplest way to fix this without ripping the entire library apart and making massive changes would be to add explicit support for arrays as parameter values. This would require code that constructs a FormData object (File API browsers) or a <form> in an iframe (older browsers) to append duplicate items/form fields when a parameter with an array is encountered. The form-support module would have to ensure that duplicate form fields are serialized this way.\nSo, let's say we have this user-provided form:\nhtml\n<form>\n   <label>Phone number 1\n      <input name='phone[]'>\n   </label>\n   <label>Phone number 2\n      <input name='phone[]'>\n   </label>\n   <label>Address\n      <input name='address'>\n   </label>\n</form>\nThe form-support module would need to generate the following params object:\njavascript\n{\n   'phone[]': ['444-444-4444', '555-555-5555'],\n   address: '1313 Mockingbird Ln'\n}\nThe array type value for 'phone' would be a clue to the code that parses the params object and generates either a <form> in an iframe, or a FormData object. In each case, duplicate fields must be generated from this model. For example, a fictional method that generates a FormData object for File API browsers would see the above params object and do something like this:\njavascript\nfunction makeFormData(params) {\n   var formData = new FormData();\n   Object.keys(params).forEach(function(paramName) {\n      var paramVal = params[paramName];\n      if (Array.isArray(paramVal)) {\n         paramVal.forEach(function(arrayVal) {\n            formData.append(paramName, arrayVal);\n         });\n      }\n      else {\n         formData.append(paramName, paramVal);\n      }\n   });\n}\nThe above is over simplified and may not be appropriately cross-browser safe, but it illustrates the goal. The code that transforms a params object into a form or a FormData object can be found in the util module.\n. jQuery is not involved here. Also, the order of the fields should not matter.. >All browser preserve the post orders from forever\nIn reality, if your server-side code depends on fields to arrive in a specific order, that seems like a bad assumption, and you may very well run into issues with this elsewhere as I'm not aware of any standard/specification that declares the order of form fields in a form submit request to be relevant.\nI didn't really understand the rest of your comment, but when (or if) I get back to this case, I'll be sure to update the code such that the data is sent to the server in a format that mirrors a native form submit.\n. Thanks for the information. I'm not sure when I'll get to this (it could be a long while). If you'd like to take a crack at fixing this, I'd be happy to help out wherever possible. It may be best to ignore non-File API browsers (IE9 and older) for this fix, as I plan on removing support for all browsers older then IE11 in Fine Uploader 6.0 anyway.. I presume by \"download\" you mean the download page on FineUploader.com, correct? Which option have you selected under \"server type\"?\n. Yes, if you'd like to download a pre-built version, you must either use npm or the download page. I'll close this, but feel free to re-open if the same issue persists.\n. Please don't ignore or delete the issue template. As it stands, without the details required by that template, it is not possible for me to even determine what you are referring to, since Fine Uploader already orients images correctly. \nIf you are attempting to report a bug or ask for a new feature, please open up a new issue, follow the template, and provide as much detail as possible. For a \"how do I do this?\" type of question, post on Stack Overflow under the fine-uploader tag.\n. I've briefly started on this. There is a new repo - FineUploader/docs.fineuploader.com - that is currently holding some recent master branch documentation (for testing). The repo is mapped to docs-test.fineuploader.com. \nI've updated the issue description with tasks that need to happen before this can be considered \"done\".\n. I plan to officially move downloadable artifacts (zip files) to GitHub releases as part of #1569, but this will not include any automation in terms of uploading the zip files to GitHub as part of the build process. I'm not sure this is completely necessary as I'd rather type changelog information into GitHub releases manually anyway, and uploading the zips is as simple as dropping them into the releases window. So #1569 will complete this case.\n. There is a bug somewhere in the code (either yours or Fine Uploader's), but the issue is very specific to your setup. In other words, v4 signatures are certainly not broken for everyone. I suspect the fact that you have a key function is important to locating the source of this bug. Perhaps if you remove it, everything works as expected. That may be the path to follow in order to determine exactly what the bug is here, or if one exists.\n. Then the next step is to determine exactly what is causing the issue in your situation, that is, that unique factor in your environment, code, or setup. Once we know that, it will be possible to address the issue.\n. Closing this due to lack of activity for an extended period of time. I'd be happy to consider reopening if more information is provided.\n. How would they be different, other then a couple less options and no template?\n. The drawThumbnail method documentation explains parameters that can be passed, and the expected outcome. For example, if you would like to generate a thumbnail onto an <img> tag for a file at ID 0, and want the thumbnail to be no more than 500 pixels tall and 500 pixels wide: your code would look like this:\njavascript\nuploader.drawThumbnail(0, emptyImgElement, 500);\nIf you need to know exactly when the thumbnail has been drawn on the <img> you provided, drawThumbnail returns a \"thenable\" value, which can also be called a Promise (though Fine Uploader's promise implementation is unfortunately non-standard, this should be sufficient for your use-case).\nThese types of questions belong on Stack Overflow under the fine-uploader tag, which is why I include a template when you create an issue (to keep issues and feature requests here - which you deleted). Please include any further support questions on Stack Overflow, and be sure to understand the rules and expectations of posting questions on Stack Overflow before doing so.\n. Your support request for generating thumbnails using the API was completely appropriate for Stack Overflow, as long as you include appropriate details and code that shows your attempt to solve the issue. A request to \"add more demos\" isn't appropriate anywhere. This is an free open source project and cannot continue to survive with a single person's efforts. If you would like to see more demos, you are welcome to contribute more demos, or ask how you can contribute more demos if that is not clear (feature request or issue: \"how can I contribute a demo?\"), or ask specific support questions (on SO) that will lead you to develop a custom integration that will lead to a demoable block of code, which you can then contribute for others in the community to benefit from.\nAs you can see, based on my activity here and on SO, I'm more than happy to respond to questions and requests at any time, even on weekends, but I expect to see well written questions/requests along with some effort from those making the request. Apps that make use of Fine Uploader's API sans the templating are doing so to build a very custom upload experience. It's quite unusual to find yourself in a place where Fine Uploader UI is not customizable enough for your use case. Short of demonstrating and documenting the API (which is already covered in a number of places), it's not clear what that sort of demo would look like. But if there is a clearly useful \"core mode\" demo that could be contributed, it should come from users of the library based on needs of their project. \n. Understood, and no problem. But this project really does need the support of the community. While I'm happy to continue to maintain and develop critical and complex features, I have a full-time job and other endeavors on the side (such as maintenance of other libraries, a book, etc). \nSo, let's say you want to see a specific demo added to FineUploader.com. If you are unable to code that up yourself, the next best thing would be to open up a feature request here in the issue tracker, and explain, in copious detail, exactly what you are hoping to demonstrate and why you think this may be useful to other Fine Uploader users. If you have code to show, such as with an incomplete demo/integration, then you also have the option of posting on Stack Overflow. In that case, an answer would update and complete your code, based on your question. In either case, whatever code you have so far would likely be helpful as well.\n. A few things that will require me to close this PR:\n1. All changes must be against develop.\n2. A detailed description of the changes and the reason for these changes is required as well. For example, why is this feature needed, and please explain the logic used to implement it.\n3. Any new features or bug fixes must include new unit tests, or a really good reason why unit tests are not feasible. \nThanks!\n. Thanks for creating this against develop, for your work, and your time.\n\nThing is, we need to upload the thumbnails in priority\n\nCan you expand upon this a bit? What determines \"priority\" here?\n\nbecause of the browser limitation\n\nWhich limitation are you referring to, and why is this an issue in your app?\nIt would be helpful if you show your Fine Uploader integration code so it is more obvious how you are using these new API methods.\n. I'm pretty sure I have a good understanding of your workflow now. You are using a single Fine Uploader instance that handles uploads to S3 and a traditional endpoint (all.fine-uploader.js). Is this correct? Or are you using two instances: 1 S3 and 1 traditional? Let's get that cleared up before I go further.\n. In that case, I'm not seeing a need for your pull request. \nIn the traditional uploader instance, it seems you can simply set the autoUpload option to false. This will allow the queue to build up as files are added, but no files will be uploaded until you call the uploadStoredFiles API method.\nThe S3 uploader can use the default autoUpload option, which is true - allowing files to be uploaded as they are added (or queued if no connections are free). Once the onAllComplete callback is hit on the S3 uploader, you can then start the traditional uploader by calling uploadStoredFiles.\n. I see. That makes sense, and I now see the need for this. But your proposed solution doesn't seem to solve this problem. The internal _uploadFile method is called for each file as soon as it is submitted if autoUpload is true. If autoUpload is false, as soon as uploadStoredFiles is called, then all files are  sent to _uploadFile. In other words, if you have submitted 50 files and at least one is currently being uploaded _uploadFile has likely already been called for all of the submitted files. \nIf you want to prevent any further queued files from being uploaded, you'll need to instead assert some control over the logic in the start method of the upload-handler-controller module. And to allow the controller to continue to loop through the queued files later and attempt to send them, you'll need to call start again, passing the ID of the file that you \"paused\" on. This may be tricky to implement without a good understanding of this module, especially since other in-progress files will attempt to call start for the next file once the upload completes. This is why unit tests for these features are important.\n. Have you tested (manually or otherwise) your recent changes? Just looking at the code, I don't think this will work at all. You're calling uploadStoredFiles to resume the paused uploads, but this will have no effect unless you have added more files after the last \"pause\". Instead, it seems like you should trigger the appropriate method in the upload handler controller to prompt it to begin processing the _waiting queue again.\n. I added a comment. Before we can move forward, some unit tests that exercise this new behavior are needed. Any changes to the internal upload queuing code make me nervous since the introduction of concurrent chunking, which made all of the logic in there much more complex.\n. I will take a peek ASAP. Thanks for the reminder.\n. Tests are passing and the code looks fine at first glance. Can you update your branch from develop next? Then I'll do some manual testing. If that all checks out, docs are next and then it can be merged into develop.\n. Is there anything left to do here? If not, then I'll start manual testing. You can begin with documentation updates if you'd like. Feel free to ask if direction is needed.\n. Sorry just a couple more questions for you before I test further:\n1. Are you using these exact changes in production yet?\n2. Have you had the opportunity to test this and existing related features (chunking, concurrent chunking, etc) in multiple browsers?\n. Thanks for the update, and apologies for the delayed response. I'll run some manual tests today. Please let me know once you have gone live with this.\n. After some manual testing, existing functionality appears to work as it did before, though I still would like to run a few more tests. However, I am seeing some issues with the new pause/resume queue feature. The underlying cause is duplicate entires for a paused file ID in the upload handler controller's _waiting array. I can reproduce it fairly easily a couple different ways.\nOne way to reproduce involves turning on the \"concurrent chunking\" feature:\n1. Ensure chunking.enabled is true. \n2. Ensure chunking.concurrent.enabled is true.\n3. Drop 3 or more files (dropping more files seems to make the issue easier to reproduce.\n4. Pause the queue before the first file completes.\n5. After the first file completes, resume the queue.\n6. Pause the queue before the second file completes.\n7. After the second file completes, resume the queue.\nRepeating the last two steps for each file will eventually result in a scenario where the queued files cannot be uploaded (they are \"stuck\"). In some cases, calling resume multiple times may \"fix\" the issue, other times not. After setting breakpoints, the _waiting array inside upload.handler.controller.js has duplicate entries for the latest queued file.\nThis can also be reproduced without concurrent chunking:\n1. Assuming the maxConnections option is set to 3, drop 6 files.\n2. Pause the queue before any of the first 3 files completes.\n3. Resume the queue once one of the first 3 files completes.\nRepeat the pause/resume steps above until the files become \"stuck\".\n. Looks like that specific issue is fixed, but I'm seeing another as I test scaled image uploading. With the feature turned on, if you select a bunch of photos, then pause the queue after the first few have upload, a call to resumeQueue doesn't resume the remaining files.\n. I suspect this will require a non trivial amount of time to track down and fix, which was my concern from the start. I'm not sure when I will be able to take a closer look. Unfortunately, I have a number of other tasks on this project that take priority.\n. I'm lacking the time to even respond to support/issue requests as of late, so I don't see this progressing with my help anytime soon.. Thanks for the report! Yes, that does seem to be a verified bug. If you'd like to see a fix in a near-future release, pull requests w/ unit tests are welcome. Otherwise, I will look into this further myself if it becomes a higher-priority issue.\n. I assume you are talking about the issue of leading the edit.gif file from the style sheet? For that you need a different loader, as webpack has suggested. Have you tried an appropriate loader for the image file?\n. I wasn't able to reproduce myself. If you are still having issues after using an appropriate loader, please post your support question on Stack Overflow.\n. Another option (though much more work) is to develop a fine-uploader-react library that duplicates the UI side of Fine Uploader as React components. If the components are small and focused, this would allow easy creation of a UI in React and make it easy to customize and create your own UI as well without building it from scratch. Of course, top-level wrapper components for S3, Azure, and Traditional endpoint builds will be needed too. It may be prudent to develop this in a dedicated repo and update fine-uploader to include builds that exclude any code that is part of \"Fine Uploader UI\".\nThis route may provide a useful and very popular upload option for the React community.\n. Any changes that need to be made to fine-uploader (likely small ones) can be covered by individual cases, to be opened as the need becomes clear. The React \"wrapper\" will be developed and planned in a separate repo: https://github.com/FineUploader/react-fine-uploader.\n. Well written feature request, but one thing to keep in mind when sending files: you have two options regarding the payload. One option is to include the entire chunk as the payload. In that case, any parameters must be attached to the request uri (url encoded). The other option is to send a multipart encoded request that includes the file bytes in one part, and any other parameters as separate parts in the multipart encoded request. I'm not sure how that fact fits into or changes your feature request. \nAlso, it's not clear how you would expect to associate different params with each chunk, if this data is determined before the file starts uploading, that is one thing and may not be too difficult to implement. But if you expect to set params for eac part on the fly, that seems like it would be quite challenging to manage for the user and to implement, for little obvious benefit. \nPerhaps you can address all of this with some more details, a set of sample request payloads, and an explanation of how this would work in terms of the API.\n. Does this fundamentally change the way data is sent with each chunk upload? Will a user upgrading to the version of Fine Uploader with your changes have to make any updates to their server code?\n. 5.10 has already been released. I'm not sure about this change yet. Unless it has obvious benefit to a large number of users, it's unlikely to make it into a near future release. As you can see from the issue tracker, there are a lot of feature requests still open. I generally prioritize the ones that have are most appealing to the user base as a whole. Features that are specific to an uncommon workflow or set of requirements are usually passed over in favor of more popular features. Also, the library is arguably bigger than it should be already, and I'm hesitant to add features that will make the library larger or more complex.\nMy time is limited, and each new feature or change will eventually result in more support requests and maintenance needs. Even though all new features must include updates to documentation and unit tests, this is still the case.\nMy time is currently gravitating towards a library for Fine Uploader that will make it much easier and more elegant to integrate into a react app.\n. Please do submit a pull request so we can discuss further. I will likely be able to spot issues with your code in the context of the library and its users. Also, I have a hard requirement that all new features must include documentation updates to properly explain to new users how to make use of the new feature, as well as unit tests. I don't promise that any feature will make it into the library quickly, even if it is scheduled for a near future release. I like to take time to think over all changes to the library. I find this helps to keep it stable and prevent breaking changes later.\n. Also, due to the complexity of the library, I would consider a change of about 100 lines to be a big one. Anything you can do to simplify and reduce changes will be helpful. This is often where my insight into the code base comes in handy though.\n. I'll be happy to assist any way I can during review of the PR.\n. @LusciousPear Check out #1597. It needs unit test work, and I have yet to review the changes.\n. Thanks for the reminder. I've added an alert to my TODO list so this doesn't fall off my radar again. However, it may be at least a week before I can look at this closely. I'll see if I can fit it in sooner.. Thanks for the reminder. I've added an alert to my TODO list so this doesn't fall off my radar again. However, it may be at least a week before I can look at this closely. I'll see if I can fit it in sooner.. @manvesh Check out #1597. It needs unit test work, and I have yet to review the changes.\n. covered by #1607 \n. Fine Uploader appears to be working as expected. There are a couple issues with your code, but the main one is due to a misunderstanding of how the scaleImage API method works. As you can see in the documentation, scaleImage returns a Promise. When that Promise is resolved, the scaled image, converted to a Blob, is passed to your resolved handler. In your onUpload callback handler, you're ignoring the return value, which means the scaled Blob is never used. \nIf you want Fine Uploader to automatically generate and upload scaled versions of files when they are submitted, see the scaling option. Otherwise, you can use scaleImage to create a scaled version of any file already submitted to Fine Uploader, and then feed that Blob back into Fine Uploader via the addFiles method (or do anything else you please with this scaled version of a submitted file).\n. ugh, thanks. I'll fix this ASAP\n. Fixed! Thanks again for the alert.\n. Thanks, I'm aware. Currently moving the blog away from WordPress, which sucks in every imaginable way, to medium, which isn't going as well as I'd hoped. back up now. Whoa, this is really cool. I honestly had no idea this API even existed. I really would like to use this in place of Crypto.js wherever possible. In fact, it looks like this is available in all File API browsers, with the exception of IE10 (which has very low market share anyway and has been made redundant w/ IE11).\nAre you able/willing to issue a pull request to cover this? I would certainly be willing to help you iron out any issue with your code and answer questions along the way.\n. This is not surprising (and even expected) since IE11 doesn't support promises.\n. > I have found that nobody ever looks at the fine-uploader section in Stack Overflow, so posting anything there is a waste of time.\nThis is ridiculous and completely untrue. I answer and comment on almost every question on SO. Care to look again?\n. In addition to your ridiculous statement about SO, you are also, for some odd reason, accessing \"private\" properties of a Fine Uploader instance. JavaScript 101: don't touch any properties that start with an underscore.\n\nall properties in the API have no examples of dynamic setting.\n\nI have no idea what you are talking about here. API methods can be called at any time. Options are set once, during initialization.\n\nI need to be able to set it dynamically in javascript based on user choices.\n\nYou can't change interceptSubmit after initialization. If you'd like to see this happen, consider a pull request. You're the first such use case that has come to my attention.\n. It looks like you ran into some issues while implementing this. Do you have plans to continue your work?\n. Sorry for the delay. I still need to spend some time looking into your proposed changes and running some manual regression tests cross-browser. Also, unit tests and documentation will need to be written. There are a number of other issues and tasks in the queue ahead of this one at the moment, and I'll be on vacation for a couple weeks. I'll try to get to this as soon as reasonably possible, but I don't have a date for you at this time.\n. closing as abandoned. Good catch, and very well explained. Thanks so much for taking the time to fix this. Once you sign the CLA, I'll merge this into develop. Since this has been broken for so long, it doesn't seem like a hotfix is necessary and I think this can wait until the next minor release, so develop is an appropriate target.\n. Thanks for catching and fixing this! Could you please take a moment to sign the CLA? It sounds silly for a single character change, but I'd like it if all contributors read and sign this document. I will then cherry-pick this change into master and then also merge into develop so we can get stable and in-progress documentation updated.\n. Thanks again for reporting this. I ended up fixing the issue myself directly on master/develop, so I'll close out this PR.\n. Thanks for reporting this. What are the values of the arguments passed into your onTotalProgress callback when this happens?\n. One possible workaround, until this is fixed, is to simply not show your total progress bar unless current progress is greater than 0.\n. Pull request welcome!\n. I'll take a look at this closer when I'm near a computer, but i would be quite surprised if the total progress bar was not functioning correctly. The CSS classes could not produce the behavior you are claiming. I suspect this may be a misunderstanding on your part regarding how total progress works. To confirm this, please let me know exactly how you are able to reproduce this behavior. Total progress represents the total progress of a current batch of files. Meaning if you only select or drop one file, total progress will only reflect the progress of that single file. If you drop or select two files at once after the first file has completed, total progress will represent the progress of those two new files only. And if you drop another file while a single file is still in progress or queued, total progress reflects the progress of both of those files, etc, etc. For more information regarding the behavior of this feature, please see the total progress section at the end of the progress bars feature page.\n. I'm not sure what you mean by \"embedded graphic arrow\". To my knowledge, this sort of thing has never been included in the library. I'll take a closer look at total progress sometime next week. Thanks for the report!\n. That particular button, if you look at the source, includes some bootstrap css classes that add this icon. I suspect that particular demo used to demonstrate integration with bootstrap. I believe I removed that demo so that I could focus more on the native styles provided by fine uploader after I overhauled the provided style sheets, but I obviously forgot to remove a couple old bootstrap classes from that demo. I'll be sure to remove the leftover bootstrap classes from that button in that specific demo soon.\n. I'm not seeing the issue you are seeing. In fact, removing the \"qq-progress-bar\" CSS class from the total progress bar breaks it completely (which is what I would expect). Everything appears to be functioning as expected. If you are seeing an issue on your end, it may be due to a browser extension or some other scripts/stylesheets causing interference on the page. I think this is a more likely scenario, as this code has not changed for a very long time, and I have not received any other reports of malfunction in this regard.\n. The workflow you are suggesting would likely be a great deal of work to implement for Azure, as it was for S3. Certainly it would be more than just allowing a SAS to be passed in for all operations. Azure requires, to my knowledge, a newly generated SAS for each request, just as S3 needs a request-specific signature. So, Fine Uploader would have to generate this SAS for each request client-side based on a supplied storage account key (and I assume storage account name would be needed as well). But this sort of operation would be unwise client-side without the ability to generate short-lived heavily locked-down access keys. I personally don't use Azure, so I'm not sure if this type of system even exists.\nProviding support for an entirely client-side signing workflow for S3 was challenging, and there is still more to do in terms of STS support for S3 (see #1406 and related cases for details). That said, I don't see anything like this making it onto my personal schedule for development anytime soon. But I would be willing to be available for anyone who is dependent on Azure and knowledgeable in that regard that is interesting in creating a pull request to add alternate signing workflow support to the Azure module.\n. > I believe it is possible to generate a single SAS that allows all blob operations on the container with read, write, create, list, and delete permissions\nHow are you able to prevent the user from using this SAS to delete or list any/all files in the storage account? \nGenerally speaking, I think client-side signing is a bad idea, and something I would probably not consider for any of my applications. That said, if keys are properly provisioned and locked down, it can be reasonable secure, so I'll be interested to know how your method of client-side signing can be secured to prevent unintended operations on the account.\nAlso, please note that it is generally difficult to get a pull request merged into Fine Uploader, especially one that supports an entirely new workflow. Ultimately, this results in more work for me in terms of support and maintenance. This is even more so the case for Azure, since I don't use Azure in any of my projects. So, for changes to be even considered for merge, the changes:\n1. Must be potentially useful for a large portion of users\n2. Must contain a comprehensive set of unit tests.\n3. Must contain comprehensive documentation.\n4. Must not include any breaking changes.\n5. Must minimize impact on the API. If there are additions to the API/options/events, they should be minimal, consistent, and intuitive. \n. Please do open a PR so we can discuss further. Worst case scenario: you have a fork with a second set of eyes on it in case there are any issues you overlooked that may affect your workflow. I do appreciate your time and effort discussing and coding this up, regardless of the outcome.\n. Can you explain how you are creating this SAS URI? I'm curious as to how this is limited in terms of scope and time.\n. @birarda I'd like to understand a bit how you are creating this SAS URI? This change will need to be documented further on the Azure feature page for other users, so I'd like to be sure I understand the best way to make use of your new API methods without sacrificing security.\n. I haven't heard back in a while, so I'm going to close this. But I would be happy to re-open once a discussion regarding best practices in the context of security can be started.\n. What prevents someone from using the sas URI to delete all items in the container?\n. Ah, I see. Thanks for the explanation. I'll look over your changes a bit as soon as I can. Can you provide some unit tests? We can use your explanation in this PR as part of the documentation for this feature.\n. Covered by #1569, which is almost finished and will be released as 5.11.0.\n. This is ultimately needed by react-fine-uploader.\n. Covered by #1569, which is almost finished and will be released as 5.11.0.\n. This is ultimately needed by react-fine-uploader.\n. This is, more or less, solved by version 6.0 (sort of in progress) which eliminates support for all browsers older than IE11. I'm not sure it makes sense to take the time to divide up the legacy and non-legacy bits before then.. Why would you want to explicitly specify an Accept header? Fine Uploader handles the response to this request and already sets the appropriate Accept header. You can't override the Accept header specified by Fine Uploader at the moment, and I don't see allowing that in the future since the only code that should care about the response is internal Fine Uploader response handling code.\n. Ok - it looks like you'll need to use a more appropriate header to relay this information to your server. The Accept header is typically used to ensure the server responds with the appropriate data exchange format. In this case, the appropriate value is \"application/json\".\n. Specifying a custom Accept header should result in both MIME types included on the header sent to the server w/ the request. This seems valid to me, and your server should be able to handle this. Is your server simply not parsing the header value correctly, or is there a syntax error in the header value? I would be surprised if the header value is invalid.\n. @drsect0r Please see my comment above.\n. Just to recap - If Fine Uploader is sending a non-standard header value when it combines its internal choice of \"application/json\" and a custom supplied Accept header, please let me know of the specifics. Otherwise, your server code will need to properly parse this header per RFC-2616. Regarding multiple values in an HTTP header, please see the end of section 4.2 in the same RFC.\n.  \ud83d\udc4f Thanks for catching and fixing this one! \n. I might just end up releasing 5.10.1 with your two fixes next week, just so other have access to these in published releases.\n. 5.10.1 just released.\n. Fixed by manually removing double, triple, and sometimes quadruple-encoded characters in the wordpress doc, and embedding gists with code instead. Along the way I noticed just how far the quality of the wordpress editor has sunk.\n. Please read the support page or the notice at the top of the new issue form before submitting a new issue.\n. This is pretty clearly an issue with your server, and not Fine Uploader.\n. You can choose version 2 or version 4 signatures. Please refer to the documentation for information on using v2 or v4. For AWS SDK issues, please post on Stack Overflow using the appropriate AWS tags.\n. Please read the support page or the notice at the top of the new issue form before submitting a new issue.\n. Please open a new issue (this time without deleting the template). Also provide a compelling use case for this feature request.\n. I was typing up an answer that suggested a lack of CORS headers on the Azure end. This is not an Azure-specific issue, and is documented at http://docs.fineuploader.com/branch/master/features/thumbnails.html#cross-origin-thumbnails.\nThanks for the follow-up. I'm going to close this as the issue has been resolved.\n. Please include code that reproduces whatever issue you are having.\n. What specific issue are you seeing? Is something broken or not functioning correctly? For example: \"The resume feature is not working if x, y, and z\" If so, please provide specific steps needed to reproduce a noticeable issue.\n. Thanks for the explanation. Can you open up a pull request with your fix so we can discuss that further?\n. There is a lot if inheritance between the modules, so all may not be as it seems. I plan to look at this closer soon.\n. The problem here is that the filename is considered, instead of the key name. In some cases, these values may be different. One approach is to simply append the key name onto the generated localStorageId in the S3-specific module. In fact, I wouldn't suggest making any changes outside of s3.xhr.upload.handler.js. The only potentially complex part here is that key determination may be an async operation. Currently, that key is first resolved when the upload begins, but that would have to change here. Also, any change to the local storage ID would potentially invalidate all existing localStorageId records, and that is not acceptable in my opinion. So code would need to be added to distinguish between the current v5.0 localStorageIds and this new version (5.?).\n. You may hide it yourself with JavaScript and CSS. I don't see how an API method is prudent to accomplish this. The simplest way to do this is set the hidden attribute on the element (IE11+) or set display: none; (all browsers), but the appropriate approach may vary depending on your situation.\n. This is covered in the feature detection section on the docs site. See the fileDrop property in this case.\n. You can certainly try to do that via JS. It's conceivable that some browsers may prevent that sort of thing though. Historically that has been an issue.\n. Why is this protocol needed? The resume feature in Fine Uploader has been in place and working well for years.\nIf such a change were to be made, it would have to be non-breaking so exiting users would not have to change any server code. And this would only apply to traditional end points since Azure and S3 have their own protocols.\n. I'd be interested to hear how it is more efficient than the present method in place. Either way, this sort of change would be very low priority at the moment. I'm currently focusing most of my free time developing react-fine-uploader and making any needed related changes to fine-uploader. But I'm always willing to give feedback and direction for anyone willing to follow through with a serious pull request for a reasonable feature.\n. > It's a pity that FineUploader defined it's own specific protocol for chunking and resuming, instead of using TUS. \nThere was no such protocol when I implemented chunking in Fine Uploader. Fine Uploader was first in this regard.\n\nFor TUS many end-points are already implemented and ready to go, whereas for the library-specific FineUploader protocol it's not.\n\nThat's not true. There is library code in PHP, Java, Node.js, etc for handling Fine Uploader chunked upload requests. It's maintained in this very GitHub organization.\n. If you're using PHP, I've published the PHP traditional server to Composer. There is also a Golang library that supports chunking in this GitHub org at https://github.com/FineUploader/fineuploader-go-server, contributed and maintained by @orlandovald. It's available via go get. Then there are Java and Node.js implementations that support chunking in the server-examples repo as you have indicated. It would be great to get those pushed up to Maven Central and npm, respectively, but some refactoring would be needed to make them more configurable.\n\nWhere would you start implementing TUS in FineUploader\n\nTUS support would have to be opt-in, since the current proprietary protocol has been in place since late 2012 and I want to avoid breaking all current projects out there that depend on Fine Uploader chunking. So, the following high-level changes/additions would be required, as I see it:\n- New property on the chunking option (perhaps something like tus, which defaults to false. This would only apply to traditional endpoints, since Fine Uploader S3 and Azure are bound to the chunking protocols defined by AWS and Microsoft Azure, respectively.\n- Refactoring of the existing code to move Fine Uploader chunking protocol support into a new module/file. This may require changes to client/js/uploader-handler/xhr.upload.handler.js. But FU-specific chunking logic may exist in some form outside of this file too. I'm not familiar with the details of TUS, so it's not yet clear to me what initial refactoring is required. That would be a needed initial investigation task.\n- Updates to documentation to explain TUS support\n- Updates to existing example code to refer to appropriate TUS support libraries.\nAll in all, it seems like a big job.\n. Implementing TUS would likely be a good amount of work, and I'm pretty busy ATM supporting Fine Uploader, updating the several-years-old build process (#1569) and developing a React wrapper for the library.\n\nRight now it feels like taking the TUS JS client and a library to manipulate images (maybe cropper, but this adds jQuery as a dependency, which I don't like that much), is the best option. \n\nThis is certainly an option, but this means you'll have to implement image scaling, file (and possibly folder) dropping, <input type=\"file\"> support + styling, and any other feature Fine Uploader provides, yourself. But I'm not sure of your specific requirements.\nI commented in the Ruby library you are referring to. It's quite simple to handle Fine Uploader's chunking protocol. It may be easiest to just write a plug-in for that library to support Fine Uploader chunking. Additional benefit could come out of that effort, such as a generic Ruby backend example for FU.\n. > The support for old browser (especially the ones without the File API), blow up the FineUploader. The first implementation is going to be without taking care of support for old browsers.\nI'm not sure what you mean here. Fine Uploader support for older browsers works as expected, and I'm not aware of any issues. What issues are you seeing?\n\nThere are no integration tests.\n\nI suppose it depends how you define integration tests. In one sense, there are a lot of integration tests, but there are no webdriver tests, that is true. I never got around to writing these, and that would take an immense amount of time to even test the most trivial features.\n\nConcurrent chunk uploading is not going to be supported by the TUS implementation\n\nThat's unfortunate. Concurrent chunking was a highly requests Fine Uploader feature, and it has the potential to speed up single large file uploads significantly. I wonder if the TUS spec can be updated to account for this.\nOne other thing - in your fork, it looks like you've reformatted almost all of the files in the repository. I'd ask that you not do this and focus specifically on the feature at hand. I suspect this will already be a very time consuming feature to write, test, and document, and I don't want the scope to get out of control. \n. As an aside, I'd love to get proper selenium/WD tests started, but that's for another case. In the meantime, I've attempted to make the existing \"unit\" tests as comprehensive as possible over the years. Either way, manual testing will always be required, as the number of workflows supported by Fine Uploader is substantial, and I simply don't yet have tests that cover all of those in particular.\n. > I just don't guarantee that it's going to work for all browser from the beginning.\nYes, chunking is simply not possible w/out the File API. I assume the feature you create will be tied to some new option or options. By default, any option that elects to use TUS support should be ignored if the browser doesn't support chunking, and Fine Uploader should fall back to the non-File API code that uploads files using form submits inside of hidden iframes.\nThe features.js module can be used to determine the capabilities of the current browser.\nAll in all, sounds great. Feel free to loop me in, ask questions, or ask for code reviews and help at any time. \n. BTW, it's probably good that you didn't get too far updating the build-related code to handle TUS support, as I literally ripped out all of the old build-related code and replaced it with a single Makefile a couple days ago.\n. This isn't a problem. Fine Uploader is functioning as expected. We don't want to remove the file record from memory. Instead, we want to update the status of the record, which is happening. \n. Please do not delete the template. I expect those instructions to be followed. As it stands, I cannot make any sense of your question.\n. I'm talking about the issue template, the text that appeared in the text area when you opened a new issue.\n. I just attempted to reproduce myself, after submitting an invalid file, the file's status was indicated as 'qq.status.REJECTEDin the associated record _and_ the appropriatestatusChangeevent was triggered.\n. Thanks for filing this. I adjusted your question formatting a bit. This _should_ be an easy fix. If you'd like to give it a try, feel free and open up a pull request. Otherwise, I'll get to this when I can.\n. We can and should talk about this more - I think a few changes are needed. But before we do that, can you close this PR and open a new one against the develop branch?\n. Looks like tests are passing, but I'd like to see a couple more changes before this can be merged into develop. Unfortunately, nothing is ever as simple as it appears in a project of this size and complexity.\n1. Upper-case for each segment in the added header:Content-Length-Range`. \n2. Manual tests using this \"header\" for chunked and non-chunked uploads.\n3. Update the \"headers\" section of the S3 feature page. There may need to be additional info added here (see my note below).\nThe 2nd item is needed as Content-Length-Range is a bit strange as it's only a policy document conditional and not a supported or recognized HTTP header. Without further changes to the code, I suspect that the bucket's CORS policy will need to be updated to allow for this request header, even though Content-Length-Range means nothing in the context of an S3 API call. I am currently not sure if we should just leave this as-is and expect any integrator who sets this param/header to know that the CORS policy must be updated, or if we should prevent this from being sent as an HTTP header.\n. Thanks for the PR. I'll take a closer look when I get a chance and will provide feedback and suggestions to allow this to be merged. \n. I think the best approach here is to completely remove the existing CloudFront-related documentation, and include a new sub-section under the main/existing \"Uploading to S3 Through a CDN\" section that talks about S3 Transfer Acceleration. Once #1016 has been verified, then we can add CF docs as part of closing that case. \n. Thanks for your input @ludofleury. Perhaps the best course of action here is to:\n1. Close #1016 in favor of S3 Transfer Acceleration support.\n2. Remove mention of CloudFront in the docs, as I mentioned in my previous comment.\n. Looks pretty good to me. No need to worry about squashing. I can squash at merge time.\n. Sorry, but the issue tracker is for bugs and feature requests only. Please see the support page for information on how to properly ask for help. Also, a fully functional php example can be found at https://github.com/FineUploader/php-traditional-server.\n. I will check later, but it's extremely unlikely that anythingb is broken in fine uploader here. Most likely your page is missing a meta utf-8 tag.\n. Sorry, I'm not able to reproduce, even using the exact filename specified in your description (file is 18 MB). Unless you can point to a specific issue in Fine Uploader client-side code, or the PHP example, this seems like a support issue with your environment. I'm going to close this, but will certainly consider re-opening if a specific bug is found in the library or example server code.\n. version 4 signatures, PHP S3 server from the FineUploader repo, chunking enabled\n. I take that back, it appears to be related to using the filename as the key. Although using the filename as a key is generally a really bad idea (collisions), this does appear to be a bug. Not yet sure if the issue is client-side, or in the PHP example server code. I'd consider this to be a low-priority bug, but would be open to walking you through a pull request to the server or client-side code once the fix is identified.\n. Issue appears to be with v4 signatures only. Again, objectPropeties.key = 'filename' appears to be required to reproduce this.\n. Why must you use the filename in this project?\n\nto prevent collisions there's a folder that is generated on a per user basis\n\nThat won't prevent collisions. User can upload two files w/ the same name at different times.\n. I see. Again, I'm able to provide assistance in tracking down and fixing the bug, but on a grand scale, this is a low-priority bug in the project since this workflow is uncommon and generally discouraged. So, I won't be able to dedicate exclusive time to dedicate to this issue.\n. Fixed in #1632. This will be part of 5.11.9.\n. This indicates one of two things: either the browser/OS is not capable of identifying these files, or your MIME types are incorrectly specified. Either way, this is not something that can be addressed by Fine Uploader. The acceptFiles validation property simply delegates to the accept attribute on the underlying <input type=\"file\"> element. \n. Interesting. Thanks for the pull request. Some follow up questions:\n- What resource did you use to come up with the code you added?\n- Have you performed any manual tests? If so, can you explain what you tested and under what conditions?\n- Can you please write some unit tests to cover each of the two new methods you added?\n. Thanks for the update. We'll need to abide by the Apache 2.0 license, since the code you added is from the AWS JS SDK which uses this license. I'm not sure what specific requirements that license has for attribution - I haven't looked yet.\nSo, remaining here:\n- [ ] Manual testing in various v4 scenarios\n- [x] Unit tests for the two new methods added\n- [ ] Proper attribution for the code copied from the AWS JS SDK.\n. > do you think that's better to rewrite the code not using the aws code ?\nNot necessarily. We just need to abide by the terms of the license. Most likely attribution is required. If so, I can be sure that this is respected in the appropriate location. \nOther manual testing will need to completed, but I can take care of that as a final step once the other items above are covered.\n. No problem. I'll try to take care of the license and manual testing myself in that timeframe.\n. I think some tests that target the new functions and the old one that was changed, specifically, are needed. Those should go in test/unit/s3/util.js. Then I would write or update at least one test in test/unit/s3/chunked-uploads.js to ensure non-ascii characters are properly encoded for all requests sent by the library.\nI will follow-up with manual tests before merge.\n. Great work, thanks. I'll run a few tests locally and then release this as 5.11.9 if all looks well. If this hasn't progressed by next week, feel free to ping me as it may have dropped off my radar.\n. Since some of this code was borrowed from the AWS SDK-JS project, we are (as far as I can tell) bound by the Apache 2.0 license, thus we must do the following:\n- [ ] include a copy of the license in any redistribution you may make that includes Apache software\n- [ ] provide clear attribution to The Apache Software Foundation for any distributions that include Apache software\nBut quite frankly, I'm not sure. Does this fall under \"fair use\" since you're only using a couple of regexps? Does \"fair use\" even apply to code? Maybe @lsegal can weigh in on this, since he contributed the referenced code to the AWS repo.\n. No need to re-write - just a question of attribution, which will be easily solved.\n. Thanks so much for your prompt response @lsegal. It looks like only a line here and there was borrowed, so a comment linking to the reference/inspiration seems reasonable to me. If it ever turns out we are in violation of the license in any sense (or of any license), I will make appropriate adjustments ASAP when prompted.\n. You're absolutely right @lsegal. We'll go with the comment. If Amazon legal ever finds this to be unsuitable, don't hesitate to let me know and I will adjust post-haste. \n@e-tip Do you think you could add a comment above the function(s) similar to the one mentioned a few comments above?\n. This will be released with 5.11.9. I may include one or two more cases in 5.11.9. That has yet to be determined.\n. Plan is to release this as 5.11.0 on Monday August 9, 2016.\n. Think I can knock this out tonight. I should also update the ES6 & CommonJS feature docs page too.\n. This looks like a bug in the build process, there were no intended breaking changes, and I'm very careful to not make any breaking changes without a major version bump, following the semantic versioning spec.\nLooking closer, the originally included jQuery bundles are missing, other than the source maps (which are new). I completely rewrote the build code in 5.11.0, so this looks like a regression. I'll look into this further and push out 5.11.3 once its fixed.\nThough I would never intentionally introduce a breaking change without a major version bump, and this issue will be scheduled for a hotfix release, there isn't really any benefit to using Fine Uploader's jQuery wrapper, and you're probably better off using the non-jQuery wrapper version anyway.\n. Regression caused by incorrect naming of the jQuery minified and unminified artifacts generated by the new Makefile build recipes - https://github.com/FineUploader/fine-uploader/blob/5.11.0/Makefile#L242. Once I fix these, the issue should be resolved. The Azure & S3 builds do no suffer from this issue - it's specific to the traditional endpoint build.\n. ugh, still missing from the zip files, though npm is fixed. I can't wait to remove the jQuery wrappers in 6.0.\nI'll have to fix this and push out 5.11.4. Completely forgot to verify the zip files before 5.11.3 was released.\n. Fixed in 5.11.4.\n. Can you edit your description to include a detailed question? \n. > However as designers we would welcome a step by step guide \nSince I'm not a designer, I'm not quite sure how to comply. Can you outline the exact elements of the guide that were confusing?\n. > how do you get it working without an understanding of JS\nYes, how indeed. The library was developed with the assumption that integrators have an understanding of HTTP, JavaScript, and at least one server-side language. In the absence of one (or all) of these traits, getting Fine Uploader up and running may be difficult. Well, getting it up and running is doable, but scaling and customizing it may be tough, but this is not a problem unique to Fine Uploader. If there is a sizable audience of designers who would like to get Fine Uploader up and running, then I'd like to hear from them and see if we can either tailor the documentation to suit their skill level, or perhaps create an alternate \"getting started guide\" for designer-types.\n. Have you seen the full stack JS uploader article and matching GitHub repo I created a while back? This is literally plug-and-play, though it is centered around Angular. Is this what you're looking for, but library/framework agnostic?\n. This is really useful feedback. I'm going to think this over a bit and outline some ideas next.\n. The market for Fine Uploader is anyone who wants to utilize all of the unique and helpful features of the library in their web application. Though most of my writing and development comes from the perspective of, no surprise here, an experienced developer. But now I have a designer's perspective, so I'd like to make good use of this gift. \n\nFine Uploader for designers\nNot a developer?\nDon't want to mess with npm, GitHub, or even the terminal?\nWant to try out Fine Uploader and its unique and comprehensive set of features?\nGet Fine Uploader up and running on your computer in three easy steps:\n\nDownload fine-uploader-for-designers-5.11.4.zip\nUnzip the file by double-clicking it.\nOpen the folder, and double-click on start.bat (Windows) or start.sh (Mac OS).\n\nAfter executing the above steps, your browser will automatically open to a page with a fully-functional and modern looking Fine Uploader instance with all features enabled (including a drop zone) and a running server. Simply hand-edit any of the CSS, HTML, or JavaScript files in the \"custom\" directory if you wish to customize your uploader.\nNeed more help? Contact @FineUploader on Twitter.\n\nI see the above page living at http://fineuploader.com/designers, with a reference to the page prominently displayed on http://fineuploader.com/. How does this sound @chriswestw? Any changes or additions you'd like to see?\n. > if you can really do it!\nI can!\n\nIf you want I will work with you to implement and test your procedure.\n\nYes, your perspective will be helpful. I'll need you to verify that the final solution is accessible. Also, I'd love it if you could design the http://fineuploader.com/designers page to make it appealing for designers. If you're able to do that, we can talk further about how you can contribute.\n\nfinding out how to upload the file.names and post them to databases\n\nFile names are available in the request sent by Fine Uploader. I plan on using a PHP server as the backend that will store files on the hard disk. Each file will reside in a folder named for the unique ID assigned by Fine Uploader. The file in this folder will include the actual name of the file.\n\nfollow dead simple instructions to take advantage of S3 \n\nI'm afraid there is really no way to make this dead simple. Getting Fine Uploader S3 up and running really does require good knowledge of S3. My target for Fine Uploader For Designers is Fine Uploader UI for \"traditional\" endpoints (i.e. not S3/Azure).\n\nresize images on load\n\nDo you mean scale an image before it is uploaded? This is something Fine Uploader provides, and all that is required is inclusion of an option. I can include some boilerplate in the turnkey JS with comments to guide designers who want to customize it further.\n\nYou could market this new (for designers) solution via Codecanyon \n\nI have no desire or intent to profit off of Fine Uploader. I'd like to keep it free for all.\nI've create a GitHub repository to house the Fine Uploader For Designers \"wrapper\" that I have described above. Nothing much has been done yet, but check back for updates at https://github.com/FineUploader/fine-uploader-for-designers.\n. Can you explain what specific steps/information is missing? A pull request with the changes would be best.\n. Thanks for the details. Those seem like reasonable adjustments. I'll take a closer look at the guide and make some changes, possibly tonight.\n. I will clarify that as well, thanks.\n. @strohhut I just created #1646 to track updates to the getting started guide. We can discuss further details their, if needed, and you can follow my progress.\n. I'm going to close this as work is scheduled and in progress at https://github.com/FineUploader/fine-uploader-for-designers. Comments and suggestions can be made in that project's issue tracker.\n. You can follow progress at https://github.com/FineUploader/fine-uploader-for-designers/issues. For the next week or so (possibly even longer) I'll be completely tied up preparing my book for publishing. I'll get back to Fine Uploader for Designers and other elective Fine Uploader duties once things have calmed down.\n. Thanks @chriswestw. Slow going right now due to other commitments. I'm looking for other serious developers, designers, and PMs to join me on this and other Fine Uploader projects. If you know of anyone who is capable and interested, please let them and/or me know.\n. Yes, available time.. Feel free, but do note that any breaking changes must be part of 6.0.0. I don't think it's possible to do this without breaking changes. So it may be best to update the release/6.0.0 branch (merge in master), complete the task in there, and release an alpha version.. The convention has been to follow gitflow to some degree, which keeps master the default and stable branch. All features and fixes are branched off of master. I would like to keep it this way as it is otherwise a bit confusing for users when they stumble onto master and are confused to find out that the code/README there does not match the latest stable code.\nBTW, I'm quite happy to hear that you're going to attempt this fix, but I consider this to be a very challenging update, so please let me know if you have questions.. This sounds like a great start, but I\u2019m a fan of the \u201cband-aid\u201d approach here, and think it will be best to rip out qq.Promise in a single PR, rather than potentially scatter breaking changes and bugs over several PRs and alpha releases. This issue is complex, but still one unit of work.. Thanks for the report, and I can confirm that this is a bug introduced by the build refactor in 5.11.0. It likely affects Fine Uploader S3 and Azure jQuery wrappers. The jQuery wrappers are not well tested anymore, which is why there have been a few regressions related to these wrappers recently. I plan to remove the wrappers entirely in 6.0 since there is really no benefit provided by jQuery wrappers in the case of Fine Uploader.\nThere are a couple workarounds until I fix this in 5.11.5:\n- Temporarily move back to 5.10.1\n- Stop using the jQuery wrapper. You can still use jQuery in your project, if you wish, but there is no real benefit to wrapping Fine Uploader w/ jQuery. More info at #1310.\n. Fixed in 5.11.5, released today.\n. Why does the library need to handle this (and how)? Can't you just define one options object and pass it into each uploader when you initialize it?\nAlso, no improvements will be made to the jQuery wrappers, since they will be eliminated in 6.0.\n. I'm still not exactly sure what you are asking for here, or what changes you are proposing.\n. Closing this, but I'm will be happy to consider re-opening if more specific details are provided regarding the required changes to Fine Uploader.\n. Thanks for the report/request. Fine Uploader S3 appears to be a never-ending feature, but I can see why this would be useful. That said, since there is a workaround, and IPv6 utilization is probably pretty light, this won't make it onto my plate for a loooong time. But, a pull request with the required changes, a new unit test or 2, and updated documentation (that's debatable though) would push this through much faster.\n. No pull request or additional requests to implement here, so I'm closing this since a workaround exists anyway. I consider page 1 to be complete at this point. Please let me know if anything seems to be missing or any further improvements are warranted.\n. The guide is a bit repetitive as I don't anticipate a single user reading every single section. Rather, I see them choosing an endpoint type and feature set, and then zeroing in on the remaining steps that address that specific selection. Writing documentation is not similar to writing code. In other words, it is often not appropriate to move duplicated instructions into a single section. Instead, repetition is a useful method for ensuring your message is absorbed by the reader. \nGreat feedback, thanks! I'll make some changes. \n. I just updated page 1 with your suggestions.\n. I'm mostly done with all of this. All that is left is to update fineuploader.com and then release 5.11.6 with the changes to the docs and templates.\n. I'll fix those lines, thanks. Anything else obviously missing? If not, I'll push out the doc, template, and website changes soon.\n. Released with 5.11.6.\n. I'm not sure I understand how generating signed URLs will reduce any complexity. Each request sent to S3 is different, and therefore requires a unique signature based on the request to be sent to S3. This is especially true when splitting a file into chunks and uploading to S3 via the multipart upload API.\n. Some of this is coming back to me now, regarding why I didn't support signed URLs initially. As far as I can tell, signed URLs cannot be used with the S3 multipart upload API. This eliminates chunking and all chunking-related features. With that in mind, I don't see a benefit to supporting signed urls.\n. Turns out this may actually work, and in fact is a workflow I need to support for another closed-source project I'm working on now. \nI believe support for signed URL uploads has been requested many times. I actually see this as being implemented into core Fine Uploader code such that support is added for a request to be sent to the server for each chunk, which can then be used to influence that chunk's upload endpoint, params, and headers. \nAdditionally, the onUpload callback will need to support promissory return values in case a request needs to be made to influence all chunk uploads for that file.. So here's my current though process:\nMake onUploadChunk accept a Promise as a return value. The resolved param will be used to influence the URL, params, and headers of the request sent for that chunk. If no such param is included with the resolved Promise, or if a Promise is not returned, the existing logic will be used to determine URL/params/headers for the chunk's upload request. A rejected Promise will exercise the failed upload code path.\nSeems onUpload should do the same, optionally. So I don't see this being an S3-specific change. In fact, it seems to make most sense to use the traditional endpoint uploader to upload to S3 using signed URLs.. That's expected. You will need a Linux or UNIX filesystem to build fine uploader going forward. On Windows I imagine cygwin will work or Windows 10 bash.\n. I'm not sure what the problem might be then as I don't use Windows for development. If you find a fix, please let me know or open up a PR. Or, if you can locate the specific issue with the build, let me know so we can discuss further. Also, be sure you have run npm install first.\n. Is this preventing you from updating the bower distribution? Something definitely looks \"off\" in the error message above. Cygwin is supposed to be mostly POSIX compliant, but I haven't tested myself and I don't know if the flavor of cygwin you are using is suitable.\n. I'm not certain what the solution is here. I was under the assumption that this would work as-is in cygwin.\n. @SinghSukhdeep Good call.. The drop zone message is meant to be informative and instructional. After the user has already selected files, my assumption was that they are already familiar with the procedure and instructions are no longer necessary. But, I can see your point. I'll look into ensuring that a lack of files always re-renders the drop zone text.\nBy the way, since this appears to be a fairly low-priority issue, it will likely be quite a while before I'm able to get to it. But if you are able to discover the issue and fix with a pull request, that may speed things up.\n. Unfortunately, there are no small changes with a library of this age and complexity. Manual workflow and regression testing is needed for all changes, and changes to the drop code are especially concerning. I will keep this bug in mind, but development has mostly been a one person job for the last four years, so i have to prioritize, especially since this is more of a hobby than anything else. \nAre you a designer, or...?\n. Hmm type definitions, that world be a good thing to add I guess\n. I plan on creating an issue to track this. Perhaps someone (maybe even myself) will pick this up when the need arises.\n. You'll probably we waiting for a while still, unless someone picks this up and works on the feature. I'll be busy for a while with a number of other Fine Uploader related features and bugs.\n. Should be covered by #1719.. Ugh, that's a nasty one. This is another regression from the build re-write in 5.11.0. I'll fix this ASAP and release a hotfix - 5.11.7.\n. This likely affects S3 and traditional builds too.\n. Released as 5.11.7.\n. Thanks for the request, but I'm not sure how downloading files is an appropriate feature for an upload library. Besides, this is pretty easy to do without a library.\n1. Return a downloadUrl for each entry in your server's response to the initial file list GET request\n2. Render an anchor link next to each file with that URL.\n. You can style the button (or any part of the template) in your template markup & via CSS. I would suggest re-thinking the \"entire drop zone is clickable\" requirement. You will likely run into problems since the file elements in the dropzone also have buttons of their own (cancel, delete, etc).\nPlease use this issue tracker for feature requests and bug reports. Stack Overflow, under the fine-uploader tag, is the best place to post support-type questions.\n. If uploading them one by one, but still all in the same session, does not result in a crash in IE11, and if the issue is limited to one browser, this hardly sounds like a memory leak. It might be a while before I am able to look into this, so anything you discover will make this easier to address.\nIt is interesting that removal of the EXIF data seems to fix the problem for you, but I'd want to be sure that this is indeed a fix and you're not just \"getting lucky\". I can't imagine, off the top of my head, how EXIF data would be an issue here, especially since you are excluding the EXIF data from the scaled uploaded files.\nA terminology note here - scaling refers to generating a smaller image from a reference image and then uploading that image. Scaling for a file only happens just before that file is about to being uploading. The demo page does not do scaling, only preview/thumbnail generation. Thumbnail generation can happen for all submitted image files at once, but there is some staggering in place by default that waits 750ms between preview generation attempts. \nI'd be interested to see if you have the same problem when plugging a third-party image scaling library into Fine Uploader (which overrides much of the internal image manipulation logic). See the scaling.customResizer option and the thumbnails.customerResizer option for more details on integrating a 3rd-party image library, like Pica.\n. This error indicates an issue with your signature server, not with Fine Uploader. Especially given the circumstances:\n- user failed to upload three times, but the fourth was successful\n- This bug is difficult to reproduce\nMost likely a temporary network issue. Do you have any information about the response (such as the payload)?\n. Fine uploader is ready after you create a new instance. What are you trying to do? What problem are you having?\n. You left \"getting previously uploaded files\" out of your question. If you want to know when Fine Uploader has completed handling an initial file list, observe the onSessionRequestComplete callback.\n. > it would be good if qq.FineUploader method has an \"initialization complete callback\" \nI'm not seeing a need for this. Just do whatever you need to do after initializing the uploader. If you are performing an async task, such as requesting initial files, then wait until that is complete.\n. ...and please do not delete the question template going forward. It exists for a reason.\n. Yes, this is correct, this is how delete requests are sent. What is your question?\n. > FineUploader sends the DELETE request without file UUID at the end of the endpoint URL. eg: http://localhost/server/upload\nIf you are seeing this and can reliably reproduce, then this is a bug. A pull request to fix this bug is welcome.\n. I just attempted to reproduce and I'm not seeing any issue. The UUID was appended to the end of the URL for an initial file delete. Since you deleted the question template, I have no idea what version or build of Fine Uploader you are using, so I can only assume that the issue is on your end.\n. sounds like a CORS issue with your server. what do you see in the dev tools console?\n. I mean, what errors, log messages do you see, especially when debug is set to true?\n. This does sound like an issue with your server's handling of CORS. Note that you must return proper CORS headers not only in response to the preflight request, but also the proper ACAO header in response to the POST. A 200 status does not indicate that CORS headers are correct. If you have further CORS questions, stack overflow is a more appropriate place to ask, since I'd like to keep this issue tracker for issues with the library and feature requests.\n. Thanks for the report. Please open up a pull request with your proposed fix. Also, reference this issue in that PR.\n. Fixed in 5.11.8 - released today.\n. Thanks so much for catching and fixing this! I'll release as 5.11.8 ASAP.\n. Please do not delete the issue template. You can create your own server by modeling it after an existing server, or by reading the server documentation.\n. Thanks for the report. If you could fix this in a pull request w/ matching tests, I'd be happy to look it over and release the fix as a hotfix.\n. Thanks so much for detecting this issue and contributing a fix. I'll run some manual regression tests to confirm that everything is still working as expected (since upload.handler.controller.js is both critical and complex). If everything checks out, I'll merge this in.\nAlso, can you please sign the CLA?\n. Can you please merge develop back into this branch?\n. I'm going to push this to 5.11.10, as I'd like to get 5.11.9 out as soon as possible and I have yet to even start on some of those bug fixes.\n. This is still on my radar, but 5.11.9 is going to be my focus first. This fix is scheduled for 5.11.10.\n. Looks like a lot of changes have been added to this branch, unrelated to the original problem. Was this by mistake?. Yep, thanks. Trying to be as transparent as possible: the number of cases for me to look into/verify is piling up, and, unfortunately, the amount of time I have to dedicate to this project is rapidly decreasing.. Going to have to push this to 5.11.11. I have to hotfixes ready for 5.11.10, and I'd like to release that today. I haven't gotten around to testing this one yet, and it's more risky than the others. At least one unit test needs to be written for this anyway, and I'm not sure when I'll get to that, so if you are able to contribute one, that will speed things up a bit.. Thanks for the PR. I'm a bit surprised that this is broken. I seem to remember this working at some point. I can see how this would fail if the file suddenly disappeared during the upload process.\nI'll take a closer look soon.\n. Interesting - thanks for the details. You are correct about the empty file when it is removed from the filesystem during the upload process. I'll take a closer look when I get a chance.\n. I expect to be able to look at this closer tomorrow. If all looks well, I'll merge into develop as part of 5.11.9.\n. Can you describe the symptoms of this issue? I'm not exactly sure what I should be seeing when attempting to reproduce.\n. I'm not able to follow the exact steps in your description, but I did notice a couple related issues:\n1. When the network connection is pulled, the upload hangs for quite a while. I think this can be solved with an XMLHttpRequest timeout.\n2. If the file is deleted while the upload is in progress, fine uploader will continue to send chunks, but they are 0 sized. It seems like Fine Uploader should fail the upload in this case.\nI think both of these issues should be addressed as part of this case. I'll look into making these adjustments soon. I hope to release those along with your fix to compete 5.11.9.\n. I was never able to hit the breakpoint above. I simply saw FU send a bunch of empty chunks at S3 after the file was deleted. But I believe your changes are correct, so I will merge this in.\nI'm going to prioritize #743 and #1669 to address the other two issues we discussed. If you'd like to help out with either, let me know.\n. The above is not your Fine Uploader configuration code. Your bug report mentions pausing an in-progress upload as part of the reproduction steps, but chunking is required for that. Chunking is not enabled in your configuration code above. \nAfter enabling chunking, I was not able to reproduce the reported issue. All is working as expected. Perhaps there is an issue in your environment, possibly CSS related.\n. Step 2 says:\n\nPause the 2nd file before it completes, but after it has started.\n\nThis is not possible without chunking enabled.\n. Sorry, I'm not seeing any issue with the individual progress bars myself. They are supposed to hide after the upload completes. Demo page is working as expected as well.\n\n. Looking into this next as part of 5.11.9.\n. Once #903 / #1673 are implemented, this will need to be considered. In other words, if empty file uploads are ever explicitly allowed, the logic in this case must be switched off or at least modified to ensure that a truly empty file upload is not flagged as an error.\n. Fixed - to be released with 5.11.9.\n. Fixed. This is the last case for 5.11.9, which will likely be release in the next few days.\n. This seems like an issue that affects a very small number of people. As such, I can't dedicate time to this, but would be able to help push through a PR.. Not able to reproduce this myself. Test site seems to have issues. If you are seeing this with recent versions of Safari. Please let me know.. You may utilize the provided API for any integrations you desire. If you have a specific question regarding integration or code, please post on SO.\n. If you can pair this with documentation updates, I think this will be ready to merge into develop.. For non-chunked uploads, a policy document is provided. This is required for non-multipart uploads to an S3 bucket. For chunked uploads, the S3 multipart REST endpoint is used instead, and no policy document is sent.. Nice catch. Thanks!\n. Thanks for the report? Can you please open a PR with the fix?\n. The markup for the docs are hosted in this repo under the docs directory.\n. While you are targeting master, it appears that your branch is based off of develop. So, I adjusted the target branch to point to develop. I'll merge into develop and then cherry-pick your commit into master. \nThanks for catching and fixing these documentation errors. Much appreciated.\n. Sorry I don't understand the question/problem.\n. Thanks so much for finding and fixing these doc issues!\n. What is \"the very last response\"? There is no guarantee regarding order of requests/responses. Since you are using the concurrent chunking feature, you are required to define a chunking.success.endpoint. This is where your server should combine the chunks and return a response that describes the entire effort.\n. Closing, but let me know if this is not yet resolved or needs more discussion.\n. Whoa. No idea how that got there. Thanks!\n. Fine Uploader doesn't actually take seconds to render them. There is a default pause between each thumbnail generation to work around a GC issue in Chrome #1279. I'm not sure if this issue still exists in Chrome. Regardless, you can control the delay between thumbnail generations via the thumbnails.timeBetweenThumbs UI option.\n. > I still wonder if it would not be better to let the browser render the image, when the thumbnailUrl is explicitly given from the session endpoint JSON.\nEven in that case, Fine Uploader scales and potentially orients the image, which means <canvas> is used. So, the same GC issue is possible in Chrome.\nGlad to be of assistance. I'll close this now.\n. Please don't delete the template. I'll re-open once you've re-inserted the template and followed the instructions for posting an issue or feature request.\n. Please don't delete the template. I'll re-open once you've re-inserted the template and followed the instructions for posting an issue or feature request.\n. Why does the input name need to be modified?\n. I don't see much value in making the input name variable to this extent. If you'd like to pass dynamic data with the file, this can be done via upload parameters. See the params option and the setParams API method for specifics. Note that you can specify functions for params, or simply update them whenever you want via the API.\n. There are no known issues with setting params, either through the API or via options. If you are having issues, please open a question on SO with all of your code for assistance.\n. Related to #1652?\n. I'm afraid I'm not the best person to implement this feature for a few reasons:\n1. I'm not familiar with Angular 2 (I used Angular 1 in previous projects, but have since moved to React).\n2. I'm not familiar enough with Typescript, though it's on my list of tech to investigate.\n3. As you mentioned, there are a number of other cases higher up on my list.\nThat said, I do see how this would be a very valuable update to Fine Uploader. I'm willing to provide advice and answer questions at any time if you are willing to participate in coding this up.\nI see creating TS definition for the API to be a fair amount of work. See the API nav menu at http://docs.fineuploader.com - I assume all events, methods, and options will need to be covered in the TS definitions. \nAs for the wrapper, as you mentioned, something similar to what I created for React Fine Uploader sounds like the right approach. More specifically, the \"wrapper classes\" I created are probably a good high-level model.\n. Since this is a public project, I'd like to maintain as much transparency as possible. So feel free to post any questions at all in this issue. If that isn't working out for some reason, we can regroup and discuss another approach.\n. cool. i'll take a closer look this weekend. or perhaps i should wait until you are \"done\" with this definitions file, then I can add comments.\nThis might work better as a pull request to Fine Uploader. You can commit to the branch associated with the PR as you complete this, and I can comment on commits much easier.\n. First step is to fork the project. Then you can submit a pull request using GitHub after you push your first commit to your branch. Subsequent commits to your branch will be part of this pull request. It will be much easier to discuss changes and plans in that context.\n. Think #1652 can be closed too.... I'll make this as \"in progress\" for now. Please do let me know when you have a question or need a code review.\n. Related #1688.\n. Thanks for finding that issue in the docs. I'll push a fix for that next. \nRegarding new - you definitely have to new up a qq.FineUploader instance. Not doing so will result in a function return type, and, as a result, you won't be able to access any API methods. Also, the internal code expects qq.FineUploader to be properly constructed, otherwise the value of this will be window instead of the qq.FineUploader instance.\nNot sure if Typescript provides some magic that makes new unnecessary. I'm not very familiar with the language myself.\n. Thanks for finding that issue in the docs. I'll push a fix for that next. \nRegarding new - you definitely have to new up a qq.FineUploader instance. Not doing so will result in a function return type, and, as a result, you won't be able to access any API methods. Also, the internal code expects qq.FineUploader to be properly constructed, otherwise the value of this will be window instead of the qq.FineUploader instance.\nNot sure if Typescript provides some magic that makes new unnecessary. I'm not very familiar with the language myself.\n. Thanks for catching that. Fixed!\n. Thanks for catching that. Fixed!\n. Note that your branch should be based off of Fine Uploader develop\n. Note that your branch should be based off of Fine Uploader develop\n. it probably doesn't matter much since, at the time you forked, master and develop were identical.\n. I'd suggest leaving any of the qq util functions out. I'd like to remove those entirely in a future major release.\n. Sorry. If you're almost done with util functions, you are free to proceed. I can just remove them once 6.0 is released, which may not be for a while anyway.\nI'll fix the docs for qq.each too.\n. docs are updated\n. I'll try to take a close look in the next few days. Other than creating the definition files, what else, if anything, needs to be done to ensure Fine Uploader can be used w/ TS in an Angular2 project? I'm also wondering how these TS def files are picked up.\n. Fine Uploader already publishes CommonJS modules. So, for example, with Webpack you can `import qq from 'fine-uploader'. Does TS not support CommonJS modules?\n. > But to use the import syntax, A library needs to have an index file at the root which would do named export of ES6 modules.\nThe package.json file already handles this.\nI haven't used rollup myself, but with Webpack, import works without issue, and it should with Rollup too, provided it has complete support for CommonJS. If something is missing, I'd definitely be interested in making appropriate adjustments though.\nI believe you're correct about tree-shaking. Webpack doesn't support this yet, but I do believe that a module needs proper export statements for this to work.\n. I'm guessing exports will be needed for all Fine Uploader builds, similar to what already exists in the lib directory.\n. Sorry, haven't gotten around to reviewing this yet. Hopefully over the U.S. holidays I'll find some time to do so.. doesn't look like that worked - you can see in the \"changes\" tab at the top of this PR. Looks like a new PR is needed instead.. Oh, ok. The def file was not automatically expanded in the diff viewer due to its size, which is probably why I overlooked it.. Just started to look at this again. Sorry for the delay, but I'm only able to pick up a few minutes here and there for the foreseeable future.  \nWhat exactly is typescript/fine-uploader.spec.ts?. Just started to look at the definition file. I can safely say that I'll never have enough time to review all of that, nor will I be able to verify since I don't use TS in any projects. So I'm included to just merge this through since no existing code was updated and this this is localized to a particular integration point that did not previously exist. But I'm wondering - how do projects pick up this definition file? How does TS locate this? Where does it have to reside inside of the package retrieved from npm?\nThis will resolve #1652, #1688, and #1689 AFAICT.. Fine with the first approach. To complete this:\n\n[ ] update to package.json as specified in your last message\n[ ] update to Makefile to ensure the proper TS files are included in the zip files & the npm package. It's probably best to include these in the /client/commonJs directory in the source tree. The contents of that dir will be included in the lib/ dir in the npm package. \n\nI think it would be nice if a feature page was created or something somewhere in the docs was updated to reflect TS support.\nRelated: Are you interested in becoming a contributor for this project? Seems you now have a better understanding of the API than most at this point.. @SinghSukhdeep Was wondering if you have any updates on your progress, or if you need anything from me?. No rush at all. Just checking in.. @SinghSukhdeep Just wanted to bring to your attention DefinitelyTyped/DefinitelyTyped#13768. It just came onto my radar a few days ago. It's not clear to me how this affects your efforts here. Was wondering if you had some comments. In particular, regarding this area of the DefinitelyTyped readme - https://github.com/DefinitelyTyped/DefinitelyTyped#removing-a-package.. The library can be used as a module. Examples/details at http://docs.fineuploader.com/branch/master/features/modules.html.. After looking at this closer, could it be that the definition file is not included with the packaged library, and that is the cause of this issue? The entire source tree is not published to npm. There is a build step that only includes the bundled code and a subset of the project root. This is something I mentioned in a comment a while back.. I'd be happy to add you both as contributors to fine-uploader. Then, this PR could be merged into a local feature branch where work could continue. How does that sound?. I've sent both of you invitations. In order to bring this into the repo without merging it into develop (since it's not complete yet), I think the next steps should be:\n\nCreate a new branch in this repo based off of develop.\nChange the target branch of this PR to the branch created in step 1 & merge it in.\nOpen up a new PR and begin to collaborate and make changes on the branch created in step 1. Please reference this PR in the new one.. 1. You deleted the issue template\nYou didn't read the contributing instructions, especially the part related to asking for support.\nYou didn't provide any information necessary to troubleshoot your issue.\n. Nice catch. This means the qq.Identify module is defined twice in the built code. Even though this is a small module and size will only decrease a small amount, I think that merits a hotfix release. Thanks!\n\nGoing forward, changes should be initially based off of develop. This is why I have an issue template, which you deleted. But I do thank you again for your help here.\n. This is going to go out today (likely) as part of 5.11.10. Thanks for your help!. This seems complicated and unnecessary. Chunks will already be sent if the file is big enough for chunks.\nJust to be sure I understand, you are looking for Fine Uploader to be able to account for servers that cannot properly handle concurrent requests? I don't really understand your distinction between chunks and files. To the server, they are both just HTTP requests with payloads that contain either multipart encoded or binary payloads.. No response after 3 days: closing.. Thanks for catching and fixing this!. I don't have access to an Android device, so I won't be looking into this. But if you are willing to investigate, I'd be happy to provide assistance where needed.. >Is this type of behaviour possible now by any chance?\nYes, see http://stackoverflow.com/questions/40377213/fine-uploader-idiomatic-way-to-add-download-button-to-each-file-uploaded for inspiration.. I'm not sure how this would be implemented in a generic way without adding a notable amount of complexity to the already complex codebase. I'm not generally in favor of adding more code to the library when the goal can be achieve by following an example that utilizes the existing API.. You'll need to return whatever data you need in your server's response to the initial files GET request. . Chunk size is only configurable for all files as an initial config option. The best option would be to limit the upload size based on your configured chunk size.. Another option would involve updating the codebase to expose an option that automatically adjusts the chunk size to an optimal setting before the upload begins, taking into account the file size.. Yes, that sounds like a good approach. I think a change at https://github.com/FineUploader/fine-uploader/blob/c1b4954f21381dbd664e379abf571c988e2265c0/client/js/upload-handler/xhr.upload.handler.js#L222 may be all that is needed. But unit tests would need to be added as well.. Unfortunately there are no simple changes in a codebase of this age and complexity. This has the potential to break any chunked uploads that are waiting to be resumed from localStorage. So that will need to be accounted for. . Long time coming, but I expect to address this in #1917. Probably will allow a function to be returned from chunking.partSize. The function would be invoked by Fine Uploader with the file ID. Integrators could determine the optimal partSize, and this would not be S3-specific.. This doesn't seem to break in non-Windows environments, but it seems the OS environment variable is non-standard. Why not use uname instead?  http://stackoverflow.com/a/17072017/486979. Looks like uname -s produces a value on every flavor of Windows that at least includes the string _NT.. \"CYGWIN\" isn't necessarily going to be in the output of uname -s.. on Windows 7, that may be true. On Windows 10, I'm seeing something a bit different. The common string in all versions of Windows seems to be _NT.. I don't personally intend to take time to setup cygwin, node, git, etc on a Windows VM to verify this. Can anyone else on a windows box verify that the build now works in Windows, at least under cygwin?. Has anyone else on a windows box verified that the build now works in Windows, at least under cygwin?. Thanks for the confirmation. Merging this into develop and planning to make this part of 5.14.0. Initially it will be part of 5.14.0-beta3 along with #1719.. This is not a bug, and what you are asking for is for Fine Uploader to report MiB, not MB. As it stands, the current measurement follows SI standards. Please read #378 for more info.. Does this happen with any image? Have you tried with a recent version of Fine Uploader (your version is very old)? What version of Firefox?. The version of Fine uploader you are using is exceptionally old. Have your tried with a newer version? Yours is the only such report, so it seems unlikely that there is an issue, at least in recent versions of the library.. I'm not seeing any issues myself. Most likely you have left out details needed to reproduce. I will be happy to reopen the issue once a foolproof set of steps needed to reproduce are included. . There is something terribly wrong with your copy of Firefox then, as that method certainly should be available. Most likely a browser extension or some other code on the page is the culprit.. 8K difference - after gzipping, that's almost a wash. Using web workers for this task seems like a big win to me, so I'm leaning towards including it in all existing S3 build files. But anything you can do to make the difference even smaller is worthwhile too.. >because RequestSigner gets created multiple times, my worker-manager gets created multiple times.. Is there a better place to create the manager, but still get the options from the signer?\nInstead of passing the workerUrl as an option to RequestSigner, why not construct the RequestSignerWorkerManager as part of the S3 upload instance initialization or in qq.s3.XhrUploadHandler, and pass the RequestSignerWorkerManager instance to RequestSigner when it is constructed as part of the signatureSpec?\n. Interested in pushing this through. Are you able to address the remaining issues?. Hey there. Sorry for the silence. Reviewing this is on my to-do list, but I have a few things ahead in the queue, and I have some other new commitments that I have to attend to as well. . Confirmed in Firefox. Updating qq.supportedFeatures.folderDrop to better detect this as support moves to additional browsers. Staged in #1917.. Best way to address this would be to open up a pull request with tests that demonstrate the issue alongside a fix. Thanks for the report. The code in question has been in place for several years at this point. If there is an issue with a specific environment, please write unit tests that reproduce the issue or provide an executable test case. A pull request that includes a test and a fix is ideal. I'm going to close this for now since I haven't heard back in a while, but will be happy to consider re-opening if executable test cases and/or a PR can be contributed.. Yes, it is: \njs\nvar id = uploader.getId(uuid)\nuploader.cancel(id). Ah yes, my mistake. Use this one instead http://docs.fineuploader.com/branch/master/api/methods.html#getUploads. The issue you are reporting appears to be unrelated to the drag and drop feature. You're simply sending files to the uploader via addFiles correct? Is that where the issue occurs? Is addFiles allowing multiple files to be sent through?\nLooks like the fact that you are using a non-UI instance is related. Can you post the logs after attempting to drop 2 files with debug: true set?. Until I get a chance to look into this further, i would suggest using the itemLimit validation option described at http://docs.fineuploader.com/branch/master/api/options.html#validation.itemLimit.. ...you can also simply reject the dropped files yourself before calling addFiles if more than one file is dropped. In fact there are a number of ways to deal with this. I consider this to be a low priority bug as a result, so I'm not sure when I will get around to fixing. However a pull request that fixes this and includes unit tests will push this through quicker.. The quickest way to accomplish this is to check the EXIF data yourself either before submitting the file to the uploader or in an onSubmit callback handler.. I posted some example code as an answer to your Stack Overflow question that should allow you to achieve this using Fine Uploader API and the exif-js library. So, I'm going to close this feature request in favor of that approach.. What is a \"File Upload dialog\"?. I'll just run a few quick manual tests sometime in the next few days or so. If all looks good, I'll release this as 5.12.0. Thanks for your work on this!. This has been merged into develop. I hope to release v5.12.0 this weekend. Thanks again!. Thanks for the example and details. I'll put this near the top of my list due to the severity of this bug.. Ah, I see. Of course, the Blob is held onto by Fine Uploader. This is required in order to ensure the getFile method returns, well, the file. For Blob objects that are simply references to files (such as those submitted directly via the <input type=\"file\"> button or dropped into the dropzone, this isn't an issue - those aren't held in memory, they're held on disk. But once you take one of those files and manipulate them client-side, the resulting Blob is held in memory by the browser.\nThis might be a tricky one to fix without introducing breaking changes in the behavior of the library. I can't simply change to code to dispose of Blob objects that are not also File objects (which means they are held in memory) after the upload - this would be a breaking change and I'd like to avoid a breaking change to fix a bug. Also, there might be instances where integrators actually want to get back the Blob when calling getFile.\nI think a reasonable solution may be to offer a new API method, something like expungeBlob. You could call it in an onComplete callback handler (or whenever you want) to remove the Blob from Fine Uploader's control and make it eligible for GC. \nWith this new API method, your initialization code would look something like this:\njs\nvar uploader = new qq.FineUploaderBasic({\n    request: {\n        endpoint: receiverUrl\n    },\n    callbacks: {\n        onComplete: function(id, name, response) {\n           if (response.success) {\n              this.expungeBlob(id)\n           }\n        }\n    }\n})\n...and this should hopefully help to alleviate the memory issues. Thoughts?. Sounds good - I'll have to add this new method then, since accessing an internal function directly is not supported and may break with any release without notice.. Implemented and published as 5.14.0-beta1. Please see the release notes for final implementation details, as they differ a bit from what was discussed here.. You could say the same for the button styles too. Not seeing how this is a bug though. I'll happily accept a pull request to \"fix\" this though.. Are you seeing a symptom of this problem? If so, a pull request with a confirmation of the fix will be helpful. Have two people verify is better than one.. I'm fairly certain that this change is not sufficient, and an empty response will still be marked as a failed request. See the isErrorUploadResponse function.. The request will be marked as an error if the success property of the response is \"falsey\". An empty object falls into that category. . I don't think so. This could have a substantial impact on existing servers that depend on the current behavior. In other words, even if the response code is 2xx, you can signal an error simply by not returning a JSON response with a success: true property. This was especially important in IE9 and older, which are still technically supported by Fine Uploader.\nI would consider this a breaking change, and, as a result, I can't release this without moving to version 6.0.0. I do have a (stale) v6 branch which I hope to get back to at some point. In that branch, I may very well remove support for all but the most current browsers (support for anything older than IE11 will be gone). There are likely already some open cases that are targeted for 6.0 that should make the response handling logic less awful.. Thanks for you time. Sorry I couldn't merge this in.. Where are you looking for these files?. yep - that was me. I forgot to upload the zip files for those that download from the website instead of via npm.. 1. Please do not delete the issue template. It is there for a reason.\n2. Please spend some time learning how to use markdown. Your code is very hard to read due to lack of formatting.\n3. The error message indicates that you are attempting to upload to an AWS region that only supports version 4 signatures. Read the v4 post at https://blog.fineuploader.com/2015/11/16/fine-uploader-5-4-aws-s3-version-4-signature-support/ for more info.. No idea. I don't see how this is a Fine Uploader issue - the error is coming from your backend code. If you can point to a specific problem with the client-side code, let me know.. No, that is not possible as far as I know. But you can verify by looking at the request. Yes you can change it. See http://docs.fineuploader.com/branch/master/api/options.html#request.inputName.. No, you must return JSON with a success property containing a value of true. This may be relaxed in a future breaking change release, but this has been a requirement since day 1.. Please do. OSS is meant to be modified.. I'm curious what is left before this can be pushed though. Is there anything I can do to help?\nNote - I just added a new method that will need to be accounted for here.. IDs are always file IDs . I'll spot check the defs, there are too many to  completely review. We should be able to eliminate the definitely typed defs after this is merged, correct?. After a quick glance, everything looks good, except for one thing - in cases where Fine Uploader returns a \"Promise\", it actually returns a qq.Promise, which is Fine Uploader's completely non-standard Promise implementation that I wrote which predates the spec, or at least my awareness of the spec. I have an open case to fix this - #1642 - but that would be a breaking change and can't happen until at least 6.0. . Excellent! One more thing - will these defs be picked up when Fine Uploader is installed via npm? It doesn't look like they are even part of the npm package, since the Makefile's setup-dist recipe contains the logic for generating the package, and the typescript folder is new. You should be able to test before even publishing to npm by following these steps:\n\nmake publish simulate=true\ncd _dist/5.14.0-beta1\nnpm link\nGo to whatever directory/project you want to install Fine Uploader to\nnpm link fine-uploader\nMake sure your TS project is able to see the defs.. Tweeted from the Fine Uploader account, but couldn't find your Twitter account. https://twitter.com/fineuploader/status/830975906852241412. Thanks for the report. Can you please fix the code formatting in your question?\n\nThis seems like an edge case, so it's unlikely that I will get a chance to look into it. But a pull request with a fix + tests will push this through faster.\nThe priority of this changes a bit if you can demonstrate an issue this causes. I'm also wondering if this is a timing issue. How much time elapses between steps 2 & 3? Must it be a small amount of time, or does that not matter?\n. Thanks. Going forward, please read the issue guidelines before opening new issues.. Not sure what happened - re-running the build results in green. \nThis looks good, but two additional requests, if you could:\n- [ ] Write a unit test to cover this new behavior\n- [x] Update the documentation to let future integrators know of this possibility. Thanks for the doc update. There are some existing integration tests for the S3 uploader. One tests a number of different failure scenarios. Perhaps you could copy that logic and simplify it a bit to form a new test that focuses on ensuring this results in a failure of the upload. \nI realize this does not test for the presence of the custom message after the failure. Another (possibly better?) option would be to test the handleSignatureReceived method in isolation. If you new qq.s3.RequestSigner({...}), you should be able to access the handleSignatureReceived implementation through the onComplete property on the constructed instance. You could then perhaps mock the parameters as appropriate, and test for the rejected promise value.. Awesome, this looks good. Thanks for your work. I'll release this as 5.13.0 sometime soon, possibly even this weekend. . Just released as 5.13.0.. Thanks for summarizing the issue and bringing this to my attention. A few things to consider:\n\nIf content-length-range is not included, the file size is unrestricted anyway.\ncontent-length-range is only sent for non-chunked requests (requests smaller than 5 MiB by default or when uploading through an ancient browser, such as IE9 and older).\nThe inclusion of such a header, unvalidated by the server, seems to present no additional risk than if the header was omitted. Server-side implementations should check for this header if this is an important restriction.\n\n\nbad security practices as some incorrect server side implementations may implicitly trust the client provided value\n\nThis is a problem, but not one that Fine Uploader (or any client-side library) can solve.\nAlso, this would be a breaking change, so there is no chance this will be introduced anytime in the near future.. Cool, thanks for the follow-up. And I do appreciate the your input on this as well.. >Why cant we remove the cache control header from the request using an option?\nBecause there is no such option...yet.. Build instructions are at https://github.com/FineUploader/fine-uploader#setup. If you find an error with the instructions, please report it. Issuing a pull request with tests is the quickest way to get a feature into the mainline.. This doesn't seem to be a bug or a feature request. For support, please post a well formed question on stack overflow, and please read the \"how to ask a question\" guide first.. True - that makes this any proposed changes to the library much less important.. let's discuss further on SO. I think this is best addressed by adding a capture option that takes a boolean which maps to the capture attribute on the file input element. Defaults to false. Would you be able to open up a pull request to address this? . Not sure I understand what you're saying.. Still not sure what you are saying.\nWhat I'm asking is: Would you be interested in opening up a pull request to include this option in the source code?. Thanks for the report. If you'd like to see this in a near-future version of Fine Uploader, a pull request will speed things up. I don't anticipate that I personally will have time to address this anytime soon.. no idea. that's been in place for at least 4 years most likely. inconsistent code evolution?. This doesn't seem necessary. You should be able to observe the existing onStatusChange event instead, looking for a newStatus of qq.status.CANCELED.. Not sure I understand what specific asynchronous task you'll monitor/create in your onComplete handler. Can you explain a bit more?. How are you going to monitor this specific operation in your handler? And why not simply defer the response to fine uploader from your server until the second process has completed?. This introduces complexity for very little gain, and I think your use case is best solved by responding to fine uploader when all related server tasks are completed instead. I appreciate the report though.. Ah, I didn't realize this was related to react-fine-uploader. One nitpick: <Thumbnail /> is not a stateless component.\nIf there is something specific missing from react-fine-uploader that could make this easier for you, please open up an issue in that repo so we can discuss further. Thanks for the update.. Yes, please do open a PR. I'd love to discuss. Fair warning: I'm discerning (some would say annoyingly so) about code that goes into a number of my libraries. I'm big on pairing new code with automated tests and comprehensive documentation. I also try to be careful to keep the behaviors/API simple and intuitive, favoring integration code over in-library code wherever it makes sense. What this means is that sometimes documentation is more appropriate than adding more code to the library. Just wanted to mention this, so it doesn't seem like I'm being arbitrarily harsh. I do appreciate contributions whether they make it into the library or not.. As the issue template asked, please show your code. And also let me know when this last worked (version). Looks like this may have never been implemented for chunked uploads. The safest option may be to check for newUuid on the response to the request made to the chunking.success.endpoint. . That may have made sense a while back, but the concurrent chunking feature changes that a bit. Since it was never implemented, or at least it hasn't been possible for quite a long time, it's not clear to me now if that was ever a reasonable assumption. Again, the safest approach at this point seems to involve mandating the newUuid be returned in response to the success endpoint. I'll leave this open as it must be addressed. It is indeed a bug.. Since I believe implementing this will be non-trivial, I plan to wait until I hear from other users who depend on or expect the ability to change the UUID of a file via an upload request response.. Depending on your needs, this may help https://docs.fineuploader.com/branch/master/api/methods.html#setUuid. >I want to handle the file delete process without doing an ajax call.\nHow would you do this, exactly?. So you are using an ajax request to delete a file, but you want to do this outside of Fine Uploader.. Interesting. On a related note have you see the (in progress) Vue Fine Uploader project?\nI can see the need for this, but there is a bit of a problem: simply changing the status of a file is often not sufficient. There is other internal logic that leads up to a status change. You can see an example in the internal _onDeleteComplete method, where a number of internal state items are updated before the file is marked as deleted. \nI think it makes sense to expose setStatus, but I don't anticipate allowing all status values to be set initially. Perhaps support for all status items could be phased in over time. Initially, qq.status.DELETED and qq.status.DELETE_FAILED would be the only status items supported, and this would require some internal refactoring to tie the logic in _onDeleteComplete to a requested state change of qq.status.DELETED or qq.status.DELETE_FAILED.. I think your suggestion may be easiest, but it sounds like a hack to me, and there may be real benefit in exposing, or at least starting to expose setStatus. The path forward for a library of this size is to make integration as easy as possible, and that means Fine Uploader's API needs to be flexible. . That sounds good. I'm not sure exactly what the code will look like yet, but it should be easily extensible to support more status updates later. Also, for the delete case, we'll need new unit tests to cover this new feature. There are existing tests to cover the current behavior in the delete-file.js test file. Perhaps new tests to cover setStatus with the two deleted status values could exist in there. Or maybe it is more appropriate to create a new setStatus test file.. Thanks! After I get some time to do a little manual testing, I'll merge this into develop and publish as 5.14.0-beta2 if all looks well.. I ended up merging this in via the command line. I did this as I encountered a few unexpected issues during manual testing, which I fixed. The issues were:\n\nUI does not update when file is deleted via setStatus().\nError message was unhelpful if file ID is not valid.\nA file could be marked as deleted several times, messing up internal status (such as the net files count).\n\nThere were also a couple documentation issues that I missed during my review.\nBut all is well now. Thanks so much for your help! This has been released as 5.14.0-beta2, now on npm.. That's not the official changelog. I used that for a while, but decided to move the changelog to the repo itself at some point. See the releases section in the repo for details: https://github.com/FineUploader/fine-uploader/releases. https://github.com/FineUploader/fine-uploader/blob/develop/.github/CONTRIBUTING.md. Sorry, I'm unable to reproduce without seeing your code. This sounds like an issue specific to your setup/code, but I'll be happy to consider re-opening once you update the issue with all of the code needed to reproduce.. Nothing is attached. It is possible to use it with any framework, of course. Why would it not be? \nBefore you ask any further questions in the issue tracker, please read the contribution rules. They are linked to at the top of the new/create issue page.. >My concern is that because I'm using an undocumented private API, my application might not be compatible with future versions of FineUploader.\nThis is a valid/correct concern. Underscored properties are not part of the public API and may change or be removed at any time without notice.\nYour best bet is to utilize the fact that both onCancel and onSubmitDelete allow for promissory return values. In that case, you can do the following for each of your callbacks:\n\nReturn a Promise\nAdd the \"ng-leave\" className to the underlying file element. You can find this element using the getItemByFileId() UI API method.\nAfter the desired time has elapsed. Add the \"ng-leave-active\" className to the element.\nResolve the Promise.. I'm not sure why you deleted the template, but if you have some ideas as to how this can be started, please do open up a pull request.. Thanks for the PR! I'll take a closer look as soon as I get a chance, but I would suggest you remove the UUID parameter. It's redundant and can be determined given an ID using the getUuid() method.. You may need both parameters, but others may not. For consistency, please stick to the single ID parameter.. Looks good! I still need to do some manual testing. If that is successful, I'll merge into develop. I've marked this and your other recent PR for 5.15.0. I plan to release 5.14.0 in the next few days.. Say, you've contributed quite a few high-quality PRs lately. I've been looking for a second maintainer for a while. I've been the only consistent maintainer of this library since 2012, and I could use a second dedicated person. Is this something you're interested in? If so, follow me on Twitter and we can discuss in more detail over DM.. Totally understand. If you change your mind, do let me know. When I was tapped to take over Fine Uploader back in 2012, I felt the same way, but it turned out to be a very worthwhile endeavor that opened up a great number of new doors. I wrote about this a bit at https://medium.com/@RayNicholus/disrupting-open-source-the-story-of-fine-uploader-80160eb557d9#.qiez71c3z.. I haven't forgotten about this. I'm in the process of switching jobs, so I have very little time to dedicate to Fine Uploader or other projects during this transition. I hope to get back to a normal OSS contribution schedule in the next couple months.. This isn't a feature request, you've asked for support. Before you ask any further questions in the issue tracker, please read the contribution rules. They are linked to at the top of the new/create issue page.. I see your point, but we'll need to define \"metadata\" exactly first, in the context of Fine Uploader S3. And second, we'll need to make appropriate changes to the code that serializes data to localStorage. I'm a bit apprehensive about that second step, as I don't want to run the risk of running out of space, since localStorage space is limited to about 5 MB or so.. Also, this is more of a feature request than a bug. Fine Uploader S3 functions as designed here.. Age of records is already a configuration point. Another tricky implementation detail: ensuring this does not break existing/persisted resumable files. I'm also quite concerned about unintended consequences of implementing this feature. Seems possible this will prevent resume from occurring unexpectedly for some integrators. Not sure I agree with invalidating the resume record if the parameters don't match. In your case you're probably better off attaching metadata server side after the upload completes, or tracking this in a DB, for example, outside of the actual S3 object.. Sorry, decided to not implement. I'm finding a possible need to the ability to store additional data in resume record keys. So I'm going to re-open this issue.. Note that this should be addressed in #1917.. Sounds like itemLimit was simply not accounted for when handling extraButton validation. Some investigation is needed to determine how difficult/possible it is to address this. . This is pretty low on my priority list at the moment. It's unlikely I'll get to this in the near future. That said, you are free to look into the issue and help push this forward. I'd be happy to offer advice/assistance.. Please open a pull request. This will allow us to discuss the changes a bit more formally and efficiently. . Closing due to lack of runnable example code. If you edit your question to provide complete code, I will consider reopening.. Please edit your question and include the code.. If you want to prevent auto-retry, your server must return a JSON payload with a \"preventRetry\": true property. This is mentioned in the server-side documentation page for traditional endpoints.. Yes, possibly. The question is: how can we best do this? Perhaps we could start simple by disabling auto-retry for 413 responses, or perhaps include a few other status codes that also indicate that the request should not be retried. This logic must be implemented in the _onAutoRetry internal method.. We can either wait for more changes to pile up, or we can release this as a hotfix: 5.14.1, or as the first beta in 5.15.0 (5.15.0-beta1). Thoughts?. roger - i'll push out 5.14.1 ASAP\n\nFuture reference: I'd like to see PRs squashed w/ a descriptive commit message when merging into develop. Merge commits just clutter up the branch history. The commit history is easier to parse w/ 1 commit per PR.. Released in Fine Uploader 15.4.1. Thanks for you work on this @SinghSukhdeep and @artursvonda.. Can you provide more detail? Why do you need to send a request to the server before the upload starts? What is the nature of this request? Can it not be sent in your onSubmit handler?. >I modified the fineuploader with another status of AlreadyExists, and set the status to this so the other events do not trigger on it.\nWhy not just return a Promise in your onSubmit and reject it if the file already exists?. duplicate of #848. I believe the problem is with the thumbnailUrl returned from your server. You're returning what AWS calls a \"path-style\" URL to the object in your bucket: https://s3.amazonaws.com/bucktname/xxx.jpeg?AWSAccessKeyId.... Since your bucket is located outside of the US East region, you must use the region-specific domain name. In your case, that would be https://s3-eu-west-2.amazonaws.com/bucktname/xxx.jpeg?AWSAccessKeyId.... This can be avoided by instead using a \"virtual hosted\u2013style\" path to your bucket, such as https://bucketname.s3.amazonaws.com/xxx.jpeg?AWSAccessKeyId..... That's a temporary solution. But I think the best solution is to change the logic in the Fine Uploader PHP S3 repository to always return a thumbnailUrl using the virtual hosted-style path format. I can't think of a good reason to use path-style urls, unless the bucket name is not DNS-compatible (which isn't supported outside of US East anyway).. I'm having some trouble understanding your question. Can you try to re-phrase and clarify what you are looking for? . >so that server side fileSize can be used to resume the upload \nThere is a lot more information needed other than file size to resume a file.\nThe only reasonable way to do this would be to export the resume record(s) generated by Fine Uploader, store them server side, and then feed then into Fine Uploader via an API method.. The only reasonable way to do this would be to export the resume record(s) generated by Fine Uploader, store them server side, and then feed then into Fine Uploader via an API method.. I'll admit I'm having a lot of trouble following your logic and your code. But it sounds like you want to be able to supply resume records from the server, and not just rely on localStorage.  In that case, I'm not sure why you are focusing on file progress/events. Progress really has nothing to do with resuming file uploads. I encourage you to take a close look at the resume upload logic in the library.\nHaving a complete understanding of the library and the various workflows: I think exporting the resume records and then re-importing them later would be, by far, the simplest route as well. This leaves a lot less margin of error as well.. What I am trying to avoid is exactly what you are doing: \"had to use the above method to change both the UI progress bar percentage and chunkParts\". If you have a valid resume record, and the user drops/selects a file that matches the record, everything will \"just work\". So providing a way to export these records and store them wherever you like, along with an API method to import them again later from your storage location of choice, seems like an intuitive approach here.. Whatever this is, I'm not going to implement it. Not seeing a question here: closing.. looks like you have created two PRs for the same issue - please close one.. May be a little while before I can take a look at this one - there are a number of others ahead in my queue, but it's on my list. Thanks for your patience.. Sorry, I can't accept this. It looks like you've simply attached a patched version of one of the many built versions of Fine Uploader. Pull requests should include modifications to one or more of the source files, in the client directory of the project.. please mark these issues appropriately. sorry, again not really understanding the question/request here. are you asking for a third callback for you to reject files? Can you describe exactly what this callback would be used for (not just for you but for others)? And what specific problem are you having that cannot be solved with the current API/events? . sorry, but this is a really very poorly written feature request. I don't really have time to ask questions just to figure out exactly what is being asked, why the requested feature is useful for a general audience, and whether the issue is a support request or a feature request. This is why I setup the template. Please spend more time curating/explaining/organizing your issues before you file them. The last several issues you've commented on have left me puzzled.. tags backfilled in FineUploader/docs.fineuploader.com@2829e2f381cb32647c1a5fc0e6640946fc553964. Docs hosting has been switched from a closed Dreamhost server to GitHub pages and docs generation now happens on Travis-CI as part of the fine-uploader build.\n\ud83d\ude03 . >Is it possible to add element.innerHTML = text; to setText()\nIt's possible, but I don't want to do this. The expectation is that you input text, not HTML, given the name of the method. This would be a breaking change.\nRegarding the other unrelated issue (#1649), please comment in that issue.. oh FFS. Ha! Nice issue type improvisation. This predates my involvement in Fine Uploader (project was created in 2010, I took over in 2012, more history in my Medium article on the subject). Andrew Valums, the original creator, was looking for a short and unique namespace for the library. Apparently, qq fit the bill. \n. going to close this - but am not opposed to continuing the discussion. >as soon as I try to add it to the filelist\nHow are you doing this? Please provide all related code.. can you please fix the formatting in your code? it's very hard to read. It's very possible that the file has not completed processing before you call uploadStoredFiles. There are a number of possible async tasks that Fine Uploader performs on each file before it is ready to be uploaded. This is why you should generally rely on callbacks. In your case, the file is ready to be uploaded when onSubmitted is called for that file, or when the file's status is updated to qq.status.SUBMITTED.. Something is invalid with your \"file\" or environment then. You'll need to set some breakpoints or logging statements in the code (specifically in the addFiles method of uploader.basic.api.js) to figure out why your file is not able to be handled by Fine Uploader.. >is there some easy workaround for this?\nNo, you must pass either a File, a Blob, a <canvas>, or a <input type=\"file\">.. Going to close this as I'm not sure what else I can do to help. You'll need to be sure you are passing one of the above types. If you can identify a bug in the library, please let me know so we can discuss. Alternatively, if you can identify a specific improvement that would help your case, let's also discuss that.. Can you show some code that details your workaround?. Are these large files? If so, is running out of memory a concern?. When you call setDeleteFileEndpoint, you are changing the delete endpoint for all files. It probably makes more sense to use a single endpoint with parameters that vary per file. For that, use the setDeleteFileParams method.. Sorry, this is not a feature request, and your question is far too broad. Please re-open when you are able to show some code with a specific question. Take a look at https://docs.fineuploader.com/features/forms.html for help with forms.. Not a TypeScript user myself, but perhaps @SinghSukhdeep can shed some light on this issue.. Is this issue specific to typescript? I'm importing fine uploader in several projects using es6 imports without issue. Not sure if export { qq } is what we want. That will always export 'lib/traditional.js', no? What if the TypeScript app uses Fine Uploader S3? Again, not very familiar with the TS world.. Do you think https://docs.fineuploader.com/features/modules.html would the the best place to locate the TS integration instructions? I'm also wondering what specific named exports you think would be appropriate in the context of TypeScript.. If you are using Fine Uploader UI, you need a template. See https://docs.fineuploader.com/features/styling.html or the demos on the home page.. The error indicates the template is not on your page, so you'll want to next figure out why the template is not available at the time the Fine Uploader instance is created.. Ideally there would be an Angular 2 implementation of the UI portion of Fine Uploader, similar to React Fine Uploader and Vue Fine Uploader. But, for now, you'll just have to ensure the template is in the DOM before you instantiate Fine Uploader UI.. @rainstormza The issue is likely due to the fact that the template is not in the DOM when your Fine Uploader instance is created. So either the <script> with the template is never added to the DOM/page, or it is added before Fine Uploader is instantiated. I'm not very familiar with Angular 2, so I can't assist much more with that. @SinghSukhdeep is much more knowledgeable in this area. . >thanks for your helping\nmai pen rai krap. There's a lot of improvements we can make to Fine Uploader - this is one of them. My apologies in advance - I'm very deeply involved in some non-code-related endeavors at the moment. It's possible I'll be able to focus more on Fine Uploader in a couple weeks again, but this may last for several months. . going to sit on this one for a bit, since this is the 5th hotfix for uglify in the last few days. It sounds like you have two templates, and you need template A for one scenario, and template B for a different workflow. Is this correct?. Ok, just to further clarify - you really only want to load one template, but you need two separate instances of Fine Uploader on the same page? Or do you need a single instance? I'm not following the workflow. . I see - in that case, as long as you've included the template in your document, there is nothing further required. The template must be present somewhere in the document before the Fine Uploader UI instance is created. By default, it will expect the template to have an id of \"qq-template\". You can override this using the template option.. Closing this as I haven't heard back in a while and it looks like the question has been answered.. In your first code block, you'll need to locate the instance of Fine Uploader in order to call API methods. You haven't shared your initialization code. If Fine Uploader's jQuery wrapper is bound to an element with an className of \"div-container-file-uploader\", your code would look something like this:\njs\nvar submittedFileCount = \n   $('.div-container-file-uploader').fineUploader(\n      'getUploads', \n      {status: qq.status.SUBMITTED}\n   ).length\nMore information and examples are available on the jQuery wrapper documentation page.\nRegarding your second code block - most likely you are executing this only once, before any files have been submitted. Your code does not suggest otherwise.\nPlease note that the jQuery wrapper will be removed in Fine Uploader 6.0.. You'll need to assign the result of new qq.FineUploader to a variable and call the method as indicated in the docs.. You'll need to assign the result of new qq.FineUploader to a variable and call the method as indicated in the docs. For example: \njs\nvar submittedFileCount = \n   uploader.getUploads({status: qq.status.SUBMITTED}).length. This is due to the default value for the validation.stopOnFirstInvalidFile configuration option. Setting that to false will process all files instead of stopping when an invalid file is encountered.. Unclear as to what the issue is exactly, or how to reproduce. Are you saying onComplete never fires in Chrome for any or the 3 completed files after following the steps in your report? If this is indeed a Chrome-only issue, perhaps there is some issue with an installed browser extension on your end? If onComplete is not fired, this indicates that the request did not complete for the associated file.. Still unclear on the steps to reproduce. If I select 1 file and upload it in Chrome, are you saying that onComplete is not called when the upload request completes?. Ok - please set the debug option to true and include all console logs in your description when reproducing the issue.. Looks like something on your end is cancelling the upload or resetting the uploader. That would explain why onComplete is never called.. according to the logs, the uploader is reset before the upload completes\n. sure thing. may i ask why you are calling reset at all?. I'm changing this to a support request (from a feature request) as this better describes the issue in my opinion.\nYou don't want to use the thumbnail image for a gallery - these are very small. Instead, you'll want to generate a larger preview, ideally on-demand, and display that in a lightbox gallery. I did just that in an Angular v1 integration example. You should be able to pick out the portion of the example that generates that larger thumbnail and displays this in a lightbox for your purposes.. >Would it be possible to include a qq-specific tag on the img element?\nOf course you can update the DOM however you want, but why do you want to do this specifically? What new problem are you trying to solve?. Did you see my original message?. Here's an alternate approach you can use if you're dealing with pre-populated/initial files as well:\n1. Add a single click handler to the element that wraps the entire uploader\n2. If the clicked element is a file <img>, use the getId method to determine the file ID.\n3. Call drawThumbnail to generate a large preview on a <canvas> or <img> element, which can then be rendered inside of a lightbox. This is also demonstrated in the demo I linked to previously.. No prob. Please also consider wrapping each <img> element in a <button> to make them properly accessible as well.. To which request do you want to add headers? The upload request? Or something else.... when do you need to set the header? when is the information you need to set the header available? Must the headers vary with each request?. You can set the upload request headers at any time using setCustomHeaders on the uploader instance. You should pass an object with header names & values, and optionally an ID if you want to target a specific file. For delete file requests, you can set custom headers the same way using setDeleteFileCustomHeaders.\nYou'll need to pick the appropriate callback or event handler to make these calls, depending on your needs.. I'm not sure what you are referring to. \nOnce you have a handle on the uploader instance, you can call any API methods listed in the documentation. For example, if you need to set a custom header of \"Foo\" with a value of \"Bar\" for all upload requests, your code would look like this:\njs\nuploader.setCustomHeaders({ Foo: 'bar' })\n...and if you only want to set this header for an upload request for a file with an id of 3, your code instead would look like this:\njs\nuploader.setCustomHeaders({ Foo: 'bar' }, 3)\nYou can follow the same pattern for setCustomDeleteFileHeaders. For more information on callbacks and how to use them, please see the callbacks section of the documentation, and/or the demos on fineuploader.com.. No problem. Let me know if I can be of further assistance. Can you verify that this actually fixes your issue. I'm not sure it will.. Closing due to lack of feedback.. Sorry, but there's not much help I can offer. If you were unable to uncover the reason for the 500 error on your server, there is certainly no way for me to make that determination. Perhaps the response body will yield some clues.. >This would seem to indicate that our web server has no real issue accepting the file, just when it's transmitted via fineuploader.\nFine Uploader sends standard multipart encoded upload requests by default, just as if the files were sent by a traditional form submit. The issue is most definitely with your server. Take a look at some of the Java server-side examples for reference.\n\nIs there anything I can add to the javascript setup to help track down why it might suffer this when using xhr?\n\nThe issue is server-side, not client-side. So you'll need to either inspect the response payload in the browser and/or set breakpoints or log messages on your server to determine where the problem lies.. This is an interesting issue. The key here is to understand that form fields are addressable by their name attribute as properties of the HTMLFormElement object. So, since you have an <input type='submit' name='submit'>, that element can be accessed as document.getElementById('qq-form').submit.\nNow, Fine Uploader attempts to extend the submit function that is present on all HTMLFormElement objects in order to inject additional logic into the submit process if/when the submit() function is called directly. Since submit actually points to the submit button you have declared in your form (since it has name='form'), Fine Uploader is actually overwriting that HTMLInputElement. Apparently Firefox explicitly prevents this, which is not entirely surprising.\nQuick fix: remove the name='submit' from your submit button, or change the name to something else.. If you require help, you'll need to follow the instructions presented to you in the new issue description.. Please add a console.log for each record in the getUploads() call that you are iterating over, and include the output in your question.. localStorage is only used for the resume feature. These records wouldn't be returned by getUploads() unless corresponding files were added to the uploader as well. Going to close this, but happy to re-open if you can reproduce w/ logs.. Thank you for your work on this, and for bringing this to my attention. I find that I learn more about S3 through user-contributed issues and PRs in this project than anywhere else. This is interesting, and appears to be a low-risk addition, so I don't see an immediate reason to reject this outright. As you said, the tests are failing though. One other note, SSE w/ KMS is only supported when using v4 signatures, so that would require some changes to your PR I believe.\nCurrently, my priority is to release Fine Uploader 5.14.2 once #1802 is solved, which is needed to push out the first stable release of React Fine Uploader. I'm also about to start a new job, and I'm the only consistent maintainer of this large suite of projects. So, it may be a while before I can take some time to code review and offer assistance here. But here's what I think is needed to push this forward:\n\nUpdates to reflect that this feature is only supported w/ v4 signatures.\nPassing tests.\nUpdates to the documentation (in this case, the S3 feature page + options).\nA full code review by me, which may result in more requested changes.. No plans to do this, thanks. Please properly format your code. I'll also need some more concrete examples, such as a specific image used to reproduce. If you can link to a live site where I can reproduce, that will speed this up the most. That will definitely not work reliably. what version of pica\n. Cold be an issue caused by breaking changes in Pica 3.x. That will probably need to be sorted out in Pica or integration code. I don't plan on making changes to Fine Uploader to accommodate changes in one specific 3rd-party lib.. there must be some specific issue with your environment as i cannot reproduce and yours is the only report. onUpload will not be called as nothing is being uploaded.. Listen for onSubmitted. For initial files, once a status changed of qq.status.UPLOAD_SUCCESSFUL Is broadcast, that initial file is now in the DOM.. please fix your formatting. code & html. thanks. which exact line is causing the failure? You'll need to use an unminified build or pull in source maps. I'll consider reopening when you are able to provide more specific information regarding the error, such as the line number in a specific unminified build.. The error indicates that your signature server is not returning valid JSON. Perhaps it is returning HTML or XML, based on the first character in the response.. > the php-s3-server still says {\"invalid\":true}\n\nYou'll need to look closely at your code and determine exactly why it is including this in the response.. Are you seeing any progress bar(s)? For any uploads on Firefox Android?. I don't have access to this environment, so you'll need to take a closer look and let me know where the problem lies. Assuming a new qq.TotalProgress instance is created, something is preventing the passed in callback function from being invoked.. Doesn't sound like an issue with Fine Uploader. Perhaps something to bring up on bugzilla? If you can demonstrate that this only exists within Fine Uploader, I'll be happy to re-open.. Works for me. Use JavaScript to set the disabled attribute on your inputs. Not a Fine Uploader issue.. Short answer: no. But in v6.0.0, which may be released in the next 10 or 20 years, the requirement to return a JSON response with \"success\": true will be removed. See #1325 for details.. Good deal, thanks!. As luck would have it - i may need this fix for one of my projects too! So I'll be looking closer at this very soon. I independently verified a similar approach, and I too am trying to integrate Fine Uploader on a page w/ react-dnd.. All moderns browsers check out except for Edge 41 (which still triggers Fine Uploader's DnD behavior when dragging non-files). I'll look closer tomorrow in hopes that Edge can be easily covered too.. False alarm - caching issue in Edge caused the above problem. Looks like we're clear to merge and release as v5.15.2. I'll do that very soon.. Just released 5.15.3 which should contain the fix. All of my other projects lack a develop branch, and I overlooked the fact that Fine Uploader has a develop branch in addition to master, which caused some confusion for me when publishing. I removed develop today to prevent this from happening in the future since develop isn't really serving a purpose anymore.. Closing due to lack of code. I will consider re-opening once you provide at least executable code to demonstrate your issue.. duplicate of #1577. This should be technically possible to achieve with Fine Uploader, but some adjustments are needed to the codebase. The process of streaming a large file to S3 using the multipart upload API (which Fine Uploader already uses for large files) is explained at http://stackoverflow.com/a/8881939/486979. I think adding support for a stream, where Fine Uploader accepts Blobs or a typed arrays with the segments of the video as it is being streamed. I'm not yet sure how you will generate this, so further discussion is needed to determine how to best support this workflow.. I'm not sure a web-based file uploader is the best choice for your situation. It sounds like you will be ingesting video onto a local filesystem. In that case, you are best looking for native (not browser-based) tools that will upload the video file as it is updated directly to S3.. The HTML Media Capture API (a W3C candidate recommendation as of yesterday) makes it possible to capture media from devices attached to the browser's machine via the file input element (such as a camera or mic). Unfortunately, support for this new capture attribute is currently limited to mobile browsers.. It's not clear what specific question you are asking here. Can you clarify? The 504 is an issue beyond the control of Fine Uploader.. the timeout has nothing to do with the retry - but the 504, which fails the upload, is likely the cause. but this is expected if you've enabled autoRetry. You haven't listed any of your code, as requested in the issue template, so I have to assume you've enabled autoRetry.. since you have access to the dropped files, you are able to validate these files however you choose before passing them onto Fine Uploader. Does look like a legit bug, but I haven't noticed as I currently manually build/publish from one of my dev machines, which are all Macs w/ HFS+ filesystems.. Sorry, I'm not able to help with .NET request signing code. Your best bet for that is Stack Overflow.. looks like a temporary Travis issue, somehow the server port was already in use. Restarting the build fixed it.. I'm a fan of squashing all commits into one with a single descriptive commit message. \nUnfortunately I haven't fully automated releases yet or setup anyone other than myself to publish to npm, but I'd like to change that.... probably need to cut a new release, push to npm, github releases, etc. @SinghSukhdeep are you interested in becoming more involved in this project? If so, I'd like to give you the power to do all of these things.. So as much as I'd like to release this, the build is failing due to something Travis-CI \"engineers\" broke on their end (which tends to happen far too often). So I'm going to have to hold off until both this is fixed and I get another block of time to release a new version. Sorry.. honestly don't know when i'll be able to come back to this, so i was able to work around Travis' latest bug, and released 5.14.3.. I've seen this message a thousand times and it always means that your server is not responding with valid JSON.. I would start by looking at the response. 0 = aborted xhr request. Probably a bug, but really a very benign one. The upload has already failed, so i'm not seeing how additional error console logs is much of an issue. Not likely I'll be able to look into this myself, but if this can be resolved cleanly with a PR, that may help.. Please open a PR. Fine Uploader doesn't upload folders - it uploads files. So, if you drop a folder, all files in that folder and all other folders in that folder will be uploaded in dedicated requests.. most likely due to small files. > IE 10 throws an exception when used with an if-else.\nCan you expand on this? Yours is the first such report, and this code has been live for quite a long time.. sorry - i don't have a lot of time to keep up this lib lately, though I am working on some big changes in https://github.com/FineUploader/fine-uploader/tree/feature/flexible-upload-support. At some point, I don't expect to support anything older than IE11 anyway.... please show your code. What does updatedParams look like exactly?. The document you are referring to was written by me, before TS support was added. And I don't personally use TS, so it's likely we need dedicated TS docs too.. Are these the breaking changes you mentioned to me earlier? If so, looks like this only affects Typescript users. Is this correct?\nDocs look fine to me. I generally only use let if I know a variable needs to be changed, which means I default to const instead. But that's really a nitpick here. \nFeel free to merge and release. Please do familiarize yourself and follow the release (and also the merging) guidelines at https://github.com/FineUploader/fine-uploader/wiki/Maintainers-guide first.. I'm fine with let, but my point is const is usually more appropriate. Both compile down to var, but const gives you additional safety checking at build time. \nLet's continue to follow semver when deciding version number. If this fixes a bug only, patch version increment. If it's more if a feature, minor version increment. Can you comment on the scope of breaking changes for typescript users? How substantial are the breaking changes?. code please. I honestly can't remember why we send this policy condition. May be best to just turn it off? I can't remember the logic offhand.. probably a code change - haven't looked yet. do you not plan on using chunked requests or uploading large files?. >Why not generating the policy direcly on the backend? We'd have control over the key (#1120), we can change the destination bucket on the backend, acl, region, expire date,...\nIt is not that easy. If you change/set the bucket or region, etc on the backend, how does Fine Uploader know about this? I guess it would have to parse the policy file? And, as mentioned before, this only covers non-chunked uploads anyway.. any reason you asked a question on SO and filed an issue here?. this belongs in the react-fine-uploader repo. You can get a handle on a file element in the UI via getItemByFileId, which you can remove with Node.removeChild.. I  do not have any recommendations. Really having trouble believing that this is necessary. The S3 upload code has been around for years, and this is the first time the issue has surfaced.. >It is worth mentioning that I need to be able to control the entire process, and I don't want any special UI generated by fine uploader.\nWhere is your current UI?. And the problem is?. sorry, i don't understand. First off changing the page URL using a click handler makes no sense. That's why anchor links exist.  set the href of your anchor link when the file status is qq.status.UPLOAD_SUCCESSFUL and be sure your version of the lib is up to date.. And if that isn't working for you for some reason, you'll have to look closer at your code. I'm sorry but I don't have much time to beg for information in order to provide support. You've provided nothing in terms of a runnable example or even information about what is and isn't happening when your issue occurs.. If you do find a specific issue in the lib, please open a pull request, with tests. The issue you are describing is already covered as far as I know. Awesome. Thanks for this!. looks like a dupe of #1846. not really sure what is causing this issue, will require further investigation. Can you open a PR?. please fix your code formatting. not sure what you mean by \"insert code\". Code formatting is explained at https://help.github.com/articles/creating-and-highlighting-code-blocks/. I'm low on time these days to step in regularly to look into these types of issues. But I'm optimistic that I will secure a regular maintainer to help out.. >I'd fork & submit a pull request, but removing var qq = ... from dnd.js would make dnd.js NOT function stand-alone. \nInstead of overwriting, why not check for window.qq first, and extend it?. Did you try out the above workarounds/solutions?. This is not something that is causing issues for me in any of my projects using Fine Uploader, but if someone here is able to commit to verifying a solution, i'm willing to write the code and then release a new version with a fix.. Are you saying the customize page only provided two versions of the dnd module, and for some reason you used them both for some reason? That is what you have said above. Or is that a typo?. if someone here is able to commit to verifying a solution, i'm willing to write the code and then release a new version with a fix.. the easiest solution here is to just not use global variables, for this exact reason. yes, this should still be supported - can someone commit to testing my fix (once I have time to write it)? Or, if someone wants to try a PR, that would be great too. PRs are accepted here. If someone has the time to submit a PR with a fix, I will review, but I don't currently have the time to address this particular issue myself.. I've also asked several times for someone to even volunteer to verify a fix, and have received zero responses, which does not give me great motivation to work on a fix that does not affect me.. Thanks @jimmalone, but i don't currently have time to work on this specific issue as others have higher priority at the moment. I'll get to this when I have time again. In the meantime, if anyone wants to try a PR, let me know.. No, there is not. The angular integration example should provide you with the information you need.. This is explained on the concurrent chunking feature page. Reading this will clear up your confusion on the matter. https://docs.fineuploader.com/branch/master/features/concurrent-chunking.html. yes, it is. Simple remove the thumbnail elements from the template, or do not use Fine Uploader UI at all - simple use the core APIs and build your own UI.. why are we singling out Edge here? why not just do this for all browsers?. Sorry for the delay. I'm in the process of moving Fine Uploader to a free/self-sustainable services before I step away from the project completely. Also looking for a new maintainer.\nI'm merging your changes now.. Not an issue with the library. Fine Uploader reports file sizes directly from data supplied by the browser/OS. Based on the referenced PR, that fix does not reliably work. I'm personally not seeing the issue myself, but if someone contributes a PR that fixes the issue and does not cause new issues, I'll make it a priority to merge it in.. If it's a major issue that blocks you, then please contribute a PR and we'll go from there. And I disagree that it's a major issue that blocks FF users from using DnD completely as I said I personally am not having this issue w/ my integrations. . It\u2019s really quite shocking to see how many users of my hard work feel they are owed something even further in particular, as if they were somehow sending me a paycheck every two weeks. It\u2019s quite simple: if this is important to you and you have a fix that does not break something else: issue a pull request. Or you could volunteer to help maintain the library. Or you could even volunteer to help pay AWS bills. OR, you can fork the project, fix the issue to your satisfaction, and simply use that in your project. So many options! And make no mistake about it, the library is not abandoned. In fact I have a public branch/PR in progress with many substantial additions to the library in progress that is now feature complete with docs, tests, and even updated Typescript defs. See #1917 for details. \nAnd again, if there are other important issues to you, the proper way to deal with them in the context of Free Open Source Software is to issue a well explained/documented/tested PR and remind the overloaded maintainer periodically, or offer to help the maintainer push the case through.. So far, I see lots of people complaining about this issue, and one user even going as far as using this issue to advertise his/her own library (which is in amazingly poor taste BTW) but not a single valid PR that fixes the issue. This is not my focus at the moment (see above) but will gladly coordinate with a developer that proposes a well tested PR for the issue.. And why, might you ask, do I require someone actually open a PR to fix this? Because I want someone other than myself to own the issue, since it is not an important issue for me. Having the proper perspective on FOSS makes these types of requests unnecessary though.. fixed in #1946. You ignored the template/instructions. Why?. I disagree with point 1 especially, but will reopen if others find this valuable. Please read https://docs.fineuploader.com/branch/master/features/thumbnails.html. It does still work.. Sorry, but I can't understand the issue here at all. Take some time time to clean this up and I'll consider reopening. Nothing random about the logic here, but you should not expect the order of files to match the exact order they are dropped for various reasons.. The message indicates that you are not signing the request correctly. I\u2019d like some explanation regarding the details of this fix. It\u2019s not clear to me why this fixes the issue, which I have not verified myself.. It is necessary. This will break cross origin uploads in older browsers. I have no plans to add any new features at this point, especially something this elaborate. . duplicate of #1320. Not a very high priority since IE 8 is a dead browser, but I'll accept a pull request that fixes this. Sorry - I'm not interested in fixing IE8 bugs. If you have suggestions to improve the code, please do so in a pull request. You haven't mentioned what this \"second bug\" even is. Ok, there's nothing Fine Uploader can do about that. Sorry - I simply don't have the time to handle support requests anymore. If you can locate a specific bug in the library or would like to contribute a feature, please do and I will do my best to assist.. Thanks for this Steph. I'll be in London all next week for Holacracy training, but perhaps we can coordinate and speak via phone sometime in the evening UTC. I'll follow up with an email shortly.. Hey @toabm, I'll send you an email shortly. Thanks for responding.\n@martinkouba let's talk more offline. How would you like to coordinate?. Unfortunately nothing has panned out on this front. But it looks like I will have some time and motivation to address some of the bigger feature requests as part of my work on BrickFTP.. Reopening as support requests are increasing and my time to work on some key features has been pushed back slightly due to other commitments. Hi Martin: I\u2019m not even aware of a Skype account that I may or may not hold. Please contact me on Twitter and we can exchange contact information there. Thanks.. Well, finding a suitable maintainer has been far more difficult than I anticipated.. @ScotsScripts Actually, that is no longer true. I do indeed rely on Fine Uploader and React Fine Uploader in a project i'm working on with my new/current employer. In fact, I have some substantial changes in progress that have been under observation in my environment for a little while now - https://github.com/FineUploader/fine-uploader/pull/1939. Changed the title to reflect the current status: \"looking for help maintaining this project\".. How shall I contact you @galvinhsiu? You can DM me on Twitter, if you'd like. My DMs are open at the moment.. @rcheung9 I have no plans to ever charge for Fine Uploader again in any capacity. It will remain FOSS for as long as I'm around.. Thanks @sizzlefinger - just sent you a DM. Anyone interested: please contact me via Twitter so we can discuss further. https://twitter.com/RayNicholus. Thanks to @SinghSukhdeep for taking the reins!. Please show your code. Sorry, I can't accept this. As far as I can tell, this call is needed.. I suggest you ensure val is not undefined before attempting to access a property.. Sorry, I can't understand anything you're saying here. . your report is the first such report, so i can assure you that the issue is very specific to your workflow. Furthermore, you're using an incredibly old version of the library, you haven't pointed to a specific line in the source code, and it's completely unclear how to reproduce. I'm not able to spend any more time on this, but a PR would be welcome.. All examples return JSON, and there are tons of them in https://github.com/FineUploader/server-examples. \nIf Fine Uploader was unable to handle JSON in response to upload requests, this issue tracker would be flooded because every single app that depends on Fine Uploader would be broken.\nAlso, the expected response is documented at https://docs.fineuploader.com/branch/master/endpoint_handlers/traditional.html.\nPlease stop wasting my time.. Had you taken the time to fill out a detailed report and not ignore the instructions in the issue tracker, perhaps this could have ended differently for you.. Sounds like an issue with your network/environment or sas server. Nothing fine uploader can do about network issues. This is definitely not a bug, as it is written.. We definitely do no support opera on iOS. Also, the issue, as you're describing it, is also definitely not an issue with this library. Custome headers will not help you to avoid preflight requests. And with that I\u2019m going to close this issue since that is the only obvious motivation for this proposal.. This should be covered by #1917.. This should be covered by #1917.. Sorry - I simply don't have the time to handle support requests anymore. If you can locate a specific bug in the library or would like to contribute a feature, please do and I will do my best to assist.. It should, assuming the mock S3 actually behaves like the real s3. Set the endpoint accordingly? What issue are you having?. Not enough info in here to debug, but I'm not seeing how fine uploader is the culprit given the response code. Most likely a server or environment issue on your end. So far, yours is the only such report, which suggests this is not an issue with Fine Uploader. So if you find a specific bug in the code or a root cause, I can look further. Sorry - I simply don't have the time to troubleshoot. If you can locate a specific bug in the library, I will be happy to re-open and address.. I see no evidence of an attempt to trim anything undefined in your post, nor do I see a stack trace. Where is the information needed to debug your issue?. Sorry, but this repo is focused exclusively on bugs in the library or reasonable library feature requests.. Sorry - I simply don't have the time to troubleshoot. If you can locate a specific bug in the library, I will be happy to re-open and address.. See the setItemLimit API method.. Please open a pull request with your changes.. https://stackoverflow.com/questions/19327410/fine-uploader-to-s3-bucket-getting-405-method-not-allowed-error. Then it's possible you have the bucket configured as a website endpoint. Regardless, this is not a fine uploader issue and some googling should present you with a solution.. 1000 is correct, 1024 is not. Well, there is no measurement for \u201ckb\u201d or \u201cmb\u201d. If you\u2019re speaking of kB or MB, then powers of ten (SI) is correct. But if you instead want KiB or MiB, then you should use powers of 2. Fine Uploader has been following the SI method for a very long time, and that will not change.. I don't have such a file, and this is the wrong repository to ask about fine-uploader-wrappers. PRs welcome at https://github.com/FineUploader/fine-uploader-wrappers.. Yes. Please read the getting started guide at https://docs.fineuploader.com/quickstart/01-getting-started.html.. Looks like you are not importing correctly. Please see https://docs.fineuploader.com/branch/master/features/modules.html. Looks like you're not using fine uploader s3. Most likely because you have inexplicably set an endpoint to null. I think this issue has run it's course. The error suggests you need to use version 4 signatures. This is covered throughout the library documentation. With the current formatting, it's too difficult for me to determine if you have initialized the library correctly. Sounds like a configuration issue with your CloudFront distribution. If you find a specific issue in the fine uploader codebase, let me know and I can reopen this.. If you find a specific issue in the fine uploader codebase, let me know and I can reopen this.. Progress here:\n\n[x] onUploadChunk can return a Promise that optionally overrides endpoint, params, headers, and method for the chunk upload.\n[x] onUpload can return a Promise.\n[x] New function type options for the chunking.success option: headers and params. Also jsonPayload boolean and method string. Finally, endpoint accepts a function value. All function options are passed the file ID.\n[x] New request.omitDefaultParams option. If set, Fine Uploader doesn't send any \"qq\" params w/ the upload request.\n[x]  New request.requireSuccessJson option. If not set, upload endpoint does not need to return { \"success\": true } to indicate success. \n[x] More flexible resume support (allow custom keys/data) \n[x] allow per-file chunking.partSize\n[x] Unit tests to cover everything.\n[x] Documentation updates.\n[x] Document chunking.mandatory option.\n[x] Typescript def file updates. (cc: @SinghSukhdeep)\n[x] fine-uploader-wrappers updates to cover any new API features (i.e. more async support).. All planned development work for this PR is now complete.\n\nThe current release with these changes (pushed to npm) is v5.16.0-alpha.12. The next step is to regroup, write some unit tests, update the docs, and upgrade this to a beta release if all goes well. After I've been using all of these changes in production for a bit I'll release 5.16.0.. @SinghSukhdeep sounds good. I don't have any of the docs updated yet, so if anything isn't clear, LMK. there are a lot of changes here.... I believe I have now written sufficient unit tests for all changes/additions in this PR.. Docs are next on my list.... API docs updated!. Thanks @SinghSukhdeep. Looks like everything is done here. Just need to let all of these changes cook on a project of mine before I release (along with a bit more manual testing). Would love to hear if others are having success with this branch.. Show your code. If your button is \"huge\", then you'll need to set the parent element to have position: relative.. definitely not - the CSS in place is needed to properly style the container, and there are consequences with simply hiding a file input element as you suggested. I've already explained how to address your issue above. I don't believe this can be disabled anymore.. I'm not able to find time to troubleshoot. Do let me know if you find a bug in either the client-side or server-side code.. Sorry - I simply don't have the time to troubleshoot, and will shortly remove the \"support request\" option from the issue tracker. If you can locate a specific bug in the library, I will be happy to re-open and address.. This is due to your server sending an invalid response. Sorry, I don\u2019t know as I don\u2019t use angular. Also, I\u2019m not able to offer support due to lack of time. Your best bet is to post somewhere on stack overflow . ...or just don\u2019t use the jquery wrapper since it provides no benefits and will be removed in 6.0. You can\u2019t, because you don\u2019t need to. Again: don\u2019t use the jquery wrapper.. Sounds like a network issue to me. How is this a library bug, and why are you still using such an old version?. Also, MacBooks don\u2019t run iOS. Closing until specific issues with the library surface.. Why does your report list iOS? Why are you using an incredibly old version of the library? . If the default browser on Mac was unable to upload files, your report would not be the first, or the only report. If you can point to a bug in the library, I will consider.. Where is your code, and what is an \u201cedit image name\u201d?. You can\u2019t change a file name after the upload has already started. thanks for catching these typos - care to open a PR with a fix?. You can edit the file directly in your browser . Yes - set validation.stopOnFirstInvalidFile to false.. Thanks for this!. This seems simple enough. I\u2019ll try to merge it in soon.. No reason for Fine Uploader to do this. Use th API to do it yourself. In particular, read the objectProperties.key configuration docs.. You can get th file using the getFile API method. From there you can do anything you like with the file bytes. Are you talking about the chunking success endpoint? If so, #1917 includes a change to the chunking.success.endpoint option that allows you to return a function, which is called with the file ID. You can then return an appropriate chunking success endpoint for each file.. Sounds like something to discuss in the React Fine Uploader issue tracker. Please open a PR with your fix and include tests. I\u2019ll taje a closer look after that. Thanks. Please explain your change in detail (the logic behind it, etc). . Thanks for that. I\u2019ll hopefully taje a closer look soon. The build will need to be fixed here as well, as one of the lint checks is failing. After looking at this a bit closer, I'm (first) not really sure I understand the problem. And second I don't think the changes here are appropriate at all. I will say the call to templating.updateThumbnail in the _maybeUpdateThumbnail method of uploader.api.js is incorrect in that it fails to pass a boolean for the third parameter (which is showWaitingImg). But it's not clear that this is related to the issue you're having.. Note that I cannot guarantee that this will not break S3 or Azure workflows as I have no longer have a way to run manual tests against either of these (even S3) anymore.. a review would be nice, but I am mostly waiting for my own internal testing in a closed source app to reveal any issues before releasing. I am unable to test against S3, so if you or anyone can do that, this would be hlepful.. Something that came up during manual/internal testing in a real-world app that's using v5.16.0-beta.0: the fact that you can cancel or pause an upload when Fine Uploader is waiting for a chunking success XHR response is problematic. Integrations, such as React Fine Uploader, see that the upload is not yet complete, and that's true, so pause/cancel buttons are rendered. Furthermore, the API accepts pause/cancel commands while in this state.\nWhy is this bad? Well, it's not guaranteed that the request can be cancelled before the file has been \"finalized\" on the server fielding the request. So, in the case of a pause, a subsequent resume may result in an error. And if the upload is cancelled at this point, it may still be considered \"completed\" on the server. So the library should probably be updated as follows:\n\nReject cancel and pause API calls while in this state.\nBroadcast a new status change event (such as qq.status.UPLOAD_FINALIZING). This will be a signal to integrators that the last byte has been sent, and they can react accordingly. Responses to this state may include removing the cancel/pause buttons and rendering a custom status message (\"your file is being verified by the server\").. @xistext I'm sorry - i cannot accept personal donations to influence my time on this project. I'm quite focused on my \"day\" job at the moment, which is demanding of my time and also spawned all of the substantial changes you see in this PR. I am however actively looking for others to help me regularly maintain this project. \n\nThat said, you can try all of this out now - it's published to npm and I'm using it on a closed source project. The latest release on npm is 5.16.0-RC1, and the description of this PR is updated as the version changes. Once I'm satisfied with the performance in my closed source project, i'll officially release. Please do let me know if you see any issues or have questions though.\nP.S. The S3 demo on fineuploader.com/demos has been dead for a while as I don't want to continue paying the AWS bills myself (~$40/month). So if you or anyone else would like to take on this support, that would be helpful.. Pretty much all of these changes focus on the traditional non-s3/azure uploaders. Note that onUpload and onUploadChunk events both accept a Promise as a return value. You can either use whichever methods you choose in onUpload to influence the file to be uploaded, or you can do so in each onUploadChunk handler by resolving your Promise with and object that contains an endpoint URI. . Docs at https://docs.fineuploader.com/tag/5.16.0-RC1/. Thanks @uriahcarpenter. Will do.. @Bhupadhy is the current RC1 working will for you?. I'm planning to release this as v5.16.0 very soon. I'd like to fit in this update as well - https://github.com/FineUploader/fine-uploader/pull/1939#issuecomment-352971246 - but I don't believe this is a regression, and may just push that out afterwards as v5.16.1.. why do you care about the internal state?. so, since you ignored the template, which I feel would have answered the question above, I'm going to close this.. just fixed - thanks. Documented at https://docs.fineuploader.com/branch/master/endpoint_handlers/amazon-s3.html. How is anyone supposed to help you without seeing any of your code?  I\u2019m also closing this because you completely ignored the template.. PR please?. Likely a small regression caused by #1903.. Excellent. Thank you. I\u2019ll make it top priority to merge this in and release. At a company retreat now but will do my best. >Note: Support requests cannot be accepted due to lack of time.. I don't have time to look into this, but if you do find the cause for your issue, and if the issue is indeed caused by Fine Uploader, please do open up a PR with the fix.. This is an instance where I would really appreciate a PR to fix this docs issue. Thanks for the report.. A .NET article would be awesome. Were I a .NET developer, I\u2019m sure I would have created a server side example, but alas I am not. So contributions welcome/encouraged.. Thanks for this. _method is a common convention used to \u201coverride\u201d the HTTP request method.. Since I don't have access to Safari 9 - I can't verify/fix anything specific to that browser. But I would be quite surprised if this was an issue with Fine Uploader, as yours is the only such report, and failure to upload to S3 in Safari 9 would certainly generate more than 1 report. You'll probably want to dig deeper to determine how your specific environment is causing this.. I would strongly welcome a PR to address this. Your suggestion sounds appropriate to me.. Options cannot be changed once they are set. If there is a specific one you need to adjust dynamically and it isn't already accounted for in the methods/API documentation, please open up a case w/ the specifics.. > So I need to clean the previous image if I try to upload one more\nYou cannot do this using clearStoredFiles - that clears out files that have not yet been uploaded, to be used only when autoUpload is set to false. You can reset though.. Not one maintained by me or anyone in this org. You'll want to file that with cdnjs. This article should provide you the information you need, or at least get you started: http://blog.stratospark.com/secure-serverless-file-uploads-with-aws-lambda-s3-zappa.html. Well, I won't have any time to do that in the forseeable future, but I welcome PRs.. Closing as you haven\u2019t shown your code. Will consider reopening if that is fixed.. Sorry - the issue tracker is only for feature requests and bug reports.. Sounds like a server or networking issue. No time to offer tech support, sorry.. Awesome, thanks! I'd like to get this merged in, and maybe you can do that. Let's continue our discussion on Twitter DM.. Sure - i'll try to make some time to write these soon.. Please look at #1939. I've added support to accommodate a workflow where the endpoint for each upload/chunk is only known at runtime via some ajax call or other async process. . Sorry, the issue tracker is only to report bugs in the library or request new features. Stack Overflow may be a good place to post questions.. Sorry, the issue tracker is only to be used for bug and feature reports. Please use the built-in template next time.. This is expected. I stopped paying the AWS bills out of my own pocket a while ago, and i don't intend to pay them going forward. So until someone volunteers to pay these bills (~$40/month) the S3 demo will continue to be broken.. well, yes and no. I'm hoping somehow i'll get someone to sponsor the project such that the relatively small AWS bills can be paid again. I do feel bad not paying them myself, but i've put countless hours into this project as it is, and i'd rather not drop any more actual money into this project myself.. Would you like to try a pull request with the necessary changes? You'll need to write some tests as well to ensure this actually works. I'm not sure it will be trivial, but maybe?. I\u2019m sorry, but I cannot assist without a properly completed bug report. The documentation page for the autoUpload option explains how to start uploads when they are in this state: https://docs.fineuploader.com/api/options.html#autoUpload. Why do you want to pause a failed upload? Just retry it manually after it fails . I see no failure here. All that failed was EXIF header parsing, which is expected.. there is no exif header in a gif file. it's not clear you understand what an EXIF header is - you can start reading here: https://en.wikipedia.org/wiki/Exif. what does \"incorrect\" mean? Looking at the code, i'm not seeing any evidence of an issue. Can you provide more concrete details?. If you can update the issue with all of your Fine Uploader config code and the full request/response headers+payload as well as any console.log statements, that would be helpful.. just to be clear, the only change was fullPath.indexOf(name) -> fullPath.lastIndexOf(name)?. thanks for your work on this! I'm going to release this as 5.15.7 shortly. travis-ci is currently broken (this actually happens a lot in my experience) so i'll be able to release once that's fixed. Most likely due to lack of support. See https://docs.fineuploader.com/branch/master/browser-support.html for details. I believe Fine Uploader uses feature testing to determine if scaling is supported, and it apparently is not for your browser/OS environment.. Probably in there due to this issue: https://github.com/FineUploader/fine-uploader/issues/1146. If you can suggest a change that will not regress the code as described in the above case please do open a PR and i'll be happy to review.. I guess we could say the same thing about Firefox on Android, as market share there is almost nonexistent. Still I will consider a well tested PR that targets only browsers with proper and non- buggy support for scaling . Thanks for looking into this @nicompte. I was unable to find the time to do that myself. I\u2019ll close this as a 3rd party bug.. Sorry, I can\u2019t understand most of what you wrote in your question. Please try to focus on one specific issue and explain with code examples.. Set a function that returns the params when called. Since Fine Uploader will pass a file ID to your function,the params can be file specific, or not. . Use the getUuid method. It doesn\u2019t need to. \nuploader.getUuid(fileId). I\u2019m not seeing a question there. The bottom line is: pass whatever params you want (or none) as I\u2019ve described. . Fine Uploader will orient any image with EXIF data during scaling by default, so there should be no need to use another library to do this. If you are running into an issue with orientation/scaling, that would be a fair issue to post, but I'm not seeing anything actionable here.. Sorry, I don\u2019t really understand the problem here, and it isn\u2019t realistic to make changes based off of line numbers in combined JavaScript files generated by the build process. Please open a PR with any required changes. Thanks.. This is not true, and eval will only be used if JSON.parse is not available, which will only occur on browsers that don't even support CSPs.. Additionally, this is a breaking change, which is not to be taken lightly. I fully intend to remove support for anything older than IE11, but in a major version update - 6.0.. Well, Fine Uploader follows the semantic versioning standard, so breaking changes will only ever (knowingly) occur as part of a major version release. There's currently a release/6.0.0 branch, but it's quite stale and I haven't had time to work on 6.0.0 for a while. I spent the last 4+ months on 5.16.0, which was a huge release that came out a week or so ago - https://github.com/FineUploader/fine-uploader/releases/tag/5.16.0. Sounds good to me, thanks. awesome, thanks!. Wow. I haven\u2019t reviewed any of this yet, but it looks like you put a LOT of work into these changes...\nIf you\u2019re willing, I\u2019d like to chat more at your convenience.\n. let's connect on twitter. There are, arguably, too many changes to really review here. But tests are passing, and skimming though I didn't see anything that looked obviously wrong. So, maybe the best course if just to do some more manual testing, and if all looks good after a bit, merge it into the 6.0 branch. I'll probably pull this down myself and test it out when i get a chance.. @SinghSukhdeep can you take a peek at this?. Everything looks fine here, but I'm not sure I understand the documentation changes. You shouldn't have to explicitly reference an index.js file when importing a module, unless I'm missing something. If that is the case here, then this would be a very significant breaking change, and we'll have to figure out how to update the code to prevent that.. Is it really necessary to reference index.js directly? I\u2019ve never had to do that myself.. So, does this there are no breaking changes then? . If any user using the library in an expected/documented manner needs to adjust their code to upgrade, then the version contains breaking changes, and that must always be avoided in minor or patch releases, per semver spec. I\u2019ll take a closer look at these changes soon to better determine if the documentation changes are necessary and if any breaking changes are present or necessary. . I think i'm ok with this provided the documentation changes are reverted. But I do want to do a bit of manual testing myself first. Thanks both of you for all of your hard work.. I\u2019m personally fine with just leaving the docs as-is (before any changes). It\u2019s common to use the index.js pattern (I\u2019m using it in several closed and open source projects) and I\u2019ve never seen docs explicitly reference the index file.. I\u2019m fairly certain everything will just work without making any code changes in webpack environments. I\u2019ll have to confirm though. But if indeed this does break for users of rollup, then without reverting the breaking code changes, this will have to sit and wait to go out with 6.0. To ensure we don't break backwards compatibility, can't we just keep the traditional.js, s3.js, etc files?. Well, if both /traditional/traditional.js and traditional/index.js point to the same location, there shouldn't be an issue, unless I'm missing something. We could eliminate traditional.js in 6.0, but this allows us to ensure there are no breaks in 5.x.. This is expected as the upload is not actually chunked. To always chunk, set the chunking.mandatory option - https://docs.fineuploader.com/branch/master/api/options.html#chunking.mandatory. sounds related to https://github.com/FineUploader/react-fine-uploader/issues/166. Turns out this was caused by user (my) error when integrating Fine Uploader.. The XHR instance is passed to your callback as a fourth parameter. You can obtain the headers from this. See the docs for more details.. Good catch, Bradley. Thanks for your work!. Thanks for the report. I don't have time to fix this right now, or even look into it. But I'd love to see a PR, if you have the time.. what is the issue exactly?. You are clicking select file and then dragging a file into the dropzone? Sorry, but that doesn\u2019t make any sense to me. Why exactly would you do that?. Can you show me the exact payload (and headers) of the upload request in question? One easy way to do this is via Chrome's dev tools network tab.. Are you asking to send the entire file to the chunking success endpoint? Or...?. Yes, see https://docs.fineuploader.com/branch/master/api/events.html#submit. Sorry, but I only accept bug reports and feature requests in the issue tracker.. A JSON object is expected, and you're returning a JSON array.. Sorry, but I can\u2019t handle support requests. What is the server returning when you are expecting a V4 signature? Does it look different than a V2 signature? Have you looked at the V4 test suite to verify the signature returned by the server?. Can someone open up a PR with the fix? I\u2019ll be happy to take a look and get that released in a hotfix update. I regret that I can\u2019t take time to answer support requests. Best of luck though. Please open up a PR with your proposal and we can discuss further. I wouldn't expect to add a callback or another option though. Instead, follow the pattern of other options that allow both function and non-function values (objectProperties.key is a perfect example).. Question 2: see the setName API method for the file name, or simply contribute an objectProperties.key function which will be called before upload. Docs will have more details.\nRegarding question 3: The S3 demo on the site is currently broken because I stopped paying the AWS bills (and Amazon couldn\u2019t care less about supporting FOSS projects). So if someone wants to offer to pay that ($40/month) we could bring the S3 demo back online.\nBut mostly this project needs at least one committed maintainer. I don\u2019t use Fine Uploader at my current job, and I\u2019m finding that I have little time and motivation to evolve or even maintain it myself. So if you know of any suitable and interested candidates who are very strong on the web dev side, please point them my way. Being a visible maintainer to a large project opened a lot of doors for me, so that is one big benefit.. That's correct. You'll want to omit the blob if you intend to serialize this data. If you see an issue in the codebase, please open up a PR with your proposed fix. Thanks.. Why not just use a sensible value and just ask your users to manually retry? If you need to retry an upload 10 times, there are other, more important issues to solve besides this one.. hideScaled is a UI option, and as such React Fine Uploader will ignore it. See https://github.com/FineUploader/react-fine-uploader/issues/163. How is this a fine Uploader issue? Don\u2019t call reset until the delete operation completes.. Sorry, this doesn\u2019t belong in the JS issue tracker. There a plenty of non-py examples that can be used to update one of the many existing py servers to handle v4 signatures. Also, there\u2019s http://blog.stratospark.com/secure-serverless-file-uploads-with-aws-lambda-s3-zappa.html. Without a clear description of the issue, I can only assume you need to adjust https://docs.fineuploader.com/branch/master/api/options-ui.html#thumbnails.timeBetweenThumbs. I don\u2019t recall specifics as it\u2019s been a while since I wrote that code, but I would expect each SAS to be very short-lived, for obvious reasons.. If you have specific improvements in mind, please open a PR. This is not a bug. There is a limit set here to prevent tying up the UI thread or memory when attempting to preview images. Does not affect uploads. Duplicate of #2028. Yes. If you don\u2019t have the courtesy to follow the template I\u2019ve provided, then I won\u2019t take the time to respond.. Fine Uploader doesn\u2019t send preflight requests. That\u2019s not how CORS works at all. The browser and only the browser controls the preflight request. The demo site issue you referenced has nothing to do with CORS. Notice the response is a 404, since I stopped paying the AWS bills long ago. And on your server, again, the error has nothing to do with CORS. Your server is returning a 403, so you\u2019ll want to look closer at that.. That header is not sent to you, you are expected to send it in the response. . We\u2019re going in circles. Please see my initial comment for an explanation of the problem you\u2019ve reported.. This isn\u2019t a fine Uploader issue. My guess is that the request is timing out or being cancelled due to the fact that the connection is idle for so long. ELBs are known to do this, for example. You\u2019ll need to consider another approach server side, such as combining chunks async or combining them as the chunks come in.. >Concurrent chunks/uploads are also a great feature which are rendered useless as well (diminishing returns due to the hashing penalty)\nI'm not following. Why does this render concurrent chunking useless?. Updating th documentation to point at this specific file is sufficient. Changing the name of the file would be a breaking change and that isn\u2019t appropriate for something this minor.. I don\u2019t think that is necessary or prudent. Again, I think a documentation update is best. In a major version release, only critical or exceptionally useful breaking changes should be introduced. . I don\u2019t expect to ever create another template . What problem would this solve?. Originally, Fine Uploader used various JS libraries for the build process, but I ripped all of that out in favor of a Makefile, which i consider to be much more elegant and simple. If you truly are interested in becoming a dedicated maintainer of the library, and the Makefile is the only thing preventing your participation, then I would certainly consider such an initial contribution. But the build process is quite complex, and I would rate the task of migrating from GNU Make to something entirely different somewhere in the range of difficult to extremely difficult, even for myself. I strongly doubt that rewriting the build process from scratch is less work than simply installing Cygwin, and I would argue that there are much more important tasks to complete in Fine Uploader or one of its many related repos. But again, if you're seriously interested in becoming a maintainer and have a solid plan mapped out for a build system rewrite, I'd love to discuss further.. I think this is probably a pretty accurate description of what this newly built uploader looks like, and the \"10 npm script calls\" https://twitter.com/Dataflow_G/status/1063405073777156097\n\ud83d\ude06 . please don't delete the issue template. @SinghSukhdeep I no longer have any time to dedicate to this project, at all. You've been pretty attentive to the project, and perhaps you'd be interested in taking over. If so, let me know and I'll make sure you have all of the appropriate permissions. I'd still be available if you have questions, but turnaround time might not be ideal.. Your only options are to call reset, or create a new Uploader instance.. Sorry, I can\u2019t help you troubleshoot your server issues. The error you see in the demo has nothing to do with CORS - the aws account backing that demo is no longer functional. As for the issue you are seeing in your code, you\u2019ll need to look closer at the response to see what the issue is. I can guarantee that the issue is on your server. And thus out of scope for this issue tracker.. >these are sent in a specific order to the server\nInstead, I'd suggest including some metadata/params to send along with each file to indicate the \"order\". You can build ordering into the UI, but without changes to the uploader code as well, they won't actually upload in the new order. I don't anticipate this being a simple change either, and probably not worthwhile to introduce that sort of additional complexity into the codebase with only one use case.. please show your code - currently, i'm not sure what i can do to help here. Saying \u201cthe browser crashes\u201d and \u201cthere is a problem\u201d doesn\u2019t provide anywhere near the level of detail needed to assist. Please take another look at the issue template, follow it, and focus on one specific issue that is not a support request.. >For some reason fineuploader sent the post of the image without write the image file\nYour server writes the image file to disk, not Fine Uploader. I can guarantee that the file is always sent by fine uploader. The issue is with your server code, and that is beyond our help.. Thanks for attending to all of these new issues @SinghSukhdeep . most likely multiple is set to false. Please see the options docs. can't reproduce w/out code. feel free to open a new issue, following the template this time. The build will likely not work on a non-POSIX system, sorry.. >1. Open download portal (using fine-uploader)\nwhat does this mean?\nWhere is your code?\nWhat build of Fine Uploader are you using?\nWhere did this build come from?. I've pretty much stepped away from the project as I don't have any time to dedicate to this project anymore, and I don't have any use for something like Fine Uploader at the moment. @SinghSukhdeep is taking over.. this has nothing to do with fine uploader. Camel case is the convention currently in place for property names.  Is there a reason why this can't be deleteClass or deleteButton?.\n. Why is the call to cancel(...) needed here?  The file will never be in-progress at this point.\n. It seems like deleting should be possible regardless of the value of these two variables/functions.\n. Yep, the code could be refactored with a private function that clears out the .  cancel and this call could reference that new function.\n. I think this can be refactored to one single line:\njavascript\nqq.extend(paramsCopy, self._options[type].params);\nOf course, both calls to _createParamsStore will need to specify a type, but reducing this to one statement means I don't have to keep adding conditionals as I add support for additional requests.\n. This can be removed.\n. This can be removed.\n. Seems like this (and setUploadSuccessParams) may be redundant here since this is already specified in qq.nonTraditionalBasePublicApi, which this inherits from.\n. Most likely a leftover from a refactor.\n\u2014\nSent from Mailbox\nOn Tue, Sep 23, 2014 at 9:50 AM, Matthieu Allegre\nnotifications@github.com wrote:\n\n\n@@ -126,6 +127,10 @@\n             this._uploadSuccessParamsStore.set(params, id);\n         },\n-        setUploadSuccessEndpoint: function(endpoint, id) {\n  True! Actually I was wondering why setUploadSuccessParams was redefined here.\n\nReply to this email directly or view it on GitHub:\n  https://github.com/Widen/fine-uploader/pull/1296/files#r17913147\n. Sounds like a good modification to make. I'm guessing the Azure-specific custom header tests do not include a header with a name that matches one of the headers in your switch block that also is set to a function value. You will probably want to modify your test to account for this case.\n. The next scheduled release is probably at least a couple months away. Either way this change can wait, so, not a problem.\n\n\nOn Wed, May 20, 2015 at 3:30 AM, Korijn van Golen\nnotifications@github.com wrote:\n\n\n```\n     getParamsAsHeaders: function(params) {\n         var headers = {};\n     qq.each(params, function(name, val) {\n\n-                var headerName = qq.azure.util.AZURE_PARAM_PREFIX + name;\n-\n             var headerName = qq.azure.util._getPrefixedParamName(name);\n       if (qq.isFunction(val)) {\n\n```\n## I'm a bit short on time for this final adjustment, can we postpone it till after release?\nReply to this email directly or view it on GitHub:\n  https://github.com/FineUploader/fine-uploader/pull/1404/files#r30680244\n. @Korijn This line should be removed as well. Otherwise, all looks good!\n. I like how this eliminates some of the boilerplate in this method, but I think the following is a bit more readable:\n\n\njavascript\nvar credentials = credentials || options.signatureSpec.credentialsProvider.get();\n. This is a bit too dense. I'd reformat as an if statement. \n. This will have to be removed/changed. Object.assign is not supported in any version of IE. Also, Safari, Chrome, and Firefox didn't add support until recently.\n. This is pretty dense hard to follow. Also, I'm not sure about determining if an error exists based on text in the error message.\n. These are a bit too dense and hard to follow, especially the 3rd line. These can probably be expanded into if statements and/or moved into other functions.\n. You should probably just refer to the qq.extend function in utils.\n. This one should be \"file\" instead of \"field\".\n. I'm not sure I understand why this action is being taken here. uploadStoredFiles applies to an entirely different behavior, and is not really related to pausing an in-progress queue. The decision to upload \"stored\" files should be made by the integrator through the API. \n. I'm not sure I like making connectionManager in its entirely available to all code outside of this module. I really don't think anything other than connectionManager should touch its internal state.\n. much better! I'll re-run manual tests when i get a chance. not sure i will have time today, but we shall see\n. Which specific section are you trying to link to?\n. You mentioned that you were able to use Fine Uploader S3 w/ transfer acceleration. Did you have to specify an objectProperties.bucket option?\n. I would expect that an explicit objectProperties.bucket option is not required here. The use S3 Transfer Acceleration, the URL must always be bucketName.s3-accelerate.amazonaws.com, and this is not a 3rd-party CDN. That said, I'm still curious if you had to specify this option yourself.\n. Please remove this commented out code.\n. please remove this commented out code\n. I'd like to keep these params alphabetically ordered.. This file is already quite large. Ideally, this logic would be split out into another JS file.. Not really fond of the name of this function. It's not obvious that a URL is to be returned here, or what the worker does.. I think a qq.Error is probably more appropriate. . Is it possible that promise can be undefined here? If so, this should be if (promise != null {.. curious why this are prefixed with _. Why would this ever be falsy?. This should be thrown. It's a no-op as it stands.. seems like this should be a warning or error. Would prefer this to be an else if and the empty return removed in the above conditional.. What does the default value of null mean?. Can you lock this to a specific version?. I'm very concerned about using template strings and let/const, since not all bowsers that support web workers support these ES6 language features.. Minor detail, but that would be great. Elsewhere in the project, underscores are used to mark publicly-accessible methods/props that are only meant to be used internally (a poor-man's private).. Great, please do.. Generally speaking, I'm in favor of Dijkstra's approach - single exit. I'm not married to this though. This is just a suggestion.. Ok. Please include this info in the option description, if you could.. Right, my bad. As long as we stick with Node 5+, we should be good.. Why was this added? It's not clear to me what consequences are associated with this change. . This (and the subsequent test) do not look valid. As far as I can tell, the test will exit before the promise is resolved. This is effectively an async test. You'll need to make use of the done function in both tests.\nIn the first test, in the second function (failure), add a call to done. In the second test, add a call to done in the first then function (success).. I would suggest reverting these changes and making use of the done function instead. You can use this test as an example: https://github.com/adrianchung/fine-uploader/blob/40db9e3652ea73cf13d7d5244a3336994afb88a5/test/unit/uploader.basic.api.js#L195. Not sure I follow. You can (and should) call done inside of either the failure or the success then callbacks. The tests are likely passing as the tests are exiting prematurely. Promises are asynchronous operations, and your tests are written as if they were synchronous. . It may be appropriate to throw a qq.Error here as well.. I think this section should be refactored to always call the onError callback, even if xhrOrXdr is absent, in which case the error message can simply omit any references to xhrOrXdr.\nThis may work (replaces everything starting w/ line 1108:\njs\n// For error reporting, we only have access to the response status if this is not\n// an `XDomainRequest`.\nif (!xhrOrXdr || xhrOrXdr.withCredentials === undefined) {\n    this._options.callbacks.onError(id, name, \"Delete request failed\", xhrOrXdr);\n}\nelse {\n    this._options.callbacks.onError(id, name, \"Delete request failed with response code \" + xhrOrXdr.status, xhrOrXdr);\n}. One more thing - can you please move all test logic into the then success/resolved function? Otherwise this can create a race condition where the assertions are executed before the file is added to the uploader. That applies to this test and the one below. Also, make use of the done function to signal that the test has actually completed after all assertions have been executed, which is important for async tests such as this one.. Please remove uuid since this can be obtained via the getUuid() API method. Also please update the docs after this change.. Can you indicate that the accepted statues here are qq.status.UPLOAD_SUCCESSFUL and qq.status.UPLOAD_FAILED?. This is not necessary. The number of bytes remaining is already something we can calculate based on the chunk size and the remaining chunks. \nAlso, please do not combine unrelated changes into a single pull request. I'd very much like to keep changes simple and focused.. any \"thenable\" object is permitted. though i dont want to encourage or promote Fine Uploader's promise impl at all. it's non-standard and just plain bad. I'd really prefer we don't even mention qq.Promise anymore. I expect/hope to rip it out entirely in 6.0.\nYes, it should be \"if\" instead of \"in\".. I'll admin I wish I hadn't added the ability to track asserts like this - it has become a maintenance mess. I ask you do one of two things here:\nEither heavily comment this line to explain the significance of this number, or rewrite this test (possibly breaking it into smaller ones) such that assert counting is no longer needed.. Why would the status ever be \"paused\" here?. ",
    "chodorowicz": "great, thanks for that and thanks for a great plugin!\n. awesome, thanks!\n. ",
    "onland": "That's what we are looking for as well. Would be great if one could select an attachment (or more) fill in some data and then if the user submits a form upload the attachments.\nFurthermore nice plugin.\n. ",
    "beeuser": "I have the latest version and my upload button looks just like here http://valums.com/files/2010/file-uploader/demo.htm in IE8. Can you also make an update for the css file?\n. Yes I got the latest version of .js file and still shows wrong in IE. But isn't this a css problem? Do you have any link with a working example in IE8?\n. ",
    "angelcervera": "For lack of time. :(\n. Thanks a lot.\n. ok, thanks.\n. My Gist with response patched: http://gist.github.com/642854\n. ",
    "jaltek": "Hi,\nI can confirm the issue with the latest FF beta 5. The \"loading.gif\" keeps spinning - but the upload seems to work (POST Response of do-nothing.htm is \"{success:true}\").\nTried with the latest version of fileuploader from \"dev\" branch.\n. Yes, I do. Well in this case Firebug is the problem - not fileuploader.\n@valums: solved ;)\n. Maybe you should demonstrate your changed code (if possible) via http://gist.github.com/ in order to see the changes you made to the code.\n. Hi there,\nhave a look at \nhttp://github.com/codepoetry-de/file-uploader/commit/54ecf383e4efe0a7904840d6376a886880e08733\n(the last few changes). We used it in the past to replace the first list item everytime a file is uploaded.\nMaybe it helps?!\nGreetz\n. Hi pixelgamma,\ntry this: https://github.com/valums/file-uploader/pull/30/files\n(last block of changes)\nI dont't know if it still works with the current version ;)\n. ",
    "fredjiles": "I think it worked for me today, but I had to disable firebug.  Are you using firebug puredoze?\n. ",
    "faust45": "Have the same trouble!\n. ",
    "malomalo": "I got mine to work by putting the dropzone outside of #qq-uploader\n. ",
    "dlandis": "I changed the _setupDragDrop.onDrop function to use something like:\n$(\".\" + self._options.classes['drop']).hide();\nwhich just hides all the drop areas after a file has been dropped. Requires jquery obviously.\n. ",
    "muanis": "thanks @dlandis, it worked perfect here.\n. ",
    "softlion": "it would be nice to have a less basic class with drag drop and single upload like in this patch.\n. new fix for version as of today, in _addToList:\nif( this._options.multiple || this._listElement.childNodes.length == 0 )\n        this._listElement.appendChild(item);\n    else\n        this._listElement.replaceChild(item, this._listElement.firstChild);\nThanks puredoze !\n. Something like:\n[HttpPost]\npublic ActionResult HandleUpload( string qqFile, HttpPostedFileBase normalFile )\n{\n  if( !String.IsNullOrEmpty(qqFile) ) {\n    using( FileStream newFile = new FileStream(someLocalPath, FileMode.Create) )\n    {\n      byte[] body = Request.BinaryRead(Request.TotalBytes);\n      newFile.Write(body, 0, body.Length);\n    }\n  } else {\n    //use normalFile\n  }\n}\nThe model binder will automagically bind the parameters.\n. In asp.net MVC the action to receive the file will be:\n[HttpPost]\n    public ActionResult ReceiveFile(string qqFileName, HttpPostedFileBase qqFile)\n   {\n        if (!String.IsNullOrEmpty(qqFileName))\n        {\n            fileName = qqFileName;\n            fileSize = Request.ContentLength;\n            inputStream = Request.InputStream;\n        }\n        else if( qqFile != null )\n        {\n            fileName = qqFile.FileName;\n            fileSize = qqFile.ContentLength;\n            inputStream = qqFile.InputStream;\n        }\n        else\n            return Json(new { error = \"No file found in request !\" }, \"text/html\");\n     ...\n   }\n. Use MVC Future Model Binders\nglobal.asax.cs / Application_Start\n```\n        #region MVC Futures: use extensible model binders to change type conversion error messages\n        ////does not support binding to HttpPostedFileBase, and tries to read \"get only\" properties.\n        Microsoft.Web.Mvc.ModelBinding.ModelBinderProviders.Providers.RegisterBinderForType(typeof(HttpPostedFileBase), new HttpPostedFileBaseExtensibleModelBinder());\n    Microsoft.Web.Mvc.ModelBinding.ModelBinderConfig.Initialize();\n    #endregion\n\n/// \n/// A model binder for HttpPostedFileBase (not included in extensible model binder from mvc futures RTM)\n/// \n/// \n/// How to register this binder:\n/// Microsoft.Web.Mvc.ModelBinding.ModelBinderProviders.Providers.RegisterBinderForType(typeof(HttpPostedFileBase), new HttpPostedFileBaseExtensibleModelBinder());\n/// ModelBinderConfig.Initialize();\n/// \n/// In your form, don't forget to set enctype to \"multipart/form-data\"\n/// \npublic class HttpPostedFileBaseExtensibleModelBinder : IExtensibleModelBinder\n{\n    // helper that returns the original file if there was content uploaded, null if empty\n    internal static HttpPostedFileBase ChooseFileOrNull(HttpPostedFileBase rawFile)\n    {\n        // case 1: there was no  element in the post\n        if (rawFile == null)\n        {\n            return null;\n        }\n    // case 2: there was an <input type=\"file\" ... /> element in the post, but it was left blank\n    if (rawFile.ContentLength == 0 && String.IsNullOrEmpty(rawFile.FileName))\n    {\n        return null;\n    }\n\n    // case 3: the file was posted\n    return rawFile;\n}\n\npublic bool BindModel(ControllerContext controllerContext, ExtensibleModelBindingContext bindingContext)\n{\n    if (controllerContext == null)\n        throw new ArgumentNullException(\"controllerContext\");\n    if (bindingContext == null)\n        throw new ArgumentNullException(\"bindingContext\");\n\n    // get value from provider\n    ValueProviderResult vpResult = bindingContext.ValueProvider.GetValue(bindingContext.ModelName);\n    if (vpResult != null)\n    {\n        bindingContext.ModelState.SetModelValue(bindingContext.ModelName, vpResult);\n        HttpPostedFileBase[] theFiles = vpResult.RawValue as HttpPostedFileBase[];\n        HttpPostedFileBase theFile = theFiles!=null ? (theFiles.Length == 1 ? theFiles[0] : null) : null;\n\n        if (theFiles != null && theFiles.Length > 1)\n            throw new NotImplementedException();\n\n        bindingContext.Model = ChooseFileOrNull(theFile);\n        return true; // success\n    }\n\n    return false; // failure\n}\n\n}\n```\n. In your form, don't forget to set enctype to \"multipart/form-data\"\n. ",
    "reinink": "Hi Ray...just found this plugin yesterday and I'm really impressed!\nJust curious, however, why this plugin does not working with standard HTML buttons? I noticed this is only the case with the IFRAME version (IE).\nIs it worth mentioning this on the main page? I took me a while to figure the problem out.\n. @rnicholus Ahh, right, okay, thanks.\n. @rnicholus Agreed...and while there are lots of jQuery uploaders available, this one really is the best I have come across.\nHonestly, the only reason I could see you moving to a jQuery plugin version is to increase it's popularity. I think there are lots of developers who will be searching for a jQuery uploader\u2014even though this uploader (in it's current state) works perfectly fine. They know jQuery, and they know how jQuery plugins work. I think it's all a little ridiculous...but that's the way it is.\nMoreover, my two cents on version three. Whatever new features you add, please keep FileUploaderBasic in its current state more-or-less. FileUploaderBasic is really what attracted me to this file uploader. I personally want control over the UI. Give me callbacks to work with. Too many other uploaders create big, complex interfaces, which can be really difficult to implement into your unique software application.\nKeep up the good work!\n. @rnicholus I'm not opposed to one plugin, as long as we have the control available now. I get the need for some of this functionality to be built in\u2014as long as it doesn't get too big or too complicated to remove all that stuff.\nPut differently, I'd love version three to not require any assets (CSS, images)\u2014just the JavaScript file.\n. @rnicholus Done. ;)\n. @rnicholus Makes good sense to me!!!\n. ",
    "cowwoc": "Why was this issue closed? How can we override the default hoverClass?\nUPDATE: I've created a new issue 141.\n. ",
    "dresende": "I never had any problem using utf-8 characters...\n. $in = fopen(\"php://input\", \"r\");\n$out = fopen($xhrtempname, \"w+\");\nstream_copy_to_stream($in, $out);\nfclose($in);\nfclose($out);\n. Could the problem be because of this option?\nhttp://www.php.net/manual/en/info.configuration.php#ini.max-input-time\n. I agree with this, but the default shoule be \"KB\" instead of \"kB\". Actually it should be:\n['KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB']\n. Check this:\nhttps://github.com/valums/file-uploader/pull/116\n. I'm not sure, but looking into my code I assume it's scriptData you're looking for (when creating uploadify object).\nThis data should be received in the $_POST array (mine does, not sure I changed file-uploader :S)\n. I haven't look deep in the code but it should work normally..\n. Although this might be usefull, it's not really necessarily. You can control when it ends by checking onSubmit (push) and onComplete (pop).\n. As I said, the event can be usefull but if you increment (or add a new item on some list/table) on \"onSubmit\" and remove it \"onComplete\" you know when it ends (when the list is empty). I'm actually not sure about it, I'm not sure when onSubmit is triggered: if when file is added or when file starts to be uploaded..\n. I just found another option... fileUpload._filesInProgress should tell you how many files are still in progress :)\nOr your fileUpload._queue. Is this private?\n.  You don't have to \"poll\". You just need to check on the event \n \"onComplete\".\nOn Mon, 28 Mar 2011 12:55:24 -0700, dvdplm wrote:\n\n@dresende: polling the queue (or reading filesInProgress) would work\nof course, but it would require polling. Not what I want. And keeping\nthe count on my own is also (needlessly) messy imo. I still think my\npatch has merit! :)\n\n\nDiogo\n. Ok, ok, your event is fine :)\nJust note that onSubmit is always executed (the default is an empty function) so your event does not bring performance, just maybe code elegancy.\n. Check this:\nhttps://github.com/valums/file-uploader/pull/116\n. Option multiple to false should do the trick.\n. This is not good either. For this to work properly you must use [ \".extension\", ... ] instead of [ \"extension\" ] or else you will fail. For example.. for files without extension but that end with the same letters of one of the allowed extensions.\n. This should solve issue #65 (haven't tested).\n. This should solve issue #96 (haven't tested).\n. strrpos() might return false. In that case, $filename will be empty [and perhaps a warning is issued by substr() ]. And in this case, the 2nd next line will break too ( $pathinfo['extension'] ).\n. I don't know about 5.2, I tried on my laptop and I'm almost sure it has version > 5.3. I did pathinfo(\"/test/path\") and 'extension' was not a key on the returned associative array.\n. ",
    "sars": "may be application/json ?\n. ",
    "devoutdesign": "Took a few hours, but I figured it out: \n    uploader._getItemByFileId(id)\nIt would be helpful if this type of example was in the readme/documentation. Here's a code example of what I mean: http://gist.github.com/581082\n. Figured it out. In my PHP (Zend Framework) application, I was using a helper function that was setting the \"Content-Type\" header to be json instead of \"text/html\". I guess it's important that the content type is set to html.\n//$result = array('success' => true);\n    $content = Zend_Json::encode($result);\n    $this->getResponse()\n         ->setHeader('Content-Type', 'text/html') //internet explorer needs this\n         ->setBody($content)\n         ->sendResponse();\n    exit();\n. ",
    "sepehr": "@devoutdesign You saved me hell of a time, thank you.\n. @rnicholus yea, I was reading the other issue and I saw your posts regarding this. It's weired but it only works with \"text/html\" in my case.\n. ",
    "saulberardo": "For me it just worked also with \"text/html\". No other option worked.\n. the latest in the repository.\n. Windows 7, IE-9 in IE-7 mode (observe I didn't actually tested on IE-7) , PHP 5.1.53, Apache 2.2.17. If you want to know something else, just ask.\n. Using \"header(\"Content-Type: plain/text\");\" the console output in IE-7 is:\nLOG: [FineUploader] Processing 1 files or inputs... \nLOG: [FineUploader] Sending upload request for 0 \nAnd it's as if the file was still being uploaded (and IE asks me to download the request endpoint file). If I click \"cancel\" to abort the upload, the lines below are appended in the console:\nLOG: [FineUploader] Cancelling 0 \nLOG: [FineUploader] Received response for 0 \n. Remember, with \"header(\"Content-Type: text/html\");\" it works like a charm.\n. The problem occurs when I use this simple php script to process the request:\n<?php\n$result = array('success'=> true);\n// or with $result = array('error'=> false);\nheader(\"Content-Type: plain/text\");\necho json_encode($result);\nIf you want I can send you the entire NetBeans project so you check if there is something else going.\n. Yes I did, and they were exact what they were supposed to be (i.e. the exact content-type I had sent as header). The project doesn't have any NetBeans specific stuff. Indeed, it's just a project to test the uploader without anything else added. You should be able to inspect it even with notepad.\n. Here it is: http://www.4shared.com/rar/wkd9WM46/doesnt_work_in_IE7.html\nThe simplest possible project to show this problem occurring. Good luck!\n. ",
    "Drachenfels": "It should be very easy and is IMHO not related to plugin itself. When you upload a file there is a input of type=\"file\" in your dom, you can access that input, get it's values or whatever you wish. You can queue it, dequeue, sing it, chant it, parse it and fix it. After you have finished just pass execute your plugin and voila. Just basic knowledge of Javascript at start and then usage of this plugin.\n. ",
    "ptcc": "this still happens to me...\n. ",
    "Alfred7": "Thanks. Now it is clearer. \nI think I will upgrade to it once I have enough traffic since the old version is adequate for now.\n. ",
    "XavierColombel": "Hello,\nI want to remove each element of the uploaded files list in an onComplete event.\nThe link you gave is broken and maybe it was the solution. Do you have an idea for me ?\nThanks a lot !\n. Hello,\nThe code seems to have changed a lot since the modification you gave me. :-(\n. Hello bgrandgeorge,\nI used your code in order to remove the uploaded file element from list, but with no success. Here is my code. How to remove the fileItem from list ?\njavascript\nonComplete: function(id, fileName, responseJSON){\n      var fileItem = uploader._getItemByFileId(id);\n}\nThanks a lot !\n. Thank you very much ! ;-)\n. Thank you very much !! ;-)\n. ",
    "bittersweet": "Take a look at this block of code, from fileuploader.js.\nYou could probably modify this to suit your needs and throw it in the onComplete callback.\n```\n_onComplete: function(id, fileName, result){\n    qq.FileUploaderBasic.prototype._onComplete.apply(this, arguments);\n// mark completed\nvar item = this._getItemByFileId(id);                \nqq.remove(this._find(item, 'cancel'));\nqq.remove(this._find(item, 'spinner'));\n\nif (result.success){\n    qq.addClass(item, this._classes.success);    \n} else {\n    qq.addClass(item, this._classes.fail);\n}\n\n},\n```\n. ",
    "azoff": "I'm having this same problem. I hate to be a complainer but why does file-uploader send its content to the server as application/octet-stream as opposed to multipart/form-data?\n. ",
    "andrewrk": "why is this closed? An explanation or link to a duplicate issue would be nice.\n. ",
    "hynese": "I'm still having problems with valum's file uploader running on Android. Runs perfectly fine in Chrome.\n. Android browser doesn't support uploading. Nothing to do with this excellent project...\n. ",
    "thenetimp": "I am having similar issues.  Code written by another developer wipes out the query string through CodeIgniter routes, and I'd rather not mess with those if I don't have too.  What ends up happening is I get a 404 error for the page because the route for the page+query string doesn't exist.\n. ",
    "bkak": "Where should I look for it? How does it get passed to server?\n. Here is how I have done it :\njavascript :\n     function createUploader() {\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('DivUploadPhotos'),\n            //            onSubmit: function (id, fileName) { alert('here') },\n            action: rootPath + 'PhotoUploading.aspx/UploadPhoto/'\n        });\n    }\n$(document).ready(function () {\n            createUploader();\n    });\nIn .aspx file \n<% using (Html.BeginForm(\"UploadPhoto\", \"PhotoUploading\", FormMethod.Post, new { enctype = \"multipart/form-data\" }))\n           {%>\n                \n          <%} %>\n\nOn server side in PhotoUploadingController I have :\n[HttpPost]\n       public ActionResult UploadPhoto()\n       {\n            //Here Request.Files is Empty for firefox but it has the image InputStream in IE.\n    // Found this code from the comments section \n     //   subfolder = Path.Combine(@\"Uploads\", Request[\"subfolder\"]);\n     //    But Requrest[\"subfolder\"] is empty in my case, I am not assigning to it.\n        }\nIn Request.QueryString qqfile is present but how do I get the Image file. I need to save it on server.\nThanks,\nBhoomi.\n. ",
    "jonashaag": "HTML5 FileAPI.\n. ",
    "ghost": "Another way I think is with flash\n. we are all waiting for 3.3 :D\n. @rnicholus I just wrote a quick and dirty patch. In the next days I will submit the pul request.\n. quick and dirty meant that it fixed only my urgency (read: form uploader).\nI will work on it to fix even xhr uploader.\nOn Fri, Nov 23, 2012 at 2:39 PM, Ray Nicholus notifications@github.comwrote:\n\nDoes this patch address the xhr AND the form uploader?\nOn Nov 23, 2012 3:58 AM, \"Paolo Lunazzi\" notifications@github.com\nwrote:\n\n@rnicholus https://github.com/rnicholus I just wrote a quick and\ndirty\npatch. In the next days I will submit the pul request.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/113#issuecomment-10654722>.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/113#issuecomment-10659732.\n. I'm having the same issue with this plugin, however, this fix is not working.  In IE9 when you attempt to upload a file, a message pops up at the bottom of the browser asking the user if they want to save a remote document to the local machine.  The upload notification spins indefinitely.\n. Ok, I solved the issue that I was having.  For whatever reason, when IE9 makes the POST request, it does not flag it as being an Ajax request.  I have code in my MVC action that checks for Request.IsAjaxRequest() and would return some JSON on false.  That JSON was what IE was asking me to download.  I removed the test and now the uploading is working just fine with the script being just as you download it.  Now I guess my issue is how to change the script so that in IE9 it correctly sets the request as being Ajax, because it clearly is one since the entire page is not refreshing on upload. \n. There's one more issue, maybe fontFamily: 'Arial, Helvetica, sans-serif' instead of fontFamily: 'Arialf' would ensure crossOS support. But not sure about that\n. Not the best solution. I figured out some problems with firefox\n. But I need to modify those parameters after the files are selected, before uploading. In this case, onSubmit method is not suitable\n. If I understand, onSubmit is triggered when I confirm the selection of the files. But what I do is, that when I select the files, I create input field for description for every selected file (together with file-uploader's elements from fileTepmlate). Later, when I start the uploading, I need to pass content of corresponding input field.\n\nLet's say I want to upload 3 files: 1.txt, 2.txt, 3.txt:\nWhen I select them,  with id='qq-upload-description-0' and 'qq-upload-description-1' and 'qq-upload-description-2' are created, where nuber at the end is id of the file in the uploader.\nWhen I call the uploadStoredFiles() I have to set parameters somehow, so 1.txt is uploaded with content of qq-upload-description-0 etc.\nWith setParams set in onUpload() it's working fine, except for the first file.\nI temporarily solved this by modification of the fileuploader.js, where I directly setParams in uploadStoredFiles function, but this is not a clean solution.\nI hope my description of the problem makes sense\n. The signature for onSubmit is:\nonSubmit: function (id, fileName) {}\nWon't it be fired each for one file?\nI don't get how I can get the count total.\n. I think it would be a very cool feature. Maybe for mobile devises it is more important, than selecting multiple files.\n. Thanks for the quick response and pointers to the right places in the doc. Unfortunately, still not getting to where I need to be.\nI'm using the web2py example almost verbatim:\nvar uploader = new qq.FileUploader({\n        dropZone: null, // EXPERIMENTED WITH AND WITHOUT THIS AND CAUSES NO DIFFERENCE IN BEHAVIOR\n        // pass the dom node (ex. jQuery(selector)[0] for jQuery users)\n        element: document.getElementById('uploader'),\n        // path to server-side upload script\n        action: '{{= URL(c=\"item\", f=\"cb_upload\")}}',\n        sizeLimit: 150000000,\n        minSizeLimit: 0,\n        //allowedExtensions: ['xls','jpg', 'jpeg', 'pdf', 'txt','doc','htm','html','xml','xmls', 'txt','ppt','png', 'gif'],\n        allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],\n        // set to true to output server response to console\n        debug: true,\n        // events\n        // you can return false to abort submit\n        onSubmit: function(id, fileName){},\n        onProgress: function(id, fileName, loaded, total){\n        },\n        onComplete: function(id, fileName, responseJSON){\n            url = \"{{= URL(c='item', f='incr_read')}}\" +\n                '/' + responseJSON.item_id\n            ajax(url, [], \":eval\");\n        },\n        onCancel: function(id, fileName){},\n        messages: {\n            // error messages, see qq.FileUploaderBasic for content\n            typeError: \"{file} {{= T('has invalid extension.')}} {{=T('Only')}} {extensions} {{=T('are allowed.')}}\",\n            sizeError: \"{file} {{= T('larger than maximum file size of')}} {sizeLimit}.\",\n            minSizeError: \"{file} {{= T('smaller than minimum file size of')}} {minSizeLimit}.\",\n            emptyError: \"{file} {{= T('is empty, please select files again without it.')}}\",\n            onLeave: \"{{= T('The files are being uploaded, if you leave now the upload will be cancelled.')}}\"\n        },\n        showMessage: function(message){ alert(message); }\n    });\nThe doc says that I can set dropZone to null:\n/*\ndropZone\nThe drop target jQuery object, by the default the complete document.\nSet to null or an empty jQuery collection to disable drag & drop support:\nType: jQuery Object\nDefault: $(document)\n*/\nbut doesn't seem to work. Obviously, I'm doing something wrong. Any thoughts?\n. It seems like it should be possible (and, perhaps, proper?) to use window.postMessage for all cases where the iframe is used in IE8 and IE9, unless I'm missing something. In the documentation, the File object is supported, along with Objects and Blobs.\nIt seems like all that would be needed would be for the iframe to be loaded from the upload endpoint domain. Data could be passed to the target using postMessage instead of a hidden form, and the JSON response could be passed back using postMessage on the endpoint, because according to the docs:\n\nThe postMessage method call does not return until the event listeners of the target document have finished executing.\n\nSo, it should be relatively simple, I think. Although I'm probably over-simplifying it and I'm sure there are bits that I'm missing. :)\nAlthough, using postMessage would add another special case for IE 10 > version > 7, and detecting the presence of a working postMessage function is a bit of an issue, apparently.\n. Excellent. I'd like to test this out, although I'm not sure that I'm building it correctly... I added ${jsSrcDir}/window.receive.message.js to coreFiles, and the build seems to work OK, but I may be missing something. \nIs there anything special I need to do (besides serve up iframe.xss.response.js)? I notice there's an xss option, but I can't see that it's ever used. Also, from a quick glance, it seems that createIframe doesn't do anything different. So I'm wondering how to get started working with these changes.\n. Hi\nThanks for the quick response.  I've tried two of the methods you mention here.  I am using autoUpload false, so didn't try that one.\nReturning a function as a param value didn't seem to work - the param didn't get passed.\nUpdating the code as in step 1 causes the params to be passed, but I don't end up getting the file (non IE browsers still get the file).\nI'm using the PHP code found here - https://github.com/valums/file-uploader/tree/master/server/php\nIs there something else that needs to happen to capture the file on IE?\nThanks.\n. My server side code was not structure to process the image if the params weren't passed, so I don't know the answer to that (and wouldn't be able to without a bit of modification).\nHere's the relevant snippet of front-end code:\njavascript\nvar uploader = $('.browse').fineUploader({\n                request: {\n                    endpoint: '/api/process-entry/'\n                },\n                autoUpload: false,\n                text: {\n                    uploadButton: 'BROWSE PHOTOS'\n                },\n                debug: true,\n                multiple: false\n            }).on('validate',function(fileData){\n                $(\"#enter-tag-desktop\").addClass(\"file-added\");\n            }).on('error', function(){\n                $(\"#enter-tag-desktop\").removeClass(\"file-added\");\n                $(\"#enter-tag-desktop\").removeClass(\"file-error\");\n                $(\".qq-upload-size\").hide();\n            }).on('upload', function(event, id, filename) {\n                $(\".qq-upload-size\").css(\"display\",\"block\");\n                $(this).fineUploader('setParams', {\n                    'first_name': $(\"#enter-first-name\").val(),\n                    'last_name': $(\"#enter-last-name\").val(),\n                    'email': $(\"#enter-email\").val(),\n                    'phone': $(\"#enter-phone\").val(),\n                    'optin': $(\"#enter-getmore:checked\").length,\n                    'page_name': 'tag-n-shoot',\n                    'sticker': $('input[name=sticker]:checked').val(),\n                    'y_pos': $(\"#y-pos\").val(),\n                    'x_pos': $(\"#x-pos\").val()\n                });\n            }).on('complete', function(response, id, fileName, data){\n                if(data.result === \"success\" || data.success === \"true\") {\n                    $(\"#enter-tag-desktop\").hide();\n                    $(\"#enter-tag-success-desktop\").show();\n                } else if(data.result === \"exists\") {\n                    alert(\"already voted\");\n                }\n            });\nAnd here's the relevant server side code:\n``` php\nrequire_once('external/qqFileUploader.php');\n        $uploader = new qqFileUploader();\n    // Specify the list of valid extensions, ex. array(\"jpeg\", \"xml\", \"bmp\")\n    $uploader->allowedExtensions = array(\"jpeg\",\"jpg\",\"png\");\n\n    // Specify max file size in bytes.\n    $uploader->sizeLimit = 2 * 1024 * 1024; // up this to 10 on the dev, staging and production servers\n\n    // Specify the input name set in the javascript.\n    $uploader->inputName = 'qqfile';\n\n    $path = '../assets/files/' . $entry->id;\n    $safe_file_name = strtolower($sanitizer->name(md5(mt_rand()).'_'.$uploader->getName()));\n\n    // To save the upload with a specified name, set the second parameter.\n    $qqresult = $uploader->handleUpload($path, $safe_file_name);\n\n```\n. Hi Ray,\nHere's the upload function:\n``` javascript\nupload: function(id){\n            /*var input = inputs[id],\n                fileName = api.getName(id),\n                iframe = createIframe(id),\n                form = createForm(id, iframe);\n        if (!input){\n            throw new Error('file with passed id was not added, or already uploaded or cancelled');\n        }\n\n        options.onUpload(id, this.getName(id));*/\n\n        var input = inputs[id],\n              fileName = api.getName(id),\n              iframe = createIframe(id),\n              form;\n        if (!input){\n              throw new Error('file with passed id was not added, or already uploaded or cancelled');\n        }\n        options.onUpload(id, this.getName(id));\n        form = createForm(id, iframe);\n\n        form.appendChild(input);\n\n        attachLoadEvent(iframe, function(){\n            log('iframe loaded');\n\n            var response = getIframeContentJson(iframe);\n\n            // timeout added to fix busy state in FF3.6\n            setTimeout(function(){\n                detachLoadEvents[id]();\n                delete detachLoadEvents[id];\n                qq(iframe).remove();\n            }, 1);\n\n            if (!response.success) {\n                if (options.onAutoRetry(id, fileName, response)) {\n                    return;\n                }\n            }\n            options.onComplete(id, fileName, response);\n            uploadComplete(id);\n        });\n\n        log('Sending upload request for ' + id);\n        form.submit();\n        qq(form).remove();\n\n        return id;\n    }\n\n```\nI've attached the request and response headers and body from IE 9 on Win 7.  All of my data gets saved as expected, except for the image.\n\n\n\n\n. OK, so there is nothing I need to do on the client side to prepare for IE being able to send the file properly?\nI'm going to prepare a test case with the example PHP code as is.\n. OK, thanks.  I figured out why IE wasn't getting the file.  I was doing a check for the qqfile param, which I'm guessing is only sent for File API enabled clients.  Switching to check for qquuid did the trick. \nThanks for your help.\n. Figured it out, for some reason the File input that FineUploader generates was sitting in front of all my entire row of action buttons... i need to find way to either move it or disable clicks on it.. ",
    "quiet2": "don't work upload file size more 30M\nmy php.ini options:\nmemory_limit = 200M\npost_max_size = 200M\nupload_max_filesize = 200M\nI use upload php.php here:\nclass qqUploadedFileXhr { \n    function save($path) {\n                $in = fopen(\"php://input\", \"r\");\n        $out = fopen($path, \"w+\");\n        stream_copy_to_stream($in, $out);\n        fclose($in);\n        fclose($out);\n                return true;\n     }\n...\nthis method not working\ni test in firefox\nyou solve this problem?\nthanks!\n. ",
    "gabomdq": "@dresende It is not bc of max input time, I was getting memory maxed out errors.\n@quiet2, you have to edit the uploader javascript file, change:\nxhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\nfor\nxhr.setRequestHeader(\"Content-Type\", \"multipart/form-data\");\n. ",
    "mortik": "Hi,\nwhen i change the Content-Type to \"multipart/form-data\" i am getting a php error with each file upload...\n\"PHP Warning:  Missing boundary in multipart/form-data POST data in Unknown on line 0\"\n. ",
    "mrvanes": "I solved the PHP out of memory issues by setting the xhr protocol to PUT instead of POST in fileuploader.js\n1446:         var protocol = this._options.demoMode ? \"GET\" : \"PUT\";\nAccording to this advice: http://stackoverflow.com/questions/10475313/ajax-file-upload-with-xmlhttprequest\n. Believe me when I say I'm soo not a GitHub guru. I just downloaded the .zip and started playing with the code when I noticed PHP going OOM on large files. After I found the solution I thought I'd share it with you guys. Please don't ask me to pull whatever I don't get (I still use svn for my own projects, oops).\n. ",
    "numinos1": ".\n. ",
    "wjzijderveld": "Would like this as well! I use this in combination with jQuery Dialog, so I want to trigger the upload (plus other form fields) on clicking a button.\n. I have figured it out, I extended the FileUploader to work with a button. It is not completely what is asked, but sufficient for me.\nBecause it is an extend, I didn't make the changes in the code itself. I'll try to add the extends in the code itself en make a pull request for it.\n. Created a pull request with the adjustments I made.\nhttps://github.com/valums/file-uploader/pull/168\n. Will have to look into that, but don't have time for it at the moment.\nI can see in my code that your first issue (double upload) can occur.\nThe second issue I can take a look at.\n. @tommymarshall Added a bugfix for uploading 'old' files.\nSee https://github.com/valums/file-uploader/issues/100 for a solution about onCompleteAll(), it is pretty simple. But to integrate it in to the code would be a bit harder, especially to maintain.\n. Should be, I call _uploadFile which on his turn triggers the onSubmit? \nBut must admit, I haven't tested all scenarios. Problem is that I don't have the time now to write tests.\n. The whole idea is not to submit on select :-)\nI will add an onChange option that I trigger in _onInputChange.\n. Added the onChange, but needs more testing in IE. Browserstack.com is awesome, but won't let me upload files\n. Thanks!\nCan you explain what you mean? \nYou can just return false in either the onChange or the onSubmit to cancel an upload.\n. I don't have a solution for that. It's a known 'bug' for me, the filelist isn't build in my uploader, not untill you press submit.\nThe reason is, that the FileUploaded uses an ID to identify each item in the list, but that ID is not generated till the upload.\nI can probably fix this, by generating that ID in an early stage, but that would mean I should alter the FileUploader, instead of just extending it as I do now. And that's something I try to avoid.\n. Sorry, missed this comment.\nNot sure what you mean. \nYou can just comment on the discussion tab, you can also goto 'diff', hover over a line and click on the comment icon on the left of the line. You then comment on that specific line.\nWhere did you add the this._button.reset(), I will add it then?\nYou can also fork my fork and apply the change :)\n. Yes, that's possible. And imho pretty clear documented.\nJust create multiple instances:\nvar imageUploader = new qq.FileUploader({ element: '#image', [..]});\nvar galleryUploader = new qq.FileUploader({ element: '#gallery', [..]});. \nAnd pass different element values to them.\n. javascript\nvar uploader = new qq.FileUploader({\n  multiple: false\n});\n. issue's aren't for support questions :)\nBut if you just read the documentation, you should be able to figure it out. How you used my example in the code above doesn't make any sense. You should use the option 'multiple' in your uploader instances. Not just add a new instance...\n. ",
    "wcolbert": "Anyone figure this out?\n. ",
    "dmolavi": "@wjzijderveld - Can you post an example of this? (or msg me here)?\n. I've been looking for something like this, however, I cannot get it to work. The button is still non-jQueryUI-ified on my page.  Does this require a change to the JS declaration?\n. Ah, I am using the standard init.  How do you go about using the wrappers init? (as a workaround, i modified the CSS of the button to match the CSS of the UI theme I'm using).\n. ",
    "esneko": "Opera 11 has support for input with multiple option now:\nhttp://www.opera.com/docs/changelogs/windows/1100/\nBut uploader does NOT allow multi-upload for Opera yet.\n. After the line:\nvar response = self._getIframeContentJSON(iframe);\nTo be added:\nself._completed_files.push({file: input, response: response});\n. ",
    "ulikkg": "What to do to have multiupload in opera an internet explorer? Safar is giving error. So only FF and Chrome supports\n. Exact same error. any solution?\n. ",
    "zackd": "..could send an ajax request to the server @ onCancel and trigger the clean-up ?\n. ..if your using jquery .. you could do:\nelement: $(\".className\")[0],\n. - same with Opera 11.0 beta\n. not a bug : was result of server-side bug in our app\n. ",
    "alfaproject": "No problem. I also have a small fix for PHP versions lower than 5.2, but I don't know if you want to support those.\n. You are right about strrpos returning false, but the next line should still work because 'extension' works fine (?) in php < 5.2.\nAnyway, I stopped caring about php < 5.2 last month, lol\n. ",
    "tyron": "Seems pretty good!\n. ",
    "TheAwesome": "One question, how could I then use the changed filename in an onComplete call?\nDon't worry, I figured it out on my own.\nIf other people need to know:\nvar filename =responseJSON['filename'];\n. I had the same problem.\nFrom memory you should be using $_REQUEST['ad_dir'] instead of $_GET['ad_dir']\n. It should be \n$hhy_dir=$_REQUEST['ad_dir'];\nnot \n$hhy_dir=($_GET['ad_dir']);\nIf it is still not working then there is problem with the other part of your code.\nBut that looks ok.\nSo try it without the brackets around the variable.\n. and I said get rid of the brackets. Did you do that?\nHave you tried using Firebug to see if the variable is being sent properly?\nOr just using a folder name directly to see if the rest of your code works?\nI'm not sure if !(is_dir($dir)) will evaluate correctly.\nI would normally just write\nif(is_dir($dir)){\n//move file\n}else{\n//create dir\n//move file\n}\nwhere in this situation //move file can just be do nothing\n. also if you're using windows then php will ignore the mode in mkdir.\n. my php:\n$dir=$_REQUEST['dir'];\n$uploader = new qqFileUploader($allowedExtensions, $sizeLimit);\n$result = $uploader->handleUpload($dir);\nWorks fine (I know that the directory exists).\nmy JS:\nparams: {dir: \"directory\"},\nwith the directory coming from php.\nSo you should check your JS variable:\nvar ad = document.getElementById('ad').value;\nas maybe it is just empty and that is why it isn't working\nhttp://getfirebug.com/\nfor chrome or firefox.\nYou can use firebug and once you have uploaded your file you can check the console and it will have all the data sent in the POST,\nso then you can see if it is being sent to php or not\n. try it with params: {ad_dir: \"ad\"}\nand see if the string ad makes it to php.\nif it does then it suggests that the javaScript variable you are passing is empty.\nSo I'd say that the problem is with:\ndocument.getElementById('ad').value;\nor with passing a javascript variable into the params,\nso maybe try encoding it with json_encode() (google it)\n. I've thought about it some more and I think I know what's wrong.\ndocument.getElementById('ad').value; is being defined when the page loads,\nso it is emtpy.\nYou need to define it when the upload button is clicked,\nso it needs it's own function to call\nie\nfunction onUpload(){\nvar ad = document.getElementById('ad').value;\n}\nand call it onClick of the upload button.\nOR\nadd it to the ulpoad function.\nSomething like:\nfunction createUploader(){\nvar uploader = new qq.FileUploader({\nelement: document.getElementById('file-uploader-demo1'),\naction: 'upload.php',\nparams: {\nad_dir: document.getElementById('ad').value\n}\n});\n}\ntry them out and see what happens.\nDo you get what I mean about it being the value when the page loads?\nThere's nothing to make that variable update itself when you type text in\n. ",
    "robink": "\"dragleave\" seems to be not fired \n. ",
    "quinn": "I'm having a similar issue.. though dragleave is fired, the code used to decide to hide the drag target doesn't seem to work:\njavascript\nif ( ! relatedTarget || relatedTarget.nodeName == \"HTML\"){               \n    dropArea.style.display = 'none';                                            \n}\nIt works in the fileuploader demos because the demos seem to be using an old version of the code. The drag / drop code was changed in this commit: https://github.com/valums/file-uploader/commit/c3fdfc37c0b22b48582ae83643f648a23c782665\nIt used to be using a timeout method. For me \"relatedTarget\" never returns a node with a name of \"HTML\", it (unsurprisingly) returns various elements near the drop target. I tried adding back in a timeout fix but the code was messy and nothing really worked consistently. Maybe it would be advisable to bind something to a mouseup event (is there such thing as a \"drag-release\" event??) that would work more consistently. \n. ",
    "ajbeaven": "Also an issue on Chrome 12. \nFor me, nodeName is always \"DIV\"\n. ",
    "xaviershay": "It also does it for IE. This occurs because fileuploader has to revert to an iframe hack to submit the form, and doesn't copy across the CSRF token. I don't have a fix yet.\n. I fixed it: https://github.com/xaviershay/file-uploader/commit/a7eeccad4ff0944793d05f154ddb98726f6f5416\n. urgh that is sad face.\nNot sure what Opera is doing, this thread suggests that should work: http://stackoverflow.com/questions/991367/how-to-get-the-form-parent-of-an-input\nPerhaps you could change it to just navigate up the dom via parentNode rather than using .form.\n. Better way of fixing it: just pass the authenticity token in the params:\nuploader = new qq.FileUploader({\n  // ... whatever\n  params: {\n    // jQuery, but you can do in whatever framework\n    authenticity_token: $('meta[name=csrf-token]').attr('content')\n  }\n})\nI retract my fix above, instead the above method can be used with the current master code.\n. ",
    "Zatvobor": "excellent!\n. but opera 11 for mac throws another js exception\nprint screen: https://skitch.com/azatvornitskiy/rp3fb/\n. ",
    "ecoulthard": "I applied this fix which got rid of the exception but now in ie8 when I upload a file it never finishes. That is the spinning gif just keeps spinning forever. My js code is below.\n$(document).ready(function() {\n  var uploader = new qq.FileUploader({\n    element: document.getElementById('file-uploader'),\n    action: '/photos/xhr_create',\nparams: {\n  authenticity_token: $('meta[name=csrf-token]').attr('content')\n}\n });\n});\n. By putting alerts everywhere, I was able to pinpoint where the code stopped. In _getIframeContentJSON it didn't make it past this line.\nvar doc = iframe.contentDocument ? iframe.contentDocument : iframe.contentWindow.document;\n. I just realized that IE8 displays the error 'Permission denied' for this same line in fileuploader.js\nI have tried to insert the token other ways, but I am afraid that I am out of my league on this one. Is there anyway to add the authenticity_token without IE8 blocking access to the iframe content?\n. ",
    "boddhisattva": "I have tried using this plugin with Rails 2.0.2(for project specific purposes) configuration and I am encountering the same error in firefox 3.6.8 and Chromium 11.0.687.0 (76345), Ubuntu 10.04. I had to uncomment the following line as shown below in my verify_authenticity_token method(this belonged to /gems/ruby-1.8.7-p334/gems/actionpack-2.0.2/lib/action_controller/request_forgery_protection.rb) to upload images via AJAX.\ndef verify_authenticity_token\n        verified_request? || handle_unverified_request          //line which was commented\nend\nThe reason behind me adding the code is , the files are pertaining to an old config and it would have changed by now.\n. ",
    "dkimbell13": "I banged my head against the wall for a couple of hours too. Using Coldfusion as a backend, and using the providing code (Which I assumed was correct) I kept getting the access denied and permission denied errors. This is due to the resulting call to the fileupload.cfc returning an http 500 error in IE8/7. \nWhy? Because there was an error in the code! The fileField attribute of the cffile tag specifies the value, 'arguments.qqfile'. This is incorrect. The correct value should be 'qqfile', the actual name of the form field used to pass the file name to the fileupload.cfc script.\nI did Fork and push a fix out. I doubt it has been included in the master yet though.\nHope this helps those of you who are having this error in IE and are using Coldfusion!\nD\n. I banged my head against the wall for a couple of hours too. Using Coldfusion as a backend, and using the providing code (Which I assumed was correct) I kept getting the access denied and permission denied errors. This is due to the resulting call to the fileupload.cfc returning an http 500 error in IE8/7. \nWhy, because there was an error in the code! The fileField attribute of the cffile tag specifies the value, 'arguments.qqfile'. This is incorrect. The correct value should be 'qqfile', the actual name of the form field used to pass the file name to the fileupload.cfc script.\nI did Fork and push a fix out. I doubt it has been included in the master yet though.\nHope this helps those of you who are having this error in IE and are using Coldfusion!\nD\n. ",
    "d1rk": "+1\n. thanks for your hint - i will check that.\n. ",
    "lukemorton": "(function ($) {\n    $.fn.fileUploader = function (settings) {\n        return this.each(function () {\n            new qq.FileUploader($.extend({\"element\": this}, settings));\n        });\n    };\n}(jQuery));\n. You could write one yourself was my point :)\n. ",
    "hamczu": "great! but i also thought about:\n- settings params\n- clearing list of uploaded files\n- list of created instances\n. ",
    "ashchan": "You don't have to hack the file-uploader script. Here's how I do it in my projects (using jquery):\nAfter the new qq.FileUploader(...) call, add this to replace the text:\n$(\".qq-upload-button\").contents().first().replaceWith(\"Your own text\");\n. ",
    "julesbou": "yes of course i did something similar but it's not the easiest solution IMHO.\nanyway thanks!\n. ",
    "joshas": "Not only labels, but error messages too should be localizable. Translations could be passed as parameters when creating file-uploader or use external file with translated strings.\n. ",
    "Camwyn": "I added two otions to the qq.FileUploader - buttonText and buttonTitle used thus:\njavascript\n            buttonTitle:'Choose new image to upload.',//text for uploader button\n            buttonText:'Click to upload a new image.', //title for uploader button\nthen went in and changed the text in the js file from \"Upload a file\" to:\njavascript\n\"<div class='qq-upload-button' title='\"+o.buttonTitle+\"'>\"+o.buttonText+\"</div>\" +\nworked like a charm, and allows it to be set for each individual instance...\n. FWIW, I did the above, and then to the __onComplete function I added: \nif(result['filename']){\n                $('.qq-upload-file').each(function(index){ //multiple buttons, so loop through them\n                    if($(this).text()==fileName){  //make sure we are changing the correct \n                        $(this).text(result['filename']);\n                    }\n                });\njust above the line: \"qq.addClass(item, this._classes.success);\"\n(note: I have multiple single-upload buttons on this particular page, if you are using the default multi-upload functionality you'll have to do some fancy text replacement ;) )\nNot the prettiest or neatest, but it works.\n. ",
    "Haddicus": "I did the same as Camwyn did, added two parameters to the options for FileUPloaderBasic at line 228 in fileuploader.js, and then added the parameters when I create the file uploader.\n. ",
    "alwhite90": "See answer in another post\n. ",
    "syslogic": "I can confirm this issue ... it's not just filesize = 0 ... it's file = undefined\nwhen it's passed to the validation... so it bugs out before that already.\n. it complains about 'wrong file type' or 'file size is zero' ... but the reason is = file = undefined.\n. Just have tested, not only the Android stock browser is affected - FireFox 4 has the same problem.\n. Think this issue might be related to this bug:\nhttps://bugs.webkit.org/show_bug.cgi?id=23933\nAny chance to get synchronous AJAX calls for mobile browsers?\n. file = undefined ... that is the main problem.\ntweaking the validation is just non-sense if there's nothing to validate.\n. haven't test this yet, but maybe it should be combined with a check for mobile browsers.\n. Using eval() is quite an anti-pattern when scripting JS... if you have jQuery loaded, that may help a lot.\nBeside JSON is neither text/plain nor text/html - the proper response header would be application/json.\nHint: Just don't send a UTF-8 encoding header to Internet Exploder...\nWell, I'd say JSON is basically rather text/plain than text/html - since un-escaped markup will break it's syntax.\nAs it seems, someone else sees it the same way as me, concerning the usage of eval():\nhttps://github.com/valums/file-uploader/pull/223\n. You need to define that for AJAX calls on IE (doesn't hurt other browsers): dataType:'json'\nBecause it's not able to recognize the response as JSON by itself - and so it treats it as string (even if it logs object).\nThat doesn't go into the onComplete method, needs to be added to the method that drops the call already.\nJust had this problem today with one of my scripts... even works on IE6!!\n. Nope, not to the instance of the object ... to it's method that drops the ajax call.\nJust set the debugger to break on XHR... this should show you where it happens.\nSorry, I'm at work right now ... but I guess this might probably close this issue :)\n. It's about the expected response dataType...\nxhr.open(\"POST\", queryString, true);\nxhr.setRequestHeader(\"X-Requested-With\", \"XMLHttpRequest\");\nxhr.setRequestHeader(\"X-File-Name\", encodeURIComponent(name));\nxhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\nxhr.setRequestHeader(\"Accept\",\"application/json\");\nxhr.send(file);\nBut I do agree: with IE a strong believe in god is required, indeed :)\n. Shouldn't be hard to fix - just use a HTTP + JS debugger.\n(Your bugged implementation is not exactly my cup of tea)\nBesides this IS the code of the upload handler.\n. Sending the content within the header seems quite strange to me?!\nWell, 'application/html' is just non-sense, there is no such content type.\nclient-side ... this is quite essential for IE:\nxhr.setRequestHeader(\"Accept\",\"application/json\");\nserver-side:\nIE just bugs out dearly when setting JSON headers\n... so just respond to it without any header :]\nhttp://www.codefx.biz/2011/02/json-with-internet-explorer\n. Try to instance both uploaders witin a single function call\nwindow.onload = createBothGalleryUploaders();\n. ",
    "igloox": "Firefox 4 works fine for me, but the stock browser on Android 2.3 and the webkit-based 'Midori' browser appear to exhibit the same problem.\nAt the very least, is there a way I can force those browsers to use the legacy iframe method until this gets straightened out?\n. > Android browser doesn't support uploading. Nothing to do with this excellent project...\nYes it does, at least as of 2.3, possibly earlier. I've been doing it all week. It even works with Blueimp's jQuery-File-Upload\nedit: I've just tested, it even works with 2.2\n. ",
    "bayarmunkh": "It doesn't work on Adroid 2.3. I got the same error that says 'EmptyError.' Does anyone have an idea?\nThanks,\n. It works. Excellent!.\n. I am not sure, is it a good idea. But, you can try.\nIn the _ValidtateFile section, change following thing.\n} else if (size === 0){\n        this._error('emptyError', name);\n        return false;\nTo :\n} else if (size == undefined){\n        this._error('emptyError', name);\n        return false;\nIt worked on my Android (My Touch 4G).\nThanks,\nBayarmunkh\nOn Thu, May 19, 2011 at 12:04 PM, oviroa \nreply@reply.github.comwrote:\n\n@ bayarmunkh how did you make it work?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/82#comment_1204844\n\n\nRegards,\nBayarmunkh\nchiigle@gmail.com\nchiigle@gmail.com\nCell Phone: 641/233-0537\n. ",
    "oviroa": "It stil won't work for me. Still get the EmptyError. I am on 2.3 on a Nexus one.\n. @ bayarmunkh how did you make it work?\n. Didn't quite work. Error is gone but file doesn't get uploaded. Ideas?\nOn 5/19/11 10:12 AM, \"bayarmunkh\"\nreply@reply.github.com\nwrote:\n\nI am not sure, is it a good idea. But, you can try.\nIn the _ValidtateFile section, change following thing.\n} else if (size === 0){\n       this._error('emptyError', name);\n       return false;\nTo :\n} else if (size == undefined){\n       this._error('emptyError', name);\n       return false;\nIt worked on my Android (My Touch 4G).\nThanks,\nBayarmunkh\nOn Thu, May 19, 2011 at 12:04 PM, oviroa \nreply@reply.github.comwrote:\n\n@ bayarmunkh how did you make it work?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/82#comment_1204844\n\n\nRegards,\nBayarmunkh\nchiigle@gmail.com\nchiigle@gmail.com\nCell Phone: 641/233-0537\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/82#comment_1204897\n. \n",
    "bgrandgeorge": "Guys, I did this, and it works on my galaxy tab:\nelse if (size === 0){            \n        //    this._error('emptyError', name);\n        return true;\nOnly problem with this is that it screws up the cancel when you want to NOT upload after clicking upload... But I can live without it for a while! (the cancel while uploading still works)\nThe problem is that Android browser(s?) are not reporting the file size... Not sure if it is an android issue, or a browser issue... is there a chrome for android?\n. Yes, like in the case of the safari browser... Not exactly sure what to put though.\nHere is the browser info on my Galaxy tab (with default browser and Gingerbread):\n- Browser CodeName: Mozilla\n- Browser Name: Netscape\n- Browser Version: 5.0 (Linux; U; Android 2.3.3; en-gb; GT-P1000 Build/GINGERBREAD) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1\n- Cookies Enabled: true\n- Platform: Linux armv7l\n- User-agent header: Mozilla/5.0 (Linux; U; Android 2.3.3; en-gb; GT-P1000 Build/GINGERBREAD) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1\n. See my post here, I've found a solution that works for me:\n82\n. Actually, if you declare your valums' uploader like this:\nvar uploader = new qq.FileUploader({...})\nYou can access to each file in the list by:\nvar fileItem = uploader._getItemByFileId(file);\nWith this this I was able to update the list item I want and change it to the image uploaded ;-)\n. You can use jQuery to change the inner html of the item in the list:\n$(fileItem).html('<whatever html code you want here>');\nOr to remove the element:\nuploader._listElement.removeChild(item);\n```\n. This is not a bug... IE just doesn't support multiple upload.\n. You just need 3 divs with different ids, and use the \"element: document.getElementById('XXX-uploader')\" parameter, to refer to each.\nCheers\n. Ah I think that you also need to change the javascript variable each time:\nvar uploader1 = new qq.FileUploader({\nvar uploader2 = new qq.FileUploader({\nvar uploader3 = new qq.FileUploader({\nBG.\n. If you want to compress the javascript file you can always minify it with YUI Compressor: http://developer.yahoo.com/yui/compressor/\n. ",
    "Deivi": "Thank you very much to solve the problem mate, I've added a few lines of code for just when browsing devices remove this._error androids ('emptyError', name) and return true. This is implemented:\n\n_validateFile: function(file){\n        var name, size;\n        // Stores data from operating system and browser you are using.\n        var uagent = navigator.userAgent.toLowerCase();\n        var deviceAndroid = \"android\";\n        var deviceMobile = \"mobile\";\n\n        if (file.value){\n            // it is a file input            \n            // get input value and remove path to normalize\n            name = file.value.replace(/.*(\\/|\\\\)/, \"\");\n        } else {\n            // fix missing properties in Safari\n            name = file.fileName != null ? file.fileName : file.name;\n            size = file.fileSize != null ? file.fileSize : file.size;\n        }\n\n        if (! this._isAllowedExtension(name)){            \n            this._error('typeError', name);\n            return false;\n\n        } else if ((size === 0) && ((uagent.search(deviceAndroid) > -1) || (uagent.search(deviceMobile) > -1))) {\n            return true;\n\n        } else if (size === 0)  {\n            this._error('emptyError', name);\n            return false;\n\n        } ......\n\n\nMany greetings to all.\n. Thanks for answering.\nI do not I just drag the image by using a button, but the tablet to get the picture gives me the error: empty file. It is as if the tablet had another system to take and upload images, unlike a PC.\nRegards.\n. ",
    "a-c-m": "Anyone confirmed the above patch/rewrite fixes it?\n. Confirmed, the above fixes the issue.\n. ",
    "entropie": "Confirmed too. Thanks Deivi.\n. Confirmed for Win7 and IE9.\n. ",
    "luxifer": "I just change the\n\n} else if (size == 0){\n  this._error('emptyError', name);\n  return false;\n\nto\n\n} else if (size == undefined){\n  this._error('emptyError', name);\n  return false;\n\nand it worked fine for me ;)\n. ",
    "njam": "It seems to me the Android 2.3 browser wrongly sets both the \"size\" and \"fileSize\" property of a selected file to zero.\nTested with the SDK emulator and http://jsfiddle.net/VgZnh/\nI find it odd that there seems no other discussion about this anywhere - does anyone see another reference/bug report?\nI think the only workaround is to ignore size===0: https://github.com/cargomedia/file-uploader/commit/c727082f5b45b9c15c380d264ca4ce9587c90df7\n. ",
    "DGuidi": "@Deivi patch works also for me with Samsung Galaxy TAB.\nThanks @Deivi :\n. ",
    "abennouna": "I used both 2.3.3 and 3.1 stock browsers with the demo webpage and only\nthing that fails is the sizeLimit parameter ie I can upload files that are\nbigger than that.\n. I tested with 2.3.6, same issue (I can upload files bigger than the sizeLimit). Other than that, everything seems to run ok.\nDisclaimer: tested the Android versions only on the 2.1.2 and to-be-released 3.0 demo pages.\n. Yes, in the current php.php file we still need this change: https://github.com/tellibus/file-uploader/commit/2e9f09660c7e2bd2d7c0494520a6342b51e77bc5 (applied on the current master's file)\n. @rnicholus it's as easy as https://github.com/tellibus/file-uploader/commit/2e9f09660c7e2bd2d7c0494520a6342b51e77bc5\n. I am not sure I'm following but provided you return the filename (ie the\nresponse JSON in the case of PHP), you can use the demo as is and use the\nserver upload path + returned filename\n. Yes I'm sorry #341 was the correct one. Thank you for correcting.\n. Don't know where to bury myself. I thought it would be two different PRs\u2026 Sorry for the trouble:\nThese changes are amongst the one we needed to make to file-uploader in a previous project. I thought it would be easier for you if I committed the relevant parts separately :o)\n-- I've just seen #339. I unfortunately don't have IE9, and we had outed any IE for the first project using FU, and now we just check for ChromeFrame :-\\ Don't know how to help?\n. Ray, I closed it to open a new PR, as you explained above in https://github.com/valums/file-uploader/pull/341#issuecomment-8776917\nAlso, maybe we just need an option \"stopOnFirstInvalidFile\" with true as default value to preserve existing behavior and bc.\nSo should I open a new PR? I didn't want from the beginning to mix JS with PHP.\nEdit: I see that when I reverted my commits, this PR is sort of \"clean\". So maybe no need to open a new PR then. Please advise.\n. Yes Ray but I guess I'll just open a new slightly-improved PR. Thanks for your patience.\n. While this is currently what I do, on second thought, I was thinking that any cleaning of file names and so on should be on client-side.\nAlso, I'm not sure that the code above handles correctly non-latin characters\u2026\nIn your setup, you've never encountered file names limitations?\n. Ok then, I'll submit a PR then\n. I believe I won't be able to file a PR in short term. I must refactor the code I suggested in order to make it optional and to allow custom sanitization patterns because that regex simply removes non-latin characters from filenames, which makes it very limited.\nYou can close this issue if you like.\n. Ray, what else would you need to get it into 2.1? Should I amend the Readme as well with the additional option?\n. I like your idea of grouping validation / error messages at the end of\nthe upload, and that still preserves BC.\nAs for the alert scenario, I'm personally attracted to BS, but if the only\nuse is for alert boxes, I guess there should be more trivial and\nlightweight js scripts.\nFor instance, if we are to be using jQuery, I'd rather favor Trent\nRichardson's Impromptu.\n. Good point.\n. @rnicholus In the updated readme you wrote sendMessage instead of showMessage.\nAlso, I've just incidentally realized that moving all the validation to server-side only gets rid of the alerts (because showMessage doesn't get fired), obvious downside is unnecessary server requests.\n. That's not what I meant :)\nI meant that even if showMessage stays like this, it won't be called in most cases if I init FU without specifying validation rules (allowedExtensions, sizeLimit, etc.) That's what I realized.\n. I've implemented #157 (https://github.com/jeremywiebe/file-uploader/commit/182e75a8c9c73d091a8f141327211fccb6160831) to achieve this one. Tested on Safari, FF, and Chrome (latest ones) on Mac OS X.\nIt does the job.\n. Am I wrong supposing that most developers and users would use binary\nprefixes? Afaik, all computers use kB, MB and GB in their binary definition.\nMy point is that someone would want to upload a 50 KiB file (that shows as\n50 kB in the file system) and that won't work with a sizeLimit of SI 50\nkB...\n. As an OS X user, I wasn't even aware that my laptop was using SI definition. I personally always assume binary even when reading kB, MB and GB.\nI would not argue with leaving things as they are now. Specifying size in bytes is not a big deal after all.\nSo voting for \"won't implement\" +1\n. You're right, I must have overlooked the already open issues.\nAnd really, thanks for your feedback and your time.\n. I'm not sure I'm more skilled in graphic design, but I'd like to help.\n. I'm nearly setup with the design (very basic TB actually). I'm looking at the gh-pages branch and I don't see boostrap there. Should I include it in the PR?\nEdit: Ok I see you've included it from a CDN. Disregard :)\n. Ok, it's still WIP but you can see what it can be at https://github.com/tellibus/file-uploader/blob/site-demo(gh-pages)/\n(no js included for the moment)\nSince it seems impossible to preview on gh: you can see it here: http://tellibus.com/fineuploader/\n. For the looks, normal. It's using the standard Css classes with really\nminor changes.\nFor the demos, yes it's in progress. I plan to have two separate pages for\nFUB and FU as you can see from the menu.\nWill keep you updated.\n. I should also include the most simplest demo on the index page. And for\neach demo, provide the underlying js code.\n. May I ask why we don't continue here or on the forum?\n. I pushed new version with demo on the homepage:\nhttps://github.com/tellibus/file-uploader/commit/cefe218df4d399448f10108576f980d9dbe3d0b1\nAlways visible at http://tellibus.com/fineuploader/\nLooking forward to your feedback\n. Well there's still work going on btw. I still have demo page(s) to do (maybe I'll skip the FUB one if there's no real interest). I'd prefer to have these separate, it's long enough on small screens (mobile) and I think one should clearly isolate the basics from the custom.\nAnyway, I wonder if I should bootstrap all the remaining demos, because as you can see/guess, there's additional markup that can lead visitors to think it's a complicated plugin. What do you think?\nFor Bootstrap's affix, I don't believe it's a good idea since the right panel would just be narrower, and that means smaller width for the code. Plus I've tested it on Android tablet and smartphone, and it's really slow. I would just drop a given plugin if its demo page is not working properly (including if it's slow) -- you see what I mean? And I'm not talking about page loading speed per se, I'm talking about (Bootstrap) JS files here.\nAnyway, I've just pushed a new version with a \"Setup\" section.\n. You can see what I mean here:\nhttp://tellibus.com/fineuploader/fine-uploader-demo.html\n. Ok we're in sync then. Let me finish it and I'll file a PR.\n. I have included now all the demos you had. I've overridden the showMessage option as well in the last one.\nWhat other demos can you think of?\nI can think of two more (may be merged):\n- One with a callback to display a (fake) thumbnail of a given uploaded image? Obviously, since no server-side processing takes place, I'll use a hard-coded dummy one.\n- One that deactivates the uploader after a number of files have been uploaded, and re-activates it if one of them is deleted / cancelled. This will be using onSubmit and onComplete callbacks as well as additional jQuery.\n. The two additional demos are there. Ray, can you tell (again :)) me what's left in order to file a PR?\nPS For the second demo, I have skipped the \"re-activation\" because it depends on the webapp. Please refer to my inline comment.\n. @rnicholus\n\nThere are a few modifications I'd like to make though,\nsuch as providing a link to releases page, a link to the\nmaster readme, and perhaps a heavily abridged version\nof the master readme.\n\nFirst two are done. For the abridged version of the readme, can you do it?\n\nI don't think it is absolutely necessary to provide a\nFUB demo, but perhaps we should since I'm not sure\nhow else we can refer to FUB (and I don't want to leave\nit out of the home/demo page).\n\nOk, working on it\n. FUB demo done (bootstrapped this time). I think I should PR now, what do you think @rnicholus?\n. Maybe you missed the link to the Releases page? It's at the very bottom on\nthe right\n. PR is #408\n. > override showMessage in FUB demo (and possibly others as well)\n\nto use something like TB alerts instead of the default window.alert function\n\nI had done it in the Various Options demo\n. I've used onProgress: I check whether uploaded size < total size and\ndisplay progress (with FUB), otherwise I display another status message. Is\nthat what you're referring to?\n. I think you missed something in the further changes, not sure what. But the secondary navbar in \"More demos\" page is no longer sticky so it's quite useless now.\nPlus, while it's a good thing to have common header and footer, we no longer see in the header navbar which page we're actually in (the class=\"active\" that was appended in the relevant menu item in each page). Now, we can work out this one with a little JS, unless we can use some server technology on gh-pages (PHP, or else)?\n. > I think you missed something in the further changes, not sure what. But the secondary navbar in \"More demos\" page is no longer sticky so it's quite useless now.\nI think I know :) You left my scrollspy script in place, but it's checking DOM nodes that are not yet present. Please put it after your header include js.\n. Yes I noticed the callback as I checked your commit, not sure the $(document).ready() is necessary inside the callback though?\nFor DRY, I agree. I just guessed no PHP on gh-pages, and I've never thought about the includes via Ajax like you did.\nFeel free to re-organize! It's just a canvas after all.\n. Please put the php code you've shown in a separate file. That is the file\nthat you should pass on to the uploader's action property in your js code.\n. Resizing is not possible now. But if you google it, you'll find easily how\nto combine jCrop and Fine Uploader. You can also do it server-side. With\nPHP, you need GD library on your server and you may do it natively or with\nthe help of WideImage 3rd party library.\n. Please see Fine Uploader Basic demo.\n. Well there's a drag and drop feature (you can try to drop a file on the button in the Fine Uploader Basic demo). But I'm not sure there are handlers for it\u2026\nOn 23 oct. 2012, at 00:45, CodeBuddy wrote:\n\nGreat,\ndoes FileUploaderBasic have drag and drop methods too?\n\u2014\nReply to this email directly or view it on GitHub.\n. Ray, except for the screencast, you can count me in if you want me to delegate some / all of the tasks.\n\nBtw, when is 3.0 expected? I haven't seen the milestone for it.\n. @rnicholus I can take the two easiest ones :-)\n\n\u2022 modify example/demo code to reflect all changes in 3.0\n\u2022 add jQuery plug-in example\n. Fine. I'll be able to work on the demo update (the two tasks I can handle) next week.\n\nOn 2 nov. 2012, at 02:56, Ray Nicholus wrote:\n\n@tellibus We should create a branch based on gh-pages and do all 3.0 work there. I don't want to merge 3.0 changes with gh-pages until the release date for 3.0. I'll create a gh-pages-3.0 branch that we can both work in tonight.\n\u2014\nReply to this email directly or view it on GitHub.\n. It is now :)\n. I may have missed the answer to this question, but do you plan to combine all the js in one file? I can't find a combined file on the 3.0 branch, so I'm combining them for the sake of the demo.\n. Oh thanks! I knew it was somewhere :)\n. Work in progress: http://tellibus.com/fineuploader/ that's all for today...\n. Ok no problem then. So long 2.x :)\n. Still WIP. Will continue and hopefully finish tomorrow.\n. Still WIP. Finished homepage and Fine Uploader demo page. Todo: jQuery wrapper (will simply convert FU page), and FUB demos (adapt to 3.0).\n. Thanks. Great you like the logo.\n. Done with PR https://github.com/valums/file-uploader/pull/459\n. Good points!\n. Fine Uploader Basic demo includes a simple callback that tracks file count,\nand even disables (ie hides) the uplader after a certain number of files\nhave been uploaded.\n. I've just tested it and I don't see that error. Can you confirm you get this error on the Fine Uploader home page? What browser are you using?\n\nOn 2 nov. 2012, at 08:52, prashant7july wrote:\n\nelement not found spinner\nthrow new Error('element not found ' + type);\nwhy I am getting this Issues during the \"Manually Trigger Uploads\" http://fineuploader.com/fine-uploader-demo.html\n\u2014\nReply to this email directly or view it on GitHub.\n. So just to make this clear, you don't have the error in the homepage demo itself, but in your own implementation?\n. If I get what you want, you want to set an  tag as the element for a qqFileUploader instance?\n\nI'm afraid it won't work, (notably) because the plugin inserts the input inside the handler element.\nIf you want to have an image as your input handler, you can set a  as the upload handler element, and set the image as the background of this div through CSS. Normally should work.\nOn 3 nov. 2012, at 19:04, Borut Toma\u017ein wrote:\n\nI am struggling with ways to attach fine-uploader to IMG element. For now I'm not sure why this doesn't work cos input element is indeed attached bellow img element after plugin init.\nIs this even possible or am I missing something?\nThanks!\n\u2014\nReply to this email directly or view it on GitHub.\n. Have you tried to actually put some text in you dom \u00e9l\u00e9ment (div)? See the\ndemo webpage for FUB. It doesn't use the jQuery wrapper but you get what I\nmean I guess.\n. http://fineuploader.com has been updated to reflect the new Fine Uploader 3.x version.\n\nThe 3.x version brings lots of features and improvements, and I suppose that previous versions are (will be?) no longer officially supported. (Ray would confirm or deny that)\nOn 22 nov. 2012, at 11:21, pinkopalla wrote:\n\nWell, I have a similar problem! Why on the official site http://fineuploader.com is reported that the fineuploader.js file is expected in client directory, i.e.\nwhile it is not available in the downloadable archive?\n\u2014\nReply to this email directly or view it on GitHub.\n. Hey Ray. Yes I can do that. Do you want them on the very homepage or a\nseparate one?\n. My attempt to it: https://github.com/valums/file-uploader/pull/528\n. Hello\n\nYou don't say what error you get (check your debug console).\nAnyway, I must say I've never personally seen that syntax \"window.$(\u2026)\". Are you sure it exists? I would use just \"$(...)\".\nGood luck\nOn 4 janv. 2013, at 12:15, udhams-optimus wrote:\n\nwindow.$\n. It seems you're using an <a> tag as a handler button for FUB? You need a block element, so the easy way to try is to style them accordingly <a style=\"display:inline-block\"> or, better yet, to use a <span style=\"display:inline-block\"> instead.\n. Just saying, have you tried simplifying the logic to uploaderList[] = new qq.FineUploader({\u2026}) instead of var manualuploader = new qq.FineUploader({\u2026})?\n. I am indeed curious as it's something I had but for accented Latin characters.\n\nPlease see also https://github.com/Widen/fine-uploader/issues/342\nYou could try\n$result['uploadName'] = utf8_decode($uploader->getUploadName());\n. ",
    "MrShift": "The \u201cContent-Type\u201d is wrongly identified when I upload files using FF. If I upload files with IE then I receive correct \u201cContent-Type\u201d.\nI use .NET and here is an example of my server handler with crucial moments:\n```\n[WebService(Namespace = \"http://tempuri.org/\")]\n[WebServiceBinding(ConformsTo = WsiProfiles.BasicProfile1_1)]\npublic class FileUploader : IHttpHandler\n{\npublic void ProcessRequest(HttpContext context)\n{\n    string fileName = string.Empty;\n\n    try\n    {\n        int length = 4096;\n        Byte[] buffer = new Byte[length];\n\n        fileName = context.Request[\"qqfile\"];\n\n        try\n        {\n            Picture loPicture = new Picture();\n            Stream loStream = null;\n\n            if (context.Request.Files.Count > 0)\n            {\n                //IE\n                loStream = context.Request.Files[0].InputStream;\n                loPicture.ContentType = context.Request.Files[0].ContentType;\n                fileName = Path.GetFileName(context.Request.Files[0].FileName);\n            }\n            else\n            {\n                //FF\n                loStream = context.Request.InputStream;\n                loPicture.ContentType = context.Request.ContentType;\n            }\n\n            BinaryReader loBinaryReader = new BinaryReader(loStream);\n\n            loPicture.Title = fileName;\n            loPicture.Bytes = loBinaryReader.ReadBytes((int)loStream.Length);\n\n            //Save loPicture in DB\n\n        }\n        catch (UnauthorizedAccessException ex)\n        {\n\n        }\n    }\n    catch (Exception ex)\n    {\n\n    }\n    context.Response.Write(JsonHelper.Serialize(result));\n}\n\n}\n```\nI encountered that bug due to [xhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");] in the latest version of file-uploader.\nThe previous version contains the following code:\n        var queryString = '?qqfile=' + encodeURIComponent(name) + '&' + qq.obj2url(params);\nxhr.open(\"POST\", this._options.action + queryString, true);\n    xhr.setRequestHeader(\"X-Requested-With\", \"XMLHttpRequest\");\n    xhr.setRequestHeader(\"X-File-Name\", encodeURIComponent(name));\n    xhr.send(file);\nThe new version has it different a bit:\n        var queryString = qq.obj2url(params, this._options.action);\nxhr.open(\"POST\", queryString, true);\n    xhr.setRequestHeader(\"X-Requested-With\", \"XMLHttpRequest\");\n    xhr.setRequestHeader(\"X-File-Name\", encodeURIComponent(name));\n    xhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\n    xhr.send(file);\nAs I can see, the \u201cContent-Type\u201d is enforced with the fixed value rather than use the value which is identified by a Browser.\nThe question is why it should be done? Just wanted to realize the changes are made in the new version of file-uploader to use this plugin safely and painless with further upgrades.\n. Sorry, How can I reopen issue?\n. ",
    "stargazer7": "My input fields weren't escaped. Here are the fields I was trying to describe:\nIf upload used:\n<input id=\"fileupload\" name=\"fileupload\" type=\"hidden\" value=\"1\"></input>\n<input id=\"fileuploadname\" name=\"fileuploadname\" type=\"hidden\" value=\"test-upload.txt\"></input>\nElse:\n<input id=\"fileupload\" name=\"fileupload\" type=\"hidden\" value=\"0\"></input>\n<input id=\"fileuploadname\" name=\"fileuploadname\" type=\"hidden\" value=\"\"></input>\n. Hi SeanJA: Thanks for the feedback. Javascript is not my expertise, but am trying to work through this. Originally, my call to the FileUploader is:\n        \n    jQuery(function(){\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('file-uploader'),\n            action: '../server/php.php'\n        });           \n    });   \n\nSo, you are recommending that I add the params portion:\naction: '../server/php.php',\nparams = {fileupload: $('#fileupload').val(), fileuploadname: $('#fileuploadname')}\nBut, what would be the name of the field that is passed from server.php? Is there some field that I could insert with a php call like the following?\n\n<input id=\"fileuploadname\" name=\"fileuploadname\" type=\"hidden\" value=\"<$php $filename ?>\" />\n. Hmm, when I change this:\naction: '/server/php.php'\nTo this:\naction: '/server/php.php',\n            params = {\n                fileupload: $('#fileupload').val(), \n                fileuploadname: $('#fileuploadname').val()\n                }\n... the Upload Files button completely disappears and the tools is not usable.\n[Thanks for the info about the 4 spaces. I finally understand what you mean]\n. To clarify, in my PHP form processor page, I collect the data with POST as done below. How can I insert FileUploadName? Would it still be a POST when dealing with fileuploader.js?\npublic function processNewMessage(){\n$Email      = $_POST['Email'];\n$Name       = $_POST['Name'];\n$FileUploadName = $_POST['FileUploadName'];\n. ",
    "victorhqc": "I'm having the same problem. Any answers? T.T\n. Sure. in the php.php file I have this:\n$uploader = new qqFileUploader($allowedExtensions, $sizeLimit);\n$idNeg=$_POST['param1'];\n$result = $uploader->handleUpload('../negocios/'.$idNeg.'/');\n echo htmlspecialchars(json_encode($result), ENT_NOQUOTES);\n\nand mi javascript:\nfunction myFunction(){ \n```\n    var miID=document.getElementById('miIdNegocio').innerHTML;\n   var uploader = new qq.FileUploader({\n      element: document.getElementById('miLogo'),\n      params: {\n          param1: miID},\n    allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],\n        action: '/myfile/mycontent/php.php',\n        debug: true\n    });\n\n```\n}\nWhat i'm trying to do is to assign one parameter with the innerHTML of a div, it is working and the assignment of the parameter is correct, my problem is in .php I have no idea how to acces that extra parameter, I tried with $_POST but it doesn't work u.u\n. It worked!! thank you so much.\nI just changed $_POST for $_GET and everything is up an running as it should n_n\n\n$idNeg=$_POST['param1'];\n$result = $uploader->handleUpload('../negocios/'.$idNeg.'/');\n\nchanged it for this\n\n$idNeg=$_GET['param1'];\n$result = $uploader->handleUpload('../negocios/'.$idNeg.'/');\n\n. yep, thanks for your help :)\n. ",
    "yapiskan": "this code block does not work in my case. should I change anything else other than the code below; \nparams['qqfileName'] = name;\ninstead of\nparams['qqfile'] = name;\nthe request.file.count is 0 and the qqFile is null in my case.\n. ",
    "dsan": "I'm not entirely sure this should go into the library as it creates an immediate dependency to jQuery, hence it  would eliminate the possibilty to use the lib without jQuery.\n. I actually send my reponse as application/json:\nself.set_header(\"Content-Type\", \"application/json\") # compare my tornado server example\nI don't have the issue you describe, also running on the same Chrome version as you.\nAlso I think the iframe is only utilized in certain browsers (IE and Opera).\nWhen sending a response to these clients text/html is perfectly fine - the part where we simply turn the innerHTML to a JSON object is a different story in my opinion.\n. I have to admin I submitted the request without reviewing the code again I wrote. After your comment I noticed that the file uploader has evolved quite a bit :-) I will review my code and then resubmit at least the Tornadoweb example, as I have seen there already is a django example.\n. ",
    "chrisdone": "Ah, I didn't even notice it wasn't using jquery. (Not sure why it doesn't tbh, it has a lot of redundant parts.)\nHowever, I believe you essentially need to perform the same task. We can use\nhttps://developer.mozilla.org/En/DOM/Node.textContent\nand for MS browsers innerText, etc. I'll implement a text() equivalent if you want.\nFWIW, looking into it more I see that Firefox just opens up application/json as an attachment (stupid but oh well), so I have switched to sending as text/plain.\n. Alternative keep sending your JSON replies as text/html and forget about this issue.\n. I'm using the frame mode because my server does not support XHR. I'm not interested in discussing this further.\n. ",
    "dvdplm": "@dresende: could you elaborate a bit on that please? I don't really want to control the upload process, I want to be notified when all uploads are complete (without having to count the files in the queue and mark them off at each onComplete event). How can I do that?\n. @dresende: polling the queue (or reading filesInProgress) would work of course, but it would require polling. Not what I want. And keeping the count on my own is also (needlessly) messy imo. I still think my patch has merit! :)\n. Well, as the onComplete fires for each file rather than when all the uploads are complete we're back where we started. And this is getting silly.\n. Sure, it's a \"ghetto version\" of the same thing. Your script is executed every time a file is uploaded, but your conditional ensures most of it is only executed for the last file. It's less elegant than having a real event for it but it works for sure.\n. Agreed. I forked and fixed this and sent a pull request. If you're in a hurry you could use my fork.\n. ",
    "Scorps": "I tried this and it seems to work for what I wanted to do :\nonComplete: function() { if (uploader.getInProgress() == 0) { ...my script... } }\nMy script is only triggered once all files was uploaded.\n. ",
    "hparra": "Not fixed in version 3. XHR should handle any 2xx, including 200, 201, 202, & 204.\nWould you mind reopening this @rnicholus? Let me know if you want to delegate it and how you want the pull request / patch to be.\n. Amazon S3 can return 204s. I use 202 in image processing batches.\nYou've already fixed related bad juju in 3.0 :). No more \"success\" message needing. handler.xhr.js#L147\n. Ugh. Internet Explorer: trolling internet users since 1995.\nI'll fork and your benevolent click can decide.\n. ",
    "phbernard": "As a reference: this issue has been fixed\nhttps://github.com/FineUploader/fine-uploader/blob/e6ae6253e4bf2f1a428855e4ac265e55554e83bf/client/js/traditional/traditional.xhr.upload.handler.js#L78. ",
    "activestylus": "After further testing with other plugins I am starting to see this is a common problem which is not specific to file-uploader. All of my testing is done on my development machine so that may have something to do with it. I will have to run this script in production in order to confirm it. You can close this issue in the meantime. If you dont hear from me again that means it's working just fine.\n. ",
    "oojacoboo": "activestylus, was this the case for you.  I haven't been able to push code to a remote server to test.  I've tried uploading a very large file and it's still reporting 100% instantly for me.  Is this b/c it has the origin path local and therefore gets the size of the file instantly?\nThanks.\n. Here is what I did instead...\n``` js\n    _addToList: function(id, fileName){\n        var item = qq.toElement(this._options.fileTemplate);\n    item.qqFileId = id;\n\n    item.setAttribute(\"class\", \"file-\" + id); //add a class to the element so we can target\n    if (!this._options.multiple) this._clearList();\n    this._listElement.appendChild(item);\n},\n\n```\nI added a class (didn't want ID conflicts if there were multiple uploaders) then I just reference that class in the callback with the id which is available.\n. +1\n. I guess I could do that.  I'm not even 100% on how these pull requests work, etc.  Plus, how that all ties into our application framework.  I've modified it a good bit already and not even sure it's perfectly clean what I've done.\nI'm happy to wrap some things up though and see what I can put together.  I can send over some code for you to have a look as well on what's worked for me.  I'm hesitant on maintaining this as another git repo within our existing git repo.\nI guess I could maintain it within another lib folder for external repo maintenance.\nOn Sep 3, 2012, at 8:43 PM, Ray Nicholus wrote:\n\nCan you offer a pull request? I would be careful to make any drastic changes, especially anytime soon. My place, in the future, is to rewrite Fine Uploader using jQuery. I will likely consider any such suggestions when that happens. That will likely be Fine Uploader 3.0.\n\u2014\nReply to this email directly or view it on GitHub.\n. Re: Issue #309\n\nThere is only a need for a \"fileTemplate\" within the js. The scenario is that you have existing uploads that you want to show on a page next to the uploader. If the entire UI has to be js loaded in, you have to now find a way to ajax load in the content from previous saves, etc.\nThe script should take the class/id tags of the elements it needs to associate with in the DOM, and only get a fileTemplate. The file template would then of course be added to the respective parent.\nI think I might have found a way to hack around this, but taking this route will extremely simplify things and the flexibility. Yes, it will require more HTML and some extra thought for some users, but it won't restrict those that need to get more out of this. As it currently stands, it's very limiting for customization.\n. Unfortunately at the moment I don't have a functional example... The event wasn't bubbling though.  :/\nOn Sep 3, 2012, at 8:28 PM, Ray Nicholus wrote:\n\nThe click event should bubble up to the anchor. Are you saying that is not happening? Can you provide a functional example that demonstrates the issue you are seeing?\n\u2014\nReply to this email directly or view it on GitHub.\n. I don't really have anything.  I ended up modifying how we were handling it to make it work as well... I can only suspect that it has something to do with the delegation and the target in terms of how this script is handling it.  The target was registered as the  within an anchor.  There wasn't any getting around it and with all the custom delegation code, etc, it wasn't worth hacking the script.  I'd file this one under a \"jQuery will solve it\" status.\n\nOn Sep 3, 2012, at 8:39 PM, Ray Nicholus wrote:\n\nCan you post any code at all? Code that you used to reproduce this? Click \nevents will most definitely bubble unless an event handler on an element \ndoes something specific (such as calling stopPropagation()) to stop the \nbubbling process. \nOn Mon, Sep 3, 2012 at 7:30 PM, Jacob Thomason notifications@github.comwrote: \n\nUnfortunately at the moment I don't have a functional example... The event \nwasn't bubbling though. :/ \nOn Sep 3, 2012, at 8:28 PM, Ray Nicholus wrote: \n\nThe click event should bubble up to the anchor. Are you saying that is \nnot happening? Can you provide a functional example that demonstrates the \nissue you are seeing? \n\u2014 \nReply to this email directly or view it on GitHub. \n\n\u2014 \nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/305#issuecomment-8249675. \n\u2014\nReply to this email directly or view it on GitHub.\n. Mmmm, yes, that's the function that throws the exception.  But the case, from what I saw was the onComplete method that sets the array to null.\n\n\nOn Sep 3, 2012, at 8:18 PM, Ray Nicholus wrote:\n\nYour message is a little confusing. I think you meant to quote this:\ngetName: function(id){\n    var file = this._files[id];\n    // fix missing name in Safari 4\n    //NOTE: fixed missing name firefox 11.0a2 file.fileName is actually undefined\n    return (file.fileName !== null && file.fileName !== undefined) ? file.fileName : file.name;\n}\nSeems like setting the element in the files array to null would also cause an exception on getSize. I'll get to this at some point.\n\u2014\nReply to this email directly or view it on GitHub.\n. Yes, but why set that id to null onComplete?  Then, how would the onCancel method get that id?  I guess I don't fully understand the point of the array in the first place though.\n. Right, which is my point.  I've commented it out in my code and all seems to be working well without any downsides that I can verify.  Thanks.\n\nOn Sep 3, 2012, at 8:41 PM, Ray Nicholus wrote:\n\nI believe setting that element in the array to null is the bug. If you look at the code, you will see that the array is used in several places to reference the underlying File object.\n\u2014\nReply to this email directly or view it on GitHub.\n. OK, so, more information on this.  It appears that this array is used to determine which files are currently in progress.  So, without setting each element to null, you can't submit a form, as the browser is still reporting that files are uploading, even though they are not.  I honestly do not know exactly how this communication with this array ties in with the browser and the uploading directly, but that's the results I found.\n\nAdditionally, the error that's getting thrown where it's null is the result of this._files[id] being set to null, but the onCancel shouldn't be available after onComplete.  In my case, I wanted the user to be able to remove the image even after the upload finished, in case they decided they didn't want to upload.  So, I attached a new item to remove.\nI would consider adding an onRemove event to remedy this issue.  Thanks.\n. ",
    "byhoratiss": "You could achieve this by ...\n\nonComplete: function(id, file, responseJson){\n// queue \nif(uploader.getInProgress() > 0){\nreturn;\n}\nalert('all queue is done');\n}\n\n. ",
    "commanddotcom": "Well, It doen't work for me \n. ",
    "jotapepinheiro": "callbacks: {\n    onAllComplete: function() {\n        console.info('done')\n    }\n}. ",
    "derek-holmes": "same issue, this does not work with ie 9\n. add   \nreturn dt && window.FileReader && dt.effectAllowed != 'none' && \n            (dt.files || (!isWebkit && dt.types.contains && dt.types.contains('Files')));\nto fileuploader.js line 771\n. diddo\n. Check out https://github.com/derek-holmes/file-uploader\n. ",
    "awysocki": "I don't have a patch, The best I could come up with was using jQuery and after the upload disabling the button so no more uploads.  I was getting back to this project this week I will see if I can move it into the code \n. ",
    "alexkuhl": "Note to anyone looking for this functionality:  there is an option called \"multiple\" that you can pass at creation type as a boolean whether you want to allow multiple file selections in the file dialog to be possible.  This works for the FileUploaderBasic version, but the more common FileUploader (the one with drag 'n drop) ignores this parameter in terms of drag 'n drop.  To add support, simply add the appropriate checks in onDrop.  How I did this can be seen in https://github.com/alexkuhl/file-uploader/commit/fe9f350353a88f6b9bdd95539b52e6c542b0ec55\n. Dang, missed it, my mistake!\n. ",
    "vesan": "I would like to see this pulled in.\n. ",
    "msolovyov": "Your fix didn't work for me.\nI have found that just adding \nvar token = $('meta[name=\"csrf-token\"]').attr('content');\nif (token) xhr.setRequestHeader('X-CSRF-Token', token);\nafter the other setRequestHeader calls on line 1203 to work.\n. ",
    "onokazu": "Is it not possible to just use the 'params' option to pass in the token value to request params?\n. ",
    "msaffitz": "This fix assumes that the uploader is nested in a Rails form that has the authenticity_token input defined.  For me, the patch worked, however when upload is complete and the iframe inputs are cleaned up, the parent Rails form's authenticity_token input was removed from the DOM.  This then prevented that parent form from submitting without invalidating the Rails session.\nInstead, I addressed this with (starting at line ~967):\n```\n...\nthis._inputs[id] = fileInput;\nvar token = $('meta[name=\"csrf-token\"]').attr('content');\nif (token) {\n  this._inputs['_csrf'] = document.createElement(\"\")\n}\n// remove file input from DOM\nif (fileInput.parentNode){\n...\n```\n. ",
    "brandoniscool": "+1 @msolovyov \n. ",
    "tonyto": "+1\n. ",
    "dei79": "Would be good to add the following lines into the function \njavascript\nfunction setHeaders(id, xhr)\njavascript\n        var token = $('meta[name=\"csrf-token\"]').attr('content');\n        if (token) xhr.setRequestHeader('X-CSRF-Token', token);\nThis ensures when a CSRF token was set it will be send as header to the server.\n. Would be good to add the following lines into the function \njavascript\nfunction setHeaders(id, xhr)\njavascript\n        var token = $('meta[name=\"csrf-token\"]').attr('content');\n        if (token) xhr.setRequestHeader('X-CSRF-Token', token);\nThis ensures when a CSRF token was set it will be send as header to the server.\n. But it's simple to steal the implementation from jquery?\njavascript\n// Caches the header\n                setRequestHeader: function( name, value ) {\n                    if ( !state ) {\n                        var lname = name.toLowerCase();\n                        name = requestHeadersNames[ lname ] = requestHeadersNames[ lname ] || name;\n                        requestHeaders[ name ] = value;\n                    }\n                    return this;\n                },\n. just makes the live easier for all system which are using CSRF for authorization. The system would work out of the box. \n. Yes right: http://guides.rubyonrails.org/security.html#cross-site-request-forgery-csrf\n. It's how RoR is doing this and the UJS support for rails in handling this as well:\njavascript\n // Make sure that every Ajax request sends the CSRF token\n    CSRFProtection: function(xhr) {\n      var token = $('meta[name=\"csrf-token\"]').attr('content');\n      if (token) xhr.setRequestHeader('X-CSRF-Token', token);\n    },\n. ",
    "ahoward": "it is true for all cases and we do that manually in all views.  it's a reasonable default and i'd say it should always be like that unless turned off.\n. +1 on this feature.  direct uploads are a must for scalability.\n. @rnicholus passing the key is a no-no, one would need to implement, server side, a backend method that would create the correct signed url, given a set of params.  you don't need to sign each chunk, just the ultimate destination url.\n. ",
    "stevenwanderski": "My implementation looks like this (using the jQuery wrapper):\n``` javascript\nvar csrf_token = $('meta[name=\"csrf-token\"]').attr('content');\n$('#uploader').fineUploader({\n    request: {\n        customHeaders: {\n            'X-CSRF-Token': csrf_token\n        }\n    },\n});\n```\n. @redterror - I actually had a lot of trouble with IE as well (big surprise). Here is my working implementation (notice the authenticity_token in the endpoint URL):\njs\n$('#uploader').fineUploader({\n    request: {\n        endpoint: '/editor/image_add?authenticity_token=' + csrf_token,\n        paramsInBody: true,\n        customHeaders: {\n            'X-CSRF-Token': csrf_token\n        }\n    }\n});\n. ",
    "redterror": "@wandoledzep - is that working for you in IE?  It's great for me in FF, but not IE.\n. @wandoledzep - Thanks for following up - I appreciate it!  Indeed, passing the authenticity token that way worked for me.\n. +1 for blog post / wiki entry / something.  An officially supported directive would be great but some docs are probably enough for most developers.\n. ",
    "alboyadjian": "This worked for me to solve the authentication token problem:\njs\n      var token = $(\"meta[name='csrf-token']\").attr(\"content\");\n      var uploader = $(this).fineUploader({\n        request: {\n            endpoint: '/my_endpoint',\n            paramsInBody: true,\n            inputName: 'uploaded_file',\n            customHeaders: {\"X-CSRF-Token\": token},\n            params: { authenticity_token: token }\n        },\nHowever, I'm still stuck when dealing with the response (only in IE, with endpoint on same domain).\nLOG: [FineUploader] Received response for 0 \n[FineUploader] Error when attempting to access iframe during handling of upload response (Error: Access is denied.\n) \nLOG: [FineUploader] iframe loaded \n[FineUploader] Error when attempting to parse form upload response (Error: Access is denied.\n) \n. Nope, it's returning a 200:\nKey Value\nResponse    HTTP/1.1 200 OK\nConnection  close\nDate    Fri, 05 Apr 2013 21:05:38 GMT\nContent-Length  91\nCache-Control   private, max-age=0, must-revalidate\nX-Runtime   103\nETag    \"2de3ec7217039bd839e8f207de77e93a\"\nContent-Type    text/plain; charset=utf-8\n. As far as I can tell, it's something to do with the document.domain.\nThere's javascript being called on the page that sets the document.domain to something different than the server host (which is a subdomain).\nI'm looking into setting the document.domain of the iframe.\nwithin \njs\nfunction createIframe(id){\n        js_source = 'javascript:void((function(){document.open();document.domain=\\'' + document.domain + ' \\';document.close();})())\"'; \n        var iframe = qq.toElement('<iframe src=\" ' + js_source + '\" name=\"' + id + '\" />');\n. Request headers:\nKey Value\nRequest POST /composition_attachments HTTP/1.1\nAccept  text/html, application/xhtml+xml, */*\nAccept-Language en-us\nUser-Agent  Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0)\nContent-Type    multipart/form-data; boundary=---------------------------7dd2d725110646\nUA-CPU  AMD64\nAccept-Encoding gzip, deflate\nHost    adam.dev.maindomain.com:3001\nContent-Length  113590\nConnection  Keep-Alive\nCache-Control   no-cache\nResponse body:\n{\"download_url\":\"/composition_attachments/26\",\"attachment_id\":26,\"success\":true}\n. ",
    "Arkiliknam": "Was a cancelAll implemented now? I found it in the js, but it's not exposed to the fileUploader. I also want to cancelAll, specifically onComplete if any fail, cancel all.\nonComplete: function (id, file, responseJson) {\n                    if (responseJson.success) {\n                        // do something\n                    }\n                    else{\n                        uploader.cancelAll();\n                    }\n. ",
    "alexksso": "well I like the drag and drop and the nice uploading icon :) and overall the whole script is w00t only lacks this option ;)\n. ",
    "vnaum": "You're right.\nLuckily, that's easy to fix :-)\n. ",
    "stephencarr": "I'd like to understand if this is possible also, seems the issue was closed without comment.\n. ",
    "thomask": "Same here!\n. ",
    "jpoehls": "I'd like more details on this as well since I just ran into a use case where this is causing a problem in our app. Our backend expects the parameters to be in the POST body, not in the URL. After a brief look at the file-uploader code it appears that this would be very easily doable. Can you please confirm whether this is doable or not, @valums?\n. Sounds good. I'm just trying to pass a CSRF token. I tried using a custom header but of course that doesn't work in IE and I don't want to pass it in the QueryString.\n. ",
    "sebastiansulinski": "I'd also appreciate if that could be added. Many thanks.\n. @borut-t: just a thought - did you try to use the the 'UTF-8' encoding with your response?\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES, 'UTF-8');\nIt's default with PHP 5.4+ and I'm not sure whether it's going to make any difference, but perhaps worth giving it a try.\n. My apologies - it seem to have gone now.\n. Hey - I couldn't agree more!\nAs long as we support all these outdated browsers - that long people will be using them - and it's a nightmare to all of us.\n. ",
    "vm370": "This is definitely needed due to simple fact that modern perl CGI module many years just skip url params in POST requests.\nSo every time you need to patch CPAN CGI module by hand or add lines of code to perl script to handle this.\n. ",
    "JeanMertz": "It's quite simple really, you only need to pass it the button you would like to bind the uploader to and the action to take when a file is submitted, like so (coffee-script):\njs\n    uploader = new qq.FileUploaderBasic\n      button: \"#button_id\"\n      action: \"/uploads/\"\nNow all you need to do is to create a button with and you're ready to go.\n. @Amukulator, the reason why you don't see the button, is because you are referencing a div, not the button. So your first solution (referencing a button) was correct, as I already stated in my first reply. The error you are getting has nothing to do with you referencing the button instead of the div, as that is the way the basic uploader works, what is causing your error though, I do not know.\n. Sorry, I almost never write in pure JS so I don't know exactly if there's a bug in your code or if there's something else. If I where you I would start debugging using console.log and Firebug.\nHere is a snippet of my code, but is is in coffeescript together with jQuery (something I recommend you start using)\n``` javascript\nuploader = new qq.FileUploaderBasic\n  button: $(\"#m4n_uploader\")[0]\n  allowedExtensions: [\"jpg\", \"jpeg\", \"png\", \"gif\"]\n  sizeLimit: 1048576\n  action: \"/uploads/\"\n\n```\n. ",
    "Amukulator": "Unfortunately, it does not work. Is it a bug?\nI have the following code:\n```var uploader = new qq.FileUploaderBasic ({\n     button: '#btnUpload'\n     action: 'Upload'\n});\n```\nAnd I get the following error. Tested in FF 3.6 / IE7 / IE6\nError: first is undefined\nSource File: fileuploader.js\nRow: 21\n. Okay, I got it now. You have the reference to a DIV element passed, not the button IDbutton: document.getElementById('file-uploader')\nUnfortunately, it still does not work. The upload button is not displayed. Now I give up and continue to use the non-basic version. Just wanted to disable the drag&drop area...\n. Thanks for the quick reply!\nOkay, now I can see the button. But when I click on it, nothing happens.\nI've just modified the demo-page. Nothing happens when I click on the button.\n Please provide a working example\n``` html\n\n\n<script src=\"fileuploader.js\" type=\"text/javascript\"></script>\n<script>\n    function createUploader(){\n        var uploader = new qq.FileUploaderBasic({\n            button: document.getElementById('btnUpload'),\n            action: 'do-nothing.htm',\n            debug: true\n        });\n    }\n\n    // in your app create uploader as soon as the DOM is ready\n    // don't wait for the window to load\n    window.onload = createUploader;\n</script>\n\n\n```\n. ",
    "chrisdavies": "I'm having exactly the same problem.  (Nothing happens when I click the button.)  When I use Amukulator's code or my own similar code.  Any ideas?\nThanks!\n. ",
    "steliyan-georgiev": "@chrisdavies, Try surrounding the button with a span and passing the span as the button property, instead of the button itself.\n\n\n\n\n        var uploader = new qq.FileUploaderBasic({\n                 action: '/someaction',\n                button: document.getElementById(\"uploadSpan\"),\n        }); \n \n. ",
    "joallard": "It is extremely unclear from the documentation how to use the FileUploaderBasic feature. I had to come here to discover that the option to set was button instead of element.\n. ",
    "maystro": "i think the element should be somthing like div or span or p but not a button\n. ",
    "projectscribe": "In case it helps, a div with the same id as the span around the span in @jamsi 's snippet seems to make IE (8 tested only) happy as well.\n```\n\n\n\n\n...\n```\n. ",
    "SimonEast": "Thanks heaps for posting your updates.  Looks great.  Gonna give your patch a try.\nEDIT:  Oops, looks like your patch might have already been merged into master... but I can't seem to see that reflected in Github anywhere.  Weird.\n. As mentioned in other pull requests, I've merged your fork into https://github.com/Valums-File-Uploader/file-uploader in an attempt to compile the best fixes and patches there.  Thanks heaps for your efforts!\n. As mentioned in other pull requests, I've merged your fork into https://github.com/Valums-File-Uploader/file-uploader in an attempt to compile the best fixes and patches there.  Thanks heaps for your efforts!\n. Thanks for your patch, I'm merging your fork into https://github.com/Valums-File-Uploader/file-uploader in an attempt to compile the best fixes and patches there.  Let me know if you have any interest in maintaining this further.  :-)\nSimon.\n. Thanks for your patch, I've pulled it into https://github.com/Valums-File-Uploader/file-uploader in an attempt to compile the best fixes and patches there.  Let me know if you have any interest in maintaining this further.  :-)\nSimon.\n. OK, that'd be great.  :-)\n. Thanks for your patch, I've pulled it into https://github.com/Valums-File-Uploader/file-uploader in an attempt to compile the best fixes and patches there.  Let me know if you have any interest in maintaining this further.  :-)\nSimon.\n. Thanks for your patch, I've pulled it into https://github.com/Valums-File-Uploader/file-uploader in an attempt to compile the best fixes and patches there.  Let me know if you have any interest in maintaining this further.  :-)\nSimon.\n. Thanks for your patch, I've pulled it into https://github.com/Valums-File-Uploader/file-uploader in an attempt to compile the best fixes and patches there.  Let me know if you have any interest in maintaining this further.  :-)\nSimon.\n. For those who are interested, I've created a public \"organization-owned\" fork of this project at:\nhttps://github.com/Valums-File-Uploader/file-uploader \nI will try and incorporate the best patches and bugfixes there.  Other interested maintainers are welcome to be involved.\n. ",
    "florinh": "Same issue here happening on IE 7,8,9.\n. ",
    "akmjenkins": "Banged my head against the wall for a couple of hours with this one folks but I finally figured it out. What I was doing was using jQuery to issue a .click() to the .qq-upload-button when a different button was clicked.....IE doesn't like this because it thinks that you are trying to be sneaky and have malicious intent - it knows that the user didn't actually click the file upload button (i.e. .qq-upload-button) and it won't let JS do everything.\nThe problem is solved by requiring the user to click .qq-upload-button (which is actually the file input itself).\nHope that helps you out!\n. dkimbell, That sounds unrelated to this issue - the error described in this thread didn't cause a server 500 error, it caused a JS Access is Denied error in IE on line 1057.....you might want to recheck through the issues to see if your fix matches up better with another one.\n. ",
    "willemvdg": "I get the 'access denied' for iframe in line 1057 in IE7 when the file is too large for the server max-upload setting (normally 4MB I believe).\nI modified the _getIframeContentJSON() code to catch this exception and return a failure, see below (haven't had time to set up github, sorry):\n```\n_getIframeContentJSON: function(iframe){\n    var response;\n    try {\n        // iframe.contentWindow.document - for IE<7\n        var doc = iframe.contentDocument ? iframe.contentDocument: iframe.contentWindow.document;\n    this.log(\"converting iframe's innerHTML to JSON\");\n    //this.log(\"innerHTML = \" + doc.body.innerHTML);\n\n    response = eval(\"(\" + doc.body.innerHTML + \")\");\n    this.log(\"innerHTML = \" + doc.body.innerHTML);\n} catch(err){\n    this.log('_getIframeContentJSON error: ' + err.description);\n    response = {};\n}\n\nreturn response;\n\n},\n```\n. ",
    "Akvel": "My solution for IE\ncomment line 825\n//self._options.onChange(input);\n//call it from code\nuploader._onInputChange(uploader._button.getInput());\n. My solution for IE\ncomment line 825\n//self._options.onChange(input);\n//call it from code\nuploader._onInputChange(uploader._button.getInput());\n. ",
    "bkbkbk": "I encountered issues for all IE versions as well, and ultimately added a conditional to default to a basic upload form for those browsers. \n. ",
    "applezqp": "I don't understand the current page's domain and the endpoint page's is same, but the issue always happened. My solution for IE is that I set same for document.domain, e.g. document.domain=\"site.com\". \n. I am sure my server returns a 200 response and the \"show friendly HTTP error messages\" setting is unchecked, but I encountered issues for all IE versions. Why?\n. ",
    "urkle": "Are the classes being added to the button?  how are you initializing the control?  you have to use the jquery wrappers not the standard file uploader initialization.\n. $('#fileuploadselector').FileUploader();\n. $('#myFileUpload').FileUploader('setParams',params);\n. ",
    "Dave2K": "How do I set setparams?\n. ",
    "EffEPi": "I was wondering the same.. \n. ok, I figured this myself.... I was hiding the \"file\" wrapper and the code was not executing the click on the input[file].\nif anyone had a similar question, this is the way to trigger the click() if the element is visible (even with 0 opacity)\n$('input[type=file]','#file-uploader').click();\n. $('input[type=file]','#file-uploader').click();\ndoesn't work on IE8 nor IE9\nthe file dialog is opened, I choose a file, the uploader seems like it is starting but it stops on \"  form.submit();  \" and nothing is sent to the server\n. what I do is save the image into a temporary folder and rename it , then pass the new name back to the script via jSon and have the page call a different URL with that file name in it that will display the image\n. give me the issue number and I'll post the code, but keep in mind that you will have to modify it as I am going to copy it stripping out most of it for security reason but leaving enough to understand how it works\n. ",
    "DrunkHyperGear": "Don't  know if your still interested but this works for me....\n$('input[name=\"file\"]').trigger('click');\n. ",
    "marcll": "Thank you for the response, it took so long that I can't even remember how I did the trick!\nHope this helps for anyone else anyway :)\n. ",
    "jonaslund": "Just put the isSupported function to return false; \nqq.UploadHandlerXhr.isSupported = function(){\n return false;\n};\n. ",
    "MrDeLeTeD": "ok sorry, i didn't see the method obj2url();\nthanks for you jobs !\n. ",
    "vtavares-egoi": "needs more testing, sorry ...\n. ",
    "jgoguen": "This shouldn't have been opened on master. My mistake. https://github.com/jgoguen/file-uploader/commit/cfce88b0a10ffa55c7244db24973402c000249cf fixes #127 (and screws with whitespace) and https://github.com/jgoguen/file-uploader/commit/d51bed4a3c0bcdcb31445a80f8bd71cd9c019f24 fixes #80, but introduced a jQuery dependency that's always fulfilled in my environment but may not be possible in all environments.\n. ",
    "vviippola": "Sorry for bothering, issue was not directly related to this great piece of coding :)\n. ",
    "kirkegaard": "+1 ... working on a fix :)\n. Fixed :D\nhttps://github.com/ranza/file-uploader/commit/af63a3324a444294438d98fdee9e799ac2dc34fa\n. ",
    "murteira": "It was my error .\n. ",
    "gustavomanolo": "Hi, i'm having the same issue, it would be great if you tell me how did you fix it.\nThanks a lot for your time.\nuncaught exception: [Exception... \"'Error: element not found cancel' when calling method: [nsIDOMEventListener::handleEvent]\" nsresult: \"0x8057001c (NS_ERROR_XPC_JS_THREW_JS_OBJECT)\" location: \"JS frame :: chrome://firebug/content/spy.js :: callPageHandler :: line 744\" data: no]\n. ",
    "gullevek": "You have to use the id of a div, FileUploaderBasic will write the hidden file handle inside. The div also needs to be visible (Text inside, border, BG color) or else you won't be able to click it.\nThen you just need to assign the div to the button\n...\nbutton: document.getElementById('someDIVid'),\n...\n. @ssineriz I just want to thank you as I ran into the same problem.\nI used just the examples (js + php) with the version of 5.16.2. Client OS is macOS with FF (latest) and Chrome (latest) and server is just plain Linux with PHP 7.2\nOnce I added the line above the chunked upload worked fine.. Thank you, I just thought OPTIONS requests are forwraded to the defined endpoint somewhere, but ti seems they end somewhere. Perhaps I can find some target in Chrome or Firefox on what level or where I can actually response to them.\nAnd 403 error means non-authorized because the missing pre-flight Access-Control-Allow-Origin header. But in what response? I never see any response to my server that could trigger those headers. That's why I am so confused about this error.\nJS-> PUT -> triggers OPTIONS from browser to S3 -> S3 sends back \"I can do this\"\nso where do I then trigger this response if my sever never sees that? Or do I have to put that in JS in the web browser? (which would make no sense). I found the problem. It had NOTHING to with your script nor with my server settings. I made a mistake in the CORS settings on the s3 server.\nI had a \"GET\" allow instead of a \"PUT\" allow\nSadly no browser gives you correct error reports about this at all. What a pitty.\nI only found out about this when I looked in the Chrome deny logs where it shows Access control request method: PUT. Firefox just never shows them, just the initial POST one.\nJesus :(. ",
    "cimm": "+1 We had this problem as well. Thanks.\n. +1\nWe need this is well, would be nice to have this merged in.\n. ",
    "carolinesalib": "Really helpful, thanks!. ",
    "sipsorcery": "I just had the same problem. I solved it by setting a custom header and loading the file's content type into it. See below for the mods I made to the qq prototype.\nqq.extend(qq.UploadHandlerXhr.prototype, {\n    /\n     * Adds file to the queue\n     * Returns id to use with upload, cancel\n     /\n    add: function(file){\n        if (!(file instanceof File)){\n            throw new Error('Passed obj in not a File (in qq.UploadHandlerXhr)');\n        }\n```\n    return this._files.push(file) - 1;      \n},\ngetName: function(id){      \n    var file = this._files[id];\n    // fix missing name in Safari 4\n    return file.fileName != null ? file.fileName : file.name;     \n},\ngetSize: function(id){\n    var file = this._files[id];\n    return file.fileSize != null ? file.fileSize : file.size;\n},\ngetType: function (id) {\n    var file = this._files[id];\n    return file.fileType != null ? file.fileType : file.type;\n},\n/\n * Returns uploaded bytes for file identified by id \n */  \ngetLoaded: function(id){\n    return this._loaded[id] || 0; \n},\n/\n * Sends the file identified by id and additional query params to the server\n * @param {Object} params name-value string pairs\n */  \n_upload: function(id, params){\n    var file = this._files[id],\n        name = this.getName(id),\n        size = this.getSize(id),\n        type = this.getType(id);\nthis._loaded[id] = 0;\n\nvar xhr = this._xhrs[id] = new XMLHttpRequest();\nvar self = this;\n\nxhr.upload.onprogress = function(e){\n    if (e.lengthComputable){\n        self._loaded[id] = e.loaded;\n        self._options.onProgress(id, name, e.loaded, e.total);\n    }\n};\n\nxhr.onreadystatechange = function(){            \n    if (xhr.readyState == 4){\n        self._onComplete(id, xhr);                    \n    }\n};\n\n// build query string\nparams = params || {};\nparams['qqfile'] = name;\nvar queryString = qq.obj2url(params, this._options.action);\n\nxhr.open(\"POST\", queryString, true);\nxhr.setRequestHeader(\"X-Requested-With\", \"XMLHttpRequest\");\nxhr.setRequestHeader(\"X-File-Name\", encodeURIComponent(name));\nxhr.setRequestHeader(\"X-File-Type\", type);\nxhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\nxhr.send(file);\n\n},\n```\n....\n. ",
    "rossdm": "Shouldn't this change be added to the source?\n. ",
    "rjwonders": "I am using the fileuploader for my site and needs to add 3 uploader for diffrent kind of things. but on single page i am only able to put only 1 uploader. can you please tell me what will be the actual problem?\n. Already made like this. but it gives me uploader only in the last option. its batter if you post the code over here.\nThanks\n. i m posting my code here\n< tr>\n    < td width=\"200\" class=\"BlueBoldSmall\" align=\"left\" valign=\"middle\"> Upload 1:\u00a0\n    < td>\n        < div id=\"abc-uploader\">\n        < ul id=\"separate-list\">\n    < /td>\n< /tr>\n< script>\n    function createUploader(){\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('abc-uploader'),\n            listElement: document.getElementById('separate-list'),\n            action: 'fileuploader1.php?id=1'\n        });\n    }\n    window.onload = createUploader;\n\n< tr>\n    < td width=\"200\" class=\"BlueBoldSmall\" align=\"left\" valign=\"middle\"> Upload 2:\u00a0\n    < td>\n        < div id=\"wxy-uploader\">\n         < ul id=\"separate-list1\">\n    < /td>\n< /tr>\n< script>\n    function createUploader1(){\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('wxy-uploader'),\n            listElement: document.getElementById('separate-list1'),\n            action: 'fileuploader2.php?id=2'\n        });\n    }\n    window.onload = createUploader1;\n< /script>\n< tr>\n    < td width=\"200\" class=\"BlueBoldSmall\" align=\"left\" valign=\"middle\"> Upload 3:\u00a0\n    < td>\n        < div id=\"mno-uploader\">\n        < ul id=\"separate-list2\">\n    < /td>\n< /tr>\n< script>\n    function createUploader2(){\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('mno-uploader'),\n            listElement: document.getElementById('separate-list2'),\n            action: 'fileuploader3.php?id=3'\n        });\n    }\n    window.onload = createUploader2;\n< /script>\nThis gives me uploader only in \"Upload 3\"\n. Thanks sir. this really helps. i appriciate\n. ",
    "azinazadi": "why this very important pull request is not included, I wonder?\n. ",
    "davidchua": "Thanks Krule! I was trying to figure out why sessions kept expiring. \nThis should be included into the main repo. \n. ",
    "vdboor": "Dropping my $0.02 in:\n...instead of reading the meta tag, I'd prefer to pass the CSRF value as parameter, so it can support Django too. Django uses the same X-CSRF-Token header, but doesn't use the <meta> tag like Rails does.\nAlternatively, there could also be a hook to adjust the xhr object (like jQuery's ajaxSend does). \n(update: found that code at https://github.com/valums/file-uploader/pull/268)\n. ",
    "Krule": "I agree. That's why this commit is closed :)\n. ",
    "aelshesh": "Yes, this field has to go to the settings section so we can pass it\n. ",
    "cutcopypaste": "I made the same change to the JSON response. I agree it would be very useful to have it included; any time the file data is being added to a database it's necessary!\n. ",
    "KJLJon": "I needed a similar solution.  So I did the following:\nhttps://github.com/KJLJon/file-uploader/commit/652ab23030f41f6ae3965ab7ae95beaddbc8c857\n. @rnicholus it looks like #347 is closed?\n@tellibus you could do the following:\n$uploader = new qqFileUploader();\n$result = $uploader->handleUpload('uploads/');\n$result['filename'] = $uploader->getUploadName();\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\notherwise your method seems to work also.\n. It looks like this pull request was used to fix #339 (specificly this post) referenced on #347\nJust want to make sure I am not misunderstanding the issue in #339?\n. @Alain-Lavoie see:\n@04fc047\nIt should fix your problems\n. Tested both on\nIE v9.0.8112.16421 and Chrome v23.0.1271.95m\n(if master is FU 3.0)\notherwise I can test it on the 3.1 branch if you would like?\n. it's only server-side code.\nIt allows for the GET request attribute name to be something different then 'qqfile' (with the default set to 'qqfile').\nreference: line 15\n(humm, and I just realized github thinks I changed the whole file, when i actually only edited like 5 lines)\nDo you know any efficient ways of making the diff only show the lines I changed (then I can also resubmit it to look cleaner)\nis the master 3.0 or should I switch to the branch 3.1 to test it?\nI tested the code on IE v9 and Chrome v23 (from a fresh download of the master branch)\nlet me know if I should test it using the 3.1 branch\n. The uploader will always send a request, its more or less for if someone visits the page that the php script is on (so it doesn't display any php errors, and only shows a json error).\nIE:\nindex.html has the code for the file uploader\nupload.php has the code that includes the classes from php.php\nif someone was to visit upload.php on a web server, they will get a fatal error notice (unless the web server has error messages turned off, but it will still stop all execution of any further code).\nIts not necessary because the file uploader will always send a content-type, but it makes php exit more \"friendly\" if a user visits the page \"upload.php\" directly.\nI believe it is useful to exit more \"friendly\" if this class is being used in some php frameworks / cms (because they might have code that runs after upload.php even if a person visits the page directly)\nlet me know if you disagree or think this is out of the scope.  :-)\nI appreciate all the work you (and others) have put into this project, and think it is an excellent tool.\n. well I don't think so but I guess I would like to hear from others :)\n. ",
    "marlonpp": "I'm having the same problem, coud you add a sample showing how to cancel a upload on FileUploaderBasic?\nThis is my code, what should I put on onClick event of cance!?\nfunction createFileUploader(){\n    var lol = new qq.FileUploaderBasic({\n        button: document.getElementById('file-uploader'),\n        action: '/readercontroller/upload',\n        sizeLimit: 51200000,\n        multiple: false,\n        debug: true,\n```\n    onProgress: function(id, fileName, loaded, total){\n        $('#book-file-uploader').hide();\n        $('input[type=submit]', this).attr('disabled', 'disabled');\n        var progress = Math.round(loaded / total * 100 );\n        $('#bookFileInfo').html(' - ' + fileName + ' ' + progress + '% ' + '  Cancel');\n},\n\nonComplete: function(id, fileName, responseJSON){\n    response = eval(responseJSON);\n    if(response.success == true){\n        $('#fileName').val(fileName);\n        if($('#fileName').val() != \"\" && $('#oFileName').val() != \"\" ){\n            $('#btn_upload').removeAttr('disabled');\n        }\n    }\n    $('#file-uploader').show();\n},\nonSubmit: function(id, fileName){\n\n},\nonCancel: function(id, fileName){}\n\n});\n```\n. Nice, now I'm getting an error at: \ngetName: function(id){\n var file = this._files[id];\n // fix missing name in Safari 4\n return file.fileName != null ? file.fileName : file.name;\n},\nfile is null \n. ",
    "jeremywiebe": "In the OnSubmit function, you have to capture the id of the file being uploaded.  I then provided a cancel link for each file being uploaded.  When the user clicks the cancel link, I call \n  uploader.cancel(id)\nThe 'id' passed to cancel is the same one that is captured in the onSubmit callback.  \nSo in your case you'd call \nlol.cancel(id);\n. I never encountered this problem so I can't really help you.  You'll have to trace through the code and figure out what's wrong.  When you do, please submit a pull request to velum, who is the original author of this fileuploader project.\nThanks,\nJeremy Wiebe\njeremy.wiebe@gmail.com\nOn 2011-Oct-05, at 10:29 AM, marlonpp wrote:\n\nNice, now I'm getting an error at: \ngetName: function(id){\nvar file = this._files[id];\n// fix missing name in Safari 4\nreturn file.fileName != null ? file.fileName : file.name;\n},\nfile is null\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/pull/157#issuecomment-2298457\n. \n",
    "tinybear": "var size = this._handler.getSize(id); only works for Firefox?\n. ",
    "klederson": "Same fileName error here\nfile is null\n. Found the problem. Its almost impossible to test it localy ( at least without change some socket stuff to simulate a slow connection ).\nThe problem is the file uploads too fast and than can't be canceled if you test on a remote server you will see that works pretty fine.\nTks\n. ",
    "marcoslhc": "I think you're right. I actually reversed the arrows and now the error doesn't shows up\n. ",
    "mtbksouth": "I had a similar issue; I cannot seem to successfully complete an upload on IE if I trigger the click on the upload button using jquery.\n. ",
    "hiulit": "@EffEPi\nHow do you that preview image thing? I've been trying and I can't get it working...\n. @EffEpi\nThanks for your answer, that's what I know i have to do, but I can't accomplish..\nWhat I was asking for is the code to do that. Would you be so kind to email it to me? Or post it in the issue I created regarding this issue so everyone can use it?\nAgain, thank you very much!\n. #214\nhttps://github.com/valums/file-uploader/issues/214\nThanks a lot! I'll try no to bother you.. :)\n. ",
    "nhance": "There doesn't appear to be a way to vote this up, so I'm tacking a comment here to note that I agree with cutcopypaste.\nDr. Harris, do you concur? Do you concur?\n. ",
    "mzooms": "me too, IE9 @ SCRIPT5: Access is denied.\nfileuploader.js, line 1023 character 9\nform.submit(); \n. found the reason for Access is denied.\nIE does not allow javascipt fired click event on its file input.\n. ",
    "sabatoc": "Have you found a solution for this ?\n. ",
    "tommoor": "Has anyone made any progress / had any thoughts on how to address this issue? \nWe seem to still be getting this intermittently in IE\n. ",
    "kindbergs": "Hi, during my tests I found that the security bug only happens when the server post is rejected (due to the post being bigger than what the server allows) - so when something different than result 200 status code is returned the iframe suddently belongs to a diferent security zone / different domain.\nWorkaround: deteching the result of the last post, and if result was different than 200 then don't try to look inside the iframe because we already know that the post failed.\n. Solution found:\nIn _attachLoadEvent: add a try{ }  catch(ex){} around the opera fix that peaks at iframe.contentDocument\nAnd in _getIframeContentJSON take the \"try{\" and move it a few lines higher up, so it too is before iframe.contentDocument\nadverticement: I am making an ASP.NET control based on this JavaScript which is available here: http://www.kindbergs.dk/ajax-safe-uploader.aspx - so I really had to fix this IE bug :-)\n. ",
    "drcapulet": "Just a heads up, if you ever set document.domain it also seems to trigger this Permission Denied error.\n. ",
    "igorcomputacao": "I apply the fix and not resolve the bug. The object \"uploader.\"  is not present at my  fileuploader.js\n. My upload works fine in Firefox, but the line 1218 (form.submit(); ) throw a exception \"Access denied.\" in IE.\nfileuploader.js, line 1218 Caractere 3.\n. @rnicholus The problem in IE 8 : Not Suport UploadHandlerXhr.\nThe way of realize the upload of file is different  between IE an FF, because the line 1215 (form.submit();) is not called.\ncall stack (IE)\n1218 - form.submit(); - _upload: function(id, params) {\n1081 - this._upload(id, this._params[id]); method - upload: function(id, params) {\n0473 - this._handler.upload(id, this._options.params); - _uploadFile: function(fileContainer) {\n0445 - this._uploadFile(input); - _onInputChange: function(input) {\n0360 - self._onInputChange(input); - _createUploadButton: function(element) {\n. Ok, you win.\nYour answer:\nYes, I click at image (X - Not Loaded) and a javascript open the window for select the file.\nOk, I understand that It's not possible, but exists any way to do this on IE?\nI see this \"feature\" works on IE, using other plugins.\nThanks.\n. How I turn off javascript for open dialog?\n. ",
    "cgmckeever": "RE Original Topic: \"Permission denied\" in IE (line 1039)\nafter a day of routing around .. I tracked it down to the document.domain issue (thanks @drcapulet) ... my fix, was (on server side) to differentiate between a form posted upload (IE) and an AJAX.  When it was the form posted, I wrapped the response in some basic html/head/body tags and made sure to include document.domain = MYDOMAIN in the head through a script tag.    \nwhat a pain in the butt\n. ",
    "Radek-Suski": "Hi Guys,\nmany thanks for responses. I just cannot stop to wonder how stupid reaction from IE it is.\nI mean I did following:\n- When user click \"my\" button, I triggered the default select button\n- Took the name of selected file, parsed it to get only a file name and copied it to \"my\" inputbox\n- When user clicked on the upload button created a form on the fly\n- Triggered the \"beforeSend\" method and Initialised a progress bar (it still worked)\n- And first now I got the \"Permission denied\" error\nSo I was sure it is trying to send it to wrong URL and lost few hours searching for this stupid error.\n. @rnicholus What's you problem? No one is reporting it as bug but apparently still some people amy not have realised that the main problem is the virtual click on the \"select\" button. \nIf people would comment it here I would probably be never ale to find the cause of the issue.\nWhy it bothers you if someone is posting in a closed bug report or not?\nBTW: Big thanks for your posts :) (bow)\n. ",
    "DarrenN": "IE9 has issues in general with this plugin. I found that by removing the Content-Type: application/json header from my JSON responses on success that IE9 deals correctly with the response from the server. Otherwise it attempts to download the JSON response.\n. ",
    "vinntreus": "Can do a +1 for that. Example for returning simple object from asp.net mvc controller:\nreturn Json(new { success = true }, \"text/html\", Encoding.UTF8);\n. ",
    "joaovpmamede": "danielpersson thanks a lot!\nHad this awful issue that you just helped me to solve it :)\n. Yup...had this issue just yesterday and solved it by doing what musial-bright just said.\nAlthough I had to parse the response to get a JSON object afterwards.\nIn the end everything worked as expected cross-browser.\n. ",
    "zachrybaker": "This fixed it for me too.  thanks Daniel.\n. ",
    "musial-bright": "A simple way to solve this issue is a upload webservice which response content type header is \"text/html\"\n. ",
    "Gutek": "+1, thanks\n. ",
    "chchrist": "The onSubmitI() event is not triggered when using the ButtonFileUploader?\n. You trigger it in startUploads() but I need to trigger it when I select the file. I'll try to figure it out myself.\n. What I actually want is to show the filename of the selected file. The onChange sound good :)\n. Thanks! I'll test it and report if any bug is found.\n. There is this private method:\n_uploadFile: function(fileContainer){\n        var id = this._handler.add(fileContainer);\n        var fileName = this._handler.getName(id);\n        if (this._options.onSubmit(id, fileName) !== false){\n            this._onSubmit(id, fileName);\n            this._handler.upload(id, this._options.params);\n        }\n    }\nI don't know if we can expose it somehow\n. I agree\n. ",
    "andreaazzara": "Hi! I'm testing your extension and It works fine. I was wondering if there's an easy way to cancel the upload of a single file.. do you have any idea about that?\nthanks for your work\n. Sorry, I realized I wasn't clear at all :)\nThat's what I would like to do: \nI replaced the file list (qq-upload-list) with a table with a row for each file I want to upload, so that I can let the user select specific settings for each of them. I would like to add a cancel button for each file (just as the one it's created in the standard file list to stop an upload) but I just don't know how can I bind a 'cancel' event to the button.\n. ",
    "jmulder": "Brilliant! Just what I was looking for. Thanks :-)\n. ",
    "elightbo": "Pretty sure I didn't comment on the change correctly. What is a good way to do this in github?\n. Thanks for the help :) I added a comment within 'diff'. You'll see my change on line 687.\n. Would love to know if anyone has figured this one out.\n. Perhaps this is the answer for now https://github.com/valums/file-uploader/pull/168\n. Gonna go ahead and agree that this would be absolutely awesome.\n. Added this:\n        this._button.reset();\nto make allow IE to upload more than one photos.\n. ",
    "devjones": "nice addition.  thanks!\n. ",
    "lgomez": "Has anyone been able to pinpoint this issue? I'm seeing it on Chrome 15.0.874.120 and Chromium 16.0.902.0 (Developer Build 104259 Mac OS X).\n. ",
    "lordenvy": "Try setting a minimum height for your button. Had the exact same problem and this fixed it for me. You might notice that before you try to set a minimum height you can click on the very top of the button and it will work. \n. ",
    "svezina": "Good stuff.  I'm in the same boat as you with Codeigniter.\nI made it work \"stock\" by using this\n            var uploader = new qq.FileUploader({\n                (snip)\n                action: 'http://www.mysite.com/upload/uploadImage/myvar1/myvar2,\n                                (snip)\n            });\nThis way, the file-upload POST is sent to my Upload controller in the uploadImage method.\nI recover my 2 variables (myvar1 and myvar2) by using $this->uri->segment('3') and $this->uri->segment('4');\nAnd finally, I get the filename throught $this->uri->segment('5');\nIn order to prevent problems when a user uploads a file with spaces and weird characters, I modified +/- line 1191 to base64 encode the filename:\n    _upload: function(id, params){\n        var file = this._files[id],\n            name = JQ.base64Encode(this.getName(id)),\n            size = this.getSize(id);\n. (more.. i pressed send by mistake)\nSo when I get the file name with $this->uri->segment('5'), I base64_decode it. I then do some character replacement in the filename to make it pretty.  Here's pretty dirty version of everything :\n$user_filename = base64_decode($this->uri->segment('5')); \n    $x = explode('.', $user_filename); \n    $fileext = mb_strtolower('.'.end($x)); \n    $caracterstoremove = strlen($fileext) * -1; \n    $filename_noext = mb_strtolower(mb_substr($user_filename, 0, $caracterstoremove));\n    $filename_noext = $this->common->remove_accents($filename_noext); \n    $characterssubstitution = array('\u00c1'=>'A','\u00c0'=>'A','\u00c2'=>'A','\u00c4'=>'A','\u00c3'=>'A','\u00c5'=>'A','\u00c7'=>'C','\u00c9'=>'E','\u00c8'=>'E','\u00ca'=>'E','\u00cb'=>'E','\u00cd'=>'I','\u00cf'=>'I','\u00ce'=>'I','\u00cc'=>'I','\u00d1'=>'N','\u00d3'=>'O','\u00d2'=>'O','\u00d4'=>'O','\u00d6'=>'O','\u00d5'=>'O','\u00da'=>'U','\u00d9'=>'U','\u00db'=>'U','\u00dc'=>'U','\u00dd'=>'Y','\u00e1'=>'a','\u00e0'=>'a','\u00e2'=>'a','\u00e4'=>'a','\u00e3'=>'a','\u00e5'=>'a','\u00e7'=>'c','\u00e9'=>'e','\u00e8'=>'e','\u00ea'=>'e','\u00eb'=>'e','\u00ed'=>'i','\u00ec'=>'i','\u00ee'=>'i','\u00ef'=>'i','\u00f1'=>'n','\u00f3'=>'o','\u00f2'=>'o','\u00f4'=>'o','\u00f6'=>'o','\u00f5'=>'o','\u00fa'=>'u','\u00f9'=>'u','\u00fb'=>'u','\u00fc'=>'u','\u00fd'=>'y','\u00ff'=>'y'); \n    $filename_noext = strtr($filename_noext, $characterssubstitution); \n    $filename_noext =  preg_replace('#[^a-zA-Z0-9\\-\\._]#', '_', $filename_noext); \n    $filename = $filename_noext.$fileext;\nI just had to tweak my permitted_characters in CI because base64 would send out some invalid characters sometimes.\n. Precision: The error happens on line +/- 1137 in the following function:\n//\nqq.UploadHandlerXhr = function(o)\n{\n    qq.UploadHandlerAbstract.apply(this, arguments);\n    this._files = [];\n    this._xhrs = [];\n    // current loaded size in bytes for each file \n    this._loaded = [];\n};\n. Well, after days of searching, I finally solved this in the hour after posting here.\nThe solution: instead of including fileuploader.js in my application's main header, I include it inside my ajax div.\nCheers\n. ",
    "weboAp": "here is my solution and it works ok for me on CI 2.0.3\n1- add a library in application\\libraries\nphp\n\n<p/\n- Handle file uploads via XMLHttpRequest\n  /\n  class qqUploadedFileXhr {\n  /\n  - Save the file to the specified path\n  - @return boolean TRUE on success\n    /\n    function save($path) {\n    $input = fopen(\"php://input\", \"r\");\n    $temp = tmpfile();\n    $realSize = stream_copy_to_stream($input, $temp);\n    fclose($input);\nif ($realSize != $this->getSize()){  \n    return false;\n}\n\n$target = fopen($path, \"w\");  \nfseek($temp, 0, SEEK_SET);\nstream_copy_to_stream($temp, $target);\nfclose($target);\n\nreturn true;\n}\nfunction getName() {\nreturn $_GET['qqfile'];\n}\nfunction getSize() {\nif (isset($_SERVER[\"CONTENT_LENGTH\"])){\n    return (int)$_SERVER[\"CONTENT_LENGTH\"];  \n} else {\n    throw new Exception('Getting content length is not supported.');\n}  \n}  \n}\n\n/\n- Handle file uploads via regular form post (uses the $FILES array)\n  /\n  class qqUploadedFileForm {\n  /_\n  - Save the file to the specified path\n  - @return boolean TRUE on success\n    /\n    function save($path) {\n    if(!move_uploaded_file($_FILES['qqfile']['tmp_name'], $path)){\n        return false;\n    }\n    return true;\n    }\n    function getName() {\n    return $_FILES['qqfile']['name'];\n    }\n    function getSize() {\n    return $_FILES['qqfile']['size'];\n    }\n    }\nclass qqFileUploader {\n    private $allowedExtensions = array();\n    private $sizeLimit = 10485760;\n    private $file;\n```\nfunction __construct(array $allowedExtensions = array(), $sizeLimit = 10485760){      \n    $allowedExtensions = array_map(\"strtolower\", $allowedExtensions);\n$this->allowedExtensions = $allowedExtensions;        \n$this->sizeLimit = $sizeLimit;\n\n$this->checkServerSettings();\n\nif (isset($_GET['qqfile'])) {\n    $this->file = new qqUploadedFileXhr();\n} elseif (isset($_FILES['qqfile'])) {\n    $this->file = new qqUploadedFileForm();\n} else {\n    $this->file = false; \n}\n\n}\nprivate function checkServerSettings(){      \n    $postSize = $this->toBytes(ini_get('post_max_size'));\n    $uploadSize = $this->toBytes(ini_get('upload_max_filesize'));        \nif ($postSize < $this->sizeLimit || $uploadSize < $this->sizeLimit){\n    $size = max(1, $this->sizeLimit / 1024 / 1024) . 'M';             \n    die(\"{'error':'increase post_max_size and upload_max_filesize to $size'}\");    \n}\n\n}\nprivate function toBytes($str){\n    $val = trim($str);\n    $last = strtolower($str[strlen($str)-1]);\n    switch($last) {\n        case 'g': $val = 1024;\n        case 'm': $val = 1024;\n        case 'k': $val *= 1024;      \n    }\n    return $val;\n}\n/*\n * Returns array('success'=>true) or array('error'=>'error message')\n /\nfunction handleUpload($uploadDirectory, $replaceOldFile = FALSE){\nif (!is_writable($uploadDirectory)){\n    return array('error' => \"Server error. Upload directory isn't writable.\");\n}\n\nif (!$this->file){\n    return array('error' => 'No files were uploaded.');\n}\n\n$size = $this->file->getSize();\n\nif ($size == 0) {\n    return array('error' => 'File is empty');\n}\n\nif ($size > $this->sizeLimit) {\n    return array('error' => 'File is too large');\n}\n\n$pathinfo = pathinfo($this->file->getName());\n$filename = $pathinfo['filename'];\n//$filename = md5(uniqid());\n$ext = $pathinfo['extension'];\n\n //the following is just for fun to standarize file names uncomment if you like \n//$CI =& get_instance();\n//$CI->load->helper('url');\n//$filename = url_title( $filename ,'dash', TRUE);\n\n\nif($this->allowedExtensions && !in_array(strtolower($ext), $this->allowedExtensions)){\n    $these = implode(', ', $this->allowedExtensions);\n    return array('error' => 'File has an invalid extension, it should be one of '. $these . '.');\n}\n\nif(!$replaceOldFile){\n    /// don't overwrite previous files that were uploaded\n    while (file_exists($uploadDirectory . $filename . '.' . $ext)) {\n        $filename .= rand(10, 99);\n    }\n}\n\nif ($this->file->save($uploadDirectory . $filename . '.' . $ext)){\n   //original return \n   //return array('success'=>true);\n\n    //modified return\n    return array('success'=>true, 'filename'=>$filename . '.' . $ext, 'filezise'=>$size);\n} else {\n    return array('error'=> 'Could not save uploaded file.' .\n        'The upload was cancelled, or server error encountered');\n}\n\n}  \n```\n}\nthen in your controller add a function :\nlike: \nfunction myuploader(){\n```\n$this->load->library('qquploadedfilexhr');\n// list of valid extensions, ex. array(\"jpeg\", \"xml\", \"bmp\")\n$allowedExtensions = array('png', 'jpeg', 'jpg', 'gif', 'bmp');\n// max file size in bytes\n$sizeLimit = 1 * 1024 * 1024;\n$uploader = new qqFileUploader($allowedExtensions, $sizeLimit);\n$result = $uploader->handleUpload('absulute/path/to/your/upload/folder');\n// to pass data through iframe you will need to encode all html tags\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\n} \n```\nin your view:\n\nImages Uploader\n\n```\n    \nAllowed files : .jpeg, .jpg, .png, .gif, .bmp\n\n\nPlease enable JavaScript to use image uploader.\n or put a simple form for upload here \n\n\n\n\n```\n<br />\n        function createuploader(){<br />\n            var uploader = new qq.FileUploader({\n                element: document.getElementById('logos-uploader'),\n                //direct it to the function we created above\n                action: '&lt;?=base_url()?&gt;mycontroller/myuploader',\n                debug: true,\n                //params: { },\n                //onSubmit: function(file, ext) {</p>\n<p>```\n            //},\n            //yes its redendant but you hasve the choice, check the extensions , size.. \n            //in the front or wait till your php upload and check and answer.. \n            //i prefer to test in the front\n            //uncomment the following if you agree<br />\n            //allowedExtensions: ['png', 'jpeg', 'jpg', 'gif', 'bmp'],<br />\n            //sizeLimit: 1 * 1024 * 1024,<br />\n    onComplete: function(id, fileName, responseJSON){</p>\n<pre><code>    //Add uploaded file to list\n    if( responseJSON.success ){\n        //do something\n        $.log(responseJSON.filename, responseJSON.filesize);\n\n        }\n}\n\n\n    });           \n}\n</code></pre>\n<p>$(document).ready(function() {</p>\n<pre><code>createuploader();\n</code></pre>\n<p>});    // end of function</p>\n<p>\n```\n. sorry for the last part parsed wrong.!!!\ni called the library :  Qquploadedfilexhr.php\nthats how i got $this->load->library('qquploadedfilexhr');\n. like this : https://gist.github.com/1254273\nthanks, hope it help.\n. ",
    "bijanv": "@starmonkey Make sure to wrap the 'name' in \nvar queryString = this._options.action + '/qqfile/' + name;\nwith encodeURIComponent otherwise codeigniter will complain once you start uploading files with funky characters.\n. ",
    "pushpinderbagga": "Thanks folkd - this helped!\n. Not possible for all cases - like generating thumbnails and uploading etc.\n. Thanks for the comments. I am actually uploading the image to my application server, resizing it to set number of thumbnails and then batch uploading to S3.\nSince S3 works with Fineuploader and I do need this functionality - I will try to generate thumbnails on the fly through Cloudfront and do only single upload from now on. Thanks!\n. I could not understand? Fineuploader does upload to S3... doesn't it?\n. Not a good idea to expose private key... also why is there a need to sign each chunk... \n. :+1:  awesome!\n. Thanks for the reply. Really appreciate you supporting an open-source project. The issue is the the button text isn't visible.\njavascript\n    if($('#patient_profile_uploader').length){\n        $('#patient_profile_uploader').fineUploader({\n            request: {\n                endpoint: 'handleupload',\n                params: {}\n            },\n            text: {\n                uploadButton: 'Upload'\n            },\n            template: '<div class=\"qq-uploader without_label\">' +\n            '<pre class=\"qq-upload-drop-area\"><span>{dragZoneText}</span></pre>' +\n            '<div class=\"qq-upload-button btn btn-success\" style=\"width: auto;\">{uploadButtonText}</div>' +\n            '<ul class=\"qq-upload-list\"></ul>' +\n            '</div>',\n            classes: {\n                success: 'alert alert-success',\n                fail: 'alert alert-error'\n            },\n            debug: true,\n            multiple: false\n        });\n. Thanks. Only thing left to sort is the progress bar now. It simply doesn't work in Ie 7,8,9 for me. I shall test it out and in-case am unsuccessful - shall get back. Thanks a ton!\n. ",
    "qazihamayun": "10000's Thanks :) Man!\nIts solved me problem, and saved much time.\n. ",
    "Valamas": "My workaround was to change the line at around 500 to this in fileupload.js\nfileTemplate: '<li style=\"display: none !important;\">' +\n. Nice work\n. I was actually looking at this problem again today. Your message prompted me to action it. The problem I was having is that my drag bar is almost 100% width. So when dragging the file off the browser sideways, the code fix does not work because the elements dont get dragged over, so the drag bar remains. Here is my implementation\n|| relatedTarget.nodeName == \"FORM\" || (e.clientX <= 0 && e.clientY <= 0)\nCan be closed...\n. ",
    "adityavm": "IE doesn't have support for dataset, does it? Maybe a custom attribute, or even an id=\"file-XX\" will be better?\n. I think it would make sense to separate out the adding and uploading actions, since it's better to show users what files they're uploading before they upload them.\nAlong with this (filesAdded) event, I'd like a startUpload() method that actually starts the upload (which could be auto-called in onSubmit() if need be).\n. ",
    "joellimberg": "Use the onSubmit, onComplete and onCancel callbacks to keep a count of currently uploading files.\nonSubmit: count++\nonComplete: count--\nonCancel: count--\nthen only submit form if count == 0.\n. Also, if the user tries to submit the form while the file is uploading, you should submit the form immediately after the upload completes (at least I think it's what the user would expect).\nSo, if the user clicks submit while an upload is in progress, set a flag like submit_after_upload = true;\nand then, in the onComplete handler:\nif (submit_after_upload) {\n    // submit form\n}\n. ",
    "n0ldor": "hi, good idea, now i using the onProgress to put a var in false and oncomplete/oncancel to put to true\n. ",
    "pesz1": "Did you find a solution to the multiple upload issue?  I am having the same issue with IE 8 & 9, can only select 1 file to upload at a time.  Chrome & FF work fine, I can select multiple files.\n. ",
    "emartini": "Multi-upload depends of the web-browser capabilities and IE 9 dont have that feature, sorry.\n. Many people has noticed this \"issue\", then I can say: yes is a normal behavior.\nI've had to develop backend-code specifically for internet explorer to deal with this issue\n. I've used this code in one of my projects, replace the file paths for your own\nhttps://gist.github.com/1360574\n. ",
    "Infrag": "Concerning point number 2 - sizeLimit is not validated. \nIf I try to upload oversize file with Chrome, Error is thrown that file exceeds limit. If I do the same in IE nothing happens.\nSo I thing it really is an IE9 bug.\n. I downloaded it just now - VERSION 2.0\nI found out in sources that there is \"encoding\" parameter which can be used to force multipart. I think it just needs little correction in Docs.\n. OK,sorry it was little confusing for me.\n. ",
    "leek": "This doesn't actually work, _createUploadHandler also needs this._options.inputName sent to the upload handler.\nBasically, change this:\nvar handler = new qq[handlerClass]({\n        debug: this._options.debug,\n        action: this._options.action,         \n        maxConnections: this._options.maxConnections,\n... To this:\nvar handler = new qq[handlerClass]({\n        debug: this._options.debug,\n        action: this._options.action,         \n        inputName: this._options.inputName,  \n        maxConnections: this._options.maxConnections,\n. Unnecessary and usually considered bad practice.\n. ",
    "richsage": "@leek - nice catch, thanks :-)\n. ",
    "gabeodess": "Just what I was looking for!\n. I also would like to ability to send a PUT request, however, my reasons are to follow development standards not for memory issues.  Is this possible?\n. Ah I see.  It appears that the Rails framework gets around this by sending a _method:'put' parameter in the post params.  I tried sending this in the querystring as a workaround, but that doesn't seem to work.  Am I correct to understand that the image data is occupying the post parameter space, thus making it impossible to send _method:'put' as a POST parameter?\n\ncitysprout\nConnecting you to local farms.\nGabriel Odess-Gillett\nLead Developer & Co-founder\n413.248.4223 mobile\ncitysprout.com\nOn Jan 11, 2013, at 7:36 PM, Ray Nicholus wrote:\n\nNo, this is not possible in IE9 or earlier due to the fact that files are \nuploaded in these browsers by submitting a form inside a hidden iframe. \nThe W3C spec states that a form element's method attribute only has two \nvalid values: POST and GET. \nOn Fri, Jan 11, 2013 at 6:28 PM, Gabe Odess notifications@github.comwrote: \n\nI also would like to ability to send a PUT request, however, my reasons \nare to follow development standards not for memory issues. Is this possible? \n\u2014 \nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/197#issuecomment-12170169. \n\u2014\nReply to this email directly or view it on GitHub.\n. \n\n",
    "fallenartist": "I would like to know that too. I have a form on my upload page where files would be uploaded only when the uploader's details has been entered correctly. Hence the need for an upload button.\n. ",
    "kris": "Same.\n. ",
    "javismiles": "i have noticed that even your demo page hangs on IE9 when try to upload an image with it\nhttp://valums.com/ajax-upload/\ncould somebody provide the fix to make it work on IE9?\nthank you :)\n. Finally some light, im starting to find out that people with Windows 7 dont see the problem,\nwhereas people with windows Vista (like me), see the problem\nso it may be related to windows vista + IE9 interaction\nI dont know if thats fixable\nyes, it seems confirmed\nthis problem happens when you have Windows Vista installed + IE9,\nit doesnt happen with Windows 7\n. ",
    "muckinger": "See my comment here, maybe some can test this with all Version of IE, because i think all of them use the iFrame:\nhttps://github.com/dirkorette/file-uploader/commit/120cb1bf6ce3547a8a4827442b77b684266930bc#commitcomment-554289\n. ",
    "vinayvinay": "do we intend to close this bug anytime soon?\n. ",
    "boethius": "This immediately creates an error IE8. No go.\n. ",
    "09309410": "i like this upload plugin very much, but it is not work in firefox 7.0.1 now\n. ",
    "imitchell": "I am seeing the same issue on Chrome - Version 22.0.1229.94 m\n. ",
    "dvidsilva": "well it would be nice to know what causes it and which configuration works\n. the truth is I'm not really sure how it happened, it was working just a moment before and then that exception started showing up.\nI'm trying to see what could have change and if found will post\n. however, could you please explain maybe what this exception means, maybe that will point me in the right path\n. ok, just for the record, the error in the code was caused by something completely unrelated.\na method misspelled some lines ahead, but i kept overlooking it because it threw this exception.\nmisteries of the universe\n. ",
    "DaveStein": "Also found this: http://stackoverflow.com/questions/7231054/file-input-size-issue-in-safari-for-multiple-file-selection\n. :+1: \n. ",
    "TimNZ": "Yes, still an issue with Safari for Windows, but really how much of an issue in the real world with Safari Windows numbers and given Apple no longer release Windows version.\nUpdate: Bug in Safari, All input.files have size 0.\nWhy is it so hard for browser makers to get this s**t right?! \n. I agree with eguciar.\nGo into client dir and there is mention of the Downloads page with links to pre-built versions - all the Downloads page talks about is purchasing a license.\nThere is no link to this development page from the site.  I had to google for 'build fine uploader'.\nA cynical person could infer that the devs are trying to compel people into buying a commercial license by making it harder to get running as it should be.\n. Ok,  mild burn on that for me - but the Readme for this dir is definitely off.\nhttps://github.com/Widen/fine-uploader/tree/master/client\nAnyway, I ended up downloading the version from your demos page, I'm a node developer and I've never had npm install run for so long and download so much, I eventually had to can it.\nI don't have an aversion to paying for software, this is a criticism of the fact you actually make it difficult for someone to quickly get started with the system without easy to find download links for built version.\n. So why not just have a link to the latest build? Like pretty much every other popular client side library?\nOn 2/09/2013, at 10:42 AM, Ray Nicholus notifications@github.com wrote:\n\nThe readme in the root of the project links to the documentation. Looks like the link in the root of the client dir is a bit stale. We've redone the documentation several times already, and the home page has been restructured as well. It's easy for us to lose sight of something like this. I'll update the client dir's readme in the next version along with some other related documentation. \nFine Uploader is a substantial product with a significant amount of complexity. The build process is quite complex as well, and that complexity will only increase as #846 and other related cases are tackled. Some of the dependencies are related to the cross-browser automated unit and integration tests that we are constantly updating and improving. Other dependencies are related to the build itself, and some of those dependencies have dependencies as so on. Once you run npm install once, subsequent updates shouldn't take very long.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "deterset": "Increasing my php memory setting to 1024K seems to fix it. But why must it use so much memory ?\n. I am having the same problem but only when using IE9, Firefox and Crome work fine.\n. I don't even remember which project I was working on now, but I found a way around my problem .\n. ",
    "drxero": "I fixed the same problem on our Debian-PHP 5.2.6-Suhosen servers by disabling the Zend Memory Manager. \nI couldn't increase the memory limit high enough to fix the PHP crash for the 150MB files I'm uploading. But disabling the Zend Memory Manger solved it and allowed me to stay at the original 128MB memory limit for PHP.\nOn our servers, we added this to the /etc/apache2/envvars files:\nexport USE_ZEND_ALLOC=0\n. ",
    "since1976": "Seems like the files are uploading fine to the uploads directory but I seem to be getting a internal server error on the dropbox code? Any ideas on why that might be happening?\nPOST http://local.mysite.com/server/php.php?qqfile=bandwprints.pdf 500 (Internal Server Error)\nXHR finished loading: \"http://local.imago.net.nz/server/php.php?qqfile=bandwprints.pdf\".\nAlso from the Network tab of the inspector there seems to be an error with either the php file of fileuploader.js\nhttp://cl.ly/3N0x3w272z0b2p0W3A14\nIn advance thanks so much for your help.\nDan\n. Sure is. Stupid I didn't think of looking in there, although it is all foreign to me.\n[19-Sep-2011 14:27:43] PHP Fatal error:  Uncaught exception 'Exception' with message 'Cannot execute request: SSL certificate problem, verify that the CA cert is OK. Details:\nerror:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed' in /Users/dan/Sites/imago.net.nz/server/php.php:101\nStack trace:\n0 /Users/dan/Sites/imago.net.nz/server/php.php(60): DropboxUploader->request('https://www.dro...')\n1 /Users/dan/Sites/imago.net.nz/server/php.php(49): DropboxUploader->login()\n2 /Users/dan/Sites/imago.net.nz/server/php.php(287): DropboxUploader->upload('uploads/bandwpr...')\n3 {main}\nthrown in /Users/dan/Sites/imago.net.nz/server/php.php on line 101\n. Sweet thanks so much Sean that was exactly what it was.\nGot the files uploading to Dropbox.\nAppreciate the help\n. Never mind I worked out that the size limits need to mimic those on the server.\n. ",
    "gabrielstuff": "Here is what I've done my self :\njavascript\nonComplete: function(id, fileName, responseJSON){\n                        $(\"#message\").html('done...').show().fadeOut(3000);\n                        if($(\".qq-upload-list\").children().size()>1){\n                            $($(\".qq-upload-list\").children()[0]).fadeThenSlideToggle();\n                        }\n                    }\nadding this function found here (http://stackoverflow.com/questions/734554/jquery-fadeout-then-slideup) before document ready\njavascript\njQuery.fn.fadeThenSlideToggle = function(speed, easing, callback) {\n      if (this.is(\":hidden\")) {\n        return this.slideDown(speed, easing).fadeTo(speed, 1, easing, callback);\n      } else {\n        return this.fadeTo(speed, 0, easing).slideUp(speed, easing, callback);\n      }\n    };\nWorks pretty good with ast jquery and 1.4\n. Hey,\nEnd up with that :\njs\nif(jQuery(\".qq-upload-list\").children().size()>1){\n                        jQuery(\".qq-upload-list\").children(':first-child').fadeOut(1000).slideUp(2000, function(){\n                                jQuery(this).remove();}\n                            );\n                    }\n. ",
    "rottmann": "Same problem, i increase php memory limit to solve it. Post file size and upload file size are big enough, but php need more memory, i dont know why.\n. Cancel not work if the file upload is in progress (php apache).\nI think we have to overwrite \"_onCancel\" to send a second request to server to remove a file, but the server can only remove if the \"canceld\" file upload finished. Crazy.\nI think without using something like APC_UPLOAD in PHP the cancel function is useless and should be removed.\n. ",
    "onhate": "Sorry for may english, I thought that I did a mistake on my explanation.\nI would like to say, to compress unsing gzip the file to be uploaded.... like I clicked choosed a .wav file, but before send it, would be great if browser comprime the .wav example file.\n. ",
    "siddo420": "How about using something like https://stuk.github.io/jszip/ now? \nCan this be integrated soon?\n. Ok thanks.\nAnd, is it possible to configure FU to open file selection dialog as soon as new qq.FineUploader(...) is called?\n. ",
    "kritzikratzi": "same problem here ... \n. ",
    "mrigor": "This issue is fixed on this fork - https://github.com/bencolon/file-uploader\n. ",
    "fabienthomas": "Up !\nI've got exactly the same problem in one of my app, my progress bar is in the file-list generated by the file uploader, it works perfectly on modern browsers, but IE does not display it, but it shows the PB placeholder with expected height and width;\nI have to admit it, i'm stuck on that issue, any help will be highly appreciate ;)\nThanks\nF.\n. Thanks for that quick answer ;)\nOk i guess i'll have to figure an other way to deal with upload progression and IE.\n. I've tried on Chrome and Firefox (both mac).\nMy app doesn't run the latest version of fileuploader, i guess i could update it, but i really have to make this version of my upload app working :)\nhere is my php server side script : http://pastebin.com/e3mNh12m\nhere is my fileuploader.js : http://pastebin.com/mYGDXHQ8\nhere is my app js file : http://pastebin.com/U9Gb9vUu\nthanks for your help ;)\n. Have you always had an issue with files of this size?\nsort of, this is the first release of this app.\nWhen reproducing this, are you attempting to upload the files on the same machine or network as your server endpoint?\nyes, this is the same machine\n. @Gildus i'll try that. \nthanks !\n. @Gildus same result ;(\nhere is what my console gives me :\nFatal error: Uncaught exception 'Exception' with message 'Getting content length is not supported.' in qqfileuploader.php:48 \nStack trace: \n0 qqfileuploader.php(130): qqUploadedFileXhr->getSize()\n1 uploadv2.php(113): qqfileuploader->handleUpload('/home/weecast/w...')\n2 [internal function]: Uploadv2->do_upload('video')\n3 /CodeIgniter.php(221): call_user_func_array(Array, Array)\n4 /index.php(129): require_once('/home/plop/p\u2026')\n5 {main} thrown in qqfileuploader.php on line 48\n(path are edited)\nthanks \n. @Gildus i've tried, several times, but the result is the same every time :/\nThanks\n. We finally made it works !\nWe've found this thread about an issue quite similar : https://github.com/valums/file-uploader/issues/61 and it helped us, now the app successfully upload big files.\nChanging the Content-Type to \"multipart/form-data\" was the key here ;)\nThanks all for your time and support !\n. I really don't know, i can't find any version number/release date :/ i'd say a few weeks.\nI'll update it asap, but i'd had to make this release work, it seems fine right know.\nThanks again for your work and your time !\n. My version hasn't that encoding option.\nWhen i'll update my app with the latest version i'll do what you described above.\n. ",
    "hugoduraes": "I managed to solve it and the error was on my code. Sorry.\n. Sorry, but I can't remember anymore what the problem was. And now I'm not even using this plugin anymore! :(\n. ",
    "sickans": "The question is, what was the problem in your code since I am experience a similar issue and cannot find the root-cause :)\nThanks.\n. Thanks anyway and as always once you start asking questions you find that tiny little bit that you have missed all along.\nMy problem was that use custom fileTemplate when creating the qq.FileUploader and there I has missed to close a </span> tag and this IE7/8 cannot handle the DOM. Problem solved here aswell :)\n. ",
    "vaibhav011286": "I am also having the same problem but earlier it was working...\nCan somebody help?\n. Yes mine tooo..lol\nOn Dec 16, 2011 11:29 PM, \"cviebrock\" \nreply@reply.github.com\nwrote:\n\nDid you make sure file_uploads is on, in either your apache config, or\nphp.ini?\nThat was my (stupid) mistake.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/205#issuecomment-3180446\n. @ichernev: i tried your method but its not working...\n. @ichernev: hey thx... it worked..\n. \n",
    "cviebrock": "Did you make sure file_uploads is on, in either your apache config, or php.ini?\nThat was my (stupid) mistake.\n. ",
    "christiansalazar": "helo folks,\nyou receive the file on server side on uploader.php ?\n...you said: \"$_REQUEST are all empty\",\ntry debugging the client part it using Firebug or the Chrome error tracker, to see what's going on in client part.\n. ",
    "mguidetti": "works for me, id like this added as well \n. ",
    "ichernev": "I just tried it again and it worked :)\nFirst add the presubmit callbacks (I did this in client/demo.htm, maybe I should add a test)\n--- a/client/demo.htm\n+++ b/client/demo.htm\n@@ -26,7 +26,11 @@\n             var uploader = new qq.FileUploader({\n                 element: document.getElementById('file-uploader-demo1'),\n                 action: 'do-nothing.htm',\n-                debug: true\n+                debug: true,\n+                preSubmit: {\n+                    form: function(id, form) { console.log(id, form); },\n+                    xhr: function(id, xhr) { console.log(id, xhr); }\n+                }\n             });           \n         }\nAlso make sure you put the client folder inside a web server -- that is, you may try to simply copy it so apache would serve it, or make a symbolic link (under linux/mac).\nThen make sure it works with xhr and a form, if you don't have a browser that doesn't support xhr, then just alter fileuploader.js to always use form:\n```\n--- a/client/fileuploader.js\n+++ b/client/fileuploader.js\n@@ -332,7 +332,7 @@ qq.FileUploaderBasic.prototype = {\n             }\n         };\n\nif (qq.UploadHandlerXhr.isSupported()){           \nif (false && qq.UploadHandlerXhr.isSupported()){         \n             handlerClass = 'UploadHandlerXhr';                      \n             if (this._options.preSubmit && this._options.preSubmit.xhr) {\n                 qq.extend(handlerOptions, {\n```\n\nFinally check at the javascript console if you get the log :-)\n. ",
    "sebpiq": "@ichernev : thanks ! Also very useful if you communicate with an API, and want to ask for a particular response type : xhr.setRequestHeader(\"Accept\", \"application/json\")\n. Hey thanks @mattfawcett !!! Great patch ! Works perfectly for me ...\n. ",
    "anton-yordanov": "sorry 'status': true was not set properly\n. ",
    "senleft": "Thank you very much!\nMay I ask you to add the documentation link\nhttps://github.com/valums/file-uploader/wiki\nto main script page http://valums.com/ajax-upload/\nand some notes about this \"issue\"?\nI think it may save a lot of time for the some peoples.\n. ",
    "patrikjensen": "Do you have any code published for the solution?\n. ",
    "maug": "Try to use ... = new qq.FileUploader(...\n. ",
    "Ridermansb": "I resolve my problem. I do not know how. =)\n. ",
    "cdvrooman": "I was just trying the \"Display Image Thumbnails\" demo and I did the following:\n1. Uploaded a test image, the thumbnail was displayed as expected.\n2. Uploaded two additional, different test images; however, the thumbnail from the first image appeared two more times. \nFor whatever reason, the thumbnail mechanism is not detecting the latest uploaded image and is reusing the first image.\nThe demos are still pretty cool!\n. ",
    "lmaurer": "Need to break this up into separate stories:\n- [x] Rethink templating - #867\n- [x] FineUploader mode UI for browsers w/ File API support - #868\n- [x] FineUploader mode UI for Non-file API support - #869\n. May require Anna/Josh's input\n. Requires Anna/Josh input.\n. Need to break up into more stories and re-estimated. \n. Add story for browser-based testing \n. Add story for browser-based testing \n. Need to break up into smaller stories after more detail is defined. \n. Need to involve Josh/Anna. \n. Need to create separate story to give licensed (paid) users special access to website. This new area is where we'd store this wizard. \n. Look into using Duck Duck Go for this. If not, reevaluate estimate.\n. Break up into 2 stories. Each 8 points. \n. No longer applies. #846 \n. Look for alt ways to accomplish this without breaking change.\n. To you for taking a first crack at these. I'd like to review/discuss before we implement.\n. Completed in #1085.\n. Need to know if it's got CORS support before estimating/prioritizing.\n. Include on per-file basis? \n. ",
    "dinther": "And of course the minute I typed the above message I found a reference online explaining that the last defined rule in the css file over rules the earlier ones.\nThis works:\n.mylook {background-image:url('dropbox.jpg'); width:100px; height:100px; padding: 10px;}\n.qq-upload-button-hover {background:#00cc00; background-image:url('dropboxover.jpg');}\nthis doesn't\n.qq-upload-button-hover {background:#00cc00; background-image:url('dropboxover.jpg');}\n.mylook {background-image:url('dropbox.jpg'); width:100px; height:100px; padding: 10px;}\n. ",
    "jhcaiced": "Hi, the main page at http://valums.com/ajax-upload/ states:\n\"This plugin uses XHR for uploading multiple files with progress-bar in FF3.6+, Safari4+, Chrome and falls back to hidden iframe based upload in other browsers, providing good user experience everywhere.\"\nSo, when using the \"iframe based upload\" the onProgress() method is not called, all you can do is set a \"Waiting...\" image and wait for the upload to finish.\n. ",
    "gGambit": "Can't IE perform XHR using ActiveXObject(\"Microsoft.XMLHTTP\") ?\nIs there a reason we can't perform the call back this way?\n. ",
    "peterldowns": "Was this ever updated? I'm experiencing the same problems reported by @valbhav011286.\n. Got it, thanks :)\n. ",
    "udonjuan": "It took a while, but I got it working. Here's how: \n```\n \n<div id=\"file-uploader\">\n\n```\nThe input field, I could only get to appear outside the \"file uploader\" div. Then within the createUploader function, I put the following code:\nonSubmit: function() {\n                    if ($(\"#reference\").val() == \"\") {\n                            alert();\n                            return false;\n                    }\n                    uploader.setParams({'reference': document.getElementById('reference').value});\n            },\nAnd that did it. The key was calling the \"setParams\" function to grab the #reference field value. Hope that helps.\n. ",
    "egeriis": "Just what I needed!\nHowever, there a bug which you ought to fix. The name of the multipart which contains the file itself, should be named qqfile instead of just file. Otherwise there inconsistence between traditional and XHR upload.\nHere's what I changed to make it work 100%:\nL1198: params['filename'] = name;\nL1207: data.append(\"qqfile\", file);\n. Wonderful!\n. ",
    "mattfawcett": "Thanks @egeriis - I have commited a fix for that and also made it possible for users to specify a field name other than qqfile if they wish, by specifying a fieldName option.\n. ",
    "acastaner": "I must be doing something wrong because this is what Chrome sends:\n------WebKitFormBoundaryM5lFQgsPqkJ676XH\nContent-Disposition: form-data; name=\"spock-rocks.gif\"; filename=\"spock-rocks.gif\"\nContent-Type: image/gif\n------WebKitFormBoundaryM5lFQgsPqkJ676XH--\nShouldn't \"name\" be \"qqfile? And shouldn't the extra parameters also be in the multi-part data?\n. ",
    "crirus": "how about uploading in chunks as blob, I read some people is using it... makes upload faster?\n. I use multipart for now and it works, the only drawback is that on server side you don't use php class anymore, or you can change the class qqUploadedFileXhr that save the file \nfunction save($path) {    \n    if($_FILES[\"qqfile\"]){\n        $rs=@move_uploaded_file($_FILES[\"qqfile\"][\"tmp_name\"],$path);\n        return $rs;\n    }else{\n        $input = fopen(\"php://input\", \"r\");\n. I select a 1.5 GB file and it appears at 100% in like 20 seconds, although on the server it takes another 30 minutes to arrive.\nI can see it in /tmp folder as it's increasing size....\n. Browser is Firefox, the pluing is latest and I am testing on client/server not locally\nThe server is pretty fast in BW 2Gbit line.\nWhat I see as far as progress, it's a very fast processing on client then server need way more time to receive all file data and respond.\nIt appears as if the browser send the file fast and report as done, then file travels 30 minutes to get to server.\n. it's not server side, I look at the file as it's uploaded on server tmp folder, it takes over 30 minutes which is normal, while the 100% appears in like 20 seconds, here is a temporary test server\nhttp://staging.magnovideo.com/\n. ",
    "tb": "It is not limited to img or  jQuery UI's drag/drop.\nIf I go to http://fineuploader.com , mark some text and \"drag\" it, then the drop areas displayed too.\n. I got uploader working perfectly with IE8 with version 3.2 from https://github.com/zakgrant/fine-uploader-rails/blob/master/vendor/assets/javascripts/fineuploader.jquery.js\nHowever, Chrome support is broken now. I started to intercept the communication and I can see that the 3.3 working version looks like this:\nPOST /answer_files?qqfile=test.txt HTTP/1.1\nHost: localhost:3000\nConnection: keep-alive\nContent-Length: 14\nOrigin: http://localhost:3000\nCache-Control: no-cache\nX-File-Name: test.txt\nUser-Agent: Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.97 Safari/537.22\nX-File-Upload: true\nContent-Type: application/octet-stream\nX-Mime-Type: text/plain\nX-Requested-With: XMLHttpRequest\nAccept: /\nReferer: http://localhost:3000/\nAccept-Encoding: gzip,deflate,sdch\nAccept-Language: en-US,en;q=0.8\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3\nCookie:  _session=a7eb5b50b4b02f8022675c6f4a078528e51fabb3\nHello Chrome!\nwhilte the broken 3.2 version of request looks like this:\nPOST /answer_files?qquuid=cee20ef3-dda0-4e21-81e7-6649e8cfee11&qqtotalfilesize=14&qqfile=test.txt HTTP/1.1\nHost: localhost:3000\nConnection: keep-alive\nContent-Length: 198\nX-Requested-With: XMLHttpRequest\nCache-Control: no-cache\nOrigin: http://localhost:3000\nUser-Agent: Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.97 Safari/537.22\nX-File-Upload: true\nContent-Type: multipart/form-data; boundary=----WebKitFormBoundary12DZXzttCTKBP3OH\nAccept: /\nReferer: http://localhost:3000/my/audits/923\nAccept-Encoding: gzip,deflate,sdch\nAccept-Language: en-US,en;q=0.8\nAccept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3\nCookie:  _session=a7eb5b50b4b02f8022675c6f4a078528e51fabb3\n------WebKitFormBoundary12DZXzttCTKBP3OH\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"test.txt\"\nContent-Type: text/plain\nHello Chrome!\n------WebKitFormBoundary12DZXzttCTKBP3OH--\nAll of the experiments are in the same environment, the only thing that I change is the 3.2/3.3 js file. How can I fix the 3.2 Chrome upload request so that it does not include the multipart/form-data and WebKitFormBoundare?\n. I think there is some issue with decoding fineUploader multipart encoded requests in rack https://github.com/rack/rack/issues/search?q=multipart\nBased on code chagnes between fineuploader 3.2 and 3.3 I was able to figure out what request setup can disable multipart and fix sending parameters (in particular authenticity_token for Chrome). \nFinally, in order to get RawUpload to correctly set content type and filename, I had to add this in fineUploader source: \n```\n--- a/app/assets/javascripts/libs/jquery.fineuploader-3.3.js\n+++ b/app/assets/javascripts/libs/jquery.fineuploader-3.3.js\n@@ -3275,7 +3275,8 @@ qq.UploadHandlerXhr = function(o, uploadCompleteCallback, logCallback) {\n         xhr.setRequestHeader(\"Cache-Control\", \"no-cache\");\n     if (!multipart) {\n\n\nxhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\nxhr.setRequestHeader(\"X-File-Name\", api.getName(id));\nxhr.setRequestHeader(\"Content-Type\", fileOrBlob.type);\n             //NOTE: return mime type in xhr works on chrome 16.0.9 firefox 11.0a2\n             xhr.setRequestHeader(\"X-Mime-Type\", fileOrBlob.type);\n         }\n```\n\nNow with server side setup:\nGemfile:\ngem 'rack-raw-upload'\nconfig.ru:\nuse Rack::RawUpload, explicit: true\ncontroller:\nfile = params[:qqfile].is_a?(ActionDispatch::Http::UploadedFile) ? params[:qqfile] : params[:file]\nand following fineUploader 3.3 request config:\nrequest: {\n  endpoint: '/your/upload/url',\n  params: { authenticity_token: authenticity_token },\n  forceMultipart: false,\n  paramsInBody: false,\n  customHeaders: { 'X-File-Upload': 'true' }\n}\nNow upload works with both Chrome and IE8.\nthrow [file.original_filename,file.content_type,file.tempfile.read]\nreuslts for uploads with Chrome and IE8:\n[\"test.txt\", \"text/plain\", \"Hello Chrome!\"]\n[\"test.txt\", \"text/plain\", \"Hello IE8!\"]\n. ",
    "thehydroimpulse": "I also got the same thing. Though only when the size of the file is above 30MB. I've tried it all on chrome, firefox, and internet explorer just to see if the two methods of uploading may be causing the problem. Currently it seems to work only in internet explorer since it uses a more normal approach to uploading if I can understand. \nMy file size limits are set above the 5G mark; i'm assuming it's not the problem. All of files work flawlessly! \nI'm also assuming that this method and the script is able to upload up to those sizes and beyond.\nThanks,\nDaniel\n. ",
    "Smayds": "I should mention that I'm having the same problem with files larger than 60MB. Using the backup ordinary POST method, the server-side PHP file properly accepts anything up to my server's limit of 192MB, and it renames and so on if the file exists. Via the progress-bar callback method, however, files will seem to transfer completely, ticking steadily up to 100%, but anything over about 60MB will return a 500 error on completion (and nothing is logged in the server's error log either).\nI'm at a complete loss, the script seems to be doing everything fine, and my host has ruled out any problems on their end (as POST uploads work fine).\nCheers!\n-Ayden\n. Finally figured this thing out.\nIt's RAM.\nI was watching my PHP memory usage very carefully as I was uploading a 70MB file. PHP slowly ticked up until it was using just over 70MB as the upload finished, then it jumped straight to 140MB, then it failed with a memory allocation error as it tried to allocate another additional 70M+1 bytes of extra RAM (PHP on my server is set up to use a maximum of 192MB - actual megabytes, here. All the previous 'MB's there meant 'million bytes.' Ahem). And then this was in the error log:\nPHP Fatal error:\nOut of memory (allocated 140771328)\n(tried to allocate 70000001 bytes) in Unknown on line 0\nIt seems that PHP is buffering the entire upload in memory, then reserving more memory when the input stream gets copied into the temporary file, then reserving even more memory when the temporary file gets copied over to the final folder.\nWhat I did to solve it was to simply change this line in the .js file:\nxhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\ninto this:\nxhr.setRequestHeader(\"Content-Type\", \"multipart/form-data\");\nAnd now, PHP consistently logs an error immediately as an upload begins:\nPHP Warning:  Missing boundary in multipart/form-data POST data in Unknown on line 0\nBut it doesn't seem to matter. Yes, I'd like to remove any and all errors, but what's important is that uploads WORK. After that warning is logged, I can see the file being written into the temporary folder as the upload is taking place. PHP was using about 700KB of RAM in total throughout the entire upload. Tested it with a 1.5GB file and it uploaded perfectly, re-downloaded the file and it matched.\nThe warning was worrying me, so I did about a thousand uploads of random images and mp3's, then re-downloaded them and used a compare utility to tell me that not a single byte was out of place compared to the folder full of originals.\nWhat's better (for me at least) is that I then skipped the temporary file altogether in the PHP uploader, so files upload directly into the folder I need them in. The function in the PHP now reads like this:\nfunction save($path) {    \n        $input = fopen(\"php://input\", \"r\");\n        $target = fopen($path, \"w\");\n        // the script spends most of its time idling on the next line:\n        stream_copy_to_stream($input, $target);\n        fclose($target);\n        fclose($input);\n        return true;\n    }\nEverything works perfectly. I imagine that there's more in the javascript to change than just the header to avoid the error, but for the moment, I am very happy.\nCheers,\n-Ayden\n. ",
    "konfiot": "Now, I don't know why, but it seems to work correctly, I think it can be the server or the client bandwith or charge. \n. I'll try, but I think I can close the issue, very nice job.\n. ",
    "doomhz": "Added text options for the Cancel button and fail upload message.\n. ",
    "logicalgroove": "Yep, this would be very helpful.\n. ",
    "EdwardIII": "Agree, was just about to write this myself until I saw the pull request.\n. ",
    "mikeschuld": "You don't have to wait for this to be pulled into the repo, just pull the commits into your own fork ;)\n. I just noticed the few spacing issues before I did the pull request. I can definitely attest to the usefulness of these additions as I am using every one of them.\nShould I re-do the pull request on the develop branch?\n. Travis CI wants the branches to come FROM develop? Why does it matter where they were branched from if they merge cleanly?\n. Interesting. The message that showed when it first failed said something like \"Whoa! Only code branched from develop can be merged.\" \nThe new message showing for me is the lint one now.\n. ",
    "kmiyashiro": "Use a shim. https://github.com/douglascrockford/JSON-js\n. ",
    "iandunn": "+1. I've only glanced at the code, but this seems like a big security vulnerability.\n. ",
    "imnemo": "Mark~\n. ",
    "NTICompass": "I can take a crack at this when I get some free time :-)\n. @maxatbrs: https://groups.google.com/forum/#!forum/fineuploader\nI'd love to have others help with the PHP code as I may not always have free time.  I was actually working last night on adding PHP 5.4 Session Upload Progress, but I don't know when I'll be ready to push that.\n. @rnicholus: Yeah.  To get the status, you need to make AJAX calls to ask PHP 5.4 for the progress.\n. @rnicholus: I don't want to interject, but I would love to help maintain the PHP example!\n. @rnicholus: Yeah.  I work, but I should have time throughout the day to help out.  I work as a web developer, so I'm doing PHP stuff all day :-)\nPlus I use a home-brewed version of the PHP script in my work code.\n. @borut-t: That's up to you.  The JSON response from the uploader can be whatever you want.  The htmlspecialchars is needed because IE uses a hidden iFrame (it submits the form normally, then parses the response).\nA \"workaround\" is to decode the HTML in the JSON response.  Like this:\nonComplete: function(id, fileName, responseJSON) {\n    if(responseJSON.success) {\n        responseJSON.html = $(\"<div/>\").html(responseJSON.html).text();\n        $('#'+target).append(responseJSON.html);\n    }\n}\nI found that trick on a StackOverflow question: http://stackoverflow.com/a/2419664/206403\nP.S. I'm Rocket Hazmat on StackOverflow.\n. @borut-t: Glad I could help :-)\n. @rnicholus: htmlescapechars is used because in IE the \"JSON\" response is displayed as text on the screen.  My guess is that IE will try to parse the HTML if it's not escaped, and if it's not valid HTML, it might be removed and therefore unable to be parsed by the uploader.\n. @rnicholus: I'm busy with work, but when I get free time, I can help out :-D\n. @rnicholus: Yay work :smile: \n. ",
    "bencolon": "Some bugs ... I will reopen it later.\n. ",
    "rayiezhf": "Cannot upload large file size.\nFile size trying to upload is 100MB.text file\nphp memory limit i have made 512mb.\npost_max_size   300M    300M\nupload_max_filesize 300M    300M\nFatal error: Allowed memory size of 134217728 bytes exhausted (tried to allocate 50664144 bytes) in Unknown on line 0\nany guesses what else can be the problem?\n. ",
    "honza": "Solved by setting\nclient_max_body_size 100M;\n. ",
    "jirubio": "I had the same problem.\nThe problem for me was the server contentType of the response.\nI changed it from \"text/plain\" to \"text/html\" and everything works correctly.\nPaul try it, no need to change the innerHTML.\n. ",
    "skoshkarev": "Hey guys,\nI tried everything to solve \"undefined\" problem in IE8/IE9. My issue is that ajax uploader works correctly in all browsers excluding IE. IE returns \"undefined\" when I try to upload a file.\nonComplete: function(id, fileName, responseJSON) {\n                if (responseJSON.error != \"\" && responseJSON != undefined) {\n                    console.log(responseJSON.error);\n                    console.dir(responseJSON);\n                }\n            }   \nConsole shows:\nLOG: undefined \nLOG: [object Object] \nI tried to change content/type and etc. Any ideas how to kill such bug?\n. You mean to set a new param like this\nvar uploader = new qq.FileUploader({\ndataType:'json'\n})\n. I found this stuff:\nxhr.open(\"POST\", queryString, true);\n        xhr.setRequestHeader(\"X-Requested-With\", \"XMLHttpRequest\");\n        xhr.setRequestHeader(\"X-File-Name\", encodeURIComponent(name));\n        xhr.setRequestHeader(\"Content-Type\", \"application/octet-stream\");\n        xhr.send(file);\nShould I change it to:\nxhr.open(\"POST\", queryString, true);\n        xhr.setRequestHeader(\"X-Requested-With\", \"XMLHttpRequest\");\n        xhr.setRequestHeader(\"X-File-Name\", encodeURIComponent(name));\n        xhr.setRequestHeader(\"Content-Type\", \"json\");\n        xhr.send(file);? \nHey can you send your code here when you get back to home? I'll pray for you to my PHP god :)\n. Hi,\nI tried your code and it didn't work. Could you give me your code of uploader (JS) and maybe you changed something in your PHP code?\nThanks\n. ",
    "symfonyau": "@skoshkarev, I had lots of trouble with IE too. To get it working I had to return a X-JSON header from PHP, for example:\nheader('X-JSON', json_encode($result));\nrather than\nheader('Content-type','application/html');\n. ",
    "pgraham": "xhr.setRequestHeader(\"Accept\", \"application/json\"); is essential for any browser since the client is expecting to get JSON back.\nThe default Accept header for Firefox is \"text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\" which could cause unexpected responses from certain servers.  This is less of an issue for chrome which uses \"/\" as a default Accept header.\nThe code suggested by @syslogic fixes this.  Is there a pull request to get this change into the repo?\n. This issue: https://github.com/valums/file-uploader/issues/237 ... which I see has been closed.\nI will retest to see if this change is still necessary.\n. Apologies for the confusion, the issue I was having was unrelated to the original issue but would have been fixed by a solution proposed in the comments.\nI've create a new issue, https://github.com/valums/file-uploader/issues/496, that outlines the problem.\n. The server framework I am using will inspect the Accept header of the request in order to determine the response format.  The process is described here: http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html. Because XML is among the supported formats the response will be in XML.\n. Content negotiation can happen for any request that sends a response body.  This is likely not an issue for other browsers.\nDefault Accept headers for other browsers:\nChrome: */*\nIE9: application/json, text/javascript, */*; q=0.01\n. Sorry for the delay, real work has picked up... Yes, adding the Accept header to customHeaders works, thanks! Also you have a good point about the form uploader, fortunately I am in a position to decide to not do anything special to support IE so I can just ignore this. \n. ",
    "edssoul": "hi, \nvia XMLHttpRequest  you need $_GET['your_params'] \nand via Form Post you need $_POST['your_params'] \ni just put it in the constructor\nif (isset($_GET['qqfile'])) {\n        $this->file = new qqUploadedFileXhr();\n        $params = $_GET['imgname'];\n    } elseif (isset($_FILES['qqfile'])) {\n        $this->file = new qqUploadedFileForm();\n        $params = $_POST['imgname'];\n    } else {\n        $this->file = false; \n    }\n. hi, \nvia XMLHttpRequest  you need $_GET['your_params'] \nand via Form Post you need $_POST['your_params'] \ni just put it in the constructor\nif (isset($_GET['qqfile'])) {\n        $this->file = new qqUploadedFileXhr();\n        $params = $_GET['imgname'];\n    } elseif (isset($_FILES['qqfile'])) {\n        $this->file = new qqUploadedFileForm();\n        $params = $_POST['imgname'];\n    } else {\n        $this->file = false; \n    }\n. ",
    "bokor": "ian did you figure this out out?\n. ",
    "irashkin": "No, never figured it out, and I ended up not using the file-uploader for \nthis project because of that as well as inconsistent browser support. \nStill using it for internal apps where browser and upload rules can be \ncontrolled by trust rather than technology.\nOn 5/7/2012 5:02 PM, Brian Bokor wrote:\n\nian did you figure this out out?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/239#issuecomment-5560768\n. \n",
    "dgrinb01": "a must for django, but instead it would be better if headers can be added, same way params are.\n. ",
    "phuongnd08": "Not only django but my rails project also demands a way to inject csrf into the uploader (so that my user session won't be reset, as according to this: http://stackoverflow.com/questions/5126721/rails-not-reloading-session-on-ajax-post). I think your commit is too django specific. \n. ",
    "aleksandrenko": "I make a small change to the js so i can add the csrf, like this:\nvar uploader = new qq.FileUploader({\n  ...\n  csrf: '{{ csrf_token }}',\nChanges:\n1. Add \"csrf: '' at line 265, after \"minSizeLimit: 0,\"\n2. Add \"csrf: this._options.csrf,\" at 328, after 'action: this._options.action,'\n3. Add\nif (this._options.csrf != '') {\n     xhr.setRequestHeader(\"X-CSRFToken\", this._options.csrf);\n }\nat line 1210, after \"xhr.setRequestHeader(\"Content-Type\", \"text/html\");\"\n. I will be cool if someone make an django app, so it can be easy to install. Now is not so much ...\n. ps me if need a code snippets ;) \n. ",
    "vjsingh": "Thanks for this sstur! Worked great for me. Handling octet-streams seemed difficult in Node.js\n. ",
    "sstur": "Glad it could be useful for someone : )\n. Sure, I'd be happy to contribute more. I've done a few other patches for things like multipart in FF3.6 and some fixes. I'll try to get around to sending you a pull request over there..\n. \"multipart/form-data\" encoding is a method of encapsulating fields of different kinds (strings, binary, files of various mime-types) into one payload to be sent via post/put/etc. A normal web form uses \"application/x-www-form-urlencoded\" if it does not contain uploads, or \"multipart/form-data\" if it does. So most server-side request parsers, understand both of those. The default for Valums file uploader is to use no encoding and send up only one file with mime-type application/octet-stream. This can be inconvenient for server-side components that expect one of the widely-used standard enctypes.\nFor more details, see http://www.w3.org/TR/html401/interact/forms.html .\nHope this helps.\n. ",
    "timoxley": "@SimonEast I don't see this code in your fork :/\n. ",
    "cherrot": "Thanks ! \nIt works for me because I'm using Spring MVC with MultipartFile to handle multipart data :)\n. ",
    "sshogunn": "Could you give the explanation of new  {encoding: \"multipart\"}?\n. ",
    "nmartynenko": "I had the same problem, but I found the cause.\nIE seems to receive all content within IFRAME as HTML. And it ignores content-type sent by server (at least I couldn't make IE do JSON as application/json). So JSON and plain text IE gets as HTML content within PRE tag.\nSo, JSON string \njson\n{\"success\":true}\nbecomes HTML node\nhtml\n<PRE>{\"success\":true}</PRE>\nI solved it in the easiest way: I started using innerText instead of innerHtml\n``` patch\n@@ -1058,10 +1058,10 @@\n             response;\n     this.log(\"converting iframe's innerHTML to JSON\");\n\n\nthis.log(\"innerHTML = \" + doc.body.innerHTML);\nthis.log(\"innerHTML = \" + doc.body.innerText); try {\n\n\nresponse = eval(\"(\" + doc.body.innerHTML + \")\");\nresponse = eval(\"(\" + doc.body.innerText + \")\");\n     } catch(err){\n         response = {};\n     }      \n```\n\n\n\nYou can use whatever solution you want.\n. BTW, here is other solution, which seems to be more universal.\nhttps://github.com/sstur/file-uploader/commit/46a05e2151d37ca79ece207e4e3944a473e38e79\n. ",
    "tomfrit": "Thanks, this brought me on the right track to solve this IE mess!\n. I noticed that the upload is named different in IE compared to any other browser. It was qqfile everywhere but POSTDATA in IE. This pointed me that way. This might not be a problem for anyone else since I'm working with a proprietary Perl framework.\n. ",
    "davekent": "what ie issue is this referring to? can you please clarify? thanks\n. ",
    "rixrix": "This ticket and the solution posted by @diconart did the fix with my IE7/8 issue. @diconart maybe you could do a pull request to the project admin and you might be able to help those people struggling to get IE working. cheers\n. ",
    "OwenMelbz": "This has also been the fix for our project, The issue was If you were uploading a file in IE then it would simply get upload failed.\nWe've added this code to all our  projects and its fixed all the issues. We recommend you investigate this and apply this fix to you base code.\n. ",
    "roper22": "(I've also changed the post_max_size also, forgot to mention that.)\n. ",
    "awpeters": "This is due to the data being read into memory instead of going to the file system. The solution is to send the data as a regular form upload. Use the changes from pull request #244 and set the option encoding: multipart when creating the uploader.\n. ",
    "vvoi": "thanks!\n. ",
    "venca256": "Thank you very much for solving this problem\nVaclav (Czech Republic)\n. ",
    "baiyilin": "same issue here, come on!\n. ",
    "csturgeon": "Ended up just changing the CSS for qq-upload-drop-area to make it hidden. That seems to have resolved the issue.\n. ",
    "Rik4444": "This is a 5 month old post so I guess this answer may not be usefull, but I imagine there may be more people with the same question. All  you have to do is use some of the built-in events. Here's an easy example:\n```\nvar uploader;\n//Total number of files queued and uploaded.\nvar totalFiles = 0;\nfunction createUploader() {\n    var elem = document.getElementById(\"file-uploader\");\n    uploader = new qq.FileUploader({\n        element: document.getElementById('file-uploader'),\n        action: '/AJAX/FileUpload',\n        onSubmit: function (id, fileName)\n        {\n            if(totalFiles < 10)\n            {\n                totalFiles += 1;\n            } else {\n                alert(\"You can only upload a maximum of 10 files at a time.\");\n                return false;\n            }\n        },\n        onCancel: function (id, fileName)\n        {\n            totalFiles -= 1;\n        },\n        onError: function (id, fileName, xhr)\n        {\n            totalFiles -= 1;\n        }\n    });\n}\nwindow.onload = createUploader;\n``\n.... file has the spinner icon next to it forever, even though the upload has completed.`\nThat\u00b4s exactly what I\u00b4m seeing, but it only ever happens on the fourth file (and onwards), I suspect because maxConnections is set to 3. I\u00b4ll test it with another setting and post the results in a minute.\nAnother thing I\u00b4ve noticed is that uploads seem to be competing for a server response. When i upload 3 files, 2 large and 1 small (and in that exact order), file 1 (large) gets uploaded, when it completes file 3 (small) immedeately starts uploading. After that one of the following things happens, either the upload for file 3 completes and file 2 starts uploading OR file 3 pauses uploading halfway, file 2 starts uploading and file 3 resumes only when file 2's upload is complete. Strange?\n. I'd be happy to test but unfortunately I cannot find earlier versions of the fileuploader on this site :(. And ofcourse this is the one time i forgot to make a back-up before upgrading.....\nCould you point me to the right page? Thanks\n. Tested the same configuration as my first post with maxConnections set to 1 and this time only 1 upload was handled, the rest \"stalled\".\nTested on Cassini local server, my IIS7 remote server is having some problems with a stubborn proxy atm :(.\nWill test with the older version momentarily.\n. A little more detail on that last test: \nI've set maxConnections at 1. Queued 4 files.\nIn fiddler i can see 1 request was sent, received and responded to, upload completed succesfully, onComplete was fired.\nImmedeately after the first upload the second request is made, it is also succesfully received and responded to, but the onComplete event does not fire.\nAfter that no more requests were sent (would expect two more).\n*Upon trying to leave the page, i do get 2 pop-ups warning me that active uploads will be cancelled.\nWill test the older version now, unfortunately this machine isn't as fast as I'd like...\n. Tested with the older version \"tree: 503611df18\".\nI've set maxConnections at 1. Queued 4 files.\nAll uploads were handled succesfully, all onComplete events fired.\nIn fiddler i can see 1 request was sent, received and responded to, upload completed succesfully, onComplete was fired.\nimmedeately after that the second request is sent and does the same thing, and likewise for the the third and fourth. Works like a charm!\n. Yup, that must be it.\nNow I could use the older version, but I'll bet that commit is useful (improvement in garbage collection?). Let's see if we can't fix this bugger :).\nIn any case, thanks for the help and the quick reply!\n. Works like a charm in IE8, I'll do some more extensive testing to see if there are no new problems.\n. Im still working on it at the moment but all tests have been succesful so far.\nTested in:\nIE 8 (8.0.6001.18702)\nFF 15.0\nChrome 21.0.1180.83 m\nSafari 5.1.7 (7534.57.2)\nOpera 12.01 (1532)  (i do get POST timeout alerts when uploading big files but I've read that that can't be helped. uploading works fine though.)\n. Well the only other thing I can test at the moment is older versions of IE (using IEtester) and perhaps IE9. Another 30 minutes or so and I think I should be done.\n. IE 5.5, my whole site crashes and the uploader doesn't work either (no big surprise)\nIE 6, a few small visual things are off but it seems to work! I am getting a \"failed\" response from the server, but the uploader itself seems to be working. I could dig into this further if you think its necessary.\nIE 7, working fine.\nCan't test any newer versions with IEtester unfortunately, so that'll have to be it for now.\n- I am using some custom css with this so I can't judge the styles at the moment, but style is not what we're testing here (right?). I'm actually working on some improvements for the standard css at the moment, will do some more testing on that before I submit it.\n. Sounds like a good approach to me, I'll do some more tweaking and testing in the mean time (extra drop zones, FileUploaderBasic). I can make a new fork with clean commits when the time comes, just give me a holler when you're ready.\nI'll just work in this fork for now, see if I can't get the hang of GitHub...\n. Hey there, im still around but i'm busy reformatting and reinstalling my pc a.t.m. (have been for a few days, things were seriously FUBAR)\nI can look into this in the weekend and merge and test the css with the newest version of uploader.js. So I'll update the css to work with the new progress bar. The only problem that remains is the \"icon mode\" I made which I believe uses the Regex you mentioned. If you don't mind I'll leave that line of RegEx to you, replace it however you like, all I need to be sure of is that the html looks the same. All that RegEx does is add a class I believe.\nDate: Fri, 28 Sep 2012 06:21:07 -0700\nFrom: notifications@github.com\nTo: file-uploader@noreply.github.com\nCC: rik@dev.tetra.nl\nSubject: Re: [file-uploader] Some visual changes. Tested in nearly all browsers. (#302)\n@Rik4444 It's going to take a little work to merge this in manually due to the age of this pull request. Unless you're still around to resolve the conflicts, I'll have to push this into 2.2. But, honestly, this may end up being pushed into 3.0 as I don't want to make too many big changes while I'm working on 3.0 to make syncing my work in 3.0 w/ changes in 2.x less nightmarish. \nI took a peek at your changes. The css changes look benign enough, but some of the js-related changes may need to be eliminated/updated. For example, the I made some changes to the progress-bar in case #327. Also, modifying the template option using regex seems like something we shouldn't be doing. \n\u2014\nReply to this email directly or view it on GitHub.                      \n. or just tell me how you'd like the RegEx replaced and I'll do fileuploader.js too.\n. slight delay, expect to be finished tonight.\n. ",
    "Vijaya2006": "where i have to define above code in script\n",
    "SMGaz": "I had the same problem when dragging a file onto Chrome, but not into the drop area then releasing the mouse. The line:\nvar relatedTarget = document.elementFromPoint(e.clientX, e.clientY);\nWas referencing point (0, 0) in Chrome - Firefox was referencing (0, -89) and coming up as null.\nChrome, however, was looking at the form element. So it might be safest to add \"FORM\" to Dysko's list\nif (!relatedTarget || relatedTarget.nodeName == \"HTML\" || relatedTarget.nodeName == \"BODY\" || relatedTarget.nodeName == \"FORM\")\n. ",
    "jeremyharris": "I think that's a fair assumption. The author doesn't seem very active on Github and definitely isn't expressing an interest in maintaining this project. It would be nice to see the official repo transferred to one of the many active fork authors, or at least add them as a contributor to the main project.\nI haven't taken the time to go through all the forks yet but if anyone has suggestions I'd love to hear them.\n. ",
    "josteinaj": "I'm also worried about this. I'm going to add upload-functionality to a site I'm building now; should I use a fork instead? If so; what are the most popular ones?\n. ",
    "ioleo": "+1 josteinaj \nI'd also like to hear from some of still active contributors - should I use master branch or some fork? If so, which one?\n. ",
    "andreymaz": "BTW, please find the fix below.\n1. Find _getIframeContentJSON method\n2. Insert the following code after this.log(\"innerHTML = \" + doc.body.innerHTML);\n/**\n    * nopCommerce custom code (fix). \n    * doc.body.innerHTML sometimes is wrapped in <PRE> tags for some reasons.\n    * That's wrong. We have to remove it before processing JSON\n    */\n    var iframeinnerHTML = doc.body.innerHTML;\n    if (iframeinnerHTML.toLowerCase().indexOf('<pre>') == 0) {\n        iframeinnerHTML = iframeinnerHTML.substring('<pre>'.length);\n    }\n    if (iframeinnerHTML.toLowerCase().lastIndexOf('</pre>') == iframeinnerHTML.length - '</pre>'.length) {\n        iframeinnerHTML = iframeinnerHTML.substring(0, iframeinnerHTML.length - '</pre>'.length);\n    }\n1. Replace\n   response = eval(\"(\" + doc.body.innerHTML + \")\");\n   with \n   response = eval(\"(\" + iframeinnerHTML + \")\");\n. ",
    "beeksiwaais": "I think that you miss the CSS file. By default, 'Failed' is displayed. The JS script adds a class when the upload was aborted or failed.\n. I think your problem is not related to PHP. Try to get the JSON response returned by the script.\n. ",
    "krasatos": "i haven't figured out exactly how the failed message appears but, still... \nwhy would adding an mkdir line inside the php.php file screw the whole thing up??\nthanx in advance :)\n. changed that... images get uploaded but still getting failed next to each filename :S\n. finally figured it out, mkdir's error message (when dir existed) was messing up my success responce.\nchanged it to \nif (!file_exists($uploaddir)) {\n    mkdir($uploaddir);\n}\nand it seems to work, will test and report back\n. finally figured it out, mkdir's error message (when dir existed) was messing up my success responce.\nchanged it to \nif (!file_exists($uploaddir)) {\n    mkdir($uploaddir);\n}\nand it seems to work, will test and report back\n. finally figured it out, mkdir's error message (when dir existed) was messing up my success responce.\nchanged it to \nif (!file_exists($uploaddir)) {\n    mkdir($uploaddir);\n}\nand it seems to work, will test and report back\n. finally figured it out, mkdir's error message (when dir existed) was messing up my success responce.\nchanged it to \nif (!file_exists($uploaddir)) {\n    mkdir($uploaddir);\n}\nand it seems to work, will test and report back\n. finally figured it out, mkdir's error message (when dir existed) was messing up my success responce.\nchanged it to \nif (!file_exists($uploaddir)) {\n    mkdir($uploaddir);\n}\nand it seems to work, will test and report back\n. ",
    "Posthamster": "I replaced in php.php\n\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\n\nwith\n\nif(isset($result[\"success\"])) echo \"{success:true}\";\nelse echo \"{error:'{$result[\"error\"]}'}\";\n\n. ",
    "weecka": "I don't know if this is really what you need, but here is how you can get the file name:\nOn PHP code, at the end of handleUpload function add second element to the returning array:\nphp\n return array('success'=>true, 'filename'=>$filename);\nAfter this, you can get the file name value in your onComplete statement as provided in your example code:\njavascript\n onComplete: function(id, fileName, responseJSON){\n         $j('#status' + x).append(' ' + responseJSON.filename + ' Uploaded!<br />');\n         alert(responseJSON.filename);\n}\n. Hm, ok, I may be wrong, but there is no option in FileUploader class like dataType.\nAnd I think, you are getting \"undefined\" because of $j('#status' + x). Shouldn't this be $('#status' + x)?\n. Oh, I see then. Can you see \"success:true\" message in debug mode after the file upload? Maybe something fails and the file isn't uploaded on server at all?\n. ",
    "mcconnellwade": "weecka, thanks a ton for the response! My code does look like that ^ now but I'm still getting \"undefined\" when I try to alert the filename in the oncomplete function.\nAny ideas?\n. Well, I have a jQuery conflict with the $ symbol, so I'm using noConflict with $j for my jQuery code. I removed the dataType option as well. No luck...\n. Here's the thing: the file seems to upload to the server, but I'm not seeing anything in debug mode.... but when I had an error I WAS getting an error as the response... So strange.\n. Update: no matter what I make the PHP file return, I get \"undefined\" on the frontend... This makes me think there's something wrong with the JS file that processes everything.\nAnd to clarify what I said in the last comment: I was getting an error for server related issues (php.ini stuff) but as soon as I started dealing with uploads... nothing :/\n. ",
    "rubenv": "This has been closed? Is this merged somewhere?\nIf not, care to explain why it was closed?\n. ",
    "Gildus": "Hello @intelligence , you can make for example:\nonComplete: function(id, fileName, responseJSON){\n    console.log(\"make something and not show the result...\");\n}\nAnd disabled the parameter debug to false.\nRegards.\n. You can to try:\n``` php\nfunction getSize() \n{\n    if (isset($_SERVER[\"CONTENT_LENGTH\"]) || isset($_SERVER['HTTP_CONTENT_LENGTH'])){\n        if(isset($_SERVER['HTTP_CONTENT_LENGTH']))\n            return (int)$_SERVER[\"HTTP_CONTENT_LENGTH\"];\n        else\n            return (int)$_SERVER[\"CONTENT_LENGTH\"];\n    } else {\n        throw new Exception('Getting content length is not supported.');\n    }\n}\n```\n. You can try to edit the $sizeLimit:\n``` php\n...\n$sizeLimit = 10 * 1024 * 1024;\nrequire('valums-file-uploader/server/php.php');\n$uploader = new qqFileUploader($allowedExtensions, $sizeLimit);\n....\n```\nFor example with:\nphp\n$sizeLimit = 2 * 1024 * 1024;\n. ",
    "meeDamian": "Milestones\nI'm totally there with you. First thing should be making everything working and establishing testing environment. Then, I'd suggest clearing up and fixing style of code. Then, adding comments to lines specific to browsers/OS's, so they won't get deleted by anyone in the future. Those kind of comments are most important, because not everyone submitting patches will be aware of hacks used in code. Rest seems OK, but some development directions should be established before starting with 2.0 . \nCoding Rules\nWell, you're the boss now & any rules are better than no rules. I, personally don't know about JSLint, but it's not useless to learn usefull stuff ;)\nPull Requests\nAre you going to look trough maintained forks too?\nDoc's\nDo you mean like demo with checkboxes, and init code automatically generated based on user setting in this demo? If so, I think there should be advanced documentation also. With every parameter, it's possible states, and parameters explained.\nMisc.\nWhy not here? Keeping things in one place seems logical & you can respond to github from email too.\n. ",
    "daggmano": "Sorry, not sure why Git has decided to change the whole file. The only line changed was at line 1302.\n. Never mind - someone else already has it...\n. ",
    "dtucke": "I can not upload images in IE is this fixed?\n. ",
    "breucker": "Hi, \nI had the same problem ( with the last v2.* from yesterday) with files > 140MB.\nI tried to do this two steps\n1- put forceMultipart: true option when declaring the fineUploader object in client\n2- comment out the following lines in php server side script :\n  if ($realSize != $this->getSize()){\n            return false;\n}\nI have tested it locally and  remotely, with chrome and firefox. So this is indeed a problem with $_SERVER \"CONTENT_LENGTH\" (I have also tried with HTTP_CONTENT_LENGTH)\nI don't get the error (obvioulsy) but the uploaded file is empty...\n. Nevermind, I didn't understood that with forceMultipart I had to use \"move_uploaded_files\" instead of stream copy. So it works now :)\n. ",
    "tommck": "IT's too early, because sometimes we need users to give more information about the file after they selected it, like a file description and or a type (not extension-like type, but what business purpose does this file serve)\n. ",
    "artissant": "javascript\nvar upload = new qq.FileUploader({\n    element:    $avatar[0],\n    action:     url,\n    multiple:   false,\n    debug:      true,\n    onComplete: function(id, filename, response) {\n        console.log(response);\n    }\n});\n. Hah, sadly I don't know how to do a stack trace. On the plus side the first selected file is still uploaded properly, and the others get ignored.\n. Actually, they do all get sent, sorry about that..\n. Yeah everything's fine with the dialog, no worries man\n. Sounds good to me; the only real problem at the moment is that all files get sent to the server (as you kindly pointed out!) so preventing that is perfect.\n. ",
    "NebuPookins": "Well, according to the JSON spec, \"{success: true}\" is not legal JSON. It may be legal JavaScript, which is why it'll get parsed by eval(), but JSON is a (very small) subset of JavaScript and is stricter about these things.\nIMHO the ideal solution would be to educate people who are having their server return \"{success: true}\" about the JSON spec and how that string is not valid JSON. A second possibility would be to first try parsing using JSON.parse, and then if that fails, falls back to eval, but that again raises the security issues inherent with eval(). Perhaps a flag could be added to let the user choose between these two possibilities?\n. ",
    "sacher74": "Have the same problem here.\nI have a dropdown list which value I need to pass to the server. If user changes selection in the dropdown after selecting files, the first file in the queue doesn't take the correct parameter value like other files do.\n. This is the complete code of the createUploader function. The parameter taken from the dropdown is \"swhouse\"\nIn the onUpload event I set the same parameters set in the \"params\" option.\nLet's say after page load the dropdown has a value of 1, and after selecting files in the uploader I select the element with value 2: first upload posts swhouse parameter set to 1, next uploads post it set to 2\nIf I omit the the \"params\" option, first upload posts no parameters\nHere is the code:  \njavascript\nfunction createUploader(uploaderId, index, cod_richiesta, cod_modello, esercizio_modello, allowedExt, acceptedMIME) {\n        $fileCount.push(0);\n        var uploader = new qq.FileUploader({\n            element: document.getElementById(uploaderId),\n            action: 'UploadController.ashx',\n            debug: false,\n            params: { richiesta: cod_richiesta,\n                      cliente: '<%=ClienteGesint.Codice%>',\n                      modello: cod_modello,\n                      esercizio: esercizio_modello,\n                      accept: acceptedMIME.join(),\n                      swhouse: $(\"#<%=SwHouse.ClientID%>\").val() },\n            allowedExtension: allowedExt,\n            acceptFiles: acceptedMIME,\n            sizeLimit: 10485760,    // Verificare anche il valore di httpRuntime maxRequestLength in web.config\n            maxConnections: 2,\n            uploadButtonText: 'Seleziona',\n            cancelButtonText: 'Annulla',\n            failUploadText: 'Invio fallito',\n            autoUpload: false,\n            onSubmit: function (id, filename) {\n                $fileExt = filename.substring(filename.length - 3).toLowerCase();\n                if ($.inArray($fileExt, allowedExt) > -1) {\n                    $fileCount[index]++;\n                    return true;\n                } else {\n                    alert(\"Attenzione !\\nTipo file non valido.\");\n                    return false;\n                }\n            },\n            onCancel: function (id, filename) {\n                $fileCount[index]--;\n                if ($uploadInProgress) {\n                    if ($fileCount[index] == 0) {\n                        $currentUploader++;\n                        triggerCurrentUploader();\n                    }\n                }\n            },\n            onComplete: function (id, filename) {\n                $fileCount[index]--;\n                if ($fileCount[index] == 0) {\n                    $currentUploader++;\n                    triggerCurrentUploader();\n                }\n            },\n            onUpload: function (id, filename) {\n                uploader.setParams({\n                    richiesta: cod_richiesta,\n                    cliente: '<%=ClienteGesint.Codice%>',\n                    modello: cod_modello,\n                    esercizio: esercizio_modello,\n                    accept: acceptedMIME.join(),\n                    swhouse: $(\"#<%=SwHouse.ClientID%>\").val() \n                })\n            },\n            // messages                \n            messages: {\n                sizeError: \"La dimensione massima consentita dei file \u00e8 {sizeLimit}.\"\n            },\n            showMessage: function (message) {\n                alert('Attenzione !\\n' + message);\n            }\n        });\n        return uploader;\n    }\n. Setting parameters before calling uploadSotredFiles it works fine. Thank you very much\n. I also need this option. Waiting for 3.2\n. Thank you, Ray. So I think it isn't also possible server-side...\n. ",
    "towerhe": "javascript\nonComplete: function() {\n   // uploader is an instance of qq.FileUploader\n   if(uploader.getInProgress() == 0) {\n     // Do Something\n   }\n}\n. I don't know why i should do a double check here. if i leave it,\nthis._storedFileIds.indexOf(id) will throw an exception.\nOn Wed, Sep 12, 2012 at 9:35 PM, Ray Nicholus notifications@github.comwrote:\n\nWhy do we need this check again? If _storedFileIds is empty, indexOf will\nreturn -1, which is already accounted for.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/322#issuecomment-8493563.\n\n\nTower He\n. ",
    "rentalhost": "Exactly! Great!\n. Suggestion: continue the \"branch\" discussion is this topic: #326\n. I agree totally with you. But I had understood that will have two versions (pure and jQuery). If you will develop only jQuery, I think that is better! I'm a jQuery user too and I think too great you develop for it.\nThere are some pure-js upload libraries on internet, so users will have two option: use it or use 2.x version (with fewer features).\n. Perfectly!\n. Maybe my first suggestion be a good thing. Create a pure-js (core) version and a jQuery bind. User can choice between both versions. jQuery only will use the core, instead of define structures.\njQuery.fn.FileUpload = function() {\n  return new FileUpload();\n}\nAll events need be similar to jQuery, like FileUpload.on('eventName', callback).\n. Yeah, basically. The difference is that your project will be compatible with pure-js and jquery users. You don't will have too much difficulty. Basically you need to work with four files, like I suggest before.\n1. core: will contains all core (FileUpload class, for instance);\n2. helper: will contains all helpers, need to core;\n3. shared: will contains all helpers that is not found in jQuery, need to core;\n4. jquery-wrapper: will contains all helpers (of jQuery, obvious) and the jQuery wrapper;\nSo, when you build, you will have only two files:\n1. pure version: core + helper + shared;\n2. jquery version: core + shared + jquery-wrapper;\nAnother advantage is: you can create more wrappers (to prototype, for instance):\n1. prototype version: core + helper + shared + prototype-wrapper -- note the helper, it'll be need to wrapper, once that you only will accept jquery-helpers. It'll turn development easy;\nSo, the helper will be used if jQuery doesn't exists. You need only replicate jQuery task (in simplied form) if it is really need. For instance: if you need jQuery.ajax, you need create your own jQuery.ajax, but simplified (only with the features that you really will use). Yeah! It's the complicated part!\nThe shared file will be used to declare functions that is not found with pure js or in jQuery helpers, like... hum... Shared.fileChunker(file, size), for instance.\n. Well... Let consider that exists a lot of jQuery, Prototype, MooTools, ... If user prefer use Prototype, they need search a Prototype compatible. Same to jQuery.\nIf you are a jQuery developer, I think that you need create it only for jQuery. You don't will rebuild the wheel, just will make it like you think. Just not abandon the project. Follow your ideas to not abandon it by disinterest. I abandoned some projects because I think in all people of the world, and not only in a specific group of peoples (including me).\nUsers that work with pure-js can have two motives: 1. is a starter and probably not will work with uploads. 2. don't know frameworks. Hard users/real developers prefer jQuery, Prototype or MooTools (etc), so it need search a library for your work.\nSo, my final opinion: make it for jQuery!\n. ",
    "walterdavis": "Would this mean dropping library-agnostic support and moving whole-cloth to jQuery? Because I would consider that to be a bug...\n. This is a very neat solution. I like it a lot!\n. But if you rewrite the core to depend on jQuery, you make it nearly impossible to use in a non-jQuery environment. Believe it or not, those do exist. \nIt's not about the file size of jQuery + FU3 vs file size of a monolithic FU3 that we're concerned with here either. It's a need to make elements that are library-agnostic so they can cooperate with whatever existing code-base they find themselves in. \nI completely understand the argument to incorporate a library -- to spackle over all the many divots in the various JS implementations on browsers and operating systems and major and minor versions of same. That's a noble thing that the librarians do for us -- I get that. \nBut not everybody gets to choose their library, and not every application that could benefit from this uploader will be compatible with jQuery.\nWalter\nOn Sep 20, 2012, at 5:05 PM, Ray Nicholus wrote:\n\n@david-proweb If I am going to re-write the app using jQuery, the most benefit is received from rewriting core using jQuery. If the majority of users vote to not go the jQuery route in the poll, I may consider your idea, but, even without a wrapper, it is trivial for non-jQuery users to integrate Fine Uploader into their application. I am actually doing this now with several of the projects I am working on. I'm just not sure it's worth the trouble to write wrappers.\n\u2014\nReply to this email directly or view it on GitHub.\n. I think I've made my point, but I want to refine one bit of it: visit MicroJS.com to see a growing number of specialized JS libraries that don't rely on any monolithic framework. By cherry-picking individual bits, you can build up just the behavior you need for your application -- often with a smaller total footprint than just jQuery itself. This is incredibly important for mobile devices with limited memory.\n\nIt is so unique and rare to see a refined uploader like yours that doesn't rely on a framework. This makes it work for everyone, not just those who pick the same library as you. \nI've had to include both jQuery and another framework into the same application, and I only did so because it was in the admin console, and I could guarantee nobody was going to use a phone to edit the intranet documents. I would never want to be forced into choosing a framework -- often that choice has already been made before I get the project.\nWalter\nOn Sep 24, 2012, at 2:26 AM, tvernum wrote:\n\nI voted against, because we use FineUploader with GWT.\nIt took some work to get it integrated into GWT, and I don't think I would be in a position to do that again with a jQuery-ised version.\nIf 3.0 becomes tied to jQuery, then we'll need to stick with 2.x or fork it.\n\u2014\nReply to this email directly or view it on GitHub.\n. Die() prints directly to the output stream whatever argument you pass it, and then kills the interpreter. It's precisely the same as doing it in two lines:\n\nprint \"some string\";\nexit;\nWalter\nOn Oct 13, 2012, at 12:57 PM, Ray Nicholus wrote:\n\nI'm not exactly sure what die does with the text passed to it. Apparently, using this does not output a proper JSON response. Your underlying problem is not the response though. It is the message contained in the error that you should pay attention to.\n\u2014\nReply to this email directly or view it on GitHub.\n. Die won't send the proper header, maybe? Look at the response in Firebug, and look carefully at the headers it is sending. \n\nI don't know the specifics of the receiving side here, but in Prototype, it's not enough for JSON to be properly formed text-wise, it also has to come under the proper header (application/javascript or application/json) rather than text/plain or text/html (PHP's default, either one of those). \nI don't know what rules file-uploader follows for consuming JSON, but since I live and breathe in Prototype, that was my first guess about what could possibly be going wrong.\nWalter\nOn Oct 13, 2012, at 1:09 PM, Ray Nicholus wrote:\n\n@walterdavis Can you tell me why die is not returning proper JSON, while the array function apparently is? I'm not very familiar with PHP.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "suncat2000": "Thanks!\n. ",
    "emanwebdev": "there are numerous jQuery uploaders available\nwhile...\nyour pure-js is the only one! Keep the good work and uniqueness of your solution!!!\n. Moving to jQuery? so you are heading to a clone of the http://blueimp.github.com/jQuery-File-Upload/ ? \nor similar to its basic plugin version (https://github.com/blueimp/jQuery-File-Upload/wiki/Basic-plugin)\nWhy to re-do what already exists?\nWhat about solutions that don't want to rely on the fat jQuery?\n. Moving to jQuery? so you are heading to a clone of the http://blueimp.github.com/jQuery-File-Upload/ ? \nor similar to its basic plugin version (https://github.com/blueimp/jQuery-File-Upload/wiki/Basic-plugin)\nWhy to re-do what already exists?\nWhat about solutions that don't want to rely on the fat jQuery?\n. > Just because the uploader is written in jQuery, does not mean that it must be a clone of some other uploader also written in jQuery. \n\nI don't plan on cloning anything. \n\nooops, sorry for having used the word clone  Take it easy. Just my poor english :)\n\nAlso, as I have already noted in this case, the non-jquery version will still exist, but it will eventually be in a bugfix-only mode.\n\nRight, I've read that in the meantime. Ok then. Great!  MANY Thanks coz good pure-js uploaders are v. seldom!\n\nWhy are you opposed to including jQuery in your source code? The minified version is 93 KB and this file can be cached more easily if we rely on a CDN.\n\nCoz some projects come WITHOUT jQuery. External  specs aso.\n. > So, my final opinion: make it for jQuery!\n... but you wrote too:\n\nYou don't will rebuild the wheel \n\nand jQ uploaders are already here, \nso why spend energy & time to rebuild the wheel instead of improving this brilliant pure-js uploader????\n. > It is so unique and rare to see a refined uploader like yours that doesn't rely on a framework\n+1\nP.S.\n\nMicroJS.com\n\nFantastic! THANKS!!!\n++ see http://headjs.com/\n. ",
    "h3": "Maybe I'm missing some things, but here's what I'd do.\n1. Core js uploader becomes a low level API\n2. A native js uploader client which extends the core can be created\n3. A jQuery (or any other framework) js uploader client can be created\nAs far as I'm concerned, the jQuery (Prototype or whatever) wrapper can even be an external project. And it probably should. It doesn't matter if  the wrappers features are not harmonized. The only thing important is that they don't alter the low level API.\nAnd yes jQuery is popular and everyone loves it (including me). But technology moves fast and even the most popular technologies are eventually supplanted. Native JS is not going away any time soon. For this simple reason, you should not tie the core to a specific framework.\nAnd of course jQuery (or any other JS framework) could ease the maintenance of this project and slim down its code base a lot. But overall, the benefits ends there. And there is still a maintenance cost to use a framework, because frameworks API change a lot more than native JS.\nTL;DR: Frameworks should use your code, not the other way around.\nMy 2\u00a2\n. ",
    "cleer73": "@rnicholus I think you are missing the point about keeping the upload library as stand alone product. My problem is having this code base tied to some other code base, that your project has no control over. Also, I HATE jQuery UI, it is a bloated pile of crap, which is sad since jQuery itself is amazing. But that's all fine, I can just fork it for myself.\nGood luck.\n. I may have picked that up from someone else's comment, sorry about that.\n. @rnicholus I agree, and that is why I revised it, I realized it was snarky and inappropriate. I am sorry for that, very.\nI appreciate that this is a spare time project for you. I hope that you make the very best decisions for you self and the project. And while satisfying everyone is a noble goal, it's really almost impossible.\nThat said, have you considered using Sizzle.js to stop maintaining your own DOM functions (I am guessing this is why the jQuery move is on the table). I believe this is what the jQuery project uses for there own CSS selections, and I am pretty sure it was started by John Resig to solve a problem of his own.\nhttp://sizzlejs.com/\n. I would say that if you are going to make jQuery a dependency, you might as well make it a plugin for jQuery. Unless of course you could not meet your personal design goals while implementing Fine Uploader as a plugin.\nAnother option I thought of, to stop having to maintain all those nice utils, would be to try to roll in Sizzle.js and Underscore.js (I think this would cover all the other needs you listed). In my mind rolling sizzle and underscore into your code base could be a real pain in the ass, over time. \nTo me, this decision comes down to respecting your time and availability. And if you are going to be the only maintainer then I would go with it as a jQuery plugin. Those of us who dislike having external dependencies can always fork this project (which I have already done) to make sure they have what they like.\nAnother option would be to start allowing more devs to get involved to ease the work load, taking more of code reviewer role. But this is based on my perception, not fact, that you are not accepting a whole lot of pull requests. So feel free to correct me on this point.\n. So far as the management goes, those are your choices, it was not ment as a criticism. It was just my impression of your stance on the management, I am sorry I offended you. As I seem to have made a total jack ass of myself on this thread I will drop all other points, and respond to your very last statement:\nFor my work, I actually use jQuery, so it's not so much that I would have to include jQuery in my projects to continue using your uploader. It's that if I ever decided to move on from jQuery, for whatever reason in the future, I would have to drop your codebase and find another, with comparable features. It just gives me more flexibility in future projects, and I think it gives you a broader audience base in the long run.\n. ",
    "tvernum": "I voted against, because we use FineUploader with GWT.\nIt took some work to get it integrated into GWT, and I don't think I would be in a position to do that again with a jQuery-ised version.\nIf 3.0 becomes tied to jQuery, then we'll need to stick with 2.x or fork it.\n. ",
    "bhumphries": "I guess it does not need to be a parameter... in my usage I was grabbing the \nfilename as a parameter via the Xhr method when running on Chrome or Firefox and \njust found I was not getting the parameter when using IE. In addition to that \nwas having trouble figuring out how to grab the file name from the request \nheaders in my PERL script (probably just lack of knowledge on my side) so found \nit was easier to get the parameter added to the form post.\n\nFrom: Ray Nicholus notifications@github.com\nTo: valums/file-uploader file-uploader@noreply.github.com\nCc: bhumphries benhumphries@att.net\nSent: Fri, September 14, 2012 6:21:29 AM\nSubject: Re: [file-uploader] Uploading using form submission to iframe is not \nadding the original filename as a query parameter (#331)\nI suppose adding this wouldn't hurt, but it really is not necessary at all.  The \nfilename is included in the request.  Is there some reason it needs to be a \nparameter as well?\n\u2014\nReply to this email directly or view it on GitHub.\n. ",
    "AnatomicJC": "Thanks for your work ;-)\n. ",
    "beatep": "Sorry :) It happens on Upload.\n. Sorry, i don't know if it has existed since a while. I had seen this project the first time two weeks ago, and I didn't test it in IE at once.\n. I think you can close it. I use multiple IEs (http://tredosoft.com/Multiple_IE) and sometimes they are a bit buggy.\n. ",
    "simonwalsh": "hey rnicholous, did you find a fix for the text on the button not being visible in IE7 ?\n. ",
    "eugentorica": "\nI think my bad.\nIn case listElement is provided ul element will remain in template thus introducing large empty space bellow the upload button.\n. I was going to ask about it because I've already committed changes but I'm new to github social coding so I wondered if I need to make Pull request again with updated changes.\n\nFor me any option that allows internalization would work. Of course if it is possible and doesn't break many things I would ask you to move all messages in a single object. Let's suppose all texts will be contained in this._options.message (or any other object). This would simplify object construction. Particularly I was talking about texts:\nuploadButtonText: 'Upload a file',\n cancelButtonText: 'Cancel',\n failUploadText: 'Upload failed',\nin FileUploader function.\n. Thank you.\nStill in case of major rewrite (I saw one that is based on jquery) is planned I think it would be great to have all messages in single javscript object that is sent as parameter in constructor. This would make construction of FileUploader object simpler from server side programming side. Now for example I have to create multiple JSON objects with messages (messages and extraMessages) instead of serializing all texts in a single object.\nPlease take this comment as one that comes from novice javascript developer :) and of course I'm sure I must be missing some important details here.\n. ",
    "Denominator": "The bug is that in case of Iframe (regular form based) upload, file name parameter is added as GET parameter although it is already included as POST parameter in POST body and leads to such confusing situations like this one.\n. I understand now.\nFirst of all please remember that I'm only trying to help here!\nSo, I will quote you :)\n\"I suppose adding this wouldn't hurt, but it really is not necessary at all. The filename is included in the request. Is there some reason it needs to be a parameter as well?\"\nThe next thing is that this suggestion was clearly from a rather unexperienced developer who added this because she/he didn't know how to get filename parameter from POST. I don't know if it is the reason to modify not trivial (and very helpful) library (especially by such developer - nothing personal!).\nThird, most important thing is that in release 2.1 uploader is not working with PHP because of that modification. I've spent more than hour trying to find out what's going on. \nFrom perspective of someone writing server-side code for uploader I think it is reasonable to treat filename in GET parameters as property exclusive for ajax upload. I think this way only because in my opinion it can be more reliable than to rely on PHP ways of testing whether it is standard form upload or not.\nI don't know - what do you think?\n. Of course I agree with you. Content type should be used for determination. \nOnly I think it is going to be hell in PHP. And one should consider Internet Explorer's tendency to do funny things with content types. Anyway still it is the problem of PHP and IE - not uploader itself.\nAbout user parameters - please notice that one will be probably using GET or POST parameters for that - not duplicating them everywhere as this is analogical example. Anyway still it is legal - why not?\nWhat I mean is it is perfectly correct thing to do, obviously.\nIt just confused me and confused someone who wrote PHP script (as we can see) and will bring other consequences as people started to rely on those parameters in GET even if it is POST. \nJust from the top of my head - I understand that if multiple files are uploaded all their names will appear in URL and in body of POST. \nWe all know about limitations on length of URL and that if it is too long it is simply clipped by server or browser without any warning. It leads to very unpleasant bugs, especially when support for uploading whole folders of files will become more popular.\nMy point is that the fact that something is possible doesn't mean it is the right thing to do. \nSorry about not noticing that 2.1 is not released. About making change in master - I started using github today to add this issue :) and I always used svn, so I simply don't know yet how to do that, but I will try tomorrow.\n. I will read github docs and open pull up request - just didn't have enough time today.\n. Update.\nGenerally it is continued explanation why this plugin didn't work for me with ie9 and PHP (using script provided with plugin) and how to make it work.\nFirst of all I return html in json response after upload - shouldn't make any difference, but just saying.\nAs a side note, using suggestion (from included in plugin php server-side script):\n// to pass data through iframe you will need to encode all html tags\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\nwas not very helpful in this case. So I didn't use it - just used:\necho json_encode(..);\nSecond of all I consider here ie9 working in \"Browser Mode: IE9\" and \"Document Mode: IE9 standard\" (press F12 to start developer tools and look at the top right corner of it to check your mode).\nI don't even have time to read about all this stupid compatibility and quirks modes mambo jambo from Microsoft. Just gave it up!\nI use html5 doctype: \"<!DOCTYPE html>\" which puts IE9 in desired modes (at least in my case).\nNow you have to watch out! \nIe9 has some stupid setting turned on by default that show sites from intranet in compatibility mode (whatever that is).\nIt is in menu called \"compatibility modes settings\" or something like that - I'm using non-english version.\nHave a look here: http://www.sevenforums.com/tutorials/1196-internet-explorer-compatibility-view-turn-off.html .\nIt is worth to read it and check out menu of those settings in your particular ie9. Please give a second to the setting turning on compatibility mode for all intranet sites(!) but also skim through others just to be safe.\nThis setting impacts developers greatly as a lot of us develop using some server in LAN (don't sure if it impacts local development). Anyway I turned it off everywhere in this menu.\nNow back to our ajax upload plugin:\nIe9 is scenario with Iframe (not XHR).\nYou upload a file and you get json response.\nJson is stored in Iframe (innerHTML).\nThen json is parsed (using eval()).\nIn ie9 parsing of this json failed for me. Parse exception was thrown, then catched and json {success: false} was returned instead of my json.\nThe reason for failure during parsing json is content-type header of response from PHP script.\nI use example PHP (php.php) script where there is no setting of content-type header. As a result in my situation text/html was returned (default? content-type of page that is owner of Iframe?).\nNow I'm pretty sure eveything worked ok in the past, but Microsoft made some updates to mime types hanlding by ie. \nResults?\nWhen ie got response which was json with content-type text/html and put it into Iframe as innerHTML, this innerHTML didn't look like the content (json) I responded from PHP. \nSome modifications were made by ie9 (closed json object earlier etc. - strange things). Anyway this modifications introduced by ie9 made syntax errors in json which resulted in parse exception later.\nGenerally ie9 destroyed my json in my opinion.\nContent-type text/html with json as content was no-no for me.\nSo I changed content-type to application/json. But (after some time of course..) I realized ie9 doesn't know application/json content-type(!).\nHave a look here http://msdn.microsoft.com/en-us/library/ms775147(v=vs.85).aspx#Known_MimeTypes .\nAs ie9 doesn't know application/json content-type it prompted to open/save response from PHP as a separated file(!).\nI tried content-type text/plain and it worked. \nI think this content-type prevents ie9 from trying to open/save response as file or doing some kind of black magic over the response (destroying it in my case).\nAlso content-type text/plain didn't broke anything in firefox or chrome (latest versions).\nPlease notice that you should include proper charset in all your content-type headers as I've read that it can open a whole cave of demons in ie if it is not there or is somehow invalid.\nExample content-type I use: \"text/plain; charset=UTF-8\"\nAlso please notice that I've seen some idea that if ie doesn't know provided content-type (like application/json) it can also try to use file extension (from url as far as I understand) but it was not my case and I don't think people use URLs like http:/....../upload.json to upload a file so I didn't care about it.\nSummary:\n- I used text/plain content-type for json response because it worked for me. Should it be a standard for this plugin and should it be commited -  I have no idea. It makes ajax upload in  ie9, and chrome and firefox work.\n- If above content-type is ok, setting of header should be included in php server-side script provided with this plugin\nI know it is long and complicated but I think it is because the problem is.\n. Are you sending html in your json response ?\n. Nope, wanted to finish my code for ie9 first for application i'm working on.\n. I use ie ver 9.0.8112..\n. I write application that is fully ajax-based for logged-in users.\nAfter upload I return json which has data as json properties and some htmls as json properties at the same time.\nI put html from those properties to different parts of application (like next list item in some list) and use for example json property 'successMsg' as string to display success notification to user.\n. I downloaded current ver from this github. In fileuploader.js :  VERSION 2.1-SNAPSHOT\n. Errors showed up on random basis - sometimes everything was OK, sometimes I have been getting whole series of access denied.\n. What version of ie9 do you use? Also can you please provide your service pack and windows version?\n. Looks the same as mine. Win 7 Home Premium, sp1. IE - same version.\n. Does your ie operate in standards or compatibility mode?\n. I don't have proof that the problem exists as I solved it by modifying source of iframe in source code. Anyway I had such problems, but simply didn't document it, so if proof is required - I don't have any.\n. ",
    "anitakfitz": "I am not sure where to find this example?\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Friday, September 21, 2012 11:28 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header (#343)\nThere, I've contributed an improved java example. I tested in briefly in Chrome and IE9. Any problems with it, please let me know.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8785149.\n. Ok, i followed your link in the message above, but I do not see any difference between this example and the version I have ?  the problem I have is that in IE9, the following line returns null for filename:\nString filename= request.getHeader(\"X-File-Name\");\nmy jsp code is as follows:\nvar uploader = new qq.FileUploader({\n                            // pass the dom node (ex. $(selector)[0] for jQuery users)\n                            element: document.getElementById('fileToUpload'),\n                            // path to server-side upload script\n                            action: streamUrl,\n                            debug: true,\n                            multiple: false,\n```\n                        // additional data to send, name-value pairs\n                        params: {\n                            lineId:\"1\"\n                        },\n                        // events\n                        // you can return false to abort submit\n                        onSubmit: function(id, fileName){\n                            //  alert(\"last file: \" + lastFile);\n                            if (lastFile != \"\") {\n                                // we could call something server side here to delete\n                                // the last file, but probably easier to delete on submit ...\n                            }\n                            $('.qq-upload-list').empty()\n                            // $('.qq-upload-list > li').remove();\n                            // disable submit button\n                                / //  $(\"#sData\").attr(\"disabled\", \"true\");\n                            $(\"#sData\").addClass(\"ui-state-disabled\");\n                        },\n                        onProgress: function(id, fileName, loaded, total){},\n                        onComplete: function(id, fileName, responseJSON){\n                            lastFile=fileName;\n                            // need to handle failure from server here\n                            //   alert(responseJSON.success);\n                            if (responseJSON.success == \"true\")\n                                $(\"#sData\").removeClass(\"ui-state-disabled\");\n                            // else\n                            //   alert(\"There was an error in accessing your file, please reselect the file and try again\");\n                        },\n                        onCancel: function(id, fileName){},\n                        messages: {\n                            // typeError: \"{file} has invalid extension. Only {extensions} are allowed.\",\n                            sizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\n                            minSizeError: \"{file} is too small, minimum file size is {minSizeLimit}.\",\n                            emptyError: \"{file} is empty, please select files again without it.\",\n                            onLeave: \"The files are being uploaded, if you leave now the upload will be cancelled.\"          \n                        },\n                        showMessage: function(message){\n                            alert(message);\n                        }     \n                });\n\n```\n. I am not sure I understand \u2026 I am using your octet stream reader class as my \u2018servlet\u2019 url being called from the jsp/html calling the file uploader, this works fine in firefox and chrome, but not in IE.  I have actually even modified your js to also include file size in the header, because I want to revalidate that the entire file has been saved.  Are you saying that this octet stream reader is NOT what I should be using to handle the url from the file uploader ?\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 10:28 AM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header (#343)\nThere is no such header sent with a multipart encoded request. Have a look\nat the servlet example in the server/java\nfolderhttps://github.com/valums/file-uploader/tree/master/server/javaif\nyour server-side language is java, which appears to be the case.\nOn Mon, Sep 24, 2012 at 9:16 AM, anitakfitz notifications@github.com<mailto:notifications@github.com>wrote:\n\nOk, i followed your link in the message above, but I do not see any\ndifference between this example and the version I have ? the problem I have\nis that in IE9, the following line returns null for filename:\nString filename= request.getHeader(\"X-File-Name\");\nmy jsp code is as follows:\nvar uploader = new qq.FileUploader({\n// pass the dom node (ex. $(selector)[0] for jQuery users)\nelement: document.getElementById('fileToUpload'),\n// path to server-side upload script\naction: streamUrl,\ndebug: true,\nmultiple: false,\n// additional data to send, name-value pairs\nparams: {\nlineId:\"1\"\n},\n// events\n// you can return false to abort submit\nonSubmit: function(id, fileName){\n// alert(\"last file: \" + lastFile);\nif (lastFile != \"\") {\n// we could call something server side here to delete\n// the last file, but probably easier to delete on submit ...\n}\n$('.qq-upload-list').empty()\n// $('.qq-upload-list > li').remove();\n// disable submit button\n/ // $(\"#sData\").attr(\"disabled\", \"true\");\n$(\"#sData\").addClass(\"ui-state-disabled\");\n},\nonProgress: function(id, fileName, loaded, total){},\nonComplete: function(id, fileName, responseJSON){\nlastFile=fileName;\n// need to handle failure from server here\n// alert(responseJSON.success);\nif (responseJSON.success == \"true\")\n$(\"#sData\").removeClass(\"ui-state-disabled\");\n// else\n// alert(\"There was an error in accessing your file, please reselect the file and try again\");\n},\nonCancel: function(id, fileName){},\nmessages: {\n// typeError: \"{file} has invalid extension. Only {extensions} are allowed.\",\nsizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\nminSizeError: \"{file} is too small, minimum file size is {minSizeLimit}.\",\nemptyError: \"{file} is empty, please select files again without it.\",\nonLeave: \"The files are being uploaded, if you leave now the upload will be cancelled.\"\n},\nshowMessage: function(message){\nalert(message);\n}\n});\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820099.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820530.\n. Ok, thanks for your help, let me try and implement this and make sure it all works ok\nI want to reverify the incoming file length against the local saved file copy, we have had several issues with file uploads having errors, without exceptions, and this is the best way I can see to make sure the entire file has gotten copied successfully\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 12:21 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header (#343)\n...please note that the Content-Length is only really useful for XHR\nuploads. For multipart encoded requests, Content-Length indicates the size\nof, not just the file, but the size of all fields in the request. In the\ncase of multipart encoded requests, you can check the file size using the\napache commons fileupload library in the example I provided.\nOn Mon, Sep 24, 2012 at 11:07 AM, Ray Nicholus ray@garstasio.com<mailto:ray@garstasio.com> wrote:\n\nCorrect. Do not use this. I removed it from master. The octet stream\nreader is just that, an octet stream reader. You are trying to read a\nmultipart encoded request. I have an example that parses such a request in\nthe java folder.\nAlso, there is no need to modify the code to include file size in the\nheader. File size should be included by the user agent in the\nContent-Length header field.\nOn Mon, Sep 24, 2012 at 10:48 AM, anitakfitz notifications@github.com<mailto:notifications@github.com>wrote:\n\nI am not sure I understand \u2026 I am using your octet stream reader class as\nmy \u2018servlet\u2019 url being called from the jsp/html calling the file uploader,\nthis works fine in firefox and chrome, but not in IE. I have actually even\nmodified your js to also include file size in the header, because I want to\nrevalidate that the entire file has been saved. Are you saying that this\noctet stream reader is NOT what I should be using to handle the url from\nthe file uploader ?\nFrom: Ray Nicholus [mailto:notifications@github.com]mailto:[mailto:notifications@github.com]\nSent: Monday, September 24, 2012 10:28 AM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header\n(#343)\nThere is no such header sent with a multipart encoded request. Have a\nlook\nat the servlet example in the server/java\nfolderhttps://github.com/valums/file-uploader/tree/master/server/javaif\nyour server-side language is java, which appears to be the case.\nOn Mon, Sep 24, 2012 at 9:16 AM, anitakfitz notifications@github.com\n<mailto:notifications@github.com%20%0b>> mailto:notifications@github.com>wrote:\n\nOk, i followed your link in the message above, but I do not see any\ndifference between this example and the version I have ? the problem I\nhave\nis that in IE9, the following line returns null for filename:\nString filename= request.getHeader(\"X-File-Name\");\nmy jsp code is as follows:\nvar uploader = new qq.FileUploader({\n// pass the dom node (ex. $(selector)[0] for jQuery users)\nelement: document.getElementById('fileToUpload'),\n// path to server-side upload script\naction: streamUrl,\ndebug: true,\nmultiple: false,\n// additional data to send, name-value pairs\nparams: {\nlineId:\"1\"\n},\n// events\n// you can return false to abort submit\nonSubmit: function(id, fileName){\n// alert(\"last file: \" + lastFile);\nif (lastFile != \"\") {\n// we could call something server side here to delete\n// the last file, but probably easier to delete on submit ...\n}\n$('.qq-upload-list').empty()\n// $('.qq-upload-list > li').remove();\n// disable submit button\n/ // $(\"#sData\").attr(\"disabled\", \"true\");\n$(\"#sData\").addClass(\"ui-state-disabled\");\n},\nonProgress: function(id, fileName, loaded, total){},\nonComplete: function(id, fileName, responseJSON){\nlastFile=fileName;\n// need to handle failure from server here\n// alert(responseJSON.success);\nif (responseJSON.success == \"true\")\n$(\"#sData\").removeClass(\"ui-state-disabled\");\n// else\n// alert(\"There was an error in accessing your file, please reselect\nthe file and try again\");\n},\nonCancel: function(id, fileName){},\nmessages: {\n// typeError: \"{file} has invalid extension. Only {extensions} are\nallowed.\",\nsizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\nminSizeError: \"{file} is too small, minimum file size is\n{minSizeLimit}.\",\nemptyError: \"{file} is empty, please select files again without it.\",\nonLeave: \"The files are being uploaded, if you leave now the upload\nwill be cancelled.\"\n},\nshowMessage: function(message){\nalert(message);\n}\n});\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820099>.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8820530>.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8823543.\n\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8824776.\n. So, it looks like in request parser, when I get the filename, it gets the full client side filename, including local path, so then in upload receiver, I need to separate out the filename only (from the full path) to create the new server side file path\nJust want to confirm \u263a\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 2:50 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header (#343)\nFor multipart: You can check the size of the FileItem object and compare it with the size of your locally saved file.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8829999.\n. Hmm, ok, I think I have a workaround, I wont be able to depend on ie security settings, since this will be whatever the clients have\nI think I do have it working somewhat, however, I am getting the file uploaded (on my local server, still have to test on the real server)\nI have noticed, however, that when the upload completes, I do get the json response (success) for ie and other browsers, but the other browsers are displaying file size where IE is not ?\nThanks so much for your help !!\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Monday, September 24, 2012 3:14 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header (#343)\nThis is what I have done in my projects since IE tends to do this in some\ncases. If you have the \"include local directory path\" setting enabled in\nyour IE security settings, the full path will be sent. Also, if the site\nyour are uploading to is marked as a \"trusted site\" you will also see the\nfull path.\nOn Mon, Sep 24, 2012 at 1:53 PM, anitakfitz notifications@github.com<mailto:notifications@github.com>wrote:\n\nSo, it looks like in request parser, when I get the filename, it gets the\nfull client side filename, including local path, so then in upload\nreceiver, I need to separate out the filename only (from the full path) to\ncreate the new server side file path\nJust want to confirm \u263a\nFrom: Ray Nicholus [mailto:notifications@github.com]mailto:[mailto:notifications@github.com]\nSent: Monday, September 24, 2012 2:50 PM\nTo: valums/file-uploader\nCc: Fitzwater, Anita\nSubject: Re: [file-uploader] IE9 java not getting 'X-File-Name' header\n(#343)\nFor multipart: You can check the size of the FileItem object and compare\nit with the size of your locally saved file.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/valums/file-uploader/issues/343#issuecomment-8829999>.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8830119.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/343#issuecomment-8830840.\n. ",
    "Thorazine": "Thanks, I will!\nBTW, client side is just demo standard. So: \nfunction createUploader(){\n            var uploader = new qq.FileUploader({\n                element: document.getElementById('file-uploader-demo1'),\n                action: '../server/php.php',\n                debug: true,\n                extraDropzones: [qq.getByClass(document, 'qq-upload-extra-drop-area')[0]]\n            });\n        }\n// in your app create uploader as soon as the DOM is ready\n    // don't wait for the window to load  \n    window.onload = createUploader;\nLike i said, it work in ff, chrome and safari. I get no js errors what so ever either. Strange :)\nThanks again, will post it there\n. ",
    "pklauzinski": "David's change works for me. Just noticed today that my uploads were broken in IE (as I never use that browser). Fixes both IE8 and 9. Thanks for the fix!\n. ",
    "rjha": "The above !empty($_FILES) check should be (!empty($_FILES) && isset($_FILE[$field]))\n@rnicholus  The $_FILE superglobal in PHP can be used to signal the \"existence of a form POST file upload\". (page 138, PHP power programming, Andyi Gutmans' Book)\nThat said, I have looked at the other threads also and I will post a robust solution. \n. That is confirmed. php://input is not available with multi-part so do not use that. For code example of how to work with XHR and form upload please look @ code here https://github.com/rjha/webgloo/tree/master/lib/com/indigloo/media\n. ",
    "maxatbrs": "Hey Everyone,\nI'm having the same issue. Both examples from rnicholous and davimann4 did not work for me. After working on this for the greater part of two days, here's what I found out:\nphp://input is not available with enctype=\"multipart/form-data\".\nREF > http://php.net/manual/en/wrappers.php.php\nWhen I was posting files in IE 9 / 8 / 7 it was cause errors because it couldn't write the file. I found that I was posting it with the multipart (used the debugger to look at my REQUEST HEADERS) and thus the stream_copy_to_stream() php wasn't working since the php://input data can't be used. \nCan anyone else confirm? \nAlso, anyone have a fix haha? I need to get this working for IE.\n. Hey Guys,\nThanks for confirming. After hacking on it for a good number of hours, I went back and checked out all my configs, server, yada yada and still no dice. Thanks for advice so far, but did not turn up anything yet.\nSo I was taking a look at what was getting posted to the server and how the PHP controller determines to use qqUploadedFileXhr or  qqUploadedFileForm (line 95 or so). We can see that it determines on how to store the file, either via the XHR or the fall back with $_FILES. \nThe issue is that IE is posting both the $_GET['qqfile'] and $_FILES but since IE is post as multi-part, the stream copying doesn't work and thus the file doesn't store on the server. You can see the debug output here: http://i.imgur.com/QWN3s.jpg\nOriginally, I downloaded the ZIP from the project page http://fineuploader.com a couple of days agp and got (what I think) is an older version of the PHP controller. I can see here on github that @weberhofer forked the project and made updates to the conditional surrounding the which class to use. This change is only 6 days old so I think maybe I got an old version of the PHP controller.\nPerhaps the project page needs a better way of giving people the code? Like forcing them to pull from master or at least get the zip? If you guys need help on this, hit me up!\nI am going to get that new copy, test it and report back. Thanks dude!\n. Okay, I can confirm that this fix from @weberhofer is working. Looks like it was merged into master, so maybe the zips in the releases (which where the btn on the project page links to) needs to be updated.\nBetter yet, display a link for the master zip? \nEveryone, really appreciate the help. This is pretty awesome!\n. Hey Dude,\nThanks for the reply. The reason why I was bringing this up is because if you go to http://fineuploader.com/, it says that it works for IE7+. This is true except for the server side PHP controller that included in the 2.1.2 release. I would say that this is going to be confusing for people. \nAs a relatively good developer, it took me about 30 minutes to get it working with every browser (sans IE) and 2 days to get it to work with IE due to the fact that I had to debug everything from file permissions, server vars, and all the other fun stuff. \nI guess my question is this: Why are you hesitant to put something into the release besides html/css/js? This fix is the only way that the PHP controller will work with IE so why wouldn't that be included? It's about 3 lines of change that have been tested, confirmed, and then merged. I know, everyone hates IE (including me) but people need cross browser support.\nAt the very least, why put a note on the release page about the PHP controller update for IE? \nNeither of these option would hurt too much and would have saved me many hours lol. Just food for thought.\n. I see where the I'm confused. The release zip only has the HTML / JS / CSS / IMG files and not client / server dirs like the source, my bad man.\nI understand what you mean about not putting in the PHP until you have maintainers. I'd like to contribute to maintaining the PHP controller. There are some improvements / streamlining that I already would like to make and would help test pre-release.  \nWhat's the first step to doing this? Should I fork or? \n- Max\n. Sure thing man. Got a link to that Google Group?\nI'm going to fork, make a few updates and keep my out for other PHP peeps. \nThanks guys!\n. Awesome, thanks for the link dude. Yeah, I'm always hacking around and get some free time here at work every so often to work on the open source stuff. I just used this for a project and got really familiar with it so I'm excited to contribute.\n. Agreed. I looked at the 3.0 branch and will make sure I'm up to date. \nShall we let this thread finally go to bed? Hahaha\n. Thanks for the suggestion dude! I took a look at it and it has a lot of great tools. I'll play around with it and see what it's all about.\nOn initial review, it seems pretty robust which is cool but might but also might be overkill. I can't say for sure right now (haven't tested it) but either way, I'll definitely look into it and see what's up.\nRocket, thoughts on that script?\nAnyone else who is interested in the improvement to the PHP controller example and discussion on that topic, please post on the Google Groups page here:\nhttps://groups.google.com/d/topic/fineuploader/-PWiKen6xCY/discussion\n. ",
    "borut-t": "Someone should take a look a the blueimps jQuery File Uploader php script that probably handles that better: https://github.com/blueimp/jQuery-File-Upload/blob/master/server/php/upload.class.php\nI didn't test it so it's just a prediction that it's better...\n. Nice...\n. header('Content-type: application/json'); in php script. But it's the same without this line. Does this defaults to json?\nI tink there is no problem with json returned. It is properly formatted. Just the html inside json is scrambled - encoded.\n$('#'+target).append(responseJSON.html).text();\nAbove code properly formats html but is not compiled against DOM - in browser I see html code instead of new element.\n. I changed it but it's still the same. \nIf I removed htmlspecialchars() method from the output than html is fine.\nAny idea ?\n. I already did. This is output:\n\n[uploader] xhr - server response received\nfileuploader.js (line 1209)\n[uploader] responseText = {\"success\":true,...\n. Crap, take a look at the screenshot her: https://dl.dropbox.com/u/88804/Other/json.png\n. The screenshot is what I get in console. In previous post I pasted the same html code like in screenshot but obviously it gets formatted within git editor. Screenshot is valid origin, this is what I get back from server...\n. Exactly. The backend is the problem. If I do this\necho json_encode($result);\n\ninstead of this\n\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\n\nthan html is fine. Otherwise not...\n. That would not be ok because after that it does not work in browser when iFrame mode is used - I've tested on IE8.\nLine from your php.php script:\n\n// to pass data through iframe you will need to encode all html tags\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\n\nThis is onComplete method:\n\nonComplete: function(id, fileName, responseJSON) {\n  if(responseJSON.success) {\n    $('#'+target).append(responseJSON.html);\n  }\n}\n. I've tested this again without conversion to entities:\necho json_encode($result);\n\nOn last version of FF it works fine. Also in Safari and Chrome. It also works in IE8 ?!?!\nI swear that before it didn't work in IE8 - that's why message withing php code was posted:\n\n// to pass data through iframe you will need to encode all html tags\n\nNow I am really confused and don't know what is right?\n\necho json_encode($result);\n\nor \n\necho htmlspecialchars(json_encode($result), ENT_NOQUOTES);\n. Thanks for you support. I will use just json_encode and will report if something goes bad wrong... Thanks again!\n. That would be nice cos I get headaches trying to figure out the best solution...\n. @rnicholus @NTICompass:\nI am thinking if it wouldn't be better to generate html code after upload completion with extra ajax request. In that case json will stay simple and more secure. What do you think?\n. @NTICompass: Your solution just works! Thanks, you saved me of a hard headache :)\n@rnicholus: That is fine. I'll stick with this solution. Also don't have problems with IE7 cos I will not support it.\n\nThank you both guys for quick and good support...\n. @rnicholus: Maybe you should add this solution to the examples on product page so others will avoid that.\n. @scabro My project is already UTF-8 based and in may case this is irrelevant. Solution for this issue has been already given by @NTICompass: https://github.com/valums/file-uploader/issues/434#issuecomment-9951588.\nThanks for suggestion anyway.\n. There is no need to support IE7 anymore...\n. I see your point but I am willing to risk to loose a few percent of users that use IE7 or bellow.\nOne great example is Google which is dropping support for IE8: http://www.computerworld.com/s/article/9231316/Google_to_drop_support_for_IE8_on_Nov._15\n. Nice! Good job...\n. This was my solution also. Ok, I'll do that. Thanks!\n. @koichirose If you cannot pass in product id than retrieve it from request after upload. I don't understand quite where the problem is?\n. Yep, totally valid...\n. @lafeber You can have html packed inside json with no problem...\n. Docs says different:\n\nThere is no need to specify the element option. It will be ignored if you pass it in. The plug-in will pass the element option for you, using the element you associated with the plug-in (the element with an id of fineUploaderElementId in the above example).\n. I've updated example but still doesn't work. How can I specify button property properly?\n. It works now. But why do I have to specify button?\nbutton: $('#docUploadButton'),\n. One more question. Why do I get the following error onValidate event when file extension is not on upload list?\n\n[FineUploader] Caught exception in 'onValidate' callback - ReferenceError: errorReason is not defined\n. If I understand you right that I need to wrap uploadButton inside parent container? Please take a look a the updated example above if I've done it right?\n. So different element for plugin instance and for button. Ok, I understand but don't see the need for this...\n. I am aware of the confusion. But the button could be the same as instance by default. If you need to specify different element for button is up to you. It's just my thought.\nAnyway I respect the rules and have already implemented like you said.\nThanks!\n. I absolutely agree with you and that's why I will use this preferred solution. Thanks for explanation and understanding...\n. Ok, I've set width to 100% and it works. There is only one small & strange issue. Css cursor:pointer doesn't show up anymore after that. Do you know the reason?\nThanks for solution. I would be great if you could include this fix in next release.\n. I've just set both height and width to 100% with no luck. Pointer is still not shown...\njavascript\nqq(input).css({\n    ...\n    cursor: 'pointer',\n    width: '100%',\n    height: '100%',\n    opacity: 0\n});\n. Sorry it's not in production yet. \nI'm testing this on mac. FF doesn't show pointer, Safari does.\n. Yeah you are right. Putting button inside  element caused this weird situation. It's fine inside div...\nThis one is causing problems: \nhtml\n<span id='UploadButtonContainer'><span id='UploadButton' class='button'>Upload</span></span>\nThis works fine:\nhtml\n<div id='UploadButtonContainer'><span id='UploadButton' class='button'>Upload</span></div>\n. Yes, no problem. Thank you !\n. Yes, I use Closure compiler which tells me about this problem.\nHow come this null; start value in loop is valid? Could you explain this to me? Thanks!\n. Exactly. This one works and compiler doesn't argue:\nfor (; from < len; from+=1)\n. ",
    "ClemensSchneider": "I'm fine with that. It would have worked at least for a german localization :)\n. ",
    "PegWeb": "Oh so it finally worked? :) I must have forked the wrong url on the first attempt.\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Wednesday, September 26, 2012 2:54 PM\nTo: valums/file-uploader\nCc: webmaster@pegweb.com\nSubject: Re: [file-uploader] Fixed the ColdFusion code so it works with IE. (#357)\nThanks for your contribution!\n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/pull/357#issuecomment-8900909 . \nhttps://github.com/notifications/beacon/J6T91GIPIyhU-8ti4GCGPxbdqWi6eWowPtqXlStQonr3G3IjfTdZwUX0vnorbVW0.gif \n. ",
    "sadiksha": "Is there any other way to get the file object like get the full path from where it was uploaded? \n. ",
    "daqing": "I have the same issue here, only filename is available in the params. I'm using version 2.1.\nAny tips?\n. Just figured out: the wiki page( https://github.com/valums/file-uploader/wiki/Rails---CarrierWave ) shows how to integrate file-uploader with Carrierwave.\n. ",
    "nugged": "\nDo you have any preferences?\n\nI think by default dragenter/dragleave must be tied to document, but user can set some parameter like \"tie_to\" or what to specify another DOM object, to which loader dragenter/dragleave will be tied, so anyone can set own div or table or what needed. That's it.\nI firstly (before writting here) tryed to dig into source to change in short that behaviour bymyself, but it was not straight as I though, it requires to learn lot of code structure to figure place and how to.\nIf it can take long to imply this feature I ready to involve to shorten that because I need both copy-drag-between-textareas and file-uploader on one page for my current project stepover so anyway need to resolve.\n. (yikes pressed close button :) )\nIf you can lead me to small part of code which does attachment I can branch and try to implement that, to help.\n. More of that: if we can attach file-uploader to only part of the page - we can attach two different uploader instances on same page so we can for example create few indepentent dropzones for quick fileuploading per item (for example in different folders, i.e. with different \"action\" and \"params\" parameters for each dropzone).\n(maybe for future to decrease JS cpu load/memory footprint uploader must be created in one-main-code for any instances on one page... anyway)\n. So they already divided by focus places with different action/prarms? Great - so only to detach uploader from whole page will be great. Okay, so - does it complex and need deep code structure knowledge? Can I involve if not-so-complex?\n. Heh, not a milestone - just another idea - it would be fun if file uploader can been attached to  field and after user drop file onto it and file been uploaded to server, newly created file url returned from server will be inserted in input field value :)... It gives ability to quick fill form with fresh uploaded file urls :). \nNot accept paragraph above as feature request, just idea / minds aloud.\n. ",
    "cob4lt": "I am using FUB and I dont understand why I am getting this error when calling cancel method\nAfter line this\napp_obj.Stupovi.fineUploader.cancel(app_obj.Stupovi.fineUploader._storedFileIds[0]);\nand the console log\n[FineUploader] Sending upload request for 0 jquery.fineuploader-3.0.min.js:56\n[FineUploader] Cancelling undefined jquery.fineuploader-3.0.min.js:56\nUncaught TypeError: Cannot read property 'fileName' of undefined \nThank you\n. Here is whole code (it is not working, I just c&p)\nhttp://jsfiddle.net/FHYCU/\nAnd when I jump to line in fineuploader-3.0-min.js, this is where it breaks\nqq.log = function(a, b) {\n    if (window.console)\n        if (!b || \"info\" === b)\n            window.console.log(a);\n        else if (window.console[b])\n            window.consoleb;\n[FineUploader] Caught exception in 'onValidate' callback - TypeError: Object 291 has no method 'get'\n. ",
    "andrew-kzoo": "The delete-button branch code looks great. I appreciate the goal of using RESTful mechanics, specifically of having Fine Uploader use a DELETE request for uploaded file deletion. However, at least for now, this choice necessitates \"smarter\" server-side code to handle request methods beyond simple POSTs. I believe this hurdle is significant enough that adding an option to FU to use \"simple\" POSTs (XHR or form upload and POST ping for file deletion) or full RESTful mechanics (using PUT for uploads and DELETE for downloads) would be good. Perhaps adding RESTful-ness to FU can wait until 3.4?\n. Here is some data for consideration regarding RESTful-ness.\nThe accepted answer for this question:\nAJAX File Upload with XMLHttpRequest\nhttp://stackoverflow.com/questions/10475313/ajax-file-upload-with-xmlhttprequest\nAnswer:\nhttp://stackoverflow.com/a/11771857/1985389\nrelates some useful bits regarding RESTful mechanics, including using PUT\njavascript\nxhr.open(\"put\", \"upload.php\", true);\nand adding file name and file size to HTTP headers, not just as query string parameters\njavascript\nxhr.setRequestHeader(\"X-File-Name\", file.name);\nxhr.setRequestHeader(\"X-File-Size\", file.size);\nAgain, I think having FU use RESTful mechanics is a worthy goal. Piecemeal implementation in stages (e.g. use PUT for uploads, use DELETE for file deletion, use HTTP headers to convey information instead of query string parameters) behind an overriding option (e.g. useRest) may make development easier.\n. :smile: \n. Yeah, I'll re-do the changes.\nThe problem most likely has to do with line ending differences. I'm working on Windows.\nhttps://help.github.com/articles/dealing-with-line-endings\n. The actual changes are available now.\nRunning the following (as per https://help.github.com/articles/dealing-with-line-endings) fixed the problem:\nbat\ngit config --global core.autocrlf true\n(At home I only run Ubuntu.)\n. I'm in CST (Kalamazoo, Michigan) and will check in from home tonight, too.\nI'm also on GitHub as http://github.com/andrewrcollins\n. I do primary development on Firefox with Firebug. However, for the systems I create I have to support IE8+. This is the primary reason I'm using FU. Going ahead I'll better cross t's and dot i's before I execute a pull request.\n. See https://github.com/andrew-kzoo/fine-uploader-examples\n. Looks cool. Thanks @akre54 for the information on AMD and providing the wrapper code.\n. @JoaoVagner You may be interested in this https://github.com/andrew-kzoo/fine-uploader-examples\n. I'm glad to help! I'm impressed by the speed at which you implemented the delete functionality. I'm excited to see it getting so close to ready.\n. Thanks @cajund for the heads-up on GitFlow. Researching further led me to HubFlow.\nA successful Git branching model\nCode: https://github.com/nvie/gitflow\nHubFlow - GitHub and the GitFlow Model Together\nDocumentation: http://datasift.github.com/gitflow/\nCode: https://github.com/datasift/gitflow/\n. :+1:\n. I originally modified the file counter demo example (using the track onComplete and related events method) and was let down to have to create so much higher-level code to maintain this simple number. My current interest is to have access to this successful upload and use it with a custom jQuery Validation validator, e.g. \"rangeFiles\" see range. I don't use the Basic mode, but I'm sufficiently motivated to create the necessary internal code to expose \"getSuccessful\" for both FineUploader and FineUploaderBasic.\n. Was commenting when you commented: Wow, GitHub is great!\nI'll open a feature request for getSuccessful and fileLimit.\nI appreciate your efforts!\n. Created two new feature requests: #634 and #635\n. :+1: Excellent! Thanks Ray!\n. :+1: Excellent! Thanks Ray!\n. :+1:\n. Awesome! I'll check out the file-limit branch (or the merged 3.4-IP if I'm delayed) in the next day or so. Thank you!\n. :+1: At some point all versions of IE have made me :cry: However, I do have fond memories of IE 5.0 and its spiffy XMLHttpRequest object.\n. This decision to support or not to support IE is not being made in isolation. The entire web development community is frustrated with IE6/7/8 and IE generally.\nMany of the comments in this thread mirror those to jQuery's announcement last summer that jQuery 2.0 would not support IE6/7/8: http://blog.jquery.com/2012/06/28/jquery-core-version-1-9-and-beyond/\nThe volume and anxiety of those comments necessitated a followup post: http://blog.jquery.com/2012/07/01/jquery-1-9-and-2-0-tldr-edition/\nPerhaps this project, its users, contributors, and maintainers, can learn from the jQuery discussion and follow a similar approach to supporting and not supporting IE?\n. For example, as a suggestion for a blog post, mirroring jQuery's post:\n```\nFine Uploader 4.0 will be the first version to support only modern browsers\n(insert list of browsers, e.g. IE10, Firefox, etc).\nFine Uploader 3.x up to 3.9 will continue to support non-modern browsers\n(insert list, e.g. IE7, IE8, etc.).\nFine Uploader 4.0 is expected in six months.\nBegin making preparations.\n```\n. :+1: Great work @rnicholus!\n. You have my apologies @davidwindell I jumped to the incorrect conclusion that you were throwing rocks and running off. Thank you for your response.\nMy experience suggests the following: Open source projects supported or sponsored by organizations, or even small groups of people--especially in the recent past few years, generally have sufficient resources to handle the requests and demands, mild and not-so-mild irritations, that come with providing support. The efforts required can be spread across different people who mutually support each other in their efforts. Single individuals, particularly in this new wild west of GitHub (see below), have a harder time. There is an adjustment occurring.\nI've been tracking the issues on this project for about a month now. From what I've seen there are many, many people who are not reading the documentation (nothing new here), not proficient with basic javascript (kinda strange), not proficient with git (understandable, but still a little surprising), and not well-versed (or just versed) in how open source \"works\" (simply frustrating).\nI am currently avoiding bringing my personal projects to GitHub because the support process could be so time-consuming.\nIt appears to me that GitHub has so significantly lowered the barrier to entry that previously existed for direct involvement with open source development that--and this is hard for me to as egalitarian-minded person to say, it may be \"too easy\" for people to participate now. The set of personal skills required for involvement is now so exceedingly low: have email address and web browser (even moreso if you use the GitHub for Windows client), but the set of expectations are so high.\nIn my view this combination of highs (ambitions, expectations) and lows (skills, valuation of others efforts) leads to the situation that exists presently.\nLATER ADDITION\nI am no expert, but there must be some software engineering/open source development research on the \"adjustment\" to which I refer. It could offer some guidance on \"How to Run a Successful GitHub Project,\" where successful covers personally satisfying, sustainable, economically viable, and congenial to or with community standards of open source development.\nI will seriously research this area in the next day or so and report what I find on this thread.\nMUCH LATER ADDITION\nThis presentation (referenced indirectly by @rnicholus above) by @desandro is worth watching, reading, perusing:\nDavid DeSandro\nhttp://desandro.com/\nhttps://github.com/desandro/masonry\nDavid DeSandro | Open-source ain't free | Fronteers 2012\nTranscript\nSlides\n. @davidwindell (and @rnicholus) Currently, I have only time, some money, and moral support to offer. I am slowly getting my head into the code, presently I can't directly field questions or issues. I am no expert, but there must be some software engineering/open source development research on the \"adjustment\" to which I refer. It could offer some guidance on \"How to Run a Successful GitHub Project,\" where successful covers personally satisfying, sustainable, economically viable, and congenial to or with community standards of open source development.\nI will seriously research this area in the next day or so and report what I find on this thread.\nMy sincere apologies to everyone who was offended by what I posted. The beginning of this thread was sour, but I hope that it's been turned around.\n. I generally don't prefer deletions, but this is a forum for discussing technical issues. I am fine with the proposed deletions for improved fidelity to the purpose of this forum. Again, I apologize to everyone for my misstatements and any offense taken.\n. I moved some text from my other post to the for-keeps post. I suggest \"How to Run a Successful GitHub Project\" or something similar but less provocative as the new title. Maybe: \"Improving Issue Support for Users, Contributors, and Maintainers\"\n. See https://github.com/valums/file-uploader/pull/695\n. Have the terms of the commercial license been settled?\n. I would like to see the log messages include the version number.\n. Currently I need to loop through ids to re-construct the set of name and uuid of successful uploads.\nPerhaps a getUploads() method (or similar) would return a JSON array of uploads:\njson\n[\n  {\n    name: \"Example.jpg\",\n    uuid: \"d12fd2c2-09ec-4c98-bcc7-ff0427cd5f25\"\n  },\n  {\n    ...\n  }\n]\n. Currently I need to loop through ids to re-construct the set of name and uuid of successful uploads.\nPerhaps a getUploads() method (or similar) would return a JSON array of uploads:\njson\n[\n  {\n    name: \"Example.jpg\",\n    uuid: \"d12fd2c2-09ec-4c98-bcc7-ff0427cd5f25\"\n  },\n  {\n    ...\n  }\n]\n. I'll give this functionality a test drive next week. BTW expunge is the perfect method name.\n. Either one identifies me, during the day @andrew-kzoo otherwise @andrewrcollins.\nWe're using Fine Uploader as the file uploader component of a form builder system. Ultimately, when a form is validated and submitted, lists of successfully uploaded files are collected from each file uploader component as described above:\njson\n[\n  {\n    name: \"Example.jpg\",\n    uuid: \"d12fd2c2-09ec-4c98-bcc7-ff0427cd5f25\"\n  },\n  {\n    ...\n  }\n]\nThese sets of pairs of uploaded file names and UUIDs are associated with specific form fields (e.g. pictures or attachments), combined with other form fields (e.g. name and address), and POSTed via AJAX to a server-side script. This script populates the form entries and form files tables. Until the form is submitted files can be uploaded, cancelled, and deleted through the file uploader components as each has its own temporary scratch area for file uploads.\n. Thank you Ray! I believe this API addition brings useful visibility to the inner workings of the Fine Uploader.\n. @rnicholus @feltnerm and the rest of the Widen team continue to produce excellent code!\nEqually important, you have great community engagement!\n:+1:\n. :+1: for the TinyMCE plugin.\n. Great work on this significant feature!\n. Thank you @rnicholus for your deep and detailed technical knowledge! Your dedication and steadfastness in solving these issues is appreciated!\n. As an aside: @borisreitman Delta Proofreader http://hypervolume.com/proofreader/ is really cool! :+1: \n. I appreciate your thoughtful blog posts @rnicholus! :+1:\n. :+1: Features :+1: Support :+1: Library Stability :+1: Library Evolution\nAnd :100: just for you Ray!\n. Changed, confirmed, and fixed.\n. ",
    "Musikero31": "I'm actually trying to incorporate PDF.js into Fineuploader. I'm trying each and every event possible but so far the best would be during onAllComplete event.\nCan anyone suggest other events for me to incorporate this?. ",
    "heralight": "+1\n. ",
    "Sydney-o9": "+1 very cool feature\n. ",
    "mikemaccana": "The main issue here seems to be that FineUploader currently assumes a single file upload button. Why not allow multiple file upload buttons which can be configured with different options? \nbuttons: {\n  '#uploadPictures':{\n    multiple: True,\n  },\n  '#takePictureFromCamera':{\n    camera: True,\n  },\n}\n['Upload pictures']\n['Take picture with camera']\nUsers can pick the option they prefer.\n. ",
    "JasonBoland": "I think it would make sense that if the browser detects an iPhone then multiple is turned off by a setting of some kind.\nWe're doing a check on our side and if the user is on a iPhone/iPad we set multiple = false.\n. However having the option for two buttons is also a good concept.  Something like \"Upload Existing\" and \"Open Camera\".  But for that option we can code it ourselves.\n. Great!\n. ",
    "brunomac": "+1 !\n. Hey guys.\nI would prefer to just disable the button and show a custom text on it. \nDeleting an item would enable the button and reset the text.\nI can imagine already some layouts problems when removing the button and adding it again when someone removes an item from the list. \nJust my opinion. \nBruno Machado\nOn 29/05/2013, at 15:59, Ray Nicholus notifications@github.com wrote:\n\nHi there, and thanks for the pull request. Don't mind the Travis CI build failure note. We're still working on that.\nI think I would prefer this to be optional, and default to the original behavior. It's possible that, instead of hiding the select files button, some integrators might want to add a click handler (along with some code that prevents the browser's default action) that informs the user why they cannot upload more files. Perhaps some integrators may want to keep this button visible, but style it a bit different as well in this instance.\nNo need to make these changes to your pull request though. I can make the appropriate changes once I get to this in the next release cycle or so. This won't make it into 3.6 as I am currently in the testing phase, but I'll look into it for 3.7.\nThanks again!\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "CheLetton": "As long as the coder users Ajax.BeginForm the XHR headers will be there. \nI have tested the code with all kinds of different files and all work. \nAn example of a header from Firefox Web Console for an Excel spread sheet is shown below:\nX-Requested-With:XMLHttpRequest\nX-File-Name:456.xls\nUser-Agent:Mozilla/5.0 (Windows NT 5.1; rv:15.0) Gecko/20100101 Firefox/15.0\nReferer:http://localhost:6648/\nPragma:no-cache\nHost:localhost:6648\nContent-Type:application/octet-stream\nContent-Length:5336576\nConnection:keep-alive\nCache-Control:no-cache\nAccept-Language:en-us,en;q=0.5\nAccept-Encoding:gzip, deflate\nAccept:text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nThe Response info:\nX-AspNetMvc-Version:4.0\n-AspNet-Version:4.0.30319\nServer:ASP.NET Development Server/10.0.0.0\nDate:Fri, 05 Oct 2012 09:00:12 GMT\nContent-Type:text/html; charset=utf-8\nContent-Length:16\nConnection:Close\nCache-Control:private\nHope this answers the question.\nChe\n. I did and it didn't work. As you thought.\nI will sort out the multipart encoding and submit a new pull request.\nChe\nOn Oct 6, 2012 4:19 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nCan you confirm that you have tested this with IE? It doesn't look like\nmultipart data requests are accounted for.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/393#issuecomment-9199065.\n. And MVC demo in VB.Net would be nice. I did submit one.\n\nChe\nOn Oct 17, 2012 10:28 AM, \"tellibus\" notifications@github.com wrote:\n\nI have included now all the demos you had. I've overridden the showMessage\noption as well in the last one.\nWhat other demos can you think of?\nI can think of two more (may be merged):\n-\nOne with a callback to display a (fake) thumbnail of a given uploaded\n   image? Obviously, since no server-side processing takes place, I'll use a\n   hard-coded dummy one.\n   -\nOne that deactivates the uploader after a number of files have been\n   uploaded, and re-activates it if one of them is deleted / cancelled. This\n   will be using onSubmit and onComplete callbacks as well as additional\n   jQuery.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/395#issuecomment-9521121.\n. In ASP.Net I have to return the success or error json strings like this:\n\nReturn \"{\"\"success\"\":true}\"\nOr for fail:\nReturn \"{\"\"error\"\":\"\"An error message\"\"}\"\nThis may be the same for you.\nHope it helps.\nCh\u00e9\nOn Oct 17, 2012 10:11 AM, \"GitOffice\" notifications@github.com wrote:\n\nWhen I set debug=true ,I found something as below in firebug console. \"\n[uploader] xhr - server response received [uploader] responseText = \" ,and\npost option is the content uploaded file in firebug console\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/405#issuecomment-9520701.\n. I admit I didn't test in chrome. I tested it in opera, ie and Firefox here\nand ok.\n\nWill check again. And try chrome.\nThanks.\nCh\u00e9\nOn Oct 17, 2012 2:48 PM, \"GitOffice\" notifications@github.com wrote:\n\nCheLetton ,Thanks a lot ! I am following your ,ASP.Net MVC VB.Net example\nof uploader! It is great in IE, but it does not work in Chrome or FireFox.\nIt seems like uploader can not find HttpPostedFile in ashx file.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/405#issuecomment-9527776.\n. Ok. Tested on the following, writing to a file system. Ideally writing to a\nBLOB or varbinary(max) would be better. All browsers shown below 'uploaded'\nto c:\\temp on local host.\n\nOpera 12.02\nIE 9\nFirefox 11.0\nChrome 22.0.1229.94 m\nThis was an ASP.Net MVC 3 app written in VB.Net.\nI don't use web handler files so no experience of them, sorry.\nCh\u00e9\nOn Oct 17, 2012 5:44 PM, \"Che Letton\" che.letton@gmail.com wrote:\n\nI admit I didn't test in chrome. I tested it in opera, ie and Firefox here\nand ok.\nWill check again. And try chrome.\nThanks.\nCh\u00e9\nOn Oct 17, 2012 2:48 PM, \"GitOffice\" notifications@github.com wrote:\n\nCheLetton ,Thanks a lot ! I am following your ,ASP.Net MVC VB.Net example\nof uploader! It is great in IE, but it does not work in Chrome or FireFox.\nIt seems like uploader can not find HttpPostedFile in ashx file.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/405#issuecomment-9527776.\n. @GitOffice when you say cant find it, do you mean the method from System.Web or find the file to upload?\n\n\nThese lines of code:\nDim myfiles As System.Web.HttpFileCollection = System.Web.HttpContext.Current.Request.Files\n Dim postedFile As System.Web.HttpPostedFile = myfiles(0)\n. @GitOffice I think I see the problem....maybe...\nin the returning parameters the filename is held in 'qqFile'.\nAre you in the options of the fileuploader initializer setting the 'inputName' to be the same value\nas the parameter in the function that handles the upload? (inputName: 'uploadFile' is what I use.)\nIf you look at my example the Function called Upload that handles the ajax request and does the actual upload has the constructor:\nFunction Upload(ByVal uploadFile As String) As String\nThe 'uploadFile' parameter must be set in 'inputName' to match this. If you do not use inputName then\nthe parameter must be qqFile like this.\nFunction Upload(ByVal qqFile As String) As String\nHope this is the problem.\nCh\u00e9\n. This is my javascript to set it all up:\n\n    function createUploader() {\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('file-uploader'),\n            debug: true,\n            sizeLimit: 5200000,\n            onComplete: function (id, fileName, responseJSON) {\n                        $('#uploaded_files').append('<b>' + fileName + '</b>');\n                            },\n            uploadButtonText: \"Click or drop files here to upload.\",\n            action: '/Upload/Index',\n            acceptFiles: ['image/jpeg', 'image/bmp', 'image/gif', 'image/png', 'image/tiff', 'application/msword', 'text/plain'],\n            allowedExtensions: ['jpeg', 'jpg', 'txt', 'doc', 'docx', 'pdf', 'tiff', 'png', 'rtf', 'gif', 'tif', 'xls'],\n            multiple: true,\n//NOTICE THIS ----->     inputName: 'uploadFile'\n        });\n    }\n    window.onload = createUploader;     \n \nIf this is not set you must use qqFile in your server side function.\nCh\u00e9\n. Glad to of helped.\nIts a great plugin\nCh\u00e9\n. Could you post the start of your ASP.Net function that handles the up load?\nI see your action is set to '/do-nothing.htm'. Do you have that URL set up?\nHave a look at my ASP.Net MVC demo. Its written in VB.Net but it gives you\nan idea.\nCh\u00e9\nOn 19 October 2012 10:15, Beav181078 notifications@github.com wrote:\n\nHi All,\nIm writing in ASP.NET 2.0 on a Windows 2008 R2/IIS7 server. Im getting\nthe above error in all browser type's. Here is a sample of my code so far,\nbut im defo sure its a server side issue.\n\n    function createUploader() {\n        var uploader = new qq.FileUploader({\n            element: document.getElementById('file-uploader'),\n            uploadButtonText: \"BROWSE\",\n            action: '/do-nothing.htm',\n            debug: true,\n            acceptFiles: ['application/msexcel', 'application/msword', 'image/bmp', 'image/gif', 'image/jpeg', 'image/png', 'image/tiff', 'text/plain'],\n            allowedExtensions: ['jpeg', 'jpg', 'txt', 'doc', 'docx', 'pdf', 'tiff', 'png', 'rtf', 'gif', 'tif', 'xls', 'xlsx']\n        });\n    }\n    // in your app create uploader as soon as the DOM is ready\n    // don't wait for the window to load\n    window.onload = createUploader;\n\nPlease enable JavaScript to use file uploader.\nCan anyone help me?\nBeav\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/410.\n. Send me and email to che.letton@gmail.com and I will send a zipped file.\n\nCh\u00e9\nOn 19 October 2012 10:25, Beav181078 notifications@github.com wrote:\n\nHi CheLetton,\nThis may explain why its not working then. How do I go abouts loadoing\nyour VB files into the website?\nP.S.\nThis is my first ASP.Net website, so im very new to this.\nBeav\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/410#issuecomment-9594548.\n. Check the Json string in the console on a browser. I thinking it's not in\nthe correct format. Have you checked out the php examples ?\nOn Oct 21, 2012 1:34 AM, \"divstudio\" notifications@github.com wrote:\nHello\nThx for this great tool !\nI'm using it with php but files are not loaded in target folder, i'm\ngetting a \"upload failed\" message.\nChrome console :\n[uploader] xhr - server response received fileuploader.js:1205\n[uploader] responseText =\nHere's what i added to my index.php :\n<?php\n```\n      // list of valid extensions, ex. array(\"jpeg\", \"xml\", \"bmp\")\n                            $allowedExtensions = array(\"jpeg\", \"bmp\");\n                            // max file size in bytes\n                            $sizeLimit = 1024;\n                        require('uploader.php');\n                        $uploader = new qqFileUploader($allowedExtensions, $sizeLimit);\n\n                        // Call handleUpload() with the name of the folder, relative to PHP's getcwd()\n                        $result = $uploader->handleUpload('uploads/');\n\n                        // to pass data through iframe you will need to encode all html tags\n                        echo htmlspecialchars(json_encode($result), ENT_NOQUOTES);\n                    ?>\n\n\nfunction createUploader(){\n    var uploader = new qq.FileUploader({\n        element: document.getElementById('file-uploader'),\n        action: '/uploader.php',\n        debug: true,\n        multiple: false,\n        allowedExtensions: ['jpeg', 'jpg', 'png'],\n        sizeLimit: 51200, // 50 kB = 50 * 1024 bytes\n        uploadButtonText: 'Ajoute ta photo !',\n        showMessage: function(message) {\n            // Using Bootstrap's classes and jQuery selector and DOM manipulation\n            $('#file-uploader').append('<div class=\"alert alert-error\">' + message + '</div>');\n        },\n        onComplete: function(id, fileName, responseJSON) {\n            if (responseJSON.success) {\n              $('#file-uploader').append('<img src=\"img/success.jpg\" alt=\"' + fileName + '\">');\n            }\n        }\n    });\n}\n\n// in your app create uploader as soon as the DOM is ready\n// don't wait for the window to load\nwindow.onload = createUploader;\n\n```\nDo you know why i got this error please ?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/412.\n. Write your own then. It's works really well for hundreds of other people.\nWhat are you doing wrong? What error messages do you get?\n\nI got it to work and it was my first dip into the javascript and jQuery\nworld.\nOn 30 Dec 2012 10:30, \"Phil Scheminger\" notifications@github.com wrote:\n\nI would like a refund on the $9 I spent on your script that does not work.\nI am not a stupid person... I actually have a MS in Computer Science and\nhave been doing web based PHP/jQuery programming for the past 12 years.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/555.\n. Oh and jQuery wasn't around until 2006....\nOn 30 Dec 2012 10:30, \"Phil Scheminger\" notifications@github.com wrote:\nI would like a refund on the $9 I spent on your script that does not work.\nI am not a stupid person... I actually have a MS in Computer Science and\nhave been doing web based PHP/jQuery programming for the past 12 years.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/555.\n. You have to name the parameter qqfile in your code, or set them with the\nfine uploads options.\nOn 22 Feb 2013 10:52, \"safr0\" notifications@github.com wrote:\nwell i'm facing the same issue.\npublic FineUploaderResult UploadFile(FineUpload upload, string extraParam1, int extraParam2)\nthis is what action asp.net mvc nuget package have on server controller\ni've not written any server code just testing it.\nand this is my endpoint\nendpoint: '@Url.Action(\"UploadFile\",\"Upload\")'\nits trying to make a following post\nPOST http://localhost:4247/Upload/UploadFile?qqfile=notes.txt 500\n(Internal Server Error)\nqqfile is no where on server. i tried changing both String Param and\nFineUpload upload param names to qqfile but this doesn't work. do tell me\nif i'm missing something here\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/564#issuecomment-13937830.\n. There is a working vs2010 version on gut hub.\n\nOr I could email you one.\nOn 17 Jan 2013 19:42, \"Geovani Martinez\" notifications@github.com wrote:\n\nHello,\nI'm creating a demo application (VS 2012, MVC4). I am using the fine\nuploader nuget package. Below is how I have my view configured.\n[image: view]https://f.cloud.github.com/assets/222680/75918/cd1b545c-60db-11e2-8f31-c72bbe0a016f.png\nThis is my controller (which never runs since the ModelBinding throws an\nerror, see below)\n[image: controller]https://f.cloud.github.com/assets/222680/75933/437e064e-60dc-11e2-9dec-c92cd46483a5.png\nThe issue I am experiencing is at the ModelBinder. The InputStream\nassignment throw out an exception. I have not been able to find a solution\nfor the provided error. Any clue as what could the issue be?\n[image: BindModel_Debug]https://f.cloud.github.com/assets/222680/75935/6762ec28-60dc-11e2-8045-eb0ef4edae0a.png\nThis is the solution tree (hoping it helps in any way)\n[image: Solution_Tree]https://f.cloud.github.com/assets/222680/75981/87f41ce0-60dd-11e2-90de-7cf5a4dbc55c.png\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/598.\n. I wrote that example....\n\nI will email you a VS2010 vB.net version.\nOn 18 Jan 2013 00:12, \"Geovani Martinez\" notifications@github.com wrote:\n\n\"It's in the server folder of this repo.\" - that is the same code on the\nnuget package that raises the exception.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/598#issuecomment-12399133.\n. What is your email address? Mine is che@talk21.com\nOn 18 Jan 2013 00:43, \"Geovani Martinez\" notifications@github.com wrote:\nthank you. I will convert it to c# and give it a shot. will try your\nexample with VS2010 as well.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/598#issuecomment-12400870.\n. What is your email address. Mine is che@talk21.com\nOn 18 Jan 2013 00:43, \"Geovani Martinez\" notifications@github.com wrote:\nthank you. I will convert it to c# and give it a shot. will try your\nexample with VS2010 as well.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/598#issuecomment-12400870.\n. Is your path to the test.aspx correct?\n\n/upload/test.aspx maybe? Or is upload a function inside the aspx file? I'm\nnot an asp person, more asp.net and MVC. There is a working MVC example on\ngit hub.\nChe\nOn 17 Apr 2013 16:21, \"Oscar Martinez\" notifications@github.com wrote:\n\nHey Guys,\nI'm getting the following error when I try to upload a file.\n[FineUploader] Error when attempting to parse xhr response text\n(SyntaxError: Unexpected token <) jquery.fineuploader-3.4.1.min.js:4\nqq.log jquery.fineuploader-3.4.1.min.js:4\nqq.FineUploaderBasic.log jquery.fineuploader-3.4.1.min.js:26\nqq.UploadHandler.log jquery.fineuploader-3.4.1.min.js:33\n(anonymous function) jquery.fineuploader-3.4.1.min.js:106\nHere my code\n$(document).ready(function () {\n$('#jquery-wrapped-fine-uploader').fineUploader({\nelement: $('#jquery-wrapped-fine-uploader'),\nrequest: {\nendpoint: '/Test.aspx/Upload'\n}\n});\n});\nVB.NET Code\n _\nPublic Function Upload() As String\n```\nDim a As String\na = \"sss\"\nReturn True\n```\nEnd Function\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/792\n.\n. Remove the aspx extension from the path. I use vbhtml not aspx pages sui\nmay be differences.\n\nHope it helps.\nOn 17 Apr 2013 22:24, \"Oscar Martinez\" notifications@github.com wrote:\n\nThe page is called Test.aspx and the function is called Upload\nI'm using ASP.NET\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/792#issuecomment-16536769\n.\n. The uploadFile parameter is qqfile by default.\nThis is changed by setting the \"inputName\" option in the view to a different value.\n\nHowever they must match in the controller and in the view where fileUploader instance is created.\n. ",
    "IronTurtle": "We used your latest code for a same run. I believe this is all the code we used for our server-side for file uploader:\n``` javascript\n// Settings\nvar settings = {\n    node_port: process.argv[2] || 3000,\n    uploadpath: __dirname + '/images/profile-pics/'\n};\napp.post('/upload', function(req, res) {\nuploadFile(req, settings.uploadpath, function(data) {\n    if(data.success){\n        res.send(JSON.stringify(data), {'Content-Type': 'text/plain'}, 200);\n\n      }\n    else\n        res.send(JSON.stringify(data), {'Content-Type': 'text/plain'}, 404);\n});\n\n});\n// Mainfunction to recieve and process the file upload data asynchronously\nvar uploadFile = function(req, targetdir, callback) {\n// Moves the uploaded file from temp directory to it's destination\n// and calls the callback with the JSON-data that could be returned.\nvar moveToDestination = function(sourcefile, targetfile) {\n    moveFile(sourcefile, targetfile, function(err) {\n        if(!err)\n            callback({success: true});\n        else\n            callback({success: false, error: err});\n    });\n};\n// Direct async xhr stream data upload, yeah baby.\nif(req.xhr) {\n    var fname = req.header('x-file-name')/*req.user.username + \".jpg\"*/;\n\n    // Be sure you can write to '/tmp/'\n    var tmpfile = '/tmp/'+uuid.v1();\n\n    // Open a temporary writestream\n    var ws = fs.createWriteStream(tmpfile);\n    ws.on('error', function(err) {\n        console.log(\"uploadFile() - req.xhr - could not open writestream.\");\n        callback({success: false, error: \"Sorry, could not open writestream.\"});\n    });\n    ws.on('close', function(err) {\n        moveToDestination(tmpfile, targetdir+fname);\n    });\n\n    // Writing filedata into writestream\n    req.on('data', function(data) {\n        ws.write(data);\n    });\n    req.on('end', function() {\n        ws.end();\n    });\n}\n\n// Old form-based upload\nelse {\n    moveToDestination(req.files.qqfile.path, targetdir+req.files.qqfile.name);\n}\n\n};\n// Moves a file asynchronously over partition borders\nvar moveFile = function(source, dest, callback) {\n    var is = fs.createReadStream(source)\nis.on('error', function(err) {\n    console.log('moveFile() - Could not open readstream.');\n    callback('Sorry, could not open readstream.')\n});\nis.on('end', function() {\n    fs.unlinkSync(source);\n    callback();\n});\n\nvar os = fs.createWriteStream(dest);\nos.on('error', function(err) {\n    console.log('moveFile() - Could not open writestream.');\n    callback('Sorry, could not open writestream.');\n});\n\nis.pipe(os);\n\n};\n```\n. ",
    "aventuralabs": "Have a look at https://github.com/senchalabs/connect/issues/709. It may solve your problem.\n. When the response parsing occurs if the response is not JSON it throws an error. Would it be possible as a final handler to search for 3 digit response code in received text?  \nOn Friday, December 14, 2012 at 11:04 AM, Ray Nicholus wrote:\n\nWhat do you mean by \"handled? Note that this is not a viable cross-browser option as there is no way to access response codes when the request is initiated by a traditional form submit (something we have to do in browsers that do not support the File API). Furthermore, non-200 response content is replaced in IE, by default, with a \"friendly\" error message loaded from disk. This is why all response codes should be 200 and all response content should be valid JSON.  \n\u2014\nReply to this email directly or view it on GitHub (https://github.com/valums/file-uploader/issues/536#issuecomment-11381267).\n. Sorry, that was poor communication on my part.  \n\nMy suggesting is due to the way that Node handles errors. Once an error is raised (413 for instance), it by default skips the rest of the middleware (including the image handler). It will then send a default error message, including the error code.\nI can of course intercept this with a global error handler at the end, but if I wrap all my errors in JSON and send success code 200 instead, it can cause errors in other parts of the site.\nAnother option could be to write path-dependent error handling, but I thought that this might be a nice fallback to add additional robustness.\nB  \nOn Friday, December 14, 2012 at 11:21 AM, Ray Nicholus wrote:\n\nIf you can modify the response content by adding a 3-digit response code, certainly you can include a success property in the response and ensure it is valid JSON, unless I'm missing something.  \n\u2014\nReply to this email directly or view it on GitHub (https://github.com/valums/file-uploader/issues/536#issuecomment-11381930).\n. Ray, I had a mistake. The status codes were being reported in my logs. Here is some sample output.\n\nError: Request Entity Too Large\n    at Object.exports.error (/Users/B/Sites/engaged/node_modules/express/node_modules/connect/lib/utils.js:43:13)\nWhat might be helpful is a parseHTML(html) option in the instantiation that would allow the user to respond to HTML feedback on their own should they need to.\nThanks for your help on this.\n. ",
    "xpleria": "I would love to help you. Let me know when you're releasing the 2.2 version. \n. Ok. I'll get the design ready for the 3.0 release then. The design will be from scratch. I'm free from the 22nd. Hope its not too late. Just let me know. Mail me a set of requirements like pages and details in pages to be displayed. I can even set up an upload in the demo where files remain for a short duration and get deleted after that so that users are convinced. All this done in php.\n. Sure. I've seen the pages. Leave me a message on my email.\n. I've renamed the php.php to ajax.php. So it includes your classes. I've put those line just above the classes.\n. I'm new to this. How do I check the JS console?\n. chrome 22\n. here's my page http://xpleria.com/demo.htm\n. [uploader] xhr - server response received fileuploader.js:1201\n[uploader] responseText =  fileuploader.js:1201\n[uploader] 'error' is not a valid property on the server response. fileuploader.js:333\nPOST http://xpleria.com/user/ajax.php?qqfile=2012-06-30+19.07.33.jpg  fileuploader.js:1566\n[uploader] xhr - server response received fileuploader.js:1201\n[uploader] responseText =  fileuploader.js:1201\n[uploader] 'error' is not a valid property on the server response. fileuploader.js:333\nPOST http://xpleria.com/user/ajax.php?qqfile=2012-06-30+19.07.25.jpg\n. Action path was wrong. But I've updated the action path and still I get the error.\n. You can find the serverside script here http://xpleria.com/ajax.txt\n. problem was in php.ini had to increase file size limits to 20MB.\nworking now.\nThanks!\n. also, not clear in the documentation as to how to use onError, i.e. in case there is an error and I need  to execute a function, how do I do it?\n. the error statement in die() is not returned. Hence it is not stored in $result. \n(so htmlspecialchars(json_encode($result), ENT_NOQUOTES) is not executed on the error statement returned by die()). \ndie() simply returns {'error':'increase post_max_size and upload_max_filesize to 20M'}\ninstead of [{'error':'increase post_max_size and upload_max_filesize to 20M'}]\n. Not sure how to use callbacks. Perhaps an example would help.\ntried using \n<script>     \n    function createUploader(){ \n            var uploader = new qq.FileUploader({\n            element: document.getElementById('file-uploader'),\n            multiple: true,\n            action: 'ajax.php',\n            debug: true\n            });\n        uploader.onComplete(alert(\"Success\"));\n    }\n    window.onload = createUploader;     \n</script>\n. ok. that's pretty much what I wanted. n I would like to suggest that you display the js code below each example. This issue is closed here. A really wonderful script.Thanks again!\n. ",
    "naamakat": "I'm using iPhone 4S which I upgraded to ios6.\nThe reason I think it's something concern with the caching is because the uploading works fine after I clear safari cookies+data (through the iPhone settings), and it works fine only once and then I need to clear again all Safari data.\n. Thanks so much for your quick response. I'll update to 2.1 and let you know if things are working fine.\n. Works great!! That's Awesome, thanks!\n. ",
    "sdeshmukh1983": "@rnicholus - sorry but i am not getting your sentence\n. ",
    "edmundjohnson": "Yes, the problem was on Firefox - apologies for the lack of detail in my post.\nI tend to assume that all non-IE browsers work the same, which isn't the case.\n. ",
    "sanojian": "I am using a rest API that defines the target location in the url string like destination/action/object\nFor example: /api/v1/folder1/upload/file?name=myname\nTo use this file-uploader I would need to destroy it and recreate it each time the user selects a different folder unless I am not understanding something.\n. I need a completely different endpoint for each file.  So for instance if I want to upload one file to \"folder1\" and one file to \"folder2\" the two API calls would be:\nhttp://myco.com/api/v1/folder1/upload/file?qqfile=filename1\nhttp://myco.com/api/v1/folder2/upload/file?qqfile=filename2\nApparently this is becoming more common in REST-style APIs to use dynamic URLS and filter them on the server side.  Query parameters are used for more specific information.\nSo, the ability to change the \"action\" parameter of the uploader after initialization is pretty important for my case. \n. Yes I know, I was petitioning to re-open this issue by giving my use-case as an example.  Perhaps I am going about it the wrong way?\n. Sure okay.  My UI includes of a tree structure of folders.  When a user selects a folder, information about that folder is displayed along with this excellent uploader.  Using the uploader results in files uploaded to the selected folder through a REST API.\nCurrently I need to destroy and recreate the uploader each time a folder is selected:\n        $('#fileUploader').empty();\n        myUploader = new qq.FileUploader({element: document.getElementById('fileUploader')...\nThis is an administrative application and so the UI is quite long-lived.  The above code could potentially be run 100s or even 1000s of times without refreshing the window.  I am unsure what the memory implications of this are.\n. ",
    "sp-niemand": "I've encountered a similar issue just now. \nI need to use the same uploader widget to upload files with different extensions to resources which have different URLs. For example: .gif images to http://example.com and .mp4 videos to http://example.com/video/, which is a reverse proxy for http://video.example.com.\n. Look like I've just necroposted. Thanks for a fast response.\n. ",
    "GitOffice": "When I set debug=true ,I found something as below in  firebug console. \"  [uploader] xhr - server response received  [uploader] responseText =  \"  ,and post option is the content  uploaded file in  firebug console\n.  CheLetton  ,Thanks a lot !  I am following your ,ASP.Net MVC VB.Net example of uploader!  It is great in IE, but it does not work in Chrome or FireFox. It seems like uploader can not find HttpPostedFile in ashx file.\n. @CheLetton  Thank you! I have the same issue as the users. http://stackoverflow.com/questions/6967577/valums-ajax-upload-w-c-sharp-ashx-returns-index-was-out-of-range-must-be-non.\nbtw: It is not I cant find the method from System.Web or find the file to upload , but ashx handler cant find. Of course, It is only my assumption. \n. @CheLetton  , I figure it out with your help.Thank you very very much!  some keys need to be careful for newbie. \n1 string qqFile = context.Request.QueryString[0].ToString();  the method can get file parameters from aspx page.\n2   context.Response.Write(\"{\\\"success\\\":true, \\\"msg\\\":\\\"upload successfully!\\\"}\");  this word of  \"success\" should be wrapped by quotation marks \n. ",
    "andrewvmail": "Actually thanks rnicholus but I got it figured it out from reading the past issue history. \nNow something that's kinda related and how I stumbled on this.\nTake a look at this drag and drop demo, it's acting funny in IE the crop doesn't appear..\n. oops \nHere you go http://html5.sapnagroup.com/demos/dragDropUploadsCrop/\n. Crazy that was fast reply. Cheers.\nOn Wed, Oct 17, 2012 at 2:16 PM, Ray Nicholus notifications@github.comwrote:\n\nI'll take a closer look for you in 4 or 5 hours.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/407#issuecomment-9544283.\n. \n",
    "Beav181078": "Hi CheLetton,\nThis may explain why its not working then. How do I go abouts loading your VB files into the website?\nP.S.\nThis is my first ASP.Net website, so im very new to this.\nBeav\n. ",
    "bodell": "The 3277 changes is odd.  I'll try and figure out what happened.  Yes, that\nwould make sense that it would have to be added to the default template.\n The use case is that I needed a way to add a remove button to each file in\nthe list, so that a user could choose to remove that file (even though it\nwas already uploaded and residing on the server). The fileId was so that I\ncould fine the remove button on the onComplete callback and attached the\ndelete url associated with the file.  While I realize I could have used the\nFileUploaderBasic to accomplish all of this by creating custom html for\nevery aspect, I really just wanted these couple of custom functions.  If\nthere is another way of accomplishing this without using FileUploaderBasic,\nI would love to hear it.\nThanks,\nBrandon\nOn Fri, Oct 19, 2012 at 7:27 PM, Ray Nicholus notifications@github.comwrote:\n\nAlso, something strange happened when you made your modifications. Github\nshows 3277 changes.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/pull/411#issuecomment-9627312.\n. \n",
    "julienchazal": "Thx a lot tellibus it worked !\nSorry i'm just good at HTML/CSS ;-)\n. just another question please, is it possible to resize file before uploading it to the target folder ?\nI tried  with no success : \n params:{\n                        resize : 1,\n                        width : 10,\n                        height: 0\n                   }\n. ",
    "CodeBuddy": "Great,\ndoes FileUploaderBasic have drag and drop methods too?\n. ",
    "johanosventer": "We use NuGet to download/manage external libraries (EntityFramework, MVC, ELMAH, jQuery, ect.) . When you use the NuGet console in Visual Studio, you can see which libraries have been updated, and then just download the newest  version of that library. No need to go check each one's website/git-repo just in case something changed.\nhttp://docs.nuget.org/docs/start-here/overview\nHave not made a Nuget Package myself though. Seems simple enough from the documentation.\nhttp://docs.nuget.org/docs/creating-packages/creating-and-publishing-a-package\n. ",
    "programcsharp": "Looks like you can run nuget on Mac/Linux via Mono: http://blog.lextudio.com/2013/01/how-to-use-nuget-on-mono-part-i/\nNuget is huge for the .NET crowd. If you're interested, I can send over some build scripts I use for generating and uploading packages on other projects.\n. I was able to get this working. I don't have time to genericize it and make a PR, but here's the basic gist to help others out.\n@rnicholus -- shouldn't be hard to change the fineuploader side, and I'm happy to send you the TinyMCE dialog code if you want to build out a quick plugin.\nSteps to do it...\nComment out event suppression in the \"dragover\" handler: \nfunction attachEvents() {\n            disposeSupport.attach(element, \"dragover\", function(e) {\n                if (!isValidFileDrag(e)) {\n                    return;\n                }\n                var effect = qq.ie() && qq.supportedFeatures.fileDrop ? null : e.dataTransfer.effectAllowed;\n                if (effect === \"move\" || effect === \"linkMove\") {\n                    e.dataTransfer.dropEffect = \"move\";\n                } else {\n                    e.dataTransfer.dropEffect = \"copy\";\n                }\n                //e.stopPropagation();\n                //e.preventDefault();\n            });\n-- this is so you can drag into TinyMce and move the insertion point around while dragging using their drag handling code.\nApply change from https://github.com/FineUploader/fine-uploader/pull/1819 so non-file drags aren't overridden:\nfunction isValidFileDrag(e) {\n            if (!qq.supportedFeatures.fileDrop) {\n                return false;\n            }\n            var effectTest, dt = e.dataTransfer, isSafari = qq.safari();\n            effectTest = qq.ie() && qq.supportedFeatures.fileDrop ? true : dt.effectAllowed !== \"none\";\n                    return dt && effectTest &&\n                                (\n                                        (dt.files && dt.files.length)                                      // Valid for drop events with files\n                                        || (!isSafari && dt.types.contains && dt.types.contains(\"Files\"))  // Valid in Chrome/Firefox\n                                        || (dt.types.includes && dt.types.includes(\"Files\"))               // Valid in IE\n                                    )\n        }\n-- half of that PR is OBE, but the effect check to find if files are included works great.\nIn the TinyMce setup call, hook the editor init and wire in a qq.DragAndDrop to catch drops on the TinyMce body:\n```\n            editor.on(\"init\", function ()\n            {\n                var doc = this.getDoc().body;\n            var dragAndDropModule = new qq.DragAndDrop({\n                dropZoneElements: [doc],\n                callbacks: {\n                    processingDroppedFiles: function ()\n                    {\n                        //TODO: display some sort of a \"processing\" or spinner graphic\n                    },\n                    processingDroppedFilesComplete: function (files, dropTarget)\n                    {\n                        var uploader = createUploader(editor);\n\n                        uploader.fineUploader(\"addFiles\", files);\n                    }\n                }\n            });\n        });\n\n```\nIn this example, createUploader() creates a TinyMce dialog with a fineuploader in it and uses that to upload the dropped files.\nFinally, apply some css to content_css to make the TinyMce body expand fully. If you don't do this, the bottom half of an empty editor won't catch drags:\n```\n    html { height: 100% }\nbody {\n    height: 100%;\n    margin: -13px 0 0 0;\n    padding: 8px;\n    box-sizing: border-box;\n}\n\n```. If you're not including the EXIF data in the resized images, please please please first rotate the original image to match the orientation set in the EXIF data before resizing. Otherwise there will be a bunch of extra work to re merge EXIF back and forth or pass the EXIF data along with the upload and do a second rotate step server side.\nThis is important to handle images uploaded by phones, which is a key use of this feature -- for phones particularly it would be nice to resize and upload a 500kb picture, for example, rather than the 5-10mb one you get using a normal file input. Phones tend to give you a rotated image and set the EXIF orientation header rather than an normally oriented image.\n. Maybe you could make it a flag you can set?\nIf you don't do the rotate on the client, you'd have to do it on the server. That would mean you couldn't use the direct S3 or Amazon uploads because you need to do the rotate. Most phones do this orientation stuff, particularly the iPhone.\nThe basic problem is that browsers don't respect the EXIF orientation header, so if you don't rotate to  normal you end up with sideways images when you upload from phones, like: https://code.google.com/p/chromium/issues/detail?id=56845\nAccording to https://bugs.webkit.org/show_bug.cgi?id=89052, standards require browsers to ignore the EXIF orientation header for backward compatibility:\n\"Note that some devices will \"tag\" an image with some metadata indicating its correct orientation, so image viewing software can do the necessary transformation themselves. Due to legacy compatibility restraints, Web browsers are required to ignore this data by default. A future level of this specification is expected to have a value that applies the metadata-specified transformation automatically.\"\nso this isn't something that will be fixed at the browser level -- unfortunately, the only way to do it is to rotate the image to standard top left.\n. ",
    "eneifert": "418\n. You are most welcome. Let me know if you need anything else.\n. ",
    "drobertson123": "Wow.  I checked out the Raphael docs and they are great.  Good source of inspiration.  Solid docs are a pain in the *** but they can really make a project useable.\n. ",
    "TBoons": "ahausammann,\nI'm having a problem in CF10 that wasn't happening in CF9. Did you ever figure it out?\n. ",
    "goinnn": "You are welcome, thanks for your quick response\nhttp://politicarock.cl/hjkl/wp-content/uploads/2011/10/copypaste.jpg :-)\n. ",
    "weberhofer": "I have had the IE problem and a patch is included, which at least works for me.\n. Currently the system guesses to receive an async upload when the $_GET['qqfile'] is set. But this variable is also set when a form upload happens. So the script starts falsely to handle a async upload instead of an file-upload.\nThe working solution is to determine whether the $_FILES['qqfile'] file upload variable is set - this one is never set in a async upload, the detection which upload should be handled is correct.\n. ",
    "mdeck": "I tried FF15, same issue.  I also have another PC running Xubuntu 12.04 & FF 16.0.1, same issue.\n. Wow, initially reported 2 years ago.\n. Sounds like it'd only affect xubuntu users, not regular ubuntu, as the thunar file manager is associated with the XFCE desktop.\n. https://bugzilla.mozilla.org/show_bug.cgi?id=609284#c8 comment 8 is pretty detailed on what works & what doesnt\n. ",
    "mayesgr": "Awesome: _getItemByFileId worked.  Thanks!  Now I can upgrade to file-uploader 2.1.2 and not worry about carrying my hacks forward.\n. ",
    "nghiaho12": "Actually, I think I found the cause of the problem. There was a 1 liner that caused it in my code:\njavascript\nvar uploader = new qq.FileUploader({\n        element: document.getElementById('file_uploader'),\n        multiple: true,\n        action: \"<?php echo site_url(\"member/upload_file\");?>\",\n        failedUploadTextDisplay: {mode: 'custom', responseProperty: 'error', enableTooltip: true},\n        maxConnections: 1,    \n        onSubmit: function(id, filename) {\n        ......\n        ......\n        // uploader.clearStoredFiles(); <--- caused problem, commenting out fixed it\n        }\n});\nI must have copied and paste some example code that had that line. The documentation says its only applicable if autoUpload is false, which by default is true.\nSo far everything works like a charm now!\n. ",
    "piotrmocko": "Hi,\nif you have disabled autoUpload and you want to know how many files were attached \nthen you can create following method\ngetStoredFilesCount: function(){\n    return this._storedFileIds.length;\n}\n. ",
    "petertellgren": "Yes, you are right, I was blindly looking at the rails log and nothing showed up there. However I can clearly see the incoming POST request in my nginx log: \n[30/Oct/2012:12:51:31 +0100] \"POST /postcards?qqfile=Tulips.jpg HTTP/1.1\" 408 0 \"http://lumado.minigrand.com/start\" \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)\"\nSo not a problem with plugin. my bad\n. ",
    "mike-aungsan": "What I mean is fileuploader use this following template for drop-area and show upload file list.\n\ntemplate: '' +\n            (!this._options.disableDefaultDropzone ? '{dragText}' : '') +\n            (!this._options.button ? '{uploadButtonText}' : '') +\n            (!this._options.listElement ? '' : '') +\n            '',\n\nIs there any way we can customize those div in our html file, rather then using template ?\nFor example, \n show drop area here \n somethign else\nshow upload file list\nsomething else\n show progrss bar here\nI understand we can pass template option as shown in example.\ntemplate: '' +\n                  '{dragText}' +\n                  '{uploadButtonText}' +\n                  '' +\n                '',\n. What I mean is fileuploader use this following template for drop-area and show upload file list.\n\ntemplate: '' +\n            (!this._options.disableDefaultDropzone ? '{dragText}' : '') +\n            (!this._options.button ? '{uploadButtonText}' : '') +\n            (!this._options.listElement ? '' : '') +\n            '',\n\nIs there any way we can customize those div in our html file, rather then using template ?\nFor example, \n show drop area here \n somethign else\nshow upload file list\nsomething else\n show progrss bar here\nI understand we can pass template option as shown in example.\ntemplate: '' +\n                  '{dragText}' +\n                  '{uploadButtonText}' +\n                  '' +\n                '',\n. Got it. Thanks.\n. ",
    "ymmark0": "Excellent, thanks, that did it. \nOn Nov 1, 2012, at 9:48 PM, Ray Nicholus wrote:\n\nUpdate: I meant to say remove the comma after the (inner) object literal, not after the the array literal. I've updated my response.\n\u2014\nReply to this email directly or view it on GitHub.\n. Excellent, thanks, that did it. \n\nOn Nov 1, 2012, at 9:48 PM, Ray Nicholus wrote:\n\nUpdate: I meant to say remove the comma after the (inner) object literal, not after the the array literal. I've updated my response.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "rainulf": "I wasn't sure of the intent instantiation of qqFileUploader since CONTENT_TYPE isn't always defined in $_SERVER unless upload occurs. But the check isn't really needed..\n. ",
    "rajaboini525": "Hi IPmen,\nI am also having same problem.\n. ",
    "IPmen": "It's MVC project C#.net\njs code\n        onComplete: function(id, fileName, responseJSON){\n            if (responseJSON) {\nServer code\n```\n [HttpPost]\n    public ActionResult StepTwo(HttpPostedFileBase file_)\n    {\n        var sample = Session[\"createSample\"] as Sample;\n    return Json(ConvertToSamplePageModel(sample));\n}\n\n```\nContent-Type    application/json; charset=utf-8\n. Server  ASP.NET Development Server/10.0.0.0\nDate    Fri, 02 Nov 2012 11:55:46 GMT\nX-AspNet-Version    4.0.30319\nX-AspNetMvc-Version 3.0\nCache-Control   private\nContent-Type    application/json; charset=utf-8\nContent-Length  405\nConnection  Close\n. ",
    "owenmead": "Was getting some errors with content type \"text/plain\"\nHad much better results with \"text/html\"\n. I'll have a deeper look at it today. The onComplete callback was not getting a responseJSON.success with \"text/plain\", yet it was with \"text/html\". Today I'll see if I can figure out why.\nRegardless if it is \"text/plain\" or \"text/html\" using \"application/json\" will defiantly break things in IE since it doesn't know to handle it in the browser, then prompts to download.\n. --- This is using text/plain ------\nLooking at IE's network log:\nResponse headers:\nContent-Type    text/plain; charset=utf-8\nResponse body:\n{\"path\": \"/media/cache/69/27/69278d2dfed114b767ac4f19532de5a2.jpg\", \"success\": true, \"filename\": \"Tulips5.jpg\"}\nFrom the JS Console with debug:\nLOG: [uploader] iframe loaded \nLOG: [uploader] converting iframe's innerHTML to JSON \nLOG: [uploader] innerHTML =   \nLOG: [object Object] \n--- This is using text/html ------\nLooking at IE's network log:\nResponse headers:\nContent-Type    text/html; charset=utf-8\nResponse body:\n{\"path\": \"/media/cache/64/2d/642d0f910d9e0b524a1cb85fec63c98c.jpg\", \"success\": true, \"filename\": \"Penguins17.jpg\"}\nFrom the JS Console with debug:\nLOG: [uploader] iframe loaded \nLOG: [uploader] converting iframe's innerHTML to JSON \nLOG: [uploader] innerHTML = {\"path\": \"/media/cache/64/2d/642d0f910d9e0b524a1cb85fec63c98c.jpg\", \"success\": true, \"filename\": \"Penguins17.jpg\"} \nLOG: [object Object] \n\nSeems that when using \"text/plain\" the response in the debug log is surrounded with a  which would throw off the JSON parser. Putting a breakpoint in my onComplete verifies that I'm essentially getting nothing back via the responseJSON parameter.\nServer seems to be sending back the proper response body.\nI know you mentioned in your notes not to use text/html esp if returning HTML in your response, but I can't find another way around it.\nUsing : IE 9.0  under  Window 7\n. Working with:\nhttps://github.com/GoodCloud/django-ajax-uploader\nIt uses your very well built JS uploader:\nhttps://github.com/GoodCloud/django-ajax-uploader/blob/master/ajaxuploader/static/ajaxuploader/js/fileuploader.js\nalthough by the looks to be about 7 months old.\nMy \"error\" wasn't so much an error. It was the fact that the responseJSON wasn't coming back with any attributes set. So the success attribute was missing, and thus resolving false. The response was wrapped in  tags. Most likely this is fixed with the updated file-uploader.js\nI have sent an issue to the other project suggesting they upgrade the outdated javascript file:\nhttps://github.com/GoodCloud/django-ajax-uploader/issues/36\n. ",
    "skoczen": "Hey there,\nI'm the maintainer of the aforementioned third-party wrapper, so it's my fault. :)  \nI generally don't have enough time to keep up the projects I'm maintainer on, let alone keep tabs on the libs they use - I try to use package managers to mitigate this wherever possible.  Is there any system for notification on new releases such as this one that I could subscribe to to keep things current?\nThanks for the help, and for writing a great library.\n-Steven\n. Hey, \nDidn't know about the twitter feed.\nAnything I can script with IFTTT would be fantastic - I'm probably going to want an email at the end of the day, but that's certainly not your responsibility.\nIf only twitter hadn't changed its TOS to exclude IFTTT, it'd be easy.  I'll set up a script somehow to get it working though.  Thanks for the info and great work!\n. ",
    "prashant7july": "I am using the Firefox 11.0 with firebug\n. \n```\n\n\n\n\n\n Upload now\n\n\njQuery(document).ready(function() {\n        var manualuploader = new qq.FileUploader({\n            element: document.getElementById('manual-fine-uploader'),\n                    multiple: true,\n            action: '../server/php.php',\n            autoUpload: false,\n            //allowedExtensions: ['jpeg', 'jpg', 'txt', 'zip', 'docx', 'doc'],\n            allowedExtensions: ['asf', 'avi', 'mpeg', 'mpg', 'wmv', 'vob', 'mov', 'mp4', 'flv'],\n            debug: true,\n            uploadButtonText: '<i class=\"icon-plus icon-white\"></i>Select Files'\n        });\n\n        $('#triggerUpload').click(function() {\n            manualuploader.uploadStoredFiles();\n        });\n});\n\n```\nHere is the basic html/js code. when i am using autoUpload: true then it work properly\n. How to upload my complete zip file in this github...... (I am new user)\nactually in the live server demo module only set the action: 'do-nothing.html',\nand in this html written {success:true} so it always give success during Select and after Upload File\n. STEP OF CHECKING\nSuppose first time \u201cSelect File\u201d button select One file and then Click\n\u201cUpload Now\u201d It work file and Upload But second time again one other file\nUpload by \u201cSelect File\u201d button and then click \u201cUpload now\u201d It gives\nOn Sat, Nov 3, 2012 at 11:13 AM, Prashant Shekher\nprashant7july@gmail.comwrote:\n\nOn Fri, Nov 2, 2012 at 6:52 PM, Ray Nicholus notifications@github.comwrote:\n\nI'm not sure what you are asking. I am also not able to reproduce this\nissue. I tested w/ autoUpload set to false in FF 16 - no issues.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/444#issuecomment-10014008.\n\n\nThanks and Regard,\nPrashant Shekher\nSoftware Eng.\n+919716004560\nSkype ID: prashant7july\n\n\nThanks and Regard,\nPrashant Shekher\nSoftware Eng.\n+919716004560\nSkype ID: prashant7july\n. ",
    "udayakiran": "OK. Thanks, rnicholus. Having an Ajax request in onComplete would be what i am going to try.\n. ",
    "andychengyang": "About response text, I think if there is one parameter like response type that can define the response text format(JSON, xml, html, and so on). That will be better.\nThanks.\n. About response text, I think if there is one parameter like response type that can define the response text format(JSON, xml, html, and so on). That will be better.\nThanks.\n. ",
    "koichirose": "The main benefit is managing all the files with a single server request.\nExample: I create a new product, with 3 images.\nIf I have 3 different request I'd have no way to know which product they refer to, since it's a new product and I don't have the ID. I should save the product, return the id and then save each image for that product (and it would require some non trivial changes on my code).\nIs that planned in the future?\nThanks\n. Yes, but since I don't have a product id yet, I'd have to change all my code to allow a two-step form submission (submit form first, get the product id, submit images).\nNot feasible for us right now.\nThank you anyway for the very quick responses.\n. There's no problem in your solution, it's just that right now we don't have time to implement it over our existing solution.\n. ",
    "omsoft": "I was wondering if there was a specific option from file-uploader plugin. I don't wanna show that list in some cases.\n. Ok, no problem. Thank you\n. ",
    "julianshaw2000": "thanks,  I used the \"qq-upload-list\" class which worked.\n. ",
    "lubosdz": "Thank you very much for fast response.\nThe problem is, that second example throw javascript error \"TypeError: this.setParams is not a function\".\nCheckbox boolean - JSON converts into string \"true\" or \"false\" which in PHP test empty($value) always evaluates to true.\nHere is full code - it is actually widget - not sure if this helps you:\n``` php\n$this->widget('ext.EAjaxUpload.EAjaxUpload', array(\n'id'=>'uploadAjaxPdf',\n'postParams'=>array(\n    \"someStaticValue\" => '$(\"#ofield-compile-pdf\").is(\":checked\") ? 1 : 0',\n),\n'config'=>array(\n       'action'=>Yii::app()->createUrl('ipdf/formular/upload', array(\n            'uploadType'=>'pdf-template', \n        )),\n       'allowedExtensions'=>array(\"pdf\"), // case insensitive\n       'sizeLimit'=>IpdfResource::MAX_FILE_SIZE, // in bytes\n       'minSizeLimit'=>IpdfResource::MIN_FILE_SIZE,\n   'onComplete'=>'js:function(id, fileName, responseJSON){ document.location.href=\"/some/Url\" }',\n\n   'onSubmit'=>'js:function(file, ext){\n        var comp=$(\"#ofield-compile-pdf\").is(\":checked\") ? 1 : 0;\n        var del=$(\"#ofield-delete-previous-pdf\").is(\":checked\") ? 1 : 0;\n        //alert(\"compile:\"+comp+\", delete:\"+del); \n        this.setParams({\"compile\" : comp, \"delete\" : del});\n   }',\n\n)\n));\n```\nThank you very much.\nLubos\n. ",
    "JonoB": "Sorry, missed that.\nCBA installing and working out how to use gradle, so I will just wait a few days.\n. :+1: \n. Dump IE7 support as soon as possible. We don't allow any browsers older than IE8 in our apps.\n. @thomas83 You can challenge me as much as you want, starting now if you wish. No need to threaten me.\nAs far as I am concerned, IE7 is a non-entity. In case you missed it, the first item in this issue clearly says: \"voice your opinion\". That's what I am doing.  So yeah, I don't take back what I say.\nI can totally understand @rnicholus frustration in writing code to support that piece of crap browser. As such, I fully support him if he wishes to dump support for IE7. \n. @shenhf Really? IE7 usage is less than 1%\nhttp://www.w3schools.com/browsers/browsers_explorer.asp\n. Thanks Ray, onValidate() was what I was looking for.\nFor anyone interested, this is how I did it:\n``` javascript\nselectedFiles = [];\nvar uploader = new qq.FineUploaderBasic({\n    ...\n    callbacks: {\n        onValidate: function(fileOrBlobData) {\n            var fileName = fileOrBlobData.name;\n            if (qq.indexOf(selectedFiles, fileName) === -1) {\n                selectedFiles.push(fileName);\n                return true;\n            }\n            return false;\n        }\n    ...\n)};\n``\n. Btw, you may want to consider adding an option to FineUploaderBasic:preventDuplicateFileNames` or something similar.\nI can't really think of a reason why someone would want to upload duplicate file names during an upload.\n. Thanks Ray, that's awesome. Implemented and edited code above. I'm glad I paid for FineUploader with this kind of support :+1: \n. And, to add another option if using jquery:\nif (jQuery.inArray(fileName, selectedFiles) === -1) {\n. Sorry about posting here.\nThanks for the help.\n. Sorry about posting here.\nThanks for the help.\n. I have been working with another JS uploader (www.dropzonejs.com) that handles uploads this way (i.e. any form elements get submitted along with the file upload). Its a nice way of doing things, and does make simple/straightforward scenarios very easy to implement.\nI think that there probably is a use case for a simple uploader that automatically sends form fields along with the file(s). I'm not quite sure why chunking would not be supported - is it not possible to send the form data along with each chunk (just like you currently send the uuid, for example)?\nFor what its worth, I have found FineUploader easier to extend, and customised it appropriately.\nI make use of modified templates when adding files to FineUploader that automatically creates the necessary form fields. Once each file has completed uploading (and stored the uuid server side), I fire off a separate ajax request for the form fields, along with the uuid. The server then automatically matches up the uuid and saves the form fields appropriately.\n. Yep, I am aware of the params and setParams - as you point out, reading an existing form and sending the data along with the files would be useful.\n. ",
    "ibrahimkais": "I'm sorry, It seems that I didn't explain correctly my problem. after some investigations and referring to\nhttp://stackoverflow.com/questions/4884920/mvc3-valums-ajax-file-upload \nwhich explain how to manage the uploaded file according to the browser type\nat the condition that check for the qqfile query string it returns false when I upload with the IE\nif (String.IsNullOrEmpty(Request[\"qqfile\"]))\n{\n       // IE\n       HttpPostedFileBase httpPostedFile = Request.Files[0];\n       if (httpPostedFile == null)\n           throw new ArgumentException(\"No file uploaded\");\n       stream = httpPostedFile.InputStream;\n       fileName = Path.GetFileName(httpPostedFile.FileName);\n       contentType = httpPostedFile.ContentType;\n}\nSo it goes to the else and execute the other browsers setps\nelse\n{\n       //Webkit, Mozilla\n        stream = Request.InputStream;\n        fileName = Request[\"qqfile\"];\n}\nwhich make the method   public virtual byte[] ValidatePicture(byte[] pictureBinary, string mimeType) at PictureService.cs didn't understand the posted binary as I said in the first comment\nSo I changed the condition \nif (String.IsNullOrEmpty(Request[\"qqfile\"]))  \nto be \nif (Request.Browser.Browser == \"IE\")\nWhich executed correctly now\n. I tested it on IE9 and firefox and no problems and the problem is the condition \nif (String.IsNullOrEmpty(Request[\"qqfile\"])) \nreturns false when it should return true\n. do you know a pc cross-browser testing tool ??\n. @prashant7july Please visit my issue\nhttps://github.com/valums/file-uploader/issues/464\n. ",
    "lafeber": "This issue might be related? https://groups.google.com/forum/?fromgroups=#!topic/prototype-scriptaculous/WOh5JAbw8Jc\n. So there's no way to have it return anything but json? Currently I have it returning html, which works fine in Firefox.\n. It's normal in Rails 3 to render a .js.erb partial after an xhr request. You can have javascript in the partial which is executed. The controller passes objects which you can also use in that partial. Example:\n$('#pictures').append('<%=escape_javascript render(:partial => 'picture', :locals => {:picture => @picture}) %>')\nThe 'picture' partial already exists because it's used to render the picture html.\nSo basically, I want my response to be html. I understand I can also use the resulting json to somehow build the html I need in the onComplete function, but it's going to be uglier than my one line .js.erb partial!\nIt's not a bug as @rnicholus mentions, but it's an issue for everyone who uses the file-uploader in combination with Rails.\n. Yes. The fact that the server response has to be valid json is slightly annoying for Rails programmers. Thank you for your quick response though, I'll include the entire rails partial in a json object as @borut-t suggested, then use that in the onComplete function!\n. ",
    "kristerkari": "If you look at the docs, it says:\nonComplete(String id, String fileName, Object responseJSON) - called when the file upload has finished.\n. ",
    "dtscript": "More information when i uploading file than click closed dialog but i notice file has been uploaded i need cancel event upload Do you have api or solution?\n. ",
    "tristanbes": "Ok thx, my bad, i completely missed that part of the documentation. Issue closed.\n. ",
    "MScottBlake": "It is true that classes are usually used for styling, but they are also used for identifying elements to assign handlers. In one situation, I have to include an entire template to simply attach a second class to the Cancel link so that my click handler don't grab it as well.\nWhile this works perfectly fine, it limits my ability to upgrade later and does not make it as clean of an upgrade as it could be.\n. In normal cases, yes I could. In this case, there is an all inclusive click handler for all a tags. I needed to add a class that is in the exception list in order for that handler to not catch it. Like I said, I was able to do it by using the template feature, but it just seems like overkill to change one word.\n. ",
    "aucman": "Yes i figure that out...but you must use jquery wrapper if I am correct?..if not can you show me \"normal way\"\nTo answer your post I was reading it in normal var uploader = new qq.FineUploader({...\nAll my problem lies in onComplete. This is my fine uploader. I upload images, pass parameters and then show thumbnail.\nThe problem is and I do not know why this happen...is it jquery fault or fine uploader? I get TWO alerts ( see alert(\"Test test\");). WTF?? How can one post and append make two server calls....and I also get two thumbanils. i use mvc 4\n``` javascript\n\n\n\n    $(function() {\n        $('#fine-uploader').fineUploader({\n            multiple: true,\n            request: {\n                endpoint: '@Url.Action(\"ImagesUpload\", \"Image\", new { area = \"Images\"  })'\n            },\n            validation: {\n                allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],\n                sizeLimit: 20971520,\n                stopOnFirstInvalidFile: true\n            },\n            text: {\n                uploadButton: 'Upload a file',\n                cancelButton: 'Cancel',\n                retryButton: 'Retry',\n                failUpload: 'Upload failed',\n                dragZone: 'Drop files here to upload',\n                formatProgress: \"{percent}% of {total_size}\",\n                waitingForResponse: \"Processing...\"\n            },\n            messages: {\n                typeError: \"{file} has an invalid extension. Valid extension(s): {extensions}.\",\n                sizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\n                minSizeError: \"{file} is too small, minimum file size is {minSizeLimit}.\",\n                emptyError: \"{file} is empty, please select files again without it.\",\n                noFilesError: \"No files to upload.\",\n                onLeave: \"The files are being uploaded, if you leave now the upload will be cancelled.\"\n            },\n            showMessage: function(message) {\n                $.confirm({\n                    'title': 'Message',\n                    'message': message,\n                    'buttons': {\n                        '@CommonTrl.Ok': {\n                            'class': 'blue',\n                            'action': function() {\n                                //do nothing\n                            }\n                        }\n                    }\n                });\n            }\n        }).on('complete', function(event, id, filename, responseJSON) {\n            if (responseJSON.success == false && responseJSON.limitReached) {\n                $.confirm({\n                    'title': '@CommonTrl.Message',\n                    'message': '@ImagesTrl.LimitReached ' + responseJSON.numberOfAllowed,\n                    'buttons': {\n                        '@CommonTrl.Ok': {\n                            'class': 'blue',\n                            'action': function() {\n                                //do nothing\n                            }\n                        }\n                    }\n                });\n            } else {\n                $.ajax({\n                    type: 'POST',\n                    url: '@Url.Action(\"GetImagePartial\", \"Image\", new { area = \"Images\" })',\n                    data:\n                        {\n                            __RequestVerificationToken: $('input[name=__RequestVerificationToken]').val(),\n                            idImage: responseJSON.idImage,\n                            showDescriptionOptions: responseJSON.showDescriptionOptions\n                        },\n                    complete: function(jqXHR, textStatus) {\n                        alert(\"Test test\");\n                    },\n                    success: function(image) {\n                        $('#Images-' + responseJSON.imageType).append(image);\n                    }\n                });\n            }\n        }).on('submit', function (event, id, filename) {\n            $(this).fineUploader('setParams', { 'idSourceTable': window.idSourceTable, 'imageType': window.imageType, 'showDescriptionOptions': window.showDescriptionOptions });\n        });\n    });\n\n```\n. Tnx everything is working now...\nHere is my code in case someone else might use it. The problem was I did not know that you can do like this this.setParams({ ... }); Maybe a few more examples in docs might be a good idea\njavascript\n<script type=\"text/javascript\">\n    var uploader = new qq.FineUploader({\n        element: document.getElementById('fine-uploader'),\n        multiple: true,\n        request: {\n            endpoint: '@Url.Action(\"ImagesUpload\", \"Image\", new { area = \"Images\"  })'\n        },\n        validation: {\n            allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],\n            sizeLimit: 20971520,\n            stopOnFirstInvalidFile: true\n        },\n        text: {\n            uploadButton: 'Upload a file',\n            cancelButton: 'Cancel',\n            retryButton: 'Retry',\n            failUpload: 'Upload failed',\n            dragZone: 'Drop files here to upload',\n            formatProgress: \"{percent}% of {total_size}\",\n            waitingForResponse: \"Processing...\"\n        },\n        messages: {\n            typeError: \"{file} has an invalid extension. Valid extension(s): {extensions}.\",\n            sizeError: \"{file} is too large, maximum file size is {sizeLimit}.\",\n            minSizeError: \"{file} is too small, minimum file size is {minSizeLimit}.\",\n            emptyError: \"{file} is empty, please select files again without it.\",\n            noFilesError: \"No files to upload.\",\n            onLeave: \"The files are being uploaded, if you leave now the upload will be cancelled.\"\n        },\n        callbacks: {\n            onSubmit: function(id, fileName) {\n                this.setParams({ 'idSourceTable': window.idSourceTable, 'imageType': window.imageType, 'showDescriptionOptions': window.showDescriptionOptions });\n            },\n            onComplete: function (id, fileName, responseJSON) {\n                if (responseJSON.success == false && responseJSON.limitReached) {\n                    $.confirm({\n                        'title': '@CommonTrl.Message',\n                        'message': '@ImagesTrl.LimitReached ' + responseJSON.numberOfAllowed,\n                        'buttons': {\n                            '@CommonTrl.Ok': {\n                                'class': 'blue',\n                                'action': function () {\n                                    //do nothing\n                                }\n                            }\n                        }\n                    });\n                } else {\n                    $.ajax({\n                        type: 'POST',\n                        url: '@Url.Action(\"GetImagePartial\", \"Image\", new { area = \"Images\" })',\n                        data:\n                            {\n                                __RequestVerificationToken: $('input[name=__RequestVerificationToken]').val(),\n                                idImage: responseJSON.idImage,\n                                showDescriptionOptions: responseJSON.showDescriptionOptions\n                            },\n                        complete: function (jqXHR, textStatus) {\n                            alert(\"fsdfsd\");\n                        },\n                        success: function (image) {\n                            $('#Images-' + responseJSON.imageType).append(image);\n                        }\n                    });\n                }\n            }\n        },\n        showMessage: function (message) {\n            $.confirm({\n                'title': 'Message',\n                'message': message,\n                'buttons': {\n                    '@CommonTrl.Ok': {\n                        'class': 'blue',\n                        'action': function() {\n                            //do nothing\n                        }\n                    }\n                }\n            });\n        }    \n    });\n</script>\n. ",
    "shane3xsds": "This is where the previous method is mentioned. I had been trying to get it to work with this. Quite frustrating. http://blog.fineuploader.com/2012/12/05/include-params-in-the-request-body-or-the-query-string/\n. ",
    "pradeepbrh": "@aucman Thanks for your code. I was stuck at some point and it gave me idea to resolve the issue.. ",
    "wiredmonkey": "Hi\nThanks for your prompt feedback. I actually realised that an error was being captured and sent to the onError method whereas Firefox did not. All sorted now.\nShaun\n. Ok. I'll sort this out just now.\nCheers\nShaun\n. Do you have a email address that I can send you details to? The website isn't live yet.\n. I'm getting the following from IE8:\n[FineUploader] Sending upload request for qq-upload-handler-iframe2\n[FineUploader] Received response for qq-upload-handler-iframe2\n[FineUploader] Error when attempting to access iframe during handling upload response (Error: Permission denied)\n[FineUploader] iframe loaded\n[FineUploader] Error when attempting to parse form upload response (Error: Permission denied)\n. What's the easiest way to do this in IE8? Does the firebug lite provide this?\n. It's looking like a ColdFusion issue, I tested the upload/resize directly with a simple file upload and found that it on some files cause Internet Explorer to display an 'Internet Explorer cannot display the webpage error which would make sense about the wrong response code. This only seems to have when the imageresize functionality is run, you don't happen to use CF do you? ;)\n. It's to avoid having to alter the how the upload works in the CMS, it currently only supports form uploads and would require me writing to different scripts to upload.\n. yeah that's what I meant. It's been a long day!\n. But it still sends it as a XHR with this option set as true?\n. Yeah, I'm looking to force all browsers to use the same method of upload i.e. multipart encoded POST requests so I can deal with it easily in one go. Not too worried about the File API as my clients users tend to be IE8 downwards :(\n. Hi Ray\nPlease close it. thanks for your help\nShaun\n\nFrom: Ray Nicholus [notifications@github.com]\nSent: 28 November 2012 23:13\nTo: valums/file-uploader\nCc: Shaun Perry\nSubject: Re: [file-uploader] Forcing upload to run via form data and iframe? (#502)\nCan this be closed, or did you have further questions on this topic?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/502#issuecomment-10827591.\n. Sure. I am building functionality to allows kids to upload images and files. I want to make it really obvious and specify exact buttons i.e. Upload an image and Upload a document. I was hoping I could pass in two buttons but I realise this would cause issues in IE as the user needs to click the input element themselves. What you have mentioned would be good, but I\u2019ll look at creating a separate uploader for the time being.\nThanks for your help. You guys are very prompt and helpful, great project!\nBest\nShaun\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: 04 December 2012 01:32\nTo: valums/file-uploader\nCc: Shaun Perry\nSubject: Re: [file-uploader] Is it possible to set multiple upload buttons but call the same FineUploader? (#508)\nThere is currently no way to do this. You will need to create a new\nuploader for each button. Fine Uploader could be modified with a new\noption that accepts an array of \"button\" elements. The uploader would need\nto hidden input elements as a children of each of these buttons.\nCan you please describe your specific use case?\nOn Mon, Dec 3, 2012 at 5:11 PM, wiredmonkey notifications@github.com<mailto:notifications@github.com>wrote:\n\nHi\nIs it possible to set multiple upload buttons but call the same\nFineUploader? or will this cause issues in IE?\nCheers\nShaun\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/508.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/508#issuecomment-10980433.\n. ",
    "pbauerochse": "In my case I'm writing an application which is using an internally developed framework, which already has some basic classes for UploadResponses. But that class unfortunately is not compatible with the structure fineuploader needs.\nTo be concrete:\nUploadResponse does not have the boolean property \"success\" but instead has a \"status\" enumeration which determines whether the upload was a success. In my case it would be nice to evaluate the server response from within the onComplete handler and let that handler return whether the upload was a success or not.\nI would then implement the onComplete handler like so\n.on('complete', function(event, id, fileName, responseJSON) {\n         // custom validation of responseJSON here\n         return responseJSON.status === 'SUCCESS';\n});\nRight now I would have to create a custom Object which introduces the boolean success property and a string error message property. This is not a big deal actually but kind of unpleasant since I'm duplicating a property which my framework already provides.\nWhat do you think?\nCheers\n. Kind of, yes. Of course I can extend the frameworks classes to alter the response but I would then duplicate an existing property (status) which is already indicating a success/error. It's a custom framework which is maintained by another department in my company.\n. ",
    "pinkopalla": "Well, I have a similar problem! Why on the official site http://fineuploader.com is reported that the fineuploader.js file is expected in client directory, i.e.\n\nwhile it is not available in the downloadable archive?\n. ",
    "zibibbalibbo": "With your example all is running, but we wanted to use struts and to receive the uploaded file through a DispatchAction reading our object from the request. Is it possible? Or the fineUpdater can only be used with a servlet?\n. ",
    "obiwanus": "classes option seems to exist only in FineUploader, so if we add these properties to classes, users of FineUploaderBasic will still have no means to change the default classes of UploadButton except overriding full methods. Please correct me if I am wrong.\nWhat I would suggest is to add another option group to FineUploaderBasic so that we could define these classes during creation of a new instance of it.\n. Yes, this sounds good. I could provide a pull request tomorrow if you don't mind.\n. ",
    "droplab": "After looking through the source code it appears this won't work as I'm expecting with autoUpload option off. It's easy enough to track files in the queue using the onSubmit handler for my purposes. Thanks for the excellent work on this library.\n. Actually, I figured it out. You can make this work by using the \"acceptFiles\" property in the validation options. I simply added \"image/*;\". \nhttps://github.com/valums/file-uploader/blob/master/docs/options-fineuploaderbasic.md#validation-option-properties\n. ",
    "goncalvesjoao": "+1 I have the same problem, I need to set the autoUpload to false but now I can't get the current number of queued files. :/\nGreat work by the way :)\n. ",
    "xiaosong": "if we want to upload some image on some internet pages, we should download it, and upload to our own site. but ,if paste enabled, we needn't to download it ,only copy and paste, it can be uploaded too.\n. I'm looking forward to see this function added!\n. addBlobs is enough,tks!\n. Endpoint may be a nice solution, nowtime we can support Chrome only ,I don't want to see the filesize increase because of this unimportant request, but thank you for your answer!\n. when paste to upload a image, i got a blob object by event.clipboardData.items, i want to use addFiles to upload the blob but it is not supported\n. Thank you! \n. ",
    "gerardo": "This would be very useful as an additional method for uploading files. Here's the pasteboard implementation (in coffeescript).\nBut anyway, is there any way right now of uploading a file, given a Blob or File object?. \n. It would be useful to pass a blob or file object to file-uploaded if the method for receiving such file is external to this plugin, like the \"clipboardData\" approach from pasteboard. Also, it seems like that's the standard way offered by the File API. \nAnother use case: I would like to pre-process an image before uploading, maybe resize it using something like load-image. \n. ",
    "relipse": "Is there a working example of this? I cannot seem to get the paste to work? Do i just press ctrl+v on the page?\n. Oh now i see, looking great. Btw, does anything work besides a textarea or <input text element for pasting?\n. ",
    "akre54": "Just upgraded to 3.0 (awesome work btw), and everything's golden. thanks.\n. That would be great. Usually it seems like plugins handle a variation of this pattern:\n$.fn.fineUploader = (options) {\n    $(this).each(index, element) {\n         options = $.merge(options, {element: element});\n         new Uploader(options);\n         ....\n    }\n}\nwhich will work for a single element or a group of elements.\n(ah thanks, good catch. At least I'm using it correctly in my code... :sweat_smile: )\n. Excellent. Thanks for implementing this so fast. I'll plug it in this week. \n. I'm still having trouble while using fineUploaderBasic. I'm finding my element isn't getting correctly attached without giving it a separate button element, and even then I don't see a way to click the input. Do you have an example of how the basic uploader would be used with jQuery? (or even a qq.fineUploaderBasic example that I can use?).\nHere's my new markup:\nhtml\n<div class=\"editor-image-uploader\">\n    <div class=\"editor-image-uploader-btn\"></div>\n</div>\nand js:\njavascript\n$('.editor-image-uploader').fineUploader({\n    uploaderType: 'basic',\n    button: $('.editor-image-uploader-btn'),\n    multiple: false,\n    request: {\n        endpoint: '/upload',\n        inputName: 'Project[workspace_image]',\n        forceMultipart: true,\n        params: {\n            type: 'Project',\n            class_id: this.classModel.id\n        },\n    },\n    validation: {\n        allowedExtensions: ['jpg', 'jpeg', 'png', 'gif'],\n        acceptFiles: 'image/*',\n        sizeLimit: 2097152, // 2 MB\n    }\n}).on('complete', function(event, id, filename, response) {\n    // insert response file into editor\n});\nThanks for your fast responses.\n. @rnicholus you're right, I was missing the purpose of inputName (I thought it changed the <input>'s name property during element creation).\nI am now using the var uploader = new qq.FineUploaderBasic({ ... }) form, but it seems like it doesn't have the behavior I want. It looks like its only job is to create an input element which has hard-coded CSS properties (like setting the font to Arial and the fontSize to 118px), which is strongly undesirable in my project.\nAll I need is to have a link that triggers an upload action and has a callback on success. Is the only way for me to do this to use FineUploader with a template?\n. @rnicholus Perfect. Worked like a charm.\nI'd been down too many rabbit holes and missed the obvious solution which was to use the <a> tag as both the jquery selector and FUB button property. Thanks for your help.\n. yup, I'll give that a go. My intuition was that\njavascript\n$('#myUploaderButton').fineUploader({\n   uploaderType: 'basic',\n   ...\n});\nwould have sufficed, since typically jQuery plugins add their own inner markdown and necessary elements to the attached element, rather than requiring a separate child element. It's an easy enough workaround, and I'm happy with how it looks now. thanks for your help.\n. want me to make a pull?\n. require/commonjs is just a way to avoid polluting the global namespace and allows you to only specify the dependencies you absolutely need for your code to function. On the browser, this also means support for asynchronously loading js file dependencies only when needed (instead of having a bunch of server-side switches in your <head> tag, for instance).\nImagine Foo, Bar, and Baz are classes, perhaps in different files, but that get loaded onto the samedocument (shared window object).\n``` javascript\nvar Foo = function() {\n  qq = qq || new FineUploader; // implicitly scoped to global namespace (window)\n  qq.doStuff();\n  qq.otherStuff = function() { alert('hello') }\n}\nvar Bar = function() {\n  qq.doStuff(); // works, but undesirable, since we haven't explicitly asked for FineUploader in this class.\n  qq.otherStuff(); // alerts 'hello'\n}\nvar Baz = function() {\n  qq = qq || new FineUploader // uses the qq created in Foo\n  qq.otherStuff(); // alerts 'hello', undesirable\n}\n```\nwith require:\n``` javascript\nvar Foo = function() {\n  var qq = require('FineUploader')\n  qq.doStuff();\n  qq.otherStuff = function() { alert('hello') }\n}\nvar Bar = function() {\n  qq.doStuff(); // throws TypeError\n  qq.otherStuff(); // throws TypeError\n}\nvar Baz = function() {\n  var qq  = require('FineUploader')\n  qq.otherStuff(); // throws TypeError\n}\n```\n. better/clearer explanation: http://requirejs.org/docs/why.html\n. well, if you're concatenating the individual files, the entire project namespace just has to be wrapped in a self-calling closure, with that commonjs line somewhere in the mix.\nyou might have a header.js file that looks like:\n``` javascript\n(function() {\n  var qq = {};\n  // could be your current return from utils.js, or you can set it up\n  // as an empty object here, and add properties to qq later\n// then setup your exports\n  if (typeof exports !== 'undefined') {\n    exports.qq = qq;\n  } else {\n    qq || (qq = qq);\n  }\n```\nthen concatenate in the rest of your utils, files, etc here.\nand in a footer.js file\njavascript\n}).call(this);\n. If I get some time early next week, I'll take a crack at it. The rest of my project is in requirejs form, so being able to import qq this way would be a huge boon for me\n. What about putting the exports statement in utils.js after the qq object has been created?\nAn alternative is the qq variable could be created as an empty object in the header code, then add individual properties / methods to the object in utils either by setting properties directly or via qq.extend. the exports.qq object will still refer to that original qq object, now with all the right properties.\nRegardless, the qq code should probably all get wrapped in a self-calling closure so that the only exposure to the global namespace is explicitly binding qq to the window object. \n. @rnicholus yeah I've been pretty swamped this past week, probably won't be able to give it some thought until I clear out some of my own backlog first. \nUsing \"commonjs\" in the title is probably a misnomer on my part, since commonjs mostly deals with synchronous dependency fetching server-side (which is not applicable here). RequireJS is actually what I was trying to get at.\nRequireJS just uses the AMD format (as laid out here), which basically requires the script to be wrapped in a closure and have it return the qq \"module\" (as opposed to binding to and checking against window).\nIn the same way we normally run\njavascript\nvar uploader = new qq.FineUploader({...});\n// (`qq` is exposed via `window`)\nAMD/RequireJS imports the script first, passing its return value as an argument:\n``` javascript\ndefine('path/to/qq', function(qq) {\n  //... my code...\nvar uploader = new qq.FineUploader({...});\n  // (qq is exposed via the arg)\n});\n```\n. Tried to reproduce this morning but couldn't (I think it was a virtual machine setting). Will reopen if I find a specific problem.\n. :+1: came here to report an issue about postdata on 3.0 and found it was already fixed in 3.1. Thanks for the awesome work.\n. We recently made CSRF tokens mandatory on the remaining AJAX requests across our site, which required that the token is sent in postdata rather than as part of the querystring as had been (I think) our only option in 3.0. \nUpgrading to master and setting paramsInBody worked as expected, and is probably the behavior we want on all of our uploaders.\n. whups, wrong branch again... hold up.\n. @rnicholus what's the reason for closing this? It would be helpful for my current project...\n. Ah, got it. I'll re-open when I get home tonight\n. Nah no worries. Ping me when its up\n. arrrgh, wrong branch again. sorry, re-opening on another\n. +1\nwe're IE8+, and it seems like most of the web is moving this way (jQuery particularly), will help keep filesize / shims down a huge amount.\n. I missed this, sorry. It worked fine for me when I checked the first time,\nbut if I remember correctly you can't span a closure across multiple files.\nI think the main thing I could suggest is that multiple files may not be\nthe best distribution mechanism for this project, since the individual\npieces, while modular, are still quite interdependent. And given that the\ncurrent design exposes everything into the global scope, a closure would\nhelp eliminate some scoping issues too.\n On Mar 31, 2013 11:10 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nThis was closed again, automatically by Github, when I released 3.4 and\ndeleted the 3.4-IP branch. I created a new issue, #776https://github.com/Widen/fine-uploader/issues/776,\nto track future work on this.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/pull/690#issuecomment-15702784\n.\n. not every browser supports map (in particular IE8 and below). Using map here would either require a shim or dropping support for older browsers\n. whole qq namespace is now wrapped in a closure to avoid implicit global scope and other bad things\n. forgot to add define as a global.\n. \n",
    "mfjohansson": "Thanks for your reply.\nIt seems to happen very often when taking a picture with the camera. Here is an isolated example of when it often fails (uploads now fails because of a server limit I've set, the problem is before the actual upload).\nhttp://mfjohansson.nu/test/fileupload/\n/Magnus\n. Hm, maybe this is a problem with just this phone model. I'll try a few other later today.\nThanks for testing.\n. I've now tried it on Samsung Galaxy Tab 10.1 with Android 4.0.4 and ZTE Blade with 4.0.4. Both seems to work.\nThis seems to be a problem with the HTC version of Android. I'll do some more research though.\n. It could also be a problem with Android 4.0.3, but I've found nothing about that.\nJust for the record: the ZTE Blade runs a non-stock ROM and is rooted. The GT kind of runs stock and is not rooted.\n. Samsung Galaxy S2 (Android 4.0.4) does it right, both in standard browser and in Chrome.\n. I would say so.\nThanks for your time.\n. ",
    "rochadk": "I do use the params option and it works fine, the issue is that the filename always is appended to the url last, in my case resulting in mod security rejecting the request. \n. You've guessed correctly, I won't be able to change the security rule. I tried forceMultipart, and as you've concluded yourself, it still appends the filename.\n. If there's no available options to avoid the filename being appended, then I guess modifying the source is the only option yes. I don't know if the situation is unusual, I'm not really that much into mod security, that I know if it's a common rule or not. \nAnyways, thanks for a great uploader :)\n. Sounds great!\n. ",
    "zlczhou": "hi:\n Thank you very much!\n I used the three classes . but ,I will try again.\nAt 2012-11-28 09:30:40,\"Ray Nicholus\" notifications@github.com wrote:\nIf you use the entire java example (all three classes) along with the associated dependencies, uploads from all browsers will be parsed correctly.\n\u00a1\u00aa\nReply to this email directly or view it on GitHub.\n. Hi,the problem has not  solved .\nI used springmvc,but in controller which POJO set a Controller annotion !  I can not get the ServletContext, allways it's a null.\nAt 2012-11-28 09:30:40,\"Ray Nicholus\" notifications@github.com wrote:\nIf you use the entire java example (all three classes) along with the associated dependencies, uploads from all browsers will be parsed correctly.\n\u00a1\u00aa\nReply to this email directly or view it on GitHub.\n. ",
    "marcelpanse": "You are right, as soon as i disabled all my plugins it started working. What surprised me is that the plugin causing grief was Firebug 1.9.1. \nAlso tested with Firebug 1.10 on OSX and that working fine.\nAny idea's on how this can break the uploader? (since it is a really popular plugin). \n. Firebug didn't suggested the update to me, not sure why. I've removed the plugin and installed the latest 1.10.6 version and the problem is solved. \nDon't investigate more into this issue, i know which questions to ask now if it doesn't work on some clients computer and how to fix it, so that is fine with me. You can close the issue.\nThanks for you help. :-)\n. ",
    "ojal15": ":::IMMEDIATE SOLUTION:::\nIn \"_createUploadHandler\" function, comment out the following lines (shown by \"//\" as prefix).\n//  if(qq.UploadHandlerXhr.isSupported()){\n  //      handlerClass = 'UploadHandlerXhr';\n  //  } else {\n        handlerClass = 'UploadHandlerForm';\n   // }\nThis creates UploadHandlerForm and we dont have to go through Xhr .\n. ",
    "chanyuenpang": "I think the respoonse string have been UTF-8 encoded, there's the screenshot of console.\nHope it helps.\nThe link is with ads, sorry about that...\nhttp://p13.freep.cn/p.aspx?u=v20_p13_photo_1212021322589268_0.jpg\n. Here're related texts I copied from console.\nresponseText = \nWarning: fopen(E:\\Share\\Yop\\Documents\\My Web Sites\\YopYan\\1\\upload\\images\\2012-12-03-101739_([tom51.com]\u9a6c\u8fbe\u52a0\u65af\u52a02_\u9a6c\u8fbe\u52a0\u65af\u52a02.rmvb)[00.35.22.604].bmp): failed to open stream: Invalid argument in E:\\Share\\Yop\\Documents\\My Web Sites\\YopYan\\1\\lib\\uploader.php on line 43\nWarning: stream_copy_to_stream() expects parameter 2 to be resource, boolean given in E:\\Share\\Yop\\Documents\\My Web Sites\\YopYan\\1\\lib\\uploader.php on line 45\nWarning: fclose() expects parameter 1 to be resource, boolean given in E:\\Share\\Yop\\Documents\\My Web Sites\\YopYan\\1\\lib\\uploader.php on line 46\n{\"success\":true,\"url\":\"upload\\images\\2012-12-03-101739_([tom51.com]\\u9a6c\\u8fbe\\u52a0\\u65af\\u52a02_\\u9a6c\\u8fbe\\u52a0\\u65af\\u52a02.rmvb)[00.35.22.604].bmp\"} fineuploader-3.0.min.js:4\n[FineUploader] Error when attempting to parse xhr response text (SyntaxError: Unexpected token W) \n. ",
    "html": "UploadProgress is a nginx module, apache has the same. http://wiki.nginx.org/HttpUploadProgressModule\nThe point is to start uploading using iframe with form and to send ajax requests in paralel which give information from server about already uploaded bytes. \n. Thank you. Here is code which does needed functionality https://github.com/drogus/jquery-upload-progress if it's author will allow to use it then it only needs to be integrated. Here is my fork which works with latest jQuery https://github.com/html/jquery-upload-progress\n. ",
    "FelixSchwarz": "Hmm, I'm wondering why? Is that just \"not high enough on my priority list\" or more \"I don't like the feature itself because it doesn't make sense technically/the implementation will complicate the code too much\"?\n. Oh, I think I badly formulated my request then:\nI create the basic uploader (this.uploader = new qq.FineUploaderBasic({...});) but the actual upload happens only some time later (when the user selects the file to upload). During that time my JS might get some server response (completely unrelated to the FineUploader, basically just a random external event) and I want to change the endpoint in response to external events).\nMaybe the interface could be similar to dynamic parameters so that the endpoint could be specific as JS callback which is only evaluated when the actual upload starts?\n. Thank you very much - I appreciate your time and I work exactly the same way on my open source projects. I just asked because I wouldn't have understood a response like \"that is stupid from a technical point of view\". :-)\n. ",
    "proycon": "I'm running into a similar issue where I would like to be able to change the endpoint based on the file select. This as the upload backend is a actually a RESTful webservice accepting files by POST request on a URL ending with the specific file name to be created.\n. Thanks for the quick implementation!\n. ",
    "erfanimani": "Sweet! I needed this as well. Makes a lot of sense for single page webapps. \n. ",
    "lucasloliveira": "Thanks! This helped me too!\n. ",
    "tanertopal": ":bow: \n. ",
    "AnilRh": "It sounds like 3.1 will solve the issue then. Thanks!\nI saw some code using a older version of FineUploader (from January I believe) . I noticed that when using IE the \"qqfile\" query string parameter was not sent (but is sent with an XHR request in other browsers) so perhaps this is a new bug/feature? \n. Thanks again!\n. ",
    "HorstBrack": "Sorry, I don't seem to have the possibility here.\nThe  \"Pull Request\" button is missing for some reason.\nAnyway:\nI checked your script and indeed in most cases your methods return arays that are then sent back to the client json_encoded.\nExcept the check for the allowed upload size, this does a die().\nSo in server/php.php, line 165,\nI changed\ndie(\"{'error':'increase post_max_size and upload_max_filesize to $size'}\");\nto\ndie(json_encode(array('error'=>'increase post_max_size and upload_max_filesize to ' . $size))); \nThat's really all there was to it..\nI am sorry I am too stupid to handle this pull request issue.\nBtw. thanks a lot for this great uploader, the most efficient and simplest I coulds find!!\n. ",
    "frozenflat": "If I upload a file larger it will get almost to the end and then fail. it then will try the 3x setting and fail each time. no file is seen in the upload folder and it just doesn't upload. Fails in all browsers and seems to fail no matter what type of file  you throw at it. \nThanks for you Help!\nCheers\nRon\nOn Dec 6, 2012, at 11:07 AM, valums/file-uploader reply@reply.github.com wrote:\n\nCan you be more specific about your problem? What happens when you try to \nupload a file greater than 300 MB? Are you seeing this issue in all \nbrowsers? etc... \nOn Thu, Dec 6, 2012 at 9:43 AM, frozenflat notifications@github.com wrote: \n\nOk I have a problem. I created a ajax based uploader from scratch for a \nweb application about a year ago. It worked great much like file-uploader \nhowever about 3-6 mo ago it stopped uploading files over 300 MB . I was \nlike great they must have changed the browser specs or something. So \nyesterday I implemented you Fine Uploader 3.0 with the full features of \nlisting files and then hitting button to upload. Still can't upload files \nover 300MB. I know it's not the server php cause those settings are dialed \nin plus the fact that I have a small plugin where I use straight instant \nuploading. Like you pick a file and bam it starts to upload. This script is \nbased on your older file-uploader I think version 1.0 even and this can \nupload a multiple GB files no problem!!! So not I like what is causing \nthis. Is this cause of a new streaming ajax that is getting limited? Can \nanyone shed some like on before I go mad :-) . It got to be client side and \nbased on some limitation in newer meth od vs older. I really like your new \nversion with jQuery and want that progress bar but has anyone ran into this \nissue? Thanks for any help you can give me . \nCheers \nRon \n\u2014 \nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/515. \n\u2014\nReply to this email directly or view it on GitHub.\n\n\n. Thanks rnicholus for you help . I think I tracked it down had to do with Zend Server which we are trying to migrate to on our new development server. Still doesn't make sense to me , seems to be an php seg fault in one of the Zend Modules(Zend Optimizer), turned off and works but this doesn't explain the issues on our production machine for my old uploader . Hopefully this new one built using the fine uploader will fix that issue(crossing fingers). I do have another problem you might be able to help me with . I have to pass customHeaders custom to each file before it uploads. can I set these headers right before each file is uploaded? Looks like you can do it for the batch but not as each file goes up. Is this correct? I need to set and order number of each file and a folder id that each file going to go in but I have to do this different for each file. Can I change or add custom headers to each file before they upload? \nThanks so much for you help \n\nCheers\nRon\n. nice , thanks again! \nCheers\nRon \nOn Dec 6, 2012, at 7:35 PM, valums/file-uploader reply@reply.github.com wrote:\n\nHeaders are not meant to be used for storing custom values, such as, in \nyour case, folder ID and order #. For this, you should use parameters. \nYou can set parameters for all files using the params option, and set new \nparameters for each individual file in your onSubmit callback using the \nsetParams function. \n. oh one more question reading the docs and put this onSubmit, will this be attached to that exact file or all files. I really like to have unique params for each file that gets put into the queue before you hit the upload button. Will this do that or do I just have to create a look up array that will go along with all files ? \nCheers\nRon \n\nOn Dec 6, 2012, at 7:35 PM, valums/file-uploader reply@reply.github.com wrote:\n\nHeaders are not meant to be used for storing custom values, such as, in \nyour case, folder ID and order #. For this, you should use parameters. \nYou can set parameters for all files using the params option, and set new \nparameters for each individual file in your onSubmit callback using the \nsetParams function. \n. :-( oh well ok I just keep adding the files to an array that can then be used on server for look up .\n\nCheers\nRon \nOn Dec 6, 2012, at 8:18 PM, valums/file-uploader reply@reply.github.com wrote:\n\nOnSubmit is called once for each file. The value you pass into the \nsetParams function will replace the existing params for that file, and \nthese params will also apply to the next file, unless you also call \nsetParams when the onSubmit for that file is called. \n. Perhaps I am confused?  So I using the file-upload that when you say select file , it will add it to the list which executed the onSubmit, right? But their is no call back for when I hit the submit button right? Each file that goes up I have to associate an order that it was added to the list and the folder that was selected to add to in my program. The old uploader since I was able to set the header for each file I was able to set the header unique to each file right before it was sent up. It would be nice that if I add a file to the uploader list it can have unique params that stay with that file so when the uploader is executed each file had those params sent with it. \n    If I attach a function how would I exactly do this ? Can I tell which file is about to go up? something like function(file_name?)\n\nThanks for all your help \nCheers\nRon \nOn Dec 6, 2012, at 8:36 PM, valums/file-uploader reply@reply.github.com wrote:\n\nWas there another way you wanted to ensure each file has a set of unique \nparams? Note that you can also pass functions as parameter values. The \nability to do this makes it possible to provide dynamic parameters, since \nany functions associated with your set of parameters will be re-evaluated \nfor each file, just before the file is sent. \n. \n",
    "ricsh": "is it possible to add in a parameter on manual retry\n```\n    $('#uploadarea_' + PointerID.replace(\"ID_\", \"\")).fineUploader({\n        request: {\n            endpoint: '/ajax/documentUpload.ashx',\n            params: { 'PointerID': PointerID.replace(\"ID_\", \"\") }\n        },\n        retry: {\n            enableAuto: false,\n            showButton: true\n        },\n        listElement: $(\".qq-upload-list\"),\n        debug: true\n    }).on('submit', function (event, id, fileName, responseJSON) {\n}).on('complete', function (event, id, fileName, responseJSON) {\n\n}).on('manualretry', function (event, id, filename) {\n    $(this).fineUploader('setParams', { ' 'PointerID': PointerID.replace(\"ID_\", \"\"), 'Retry': \"true\" });\n});\n\n```\n. ",
    "flint0131": "Reason 1\nThe situation I'm in: A client wants me to create an upload form using the html returned by their server. Now, their server returns <input type=\"button\" {...} /> which is not the right element for the 'button' option as <input type=\"file\" /> will be inserted inside the element. I spent almost an hour trying to figure out why it won't work until I found out it needs to be in a container. To fix this issue, I waited for a couple of minutes and awkwardly talked to one of their php devs to change <input type=\"button\" /> to a <button></button> tag. Just for that reason alone.\nReason 2\nCode Aesthetics:\nhtml\n<!-- lookin' good -->\n<button>Click Me</button>\n<input type=\"file\" />\n<!-- or -->\n<input type=\"button\" value=\"Click Me\" />\n<input type=\"file\" />\nis better written than..\nhtml\n<!-- what happened? -->\n<button>\n   Click Me\n   <input type=\"file\" /> <!-- this, happened -->\n</button>\nThis can be argued, but to some people (including me) the first looks better.\nReason 3\nWhy can't <input type=\"button\" /> have what <button></button> have? <input type=\"button\" /> have rights too.\nThat's HTML racism.\n. ",
    "umassthrower": "Note: there is also a 3rd time it's being called, but I'm not observing this particular call in practice:\n``` javascript\nqq.FileUploaderBasic.prototype = {\n...\n    _error: function(code, fileName){\n        var message = this._options.messages[code];\n        function r(name, replacement){ message = message.replace(name, replacement); }\n    var extensions = this._options.allowedExtensions.join(', ');\n\n    r('{file}', this._formatFileName(fileName));\n    r('{extensions}', extensions);\n    r('{sizeLimit}', this._formatSize(this._options.sizeLimit));\n    r('{minSizeLimit}', this._formatSize(this._options.minSizeLimit));\n\n    this._options.onError(null, fileName, message);\n    this._options.showMessage(message);\n},\n\n...\n```\nI'm guessing this is a client-side error, not a server response error?\n. Thanks for the miraculously quick response (I wish paid support was this fast, lol).  \nIMO it should only be called in the event of a non 2xx response, but I realize I'm in the minority there.  Though, non 200 is probably not a great way of determining error since many other 2xx codes are valid.  If you don't want to only call onError once then I'll just handle that.\nThanks again.\n. I remember reading that awhile ago, thanks.  I'll add this to our list of IE compromises.\n. /\n- http://github.com/Valums-File-Uploader/file-uploader\n  \n- Multiple file upload component with progress-bar, drag-and-drop.\n  \n- Have ideas for improving this JS for the general community?\n- Submit your changes at: https://github.com/Valums-File-Uploader/file-uploader\n- Readme at https://github.com/valums/file-uploader/blob/2.0/readme.md\n  \n- VERSION 2.2-SNAPSHOT\n- Original version: 1.0 \u00a9 2010 Andrew Valums ( andrew(at)valums.com )\n- Current Maintainer (2.0+): \u00a9 2012, Ray Nicholus ( fineuploader(at)garstasio.com )\n  \n- Licensed under MIT license, GNU GPL 2 or later, GNU LGPL 2 or later, see license.txt.\n  */\nI'll take a look into 3.0.  Thanks,\n. ",
    "mdotterer": "I'm using the basic uploader to upload an image and the resource normally responds with an html document that contains, among other things, a status message to show to the user.  Even though it is html and not json the UploadHandlerXHR tries to parse it as JSON anyway and logs an error.  (https://github.com/valums/file-uploader/blob/master/client/js/handler.xhr.js#L138) \nLooking at the code again, I might be able to get all the information from the fourth argument sent to the callback, but it would still be nice if it didn't log an error in this case and behaved more like the success handler on jQuery.ajax where it parses the JSON only when the server responds with the proper content type.\n. Handling a non-JSON response is what I was asking for. Feel free to close this ticket.\nI think the uploader should be able to know if the operation was successful from the status code of the response instead of content in the body. In that case, the user would be free to use whatever format they feel like. The full uploader would probably still require a JSON response because it has more demands on the data, but it would make the basic uploader more flexible.\n. ",
    "esteveavi": "Hi,\nI beg your pardon. I thought I described it. \nWell, it would be nice to have fineuploader work like a Angularjs directive so that we can achieve something like this in HTML:\nhtml\n<fine-uploader id=\"id\"  endpoint=\"/upload/endpoint\" typeError=\"This is type error message\" multiple=\"true\" ...>\nFile uploading is a frequent issue in AngularJs forums and it isn't resolved yet. Fineuploader is very good alternative and can gain much attention from Angular user base.\nhttp://docs.angularjs.org/guide/directive\nThanks in advance.\nRegards,\n. ",
    "willvincent": "Here's a pretty rudimentary directive that is working pretty well for me thus far in a current project I'm working on that uses AngularJS (1.0.3) and Twitter Bootstrap.\nObviously it's not totally complete...\njavascript\napp.directive('fineUploader', function() {\n  return {\n    restrict: 'A',\n    require: '?ngModel',\n    scope: {},\n    link: function($scope, element, attributes, ngModel) {\n      $scope.uploader = new qq.FineUploader({\n        element: element[0],\n        request: {\n          endpoint: attributes.uploadDestination,\n        },\n        validation: {\n          allowedExtensions: attributes.uploadExtensions.split(',')\n        },\n        text: {\n            uploadButton: '<i class=\"icon-upload icon-white\"></i> Upload File(s)'\n        },\n        template: '<div class=\"qq-uploader\">' +\n                    '<pre class=\"qq-upload-drop-area\"><span>{dragZoneText}</span></pre>' +\n                    '<div class=\"qq-upload-button btn btn-info\" style=\"width:auto;\">{uploadButtonText}</div>' +\n                    '<span class=\"qq-drop-processing\"><span>{dropProcessingText}</span><span class=\"qq-drop-processing-spinner\"></span></span>' +\n                    '<ul class=\"qq-upload-list\" style=\"margin-top: 10px; text-align: center;\"></ul>' +\n                  '</div>',\n        classes: {\n          success: 'alert alert-success',\n          fail: 'alert alert-error'\n        },\n        chunking: {\n          enabled: true\n        }\n      });\n    }\n  };\nUsage:\nhtml\n<div fine-uploader upload-destination=\"/upload/\" upload-extensions=\"jpg,jpeg,png,gif\"></div>\n. This is the directive I ended up using for this:\napp.directive('fileUploader', function() {\n  return {\n    restrict: 'A',\n    scope: {\n      uploadedFilesModel: '='\n    },\n    link: function($scope, element, attributes) {\n      $scope.uploader = new qq.FineUploader({\n        element: element[0],\n        multiple: false,\n        request: {\n          endpoint: attributes.uploadDestination,\n        },\n        validation: {\n          allowedExtensions: attributes.uploadExtensions.split(',')\n        },\n        text: {\n            uploadButton: attributes.buttonText || '<i class=\"icon-upload icon-white\"></i> Upload File(s)'\n        },\n        template: '<div class=\"qq-uploader\">' +\n                    '<pre class=\"qq-upload-drop-area\"><span>{dragZoneText}</span></pre>' +\n                    '<div class=\"qq-upload-button btn btn-info\" style=\"width:auto;\">{uploadButtonText}</div>' +\n                    '<span class=\"qq-drop-processing\"><span>{dropProcessingText}</span><span class=\"qq-drop-processing-spinner\"></span></span>' +\n                    '<ul class=\"qq-upload-list\" style=\"margin-top: 10px; text-align: center;\"></ul>' +\n                  '</div>',\n        classes: {\n          success: 'alert alert-success',\n          fail: 'alert alert-error'\n        },\n        chunking: {\n          enabled: true,\n          partSize: 256000\n        },\n        callbacks: {\n          onComplete: function(id, fileName, response) {\n            if (response.success) {\n              $scope.uploadedFilesModel = response;\n              $scope.$apply();\n              jQuery('li.alert-success').delay(500).fadeOut('slow', function() { jQuery(this).remove(); });\n            }\n          }\n        }\n      });\n    }\n  };\n});\nAnd, the html markup to make it work:\n<div file-uploader uploaded-files-model=\"modelName\" upload-destination=\"/upload/image\" upload-extensions=\"jpg,gif,png\"></div>\nWorked great for me.  I backed this with a node/express server, which would generate thumbnails for me automatically, ensure filenames were unique (by renaming files until they became unique), and communicate back to the client via sockets when the thumbnails were available, at which point the client would then fetch the thumbnail. :+1: \n. you can't use UUID to name files if you want to retain somewhat human file names. ;)\nRe: templating in 4.0.  Sounds like 4.0 won't be terribly friendly with Angular then.\n. To each their own.  Those looking for how to use this with Angular, my directive above works nicely. I'm out.\n. ",
    "kristoffernolgren": "+1 on this!\n. Sure! what e-mail should I use? I can't find one on your webpage.\n2014-01-27 Ray Nicholus notifications@github.com\n\nIt looks like you are a license holder as well. If you send an email to us\nfrom the address you used when purchaing the license, I'll be happy to\nbuild a 3.9 version and send it to you.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1111#issuecomment-33381405\n.\n. \n",
    "feltnerm": "Nice @willvincent! Thanks for sharing! :clap: \n. # Blog Post: http://blog.fineuploader.com/2013/11/01/full-stack-javascript-image-uploader-using-angularjs-node-js/\n. I did some experiments on AMD support for FineUploader a few weeks back.. The most effective solution I found was to wrap the concatenated Fine Uploader sources in a UMD wrapper using grunt-umd. It was pretty easy.\nNot sure if this is something we would want to offer by default in the distributed sources, or just allow users to do on their own if they so choose.\n. http://fineuploader.com/#s3-demo has delete\nfixed since a06a7a0605409ce348ee1d3ffb080a783234043b\n. Noting that this is in regards to our own upload server on an aws ec2 instance. Could be a candidate for 4.2 once the server-side examples are improved.\n. Testing these appears to be tricky. Not only do all of these require some user-interaction to determine whether they work, but they also require a working (mocked?) upload and delete server. showPrompt is used only when the user submits a paste so pasting needs to be simulated (in supported browsers) in the integration tests first. showConfirm is simpler, but a file needs to be uploaded, then the delete link needs to be clicked to test.\n. :+1:  I'm looking into IE11 support at the moment (#933), and it's a 2 as well, mostly due to the \"just in case\" factor.\n. Ideally the documentation is terse and easy to edit, two criteria where HTML fails. The build script(s) could pre-process Markdown or markdown-esque syntax (such as: Creole, reST, et al.). A tool like Docco or readthedocs could be used to ensure the code and documentation stay up to date.\n. > I think the goal here is to make the documentation:\n\nsearchable\n  easy to read\n  appealing visually\n...\nPerhaps some sort of documentation templating system exists that would generate HTML for our docs and allow us to define styles for them based on some set of conventions. \n\n:+1: \nI'll keep an eye out for something that'll satisfy our needs. Worst case scenario, we write a custom markdown extension (which is basically regex) which renders a specific syntax into <script></script> tags. This would enable executable demos. A static site generator / templates could generate the HTML which could then be styled via CSS.\n. Note: React has nice docs. They use CodeMirror\n. +Note: we need to ensure that the links to the previous docs still work.\n. Internet Explorer 11 appears to have the same behavior as Firefox (i.e., can only paste images into contenteditable elements) [1]\n[1] - http://msdn.microsoft.com/en-us/library/ie/dn265023(v=vs.85).aspx#clipboard\n. Bumping this.\n- Latest jQuery is going to use AMD modules. Proof there is a clear push for JS libraries to support AMD, and that it is more than possible.\n- We already have pull request demonstrating that this is possible.\n- Being able to use a node-like require system would greatly enhance the custom build process\n. @raulferras -- We have been punting on this in lieu of other features and bug fixes.  Could you post your code/issue on StackOverflow? Maybe we can at least help debug your issue as Fine Uploader should still work in CommonJS environments.\n. https://github.com/FineUploader/fine-uploader/compare/feature/umd (specifically https://github.com/FineUploader/fine-uploader/commit/697e6e95967ad590f73c4a3804efd4b7347f108d) has the initial work required the make this happen.\nSeems like some tests were failing, and then this got de-prioritized, but should be a good launch point for anyone wanting to make this happen.\n. I did a bit of exploration with client-side Javascript testing. I think the the goals of the testing suite should center around:\n- Continuous integration\n- Testing all supported browsers\n- Testing in the browser\nWe could get continuous integration with Travis CI, but the caveat is that Travis is an Ubuntu VM thus we can only test on that with PhantomJS (WebKit), Firefox, and Chromium. One solution is to just test the edge cases (I'm looking at you, IE) locally, and just use Travis as a benchmark for more modern browsers.\nOther option is something like BrowserStack or Sauce Labs.\nPutting #852 here for reference.\n. > I see that you've already prioritized some of these using Huboard. Nice! I may make adjustments, FYI, but I agree these should be near the top.\nDefinitely feel free to make adjustments, especially as I become more familiar with the project. I think Huboard will be extremely useful. \nBTW, can anyone view the Huboard site, or is it just those with commit access?\n. As of https://github.com/Widen/fine-uploader/commit/a814ee3b574ea3275d7071e94e32cf406961d517. An automated testing process has been established. It doesn't hit all of our goals, but it's something.\n. An automated build process has been established. Features:\n- Concat-/minifi-cation of JS and CSS source files (using uglifyjs and clean-css, respectively) - [make build]\n- Continuous integration testing via Travis or on local machine - [make test or make watch)]\n  - Travis build images are added as well.\n- Node.js server for local development testing with the goal of being a fully-fledged example server one day.\n- Automatic linting of Javascript before building (disabled currently, lint rules need to be defined. @rnicholus -- discuss soon?)\n. Closed since  0ccf48667986f602d1734ce204a2591d33ffa24e. Next story/step is to fill in the cracks for unit tests and begin research/exploration into Selenium automated tests.\n. # Release Contents\n```\nfine-uploader-/\nexample.html\nexample-jquery.html\nexample-bootstrap.html\nLICENSE\nREADME\n\nimg/loading.gif\nimg/processing.gif\n\ncss/fine-uploader-<version>.css\ncss/fine-uploader-<version>.min.css\n\njs/fine-uploader-<version>.js\njs/fine-uploader-<version>.min.js\njs/jquery-fine-uploader-<version>.js\njs/jquery-fine-uploader-<version>.min.js\njs/iframe.xss.response-<version>.js\njs/iframe.xss.response-<version>.min.js\n\n```\nWould that be all the constitutes a release? Am I missing anything?\nI'm assuming a 'release' constitutes something that an end-user would want to download and use. As such, I assume that they'll not want the tests, docs, and other development scripts and tools that are found in the repository.\n. :+1:  The option and API method seems reasonable. I don't see anything immediately wrong with either.\nI don't think an extra parameter should be added to the callbacks.\n. Seems ok.\n\nAlso, CORS support: What happens when one extraButton's endpoint is across origins whilst another is not? Maybe this is an uncommon use-case, though.\n. A project was brought up mentioning an implementation of Fine Uploader on http://www.widen.com/api/ . To be fully effective, a server is going to need to be used. Maybe it could be general enough to support 3rd parties and just delete files after a certain length of time?\n. After some more thought...\nThe boilerplate generator (and even client-side code generation) won't be too difficult to put together. The part that I believe needs to be cleared up and put into writing is the business logic surrounding trial users and commercial license holders.\n. # Builds\nEndpoints\n\nTraditional\nS3\n\nExtras\n\njQuery\nUI mode\nPaste\nDrag 'n' Drop\nEdit Filename\nDelete File\nImage Previews\n\n(any more?)\nTodo:\n1. Edit the copy for the success email\n1. Finishing touches on the customize.html page on gh-pages\na. Email confirmation field\n   b. Tooltips for explaining features\n   c. Support email link (in case something is broken -- prolly just my email address)\n2. AWS Notifications (again, in case something is broken) / Email from server in case of fatal error\n3. Verify builds are error-free (@rnicholus -- Can you verify that that the code passes your inspection?)\n. 5db143a lookin' good :sunglasses:\nAlmost ready to :shipit:\n. :+1: Nice!\n. One part of this process was to have Travis automatically detect pull requests to master and issue a failed test to discourage that sort of contribution. As of 6422388a94b2d0580172152134a85abcc105184e this is implemented and working.\n. This is on Huboard as an 'In Progress' task -- really it's sort of a meta task that is supposed to keep track of other cases. I'm thinking of closing this an moving the unchecked cases into their own stories. Objections @rnicholus ?\n. As far as \"Automated Build Scripts\" go. The build process done with Grunt is automated, and it builds the library properly... \n. Okay, issues #862, #875, #859 (you are all basically the same issue anyways) I've given you some thought and you are going to be messy to say the least.\nThe ability to write Selenium tests is there (see the test spike in './test/functional/spike.coffee' and the grunt task grunt mochaWebdriver), but I have a few concerns:\na) Complicated tests. I understand we aren't writing Computer Science theses, but the code (at least the way I have it in my head) to combine Selenium browser controls with client-side tests looks messy and like a maintenance nightmare. Which leads me to my next point...\nb) Little benefit. If we can hit >90% of our codebase with unit tests running in all the browsers then I think we're doing really well, and I think that's a much better scenario than running integration tests. This goes along with our \"agile\"-ness. I've been doing a lot of research around this, and it seems like most developers are content with running PhantomJS, Chrome, and maybe IE9 for their testing stack. We're hitting so many more browsers. Also, unit tests take ~5 seconds to run, integration tests take at least 10 minutes. Integration tests require complicated code and take a while to write. Unit tests should take (generally) a much shorter time to write.\nI advocate for us to continue writing unit tests, and get our code coverage up in all supported browsers.  Maybe then we think again about integration tests. Until then, start getting creative with ways to unit test this thing. Gonna be a fun challenge!\n\nAn SO question I asked that sort of outlines the code structure I envisaged: http://stackoverflow.com/questions/18729901/mixing-client-server-side-tests\n. Removed.\n. Have already begun work on the Nodejs server.\n. This is a draft proposal for improving template syntax.\nUnless I'm missing something, templates could be moved from the options and instead embedded in <script> tags on a page with a Fine Uploader instance. The template and fileTemplate options would take an id corresponding to the element where the respective template is defined. These tags are not rendered visually in any browser.\n``` html\n\n\n\n\n```\njavascript\ntemplate: 'qq-template',\nfileTemplate: 'qq-filetemplate'\nI believe this could be done by getting the .innerHTML of each respective <script> as a string and running it through a fairly simple parser. The parser would use identify three types of things:\n- Regular HTML\n- Variables - { variable_name }\n- function - {% function_returning_string() %}\nAt this moment regex is used to replace variables with values before being rendered on the DOM.\nThis is a win because:\n- The complicated template syntax in the options is removed\n- Templates are no longer as brittle\nIt would involve:\n- Defining a template grammar and a parser ( {{ var }}, {% function %}, ...)\n- Moving template strings to HTML files\n- Packing these HTML files with each release\n- Documentation\n- Breaking changes to previous versions unless we decide to allow for both options to exist \nThere could a public API function, renderTemplate(String templateString) which could be overridden to allow integrators to tie in their own templating engine.\nI'm not entirely sure how to solve the points you bulleted out @rnicholus, but maybe the parser could have some logic to check class attributes (to discuss...) and ensure that all the required one are there / turn of options / fallback \"gracefully\" if they're not.\nThis would enable us to tackle #868 and #869 because those involve some major UI changes, and if there's a possibility of major UI changes I don't want to be doing them in those string templates that are there now.\n. > The renderTemplate method sounds interesting, but I don't anticipate making that part of this story.\n:+1: I realize that users can still use a template engine like Mustache.js, they just would need to compile the Mustache template (so it exists in the DOM) before Fine Uploader is instantiated.\nMore thoughts:\n- How to package this into a release? Once #846 is complete this will be easier, but until then ... provide a default index.html inside of each zip? \n- What happens when the templates have not been defined?\n. Another option instead of docco: https://github.com/Nuulogic/sphinx-jsapidoc\n. I've researched some more options [1][2][3]. Specifically for API documentation via parsing comments in the source code. Each one of these supports all sorts of syntaxes for specifying whether your method is private, public, etc; your class is inherited, polymoprphic, etc; and much more. Like a Java(Script)Doc:\n- yuidoc -- Slick and sleek. Backed by Yahoo!. Searchable docs. Themeable. Have not used.\n- jsduck -- used by sencha\n- jsdoc -- Have not used. Overkill?\n- ScriptDoc -- seems very similar to JavaDoc\n- Sphinx -- is used a lot in Python circles. Uses Restructed Text in the source.\n- dox -- parses comments from JavaScript source code and outputs JSON. Lots of potential headaches and/or awesome.\nThere are probably infinite other solutions. I listed these in order of my own rating.\nSources\n1 - http://dailyjs.com/2011/01/13/framework-part-46/\n2 - http://www.lsauer.com/2013/05/javascript-documentation-generator.html#.Ufk1BGTXhJk\n3 - http://stackoverflow.com/questions/669698/what-options-are-available-for-documenting-your-javascript-code\n. Good boy.\n. :+1: \n. Going to want to add this to one of the git hooks to run lint before a commit is made.\n. I've been using the following JSHint rules when writing unit tests. They've steered me clear of a lot of browser quandaries.\nvalidthis: true\nlaxcomma: true\nlaxbreak: true\nbrowser: true\neqnull: true\ndebug: true\ndevel: true\nboss: true\nexpr: true\nasi: true\nGruntfile.coffee\n. :+1: \n. Closing since our homepage does have this currently. A tab for non-jQuery, jQuery, and the template.\n. :+1: \n. I know we are dependency-free, but what if we used an existing promise implementation (i.e., https://github.com/then/promise), and swapped out the current FU Promise for whichever implementation we decide on rather than reinventing the wheel?\n. This should be closed, no? \"SemVer\" is displayed and the link takes you to the 2.0.0 version of the spec.\n. What about refactoring this line out into a function to make it unit-testable and catch other possible parsing errors (?)\n. Not sure what's going on either. One issue is that the img source on both README.md and the overview page in the docs is pointing to: https://saucelabs.com/buildstatus/feltnerm when it should be pointing to https://saucelabs.com/buildstatus/fineuploader . Interestingly enough, even this image is displaying an 'unknown' status. Blame it on saucelabs?\n. Even on the Saucelabs site it's 'unknown' (top-right corner) even though the last 25+ builds have appeared to have succeeded. The browser matrix is all green as well.\n. @wesleywong here's an example of using addFiles, although I bet it is not exactly what you're looking for.\nI'm also curious as to your plan for integrating FineUploader with the Dropbox Chooser API. Correct me if I'm wrong, but it appears that hte Dropbox Chooser downloads stuff from Dropbox. How does FineUploader fit in?\n. > I working on the module which people can upload a photos post (similar like fb) by uploading from (fineuploader) + additional feature to allow them to get their media from their Dropbox account. If I split them into 2 diff methods to upload that might confused.\nIt sounds like you have two different methods:\n1. The upload method (via FineUploader)\n2. The download method (via Dropbox)\n\nSupporting uploads directly to Dropbox is a potential feature that has been on the horizon recently. If, in fact, this is what you're trying to achieve, I'd appreciate it if you'd be willing to share any progress you make, and if you run into any more problems feel free to PM me here.\n. The Getting Started page on the docs outlines the differences between the jQuery and non-jQuery constructors.\nThe jQuery-specific page shows how to specifically use the jQuery plugin.\nI would say this is closed.\n. @rnicholus , thoughts on closing this? I think current docs accomplish this goal although maybe not in the exact way we had in mind.\n. In an ideal world, we'd have a demo + example code for all the use cases that are feasible to demo.\nI :+1: what @danielwalls has to say about the documentation having room for improvement.\n. Here's an outline of a documentation structure that I propose. Note that is still in flux.\nI figured I'd post it here to allow anyone else who is perusing issues/this issue to comment on what they think could be improved.\nhttp://goo.gl/klpMhI\n. http://docs.fineuploader.com/branch/master/overview/development.html#coding\nAre these docs not clear enough, or did you just have trouble finding them?\n. The overview page does not exist anymore, so I'm marking this as closed.\n. It appears that the <input> element with class qq-edit-filename is being placed above (in terms of z-index) the 'Cancel' or 'Delete' buttons on the DOM. \nOne idea is to change the z-index of this element to something very negative so that it will not handle click events.\nAbout to test this change in non-Chrome browsers...\n. Another potential solution:\nEditing fineuploader.css and setting the position to be fixed instead of absolute\n. Please post to StackOverflow. Include any relevant code that you think may assist in diagnosing your problem.\n. Good thing Sauce added support yesterday! http://sauceio.com/index.php/2013/11/windows-8-1-and-ie-11-now-available-on-sauce-labs/\n. Issues Found:\n- Much like Firefox IE relies on the element to-be-pasted-onto to be contenteditable (http://msdn.microsoft.com/en-us/library/ie/dn265023(v=vs.85).aspx#clipboard) #774\n- #1043 \n. > IN this specific instance you'd be right.  However they could drag in more than 5 files\u2026 so in this situation we'd be looking at potentially queueing files.  This will be the next evolution for us, implementing some type of upload manager.\nIt's not a solution, and a bit of an unrelated idea, but ...\nI wonder if your upload manager could compress files using zip.js or something similar. This would be quite useful while files are queued since they aren't doing anything to the network and CPU time is not really being used.\nAs for implementation you could find a way to add all files to be uploaded to a single zipped file, and then upload that zipped file, or zip each file individually before sending, or even zip each chunk before sending (going to look into the possibility of this). \nThe logic for determining when to zip or not (if you want it to be automatically detected and not set by the user) may be non-trivial.\n. Current status of bugs that need fixing:\n1. [x] Safari is attempts to send 0-sized chunks in some cases, especially when when we attempt to send multiple chunks of the same file at once\n2. [x] S3: A failure to combine parts due to an invalid chunk does not result in a reset of the upload.\n3. [x] IE8 is throwing exception in upload.cleanup()\n4. [ ] ~~Multiple entries for the same chunk data (id and etag) in localstorage for a file (working on a reproducible test case for this one)~~\nI'm currently looking into creating a reproducible test case for the 3rd issue, with an eye of looking into the 1st one again afterwards\n. I don't believe this is Travis' fault. The combination of SauceLabs and Selenium may be to blame. More investigation will certainly take place when my integration-test branch is fixed up and merged.\n. Need to investigate this more...\nDo these builds look like the typical failure? The first one succeeds, but the subsequent ones fail even tho all that has been changed is the documentation.\n484 - success - change to docs - https://travis-ci.org/Widen/fine-uploader/builds/10949519\n485 - fail - change to docs - https://travis-ci.org/Widen/fine-uploader/builds/10949865\n486 - fail - change to docs - https://travis-ci.org/Widen/fine-uploader/builds/10949882\n487 - fail - change to docs - https://travis-ci.org/Widen/fine-uploader/builds/10949902\n488 - fail - change to docs - https://travis-ci.org/Widen/fine-uploader/builds/10949944\nIf so, then as soon as I can I'm going to investigate the commits, SauceLabs build logs, and travis logs and see if I can notice something. If I find something, I'll see if I can reproduce. \nI still think this is a concurrency and/or SauceTunnel issue.\n\nOn another note, we can pretty much do whatever we want with Sauce and Travis now (i.e., run some custom scripts, block until something happens, etc. etc. etc.) with these scripts and the .travis.yml before_script and before_install hook/task/function/things.\n. Let's try to remember to append [ci skip] to doc related commit messages and see if that improves anything\nhttp://about.travis-ci.org/docs/user/how-to-skip-a-build/#Not-All-Commits-Need-CI-Builds\n. Document some relevant metadata in each document (tags, etc.). \n``` markdown\nTitle: Drag and Drop\nTags: drag, drop, dnd, html5\n\n.... # actual rendered documentation goes here...\n```\nWhen docs are generated some JSON file is made that maps those tags to specific links. When users search, this JSON file is GET'd and some sort of logic goes on to determine the best match. I don't think it'd be too tedious, and once it's done, we have search.\nThis also means we could sort of 'redirect' searchers to where we think they should be by strategically tagging documents.\n. Docs are searchable in develop since b4484051f2a153eb889b3e6393147547133ef7cd -- will be live once dev is merged into master / our next release.\n. Yes :rocket:\n. Starting work on this now. \nMy immediate goal is to generate client-side code based on the values provided on fineuploader.com/customize, with the code being basically just the constructor function for the respective build.\n- jQuery and non-jQuery\n- S3 and non-S3\n- UI and non-UI\nOnce these are constructing properly, I'll move onto allowing the user to specify options (such as endpoint, cors, etc.).\n. Yes ... they are on a branch in my local repository, and probably a few releases behind.\nAll they do is take a custom build formula, concatenate the sources, and select unit test files that match up to the included custom build files. Those test are then run in phantomjs. If I remember correctly, some the tests are not completely decoupled from certain scripts.\nSo ... to get this going I'd have to rebase and bring that commit up to date, and then there would be small a bit of test refactoring since all the tests assume they are working on all.fineuploader.js.\nI think this was punted originally because I created it just as we were releasing.\n. > Is this still a \"3\"?\nYes. I think that is fair.\n\nShould at least check that the zips are valid, the all the expected files are included in the zips, & the version number is valid.\n\nNote that the tests I mentioned above don't actually test for the above :cold_sweat: I'm not sure what would constitute a \"valid\" zip. There's a few ways to go about that I guess: check expected files, names, sizes, ... for now I'd just say bringing the custom build tests up to date would be good. Thoughts?\n. > Should at least check that the zips are valid, the all the expected files are included in the zips, & the version number is valid.\nThis would be ideal to ensure that we don't somehow accidentally break the build.\n. It looks like you are using Fine Uploader S3, but you have your options specified in a way that would indicate you are using Traditional mode. Are you looking to upload to Amazon S3 or to your own server?\n. > Looking to upload to S3. However I wanted to POST the file to our server, and then upload it to S3. I want to avoid going directly to S3.\nFine Uploader's S3 plugin was made specifically for uploading files directly to S3, so I don't see why you're using that mode.\n. To the support forum\n. I would add that there should be an alert near the top of the events page that indicates the syntactical difference between both versions.\n. Duplicate of #784 \n. Rackspace's blog just released some code showing how to upload via AJAX to their CloudFiles service: http://developer.rackspace.com/blog/upload-files-directly-to-rackspace-cloud-files-from-the-browser.html\n. Thanks for chiming in @petesankey. It has been on our radar. Due to the holidays it may not make it into 4.2, but I could see this feature being a part of the 4.3 release.\n. Closed at df749efd23830485f941546da95f3dcba86a6fa2 / #1034 (accidentally created two cases for this one)\n. Closed since df749efd23830485f941546da95f3dcba86a6fa2\n. Done since https://github.com/feltnerm/docfu/commit/1d48a49582834a809db58686965522716630db33\n. 3 story points for this case seems reasonable. Some of the \"fixes\" for the various inefficiencies may take more story points, but we can cross that bridge if/when it appears.\n. There are still a lot more potential demos (~28) than the 4 listed here. With just these 4 we'd be packing in a ton of features into just 4 demos. What do we do with them?\n\nIn particular, is there a more clean, elegant way to lay out the description and the code than the current left/right columny layout?\n\nI think, for each demo we could have code for each type of constructor of FU that there might be. The types: qq.FineUploader, qq.FineUploaderBasic, qq.s3.FineUploader, qq.s3.FineUploaderBasic. You could separate the code demos by a tabbed <div> where you can click a tab and see code specific to that type of uploader.\n| Fine Uploader | jQuery Fine Uploader | Fine Uploader S3 | jQuery Fine Uploader S3 |\n| --- | --- | --- | --- |\n| code specific to each instance goes here ignore the columns to the right on this row |  |  |  |\nThis means we'd have to decide what exactly is going to be demoed. I vote that each feature on the features/home-page links to a demo featuring that feature.\nAlso see: #906 \n. Why support.fineuploader.com ? It already redirects to fineuploader.com/support\n. Which features? The list in the docs dropdown is a good start, I guess.\n. Tier 1\n1. Progress bar\n2. Multiple file selection\n3. Drag and Drop\n4. Retry automatically or manually\n5. Built-in and custom validations rules allowed\n6. File chunking/partitioning\n7. Pausing and resuming uploads\n8. Delete Uploaded Files\n9. Upload to the cloud (S3 for now)\n10. Media previews (right now only images, may expand in the future)\nTier 2:\n1. jQuery plugin (optional)\n2. Auto and manual upload\n3. Cancel uploads\n4. Simple to style and customize (comes with templates, CSS, etc.)\n5. CORS (cross-origin) support\n6. Paste to upload\n7. Upload from mobile camera\n8. Edit file names\n9. Multiple upload buttons\n. I can do it quickly. I'd story point this a 0. Forgot about this. Many editors parse .editorconfig and can automatically use spaces over tabs, indent 4 or 2, or w/e rules are setup inthe .editorconfig. I would assume those rules would match the style and lint rules we have established.\n. Usually 4 weeks (+/- a few days). The current release cycle is being extended a bit, and it should end early to mid January. This is because of the holidays here in the US and the fact that we have only two developers\n. :+1: That's a lot of commits! Good stuff!\n. @raulferras there are issues with the way bootstrap's buttons function. When you call reset it clears the innerHTML of the button (which includes the <input> elements that Fine Uploader requries). See: http://stackoverflow.com/questions/18476872/fine-uploader-only-works-for-a-single-batch-of-files\n. Go for it, I explored some ideas related to this in node-fine-uploader-server. \n. Thanks @daniellwu! I'm going to merge this right into master. Looks like SauceLabs was having issues when your the test ran, but since it's just a documentation update, I say it passes! :shipit: \n. We are dealing with this on StackOverflow, so I am closing this until we have discovered whether this is a bug or not.\nhttp://stackoverflow.com/questions/20525214/invalid-according-to-policy-policy-condition-failed-starts-with-content-type\n. Interesting, I've never used DreamObjects. I wonder if -- using a signature server -- Fine Uploader could just upload directly to the same bucket that DreamObject is using. This may require being able to change the canonical bucket name.\nRight now Fine Uploader does not support client-side direct-to-S3 uploads. You need a signature server in order to validate each request to S3.\nThe case for completely eliminating the middle-man for S3 is #1047 -- +1 that if you think it should be implemented.\n. I realized that DreamObjects is based on OpenStack's Swift data-store (much like Rackspace's Cloud Files and Softlayer) so I'm linking this case with #1025 \n. Please direct support questions to StackOverflow (http://stackoverflow.com/questions/tagged/fine-uploader) and tag the question under 'fine-uploader'. This issue tracker is for bugs and feature requests, not for support. If we find a bug due to your case, it will get filed here.\n. Closed since 35a64cf72c85e46cc64b849677c23b48f0bd9144\n. Using an array of strings as the value of the acceptFiles options does not\nappear to conform to HTML spec, and is not guaranteed to work on all browser\nimplementing the spec. Using a comma-separated list of mimetypes is a better\noption.\n. Fixed since 9a9a33c . Seems like your branch wasn't up to date with master so I made the change myself. Thanks for noticing anyways!\n. Sounds good. I think there's at least a day or two of work left on it currently.\n. Yes. Leave open. There's a lot that could be improved/automated in terms of the site, imho.\n. Closed since 0ba73fa33e6b42da2ba65887c21d5a7c3cb61b28\n. :+1: -- future developers may grow to hate us if the Gruntfile continues to grow.\nA few ideas:\n- Since Grunt tasks are just Objects they could be put into their own files and require'd\n- Rewrite the build system using Gulp (seriously, after playing with Gulp I think it is more suitable than Grunt for large projects)\n. I noted a few pain points that I experienced recently when working with the Gruntfile,\n- [x] Very large Gruntfile could be split up into sub-tasks.\n- [x] Coffeescript (need I say more?)\n  - Actually, yes, I do need to say more. Because we are using a mix of coffee- and java-script. Sometimes I cannot remember what I am writing in since they are so similar, yet extremely different.\n- [x] We still have left over Saucelabs code\n- [ ] grunt test:Safari works, but there is also a task called \"tests\" which makes it confusing. \"test\" works but not \"tests\". I think \"test\" runs \"tests\" interally. God, that makes no sense.\n- [ ] No way to list the browsers that can be tested\n- [ ] We distribute custom builds but we test against the \"all\" build. We should be testing the code we are distributing.\n- [ ] There are little to no comments in our build file.\n. Not sure why that build is failing. I am able to run the same task locally ... I'll have to look into it another day unless anyone has any clues.\nIn the meantime, let me collect my thoughts:\nI made progress on slimming down the Gruntfile (down to 217 lines from 902) by putting each task config in a module in ./lib/grunt/tasks. I may change the naming from 'tasks' to 'config' because actual task functions (those registered with grunt.registerTask should exist in the ./lib/grunt folder as well.\nOne win we gained by putting the task configs into modules was the ability to convert them to Javascript. Props to vim for letting me run %!coffee --stdio -pb to automatically convert the coffeescript to javascript. As such, there are some minor formatting issues: tabs are at 2 spaces (rather than the preferred four). I plan to fix these before finishing this task.\nThe last change was that I removed all saucelabs related stuff. This will slim down the dependency install a bit.\nOnce I fix the build, I'd like to convert the custom grunt tasks into separate modules, convert the Gruntfile to Javascript, and then think about a better \"public API\" for the build tasks. Thoughts and ideas are appreciated.\n. > :thumbsup: Glad to see this happening. I'll also be glad to rid this repo of coffeescript.\nYes. It's one of those small annoyances that builds up. Fixing it is my recompense for the n00b javascript era I was in when I put the build tools together. No coffeescript is always :ok_hand: in my book.\n\nThe build error happens during the bower task . This could be a dependency version issue. Hard to investigate since the task runs fine locally; even on a freshly cloned repo.\nMy (truncated) local output for grunt travis:\n```\nRunning \"bower:test\" (bower) task\n[D] Task source: /Users/mark/code/fine-uploader/node_modules/grunt-bower-task/tasks/bower_task.js\nVerifying property bower.test exists in config...OK\nFile: [no files]\n\n\nCleaned target dir /Users/mark/code/fine-uploader/test/_vendor\nbower cached https://github.com/allmarkedup/purl.git#2.3.1\nbower validate 2.3.1 against https://github.com/allmarkedup/purl.git#~2.3.1\nbower cached https://github.com/jquery/jquery-simulate.git#master\nbower validate master against https://github.com/jquery/jquery-simulate.git#\nbower cached https://github.com/Jxck/assert.git#master\nbower validate master against https://github.com/Jxck/assert.git#\nbower cached git://github.com/jquery/jquery.git#1.10.0\nbower validate 1.10.0 against git://github.com/jquery/jquery.git#1.10.0\nbower cached git://github.com/douglascrockford/JSON-js.git#master\nbower validate master against git://github.com/douglascrockford/JSON-js.git#*\nbower cached git://github.com/visionmedia/mocha.git#1.11.0\nbower validate 1.11.0 against git://github.com/visionmedia/mocha.git#~1.11.0\nbower install json2#master\nbower install mocha#1.11.0\nbower install jquery#1.10.0\nbower install jquery.simulate#master\nbower install assert#master\nbower install purl#2.3.1\nInstalled bower packages\nReading /Users/mark/code/fine-uploader/bower.json...OK\nParsing /Users/mark/code/fine-uploader/bower.json...OK\ngrunt-bower copying  dir bower_components/assert -> test/_vendor/assert\ngrunt-bower copying  dir bower_components/jquery.simulate -> test/_vendor/jquery.simulate\ngrunt-bower copying  dir bower_components/json2 -> test/_vendor/json2\nReading bower_components/jquery/jquery.js...OK\nWriting test/_vendor/jquery/jquery.js...OK\ngrunt-bower copying bower_components/jquery/jquery.js -> test/_vendor/jquery/jquery.js\nReading bower_components/purl/purl.js...OK\nWriting test/_vendor/purl/purl.js...OK\ngrunt-bower copying bower_components/purl/purl.js -> test/_vendor/purl/purl.js\nReading bower_components/mocha/mocha.js...OK\nWriting test/_vendor/mocha/js/mocha.js...OK\ngrunt-bower copying bower_components/mocha/mocha.js -> test/_vendor/mocha/js/mocha.js\nReading bower_components/mocha/mocha.css...OK\nWriting test/_vendor/mocha/css/mocha.css...OK\ngrunt-bower copying bower_components/mocha/mocha.css -> test/_vendor/mocha/css/mocha.css\nCopied packages to /Users/mark/code/fine-uploader/test/_vendor\nCleaned bower dir /Users/mark/code/fine-uploader/bower_components\n```\n\n\n@rnicholus, if you get a chance, maybe you have some ideas? I'm running grunt travis as specified in ./.travis.yml\nIt's frustrating me, but I'll have look at this another day ...\n. Able to recreate locally by running bower cache clean followed by grunt travis. \nUgh, it seems like grunt-bower-task is using an older version of bower. Appears to be fixed in a pull request\nI updated the dependency and fixed the build in f1051a9\n. Haha! I think I got rid of it all.\n. Actually, I lied. A lot of the custom build generator logic is still in Coffeescript.\n. last commit has a close message because I believe I tackled the initial issue. I mentioned a few other things earlier that are probably just extra at this point:\n\n\n[ ] grunt test:Safari works, but there is also a task called \"tests\" which makes it confusing. \"test\" works but not \"tests\". I think \"test\" runs \"tests\" interally. God, that makes no sense.\n[ ] No way to list the browsers that can be tested\n[ ] We distribute custom builds but we test against the \"all\" build. We should be testing the code we are distributing.\n[ ] There are little to no comments in our build file.\n\n\nFWIW, I'm basing my build retooling work off of develop, which has this work merged in already.\n. > Called just before an item begins uploading to the server.\nRight. An \"upload\" is defined as when the client sends file data over HTTP to the server. So the behavior is correct in that it should emit the upload event twice if you have stopped uploading (paused) and then started again (resumed).\nThe submitted event would be the one you are looking for if you are looking to do something just before the initial upload request.\nEDIT: After thinking about this more, submitted would only be a good workaround if autoUpload was set to true.\n. The upload event is called in a few places, notably when the uploader attempts to retry an upload, resume an upload, make the initial upload request, and/or continue a paused upload -- which appears to be your use case.\nThe emitting of the upload event when continuing a paused upload is due to the upload handler having no real concept of a paused upload. To pause an upload, Fine Uploader will simply abort the XHR request, and to continue it will send the request again. In existing design of Fine Uploader this will emit another upload event which is why you are running into this issue.\n\nI would assume it should only be triggered once per upload [...] I need to take page actions based on the initial start of the upload.\n\nWhat exactly would you define as the initial start of the upload? And what is your use case -- there could be another way...\n. @borisreitman -- Sweet tool!  It does not seems so, but is it possible to have Delta Proofreader post spelling mistakes as issues/auto-fill a GitHub issue with the corrections?\n. It looks cool, but I'm not convinced that our users would actually use it. We'd need have to have it prominently displayed somewhere so they know it exists, and users would still need to post a new issue on GitHub. It just seems like a lot of steps to submit a spelling mistake.\nOne idea is to have a link directly to the source of each page on GitHub. A site I whipped up a while ago has an example of this. To the right of the post title there are a few links. 'v' takes you to GitHub to view the source and 'e' takes you to GitHub ready to edit the source. There are a few other links in that example that take you to the first or last commit (so you can see the diff over time) and the tag that that post is related to.\nI could image the docs having small icons near the version at the top of the page that would take the users to a GitHub page where they could view the source and/or fork/pull-request easily for that page.\n. > This is pretty much what Angular does for their docs. See the \"Improve this doc\" button at the top-right of any doc page at http://docs.angularjs.org/api.\nSimple, and I like it. :+1: \n. The current template does integrate with bootstrap 3. Obviously you need to add our own classes and such. A good example is on the full-stack example on the official blog\nOr are you requesting that an already bootstrappified template come included in the final .zip?\n. Closed in https://github.com/Widen/fine-uploader-server/pull/26\n. This is what I am seeing when running the google closure compiler on all.fineuploader.js:\n```\n% /usr/local/bin/closure-compiler --js all.fineuploader.js\nall.fineuploader.js:378: ERROR - Parse error. identifier is a reserved word\n        qq.each(bytes, function(idx, byte) {\n^\nall.fineuploader.js:379: ERROR - Parse error. identifier is a reserved word\n            var byteAsHexStr = byte.toString(16);\n^\nall.fineuploader.js:9597: ERROR - Parse error. identifier is a reserved word\n        qq.each(byteString, function(idx, char) {\n^\nall.fineuploader.js:9598: ERROR - Parse error. identifier is a reserved word\n            intArray[idx] = char.charCodeAt(0);\n^\n4 error(s), 0 warning(s)\n```\n@coolbloke1324 -- this is consistent with your findings? It is my first time using the Google closure compiler; not sure if you are using any extra flags or anything.\n. Enabling the es3 option in jshint would help us catch stuff like this in the future. It seems like these words are only reserved in ES2/3 according to MDN. Also maybe not a bad idea to enable that since we support browsers running ES3 engines ... \n. Forgot to add that I fixed this in 59c66ce\n. > Also please version:build\n:ok_hand:  306cd7e956\n. Just glanced at the source, it appears this is set because it is the largest possible integer in JS. Is this realistic?\n. Hmm... I just blew away my node_modules and ran npm i and grunt package and I did not experience this. \nI'm running:\n% grunt --version                                                                                                                                                                                                                                                            \ngrunt-cli v0.1.13\ngrunt v0.4.4\nWhat version of grunt are you on? I think they've had API changes recently.\ngrunt --version\n. Did you run npm i inside of the project dir? You also need a local grunt.\n. @craigrbruce -- No worries, everyone's development workflow is a bit different. Thanks for the effort! We'll review this as soon as we can. Thanks again for your contribution! :clap: \n. @craigrbruce, What is your fix for exactly? I think I found it as a comment here, but I'm not sure.\nAlso, I am not able to reproduce seeing any exceptions when dragging and dropping HTML elements into the dropzone. Do you have any steps to reproduce? That would be super helpful. Thanks\n. :+1: x :100: \n. This is intended. All the demos except the S3 demo (which is fully functional) are rigged to continue to work on GitHub pages where we can only do GET requests.\n. The ability to get this data exists already. See Stats and Status Updates\nThat combined with the public API methods getUploads, getInProgress, and getNetUploads combined with the onAllProgress event it should be fairly trivial to add some sort of indicator.\nUnless you are advocating that this be included with the UI by default for those using the default UI mode. Any ideas as to how that would look?\n. @anbalaganM,\nThe reason your attachments are not working is because you are replying via email rather than using the built-in editor here at #1205 . For instructions on adding an attachment, please see: https://help.github.com/articles/issue-attachments\n. > Entirely client-side\nThis should be an end-goal, definitely. Might be an easy win to make a CommonJS exported function that deals with raw binary data (Uint8Array, Buffer, etc.), and then build client-side functionality (canvas->buffer, image tag->buffer, etc.) on top of that.\nAPI\n```\nmodule.exports = function(threshold, image_1, image_2[, ..., image_n]) {\n}\n```\nImplementation / Algorithms\nImage Comparison\nPerceptual Hash\nA hashing function which will return hashes that are \"close\" to each other if the features of the hashed object are similar.\nHistogram Matching\nNot entirely sure what is going on here. Somehow the image data is transformed into a histogram (similar to Fourier transform maybe?). Then you can subtract histograms from each other to detect similarity/difference.\nHaar Wavelet\nAgain, not really sure what this is, but I'm seeing it pop-up a lot on the literature surrounding dup. image detection.\nStoring Results\nk-d tree\nSpinning off of the tree idea proposed by Ray, I found about a k-d tree (a k-dimensional tree). Since each pixel is composed of 4 \"vectors\" (R,G,B, and A) we would say each vector is a dimension in the k-d tree. Seems to have good efficiency.\nBloom Filter\nA bloom filter could be used to store a set of the unique images from the user, and then we can test whether newly added images are within that set (within a certain probability of a false positive).\nPros: efficient\nCons: can only detect if something is NOT in the set, or there in the set within a certain probability\n/cc'ing @aswenson and @uriahcarpenter to see if they have any ideas :)\n. /cc'ing @nmall as well\n. i put together a simple jsbin that compares two images, pixel by pixel, in the browser. it's fairly speedy, surprisingly. obviously would slow down as more files are added. The comparison (right now) is only between two images, not against the set of all inputted images.\nFeel free to edit and/or provide suggestions. \nSince the image data is now in a more malleable form, I think next I'd like to create a way to experiment with different comparison algorithms and do some profiling of the different algos.\nstarting point? \n. Ah yes, you're correct. I knew something was up when I was using FileReader. URL.createObjectUrl is what was needed to Blob -> <img>.\nUpdated, and removed unused code: http://jsbin.com/nosamu/23\n. Unable to reproduce using your test image on FF 29.0.1 on Windows 7.\n\n@yairEO -- any other steps to reproduce? Otherwise I vote we close this.\n. I'm all for jscs enforcement.\n@mrjoelkemp Thanks! Be sure to make a pull request off of develop, we have some changes to the build scripts in there that have not made it to master yet. :+1: :beers: \n. It seems like all the stuff under client-side integration would fall under that category (in the docs) whilst (almost) everything else looks like it can exist in the blog\n. Hello @trinzia, \nYour total file size is determined by the amount and number of separate modules you build the library with. The maximum file size you can expect (that means ALL features and endoints included in one build -- a rare case indeed) is less than 60kB.\nWe use the issue tracker primarily for bug reports, feature requests, and the like. For any licensing questions, please email licensing@fineuploader.com and we'll respond immediately.\nThanks\n. Confirmed.\nThe resulting uploaded file on disk is 0 bytes.\n```\n\n\nHEADERS: \n{ host: 'mfeltner.local:8000',\n  accept: '/',\n  'x-requested-with': 'XMLHttpRequest',\n  'accept-language': 'en-us',\n  'cache-control': 'no-cache',\n  'accept-encoding': 'gzip, deflate',\n  'content-type': 'multipart/form-data; boundary=----WebKitFormBoundaryP5VKAiuYnd3r5bwo',\n  origin: 'http://mfeltner.local:8000',\n  'user-agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_1 like Mac OS X) AppleWebKit/537.51.2 (KHTML, like Gecko) Version/7.0 Mobile/11D201 Safari/9537.53',\n  'content-length': '539',\n  dnt: '1',\n  referer: 'http://mfeltner.local:8000/',\n  connection: 'keep-alive' }\n\nFILESIZE: \n'0'\n```\n\n\n\nLooking into causes.\n. @bjornbos, Found out your problem. You have a typo in 'maxsize' it should be 'maxSize'. Looking into why this is choking on iOS but not in chrome \n. Not sure how that'd work, as the page needs to scroll as well... \nI haven't come up with a better idea yet, though... maybe we could categorize features, and offer sub-menus?\n/cc'ing @joshuaArd and @avo  to see if they have any ideas\n. Update the onValidateBatch callback to reflect this more clearly as well.\n. @PauloCelso -- are you saying that Fine Uploader is attempting to retry the upload when the connection fails, even though you have set autoRetry: true?\nI'm not really sure what settings you are using. Do you have any code I could look at? Is there any information in the javascript console or network tab? Adding { debug: true } to your Fine Uploader constructor should log more information too.\n. Hmmm... We do not have a Huawei P6 handy, unfortunately. I can't seem to find an emulator anywhere online either...\n. @firepol -- Not able to reproduce on Firefox on native Windows 7, virtual-machine Windows 7, or on OS X.\nI wonder if the extra javascript and other visual effects on the site could be inflicting some performance issues on the user's machine, thus making the button seem unresponsive/janky. I tested on a fairly beefy machine, and the background effect was lagging around a bit.\nIf you could boil your issue down to the smallest possible test case able to reproduce, then we could most likely come up with a more definite answer as to what is going wrong.\n. @rnicholus -- I'd still love to overhaul it simply because I think it should be easier to develop against our documentation generator, and it should be easier to compile the docs.\n. @feryardiant -- ./lib/modules contains definitions of different Fine Uploader \"modules\" for inclusion in a customized zip file. The grunt custom task is what uses that file to assemble a build and ensure everything is in the right order.\nThe task's arguments are just a comma-separated list of \"modules\" as defined in ./lib/modules. Each argument is basically stating what should be concatenated to the final script, and in what order they should be concatenated.\nFor example,\ngrunt custom:fuSrcCore,fuSrcTraditional,fuSrcUi,fuDeleteFileModule,fuPasteModule,fuDndModule,fuImagePreviewModule,fuUiEvents,fuDeleteFileUiModule,fuEditFilenameModule,fuSrcJquery,fuSrcJqueryDnd \nwould build a pretty standard traditional build (see fuSrcTraditional) and put a zip in your local ./_custom folder in the project root.\ngrunt custom:fuSrcCore,fuSrcS3,fuSrcJquery,fuSrcS3Jquery would build a minimal S3 endpoint build\nand so on...\nIn hindsight the build formulae should have maybe been subtractive (rather than additive) so that the build strings are not so long, but c'est la vie...\nAutomating this is a bit tricky, just because there are a lot of potential combinations.\n. Right, there currently is no API method supporting this operation. Could you not just use setUploadSuccessParams to send extra parameters to the success endpoint, or must it be on a unique endpoint?\n. Thanks, @xzyfer. And the tests pass :beers: !\nI'll check this out later today. In an in-progress branch, I actually removed bower (4d92a2d468146710eff63183ccef0c0adde05ec8) so dd83522 may not be required.\n. > For what it's worth the patch doe bower was just to get Travis passing.\nRight. I ran into the same issue too.\n\nThe actual bug I'm fixing is rather crippling for us and worthy or a hotfix\nrelease IMHO.\n\nI think you're right. I still need to verify, but once/if I do I will schedule a hotfix.\n. Okay I verified this in the current release. I've scheduled this for the next hotfix release. I don't have a date for the next hotfix release, but it should be soon.\nthanks for the report / pull request.\n. >  users complain that dragging folders gives an inconsistent experience.\nWhat is inconsistent?\n. :+1: Agreed.\n\nApple, breaking the file input element since 2012 ...\n. > Not specifying a href means the styling doesn't work to act as a link.\n\nYou can style it however you want. Why does it need to be an <a> tag? You can circumvent page reload with a hash link \"#\" as the href like Ray suggested.\nAlso, programmatically submitting click events within click events is not going to work cross-browser.\n. Fine Uploader should really have a CHANGELOG file in the root of the repository that outlines detailed changes to objects and functions based on the commit conventions we have been using in the project.\nThe point of the CHANGELOG is more for devs/QA to be able to quickly and easily refer to changes that have occurred between releases.\nNote that this is different from Release Notes (#1294).\n. Should contain:\n- release, buildnumber\n- all fixed bugs including bug number  (link to issue/commit)\n- all added features including links to design docs (link to issue/commit)\n. Does calling reset() on the Fine Uploader instance work?\n. Release notes should contain:\n- release, buildnumber\n- all fixed public bugs (aggregated by issue #)\n- all added public features (aggregated by issue #)\n. Closed. I need to remember to search first (#1280) :blush: \n. @mrjoelkemp wow! thanks for doing this! :+1: \n@rnicholus what is the addCanvas branch?\nOtherwise, the other branches (except gh-pages, of course) are mine (and some may be old/dead), I can take care of any conflicts with those.\nI think the only conflicts that may arise would be due to stuff that has changed because of 5.0.6, but that shouldn't be too difficult to deal with. Worst case, we have to fix a just few styles again.\nGodspeed, @mrjoelkemp !\n. I'm with you @sjelfull it'd be a great addition to Fine Uploader. \nWe need to finish #789 for this to be possible. What I am thinking is that we could have FU use UMD which would allow it to work on CommonJS, AMD, and current. This would mean no breaking changes for previous integrators still loading FU from the window object.\nUnfortunately, that's a lot of work, and refactoring FU to use CommonJS requires touching a lot of code.\nThe other weird bit is that when FU was created there was no CommonJS or AMD so -- instead -- it namespaces itself by creating the qq object on the window (qq being a namespace that will probably not be used by any other lib, but this is not guaranteed). That being said, if we wanted to make FU use CommonJS/AMD/UMD then this qq object will need to be rethought (and maybe even removed (?)). I would not want to require('qq') but instead require('fine-uploader').\nMaybe what we could do is export a FineUploader object (which has the S3, Azure, and traditional versions on it) for CommonJS/AMD, and export a qq object on the window for non-CommonJS/-AMD. That being said, a lot of the internal code refers to objects on the qq namespace.\nIn essence, making FU work with browserify (commonjs) is a lot of work, but doable.\nI think this is an important feature to add because it keeps FU current with what appears to be a emerging (emerged?) standard for JS libs on both the web and the server.\n. Also, one of the major benefits of browserify is the ability to npm install a module and use it right away in your web-projects. Fine Uploader's licensing is meant to prevent commercial users from using the library for free, while allowing OSS and non-commercial projects to freely use the software. Enforcing this when the library is on npm is probably impossible. That being said, npm can use github urls to install so maybe it's not worth worrying about.\n. I was able to wrap the concatenated Fine Uploader sources in a UMD wrapper using grunt-umd pretty easily. From there I don't see any reason why you wouldn't be able to require Fine Uploader in your browserify bundle.\n. Does this method apply to traditional endpoints?\n. Once I get some tests done for this (this week hopefully) this should be merged in somewhere. @rnicholus if you think this is hotfix-worthy I can get this branch to be off master instead of develop, otherwise we can bundle it with the next minor/major release. \nIf this was to be merged into develop, should the build number be incremented?\n. Cool. I'll merge into develop once I get tests, and then also increment the build number.\n. My understanding is that you are trying to get image previews working on Android 2.3.3. Does that sound right?\nIf so, I don't believe this is possible in Android 2.3.3 stock browser. We have a table that shows which features are supported by which browsers here: http://docs.fineuploader.com/browser-support.html\nIf the onComplete event is truly not firing then either a) your server is not responding correctly or b) we have a bug. If you could show your code so we could try and reproduce that'd be great! For information on how to format code, please see: https://help.github.com/articles/markdown-basics/#code-formatting\n. +1\nI can definitely take care of the docs site :)\n. > I need to get moment when all files were submitting.\nYou're trying to load all the files, and then begin sending them, rather than sending each one as soon as as possible?\nIf so, maybe you could set autoUpload to false, and begin the upload once you've finished adding your files. With autoUpload: false you should be able to pretty easily control when your files begin uploading.\n. Correct. The custom build generator was deprecated in favor of just linking to zip files containing the entire source. A few reasons:\n1. Some people were encountering bugs due to them thinking they had selected a module, when in actuality they had not.\n2. The extra 60k does not add much overhead. On a 1Mbps connection it'll only take ~.5 seconds to get the extra 60k. Add in the fact that should have caching and compression on your server, and this time becomes even less.\n3. Maintenance of the build generator was slowing down our releases, and adding extra overhead for not a ton of perceived benefit (the benefit being smaller sizes for some customers, but that size is negligible when you take into account the fact that modern browsers and servers can cache and compress resources which considerably reduces the size of the payload.\n4. The latest release was published on npm, and for consistency we decided that the build generator should follow the layout and structure of the code distributed via that.\nFor the future, we are thinking about putting up multiple packages on npm (so you could install: npm install fine-uploader-{azure,s3,traditional}. Maybe in the future we could have separate modules (DnD, Image resizing, etc.) be modularized on npm so that you could optionally include these if you wanted.\n@hn1 -- is there any compelling reasons you can think of (besides size of code-base) that would merit a return of the custom build generator?\n. That library seems like a dirty hack. It's really smart, but still ... do we really want to make a request to some random GitHub URL and trust that their video is indeed muted and invisible? I wouldn't ...\nI feel like I've seen some new W3C specs coming out that address this more formally ... maybe something like service workers or similar would be a better fit ...\n. Running into this issue now when trying to upload from an EC2 instance that has credentials supplied via IAM instance profiles.\nIdeally, should be able to provide the session token at Fine Uploader initialization (much like accessKey) (and maybe even dynamically to account for the case when a token may expire in the middle of an upload).\n. Since the secret key and access key should change in tandem would it make sense to have the signature endpoint return the accessKey? This would ensure each request was signed using the right secret-/access-key pair (I think).\n. Interesting. I am unable to even open the file chooser to be able to select a video. The instant I tap the file chooser the browser just crashes and brings me back to Facebook (also of note, subsequent URLs will not open the browser any more until you restart the Facebook app).\n. @albertpr9 I went through that process. Unfortunately, there is little feedback and they don't provide you with a way to actually track the bug's progress or see if they're working on it. As far as  I know, the report could just be sent to /dev/null\n. @albertpr9 sounds exactly like the UIWebView issue Chrome was having. Facebook needs to recompile their app against the iOS8 SDK.\n. What issue? What plugin? What extension? Please provide steps to reproduce.\n. Steps/code to reproduce?\n. ",
    "zgbjgg": "Hello, recently I've worked with fine-uploader from angular and nodejs, and I want download the files (maybe saved into a db) of a user previous upload, the user is identified by an id, so for example, I did the next modifications:\n- In the fine-uploader.js, I change the reset function, providing a custom URL in the endpoint so the next reset execute a call to our system (an endpoint of REST API):\n``` javascript\nreset: function(endpoint) {\nthis.log(\"Resetting uploader...\");\nif ( typeof endpoint != 'undefined' ) {\n    this._options.session.endpoint = endpoint;\n} else {\n    this._options.session.endpoint = null;\n}\n```\nUPDATED: The above step is optional, you can perform only the next steps and declare a new attribute into the directive: session-endpoint='/getimages/{{user_id}}' and fill the user_id from controller \ud83d\udc4d \n- In my directive, I add a custom reset, and I add a broadcast, so for example, from any controller I can reset the directive and then call to download specific images!:\n``` javascript\n$scope.resetUploader = function(id) {\n    $scope.sessionendpoint = '/getimages/' + id;\n    uploader.reset($scope.sessionendpoint);\n     console.log('uploader', uploader);\n};\n$scope.$on('resetUploader', function(event, data) {\n    $scope.resetUploader(data.id);\n});\n```\n- Finally in controller:\njavascript\n$rootScope.$broadcast('resetUploader', {id: $scope.user_id});\nI hope this can help you if you have the same problem !!\nThanks!!\n. ",
    "templth": "Hello Ray,\nThe callbacks section (https://github.com/valums/file-uploader/blob/master/readme.md#callbacks) seems to correspond to version 2 instead of version 3.\nOtherwise, I can see that the other callbacks section (https://github.com/valums/file-uploader/blob/master/readme.md#callbacks-fineuploader--fineuploaderbasic) is up to date.\nThierry\n. I understand better now! Thanks!\nPerhaps could you add a listing for the callbacks section (https://github.com/valums/file-uploader/blob/master/readme.md#callbacks).\nWhy it's not the same way to configure callbacks for both ways? It could appear confusing for developers from my point of view...\nOtherwise thanks very much for your excellent tool and documentation. All my comments only aim to help you improving it.\nThierry\n. I understand better now. Thanks for the hints!\nThierry\n. ",
    "farhantahseen": "I am using older version and I am facing the same issue but in all browsers. It occurs when if you press delete link before upload complete. after 2,3 times uploading stopped with following error in console.\n TypeError: a is undefined (file: jquery.fineuploader.min.js)\nif (a.querySelectorAll){ \nAccording to my finding if i am not wrong each time when upload starts till complete there are multi status for a, from li to li.qq-upload-success\nplease help.\ngetByClass: function(b) {\n            var c, d = [];\n            if (a.querySelectorAll) //this line creating issue\n                return a.querySelectorAll(\".\" + b);\n            c = a.getElementsByTagName(\"*\");\n            qq.each(c, function(a, c) {\n                qq(c).hasClass(b) && d.push(c)\n            });\n            return d\n        }\n. Everything is going good, if you suggest anything in this regard i will be thankful to you dear\n. basically I am using jquery-uberuploadcropper library to upload, crop and drag images with a lot of customize code therefor I was asking for a quick fix. Anyhow I will upgrade all libraries then if there would be any issue I will let you know, Thanks \n. I think they are using fine uploader: below is the link\nhttps://github.com/trentrichardson/UberUploadCropper\n. That's mean my issue will be resolved if uberUploaderCropper will update their library? also there is no support for IE 11 for drag and drop\n. ok thanks a lot for your kind support\n. ",
    "ronnieoverby": "I've tested with latest of all of the big 5 (chrome, ff, ie, opera, and safari)\nMy improvements are:\n- Code is c# (way more c# developers than vb.net)\n- Idiomatic asp.net mvc classes that take advantage of the framework\n- Way less code in the controller to accept and process an uploaded file from FineUploader\n- Very easy to return a proper response to FineUploader client\n- Examples of increasing request length limits in asp.net for uploading larger files\n- readme references nuget package making it very easy to pull FineUploader into an asp.net mvc project\n. Thank you for the library!\n. ",
    "NotionCommotion": "What if I have a table or list of items each with its own uploader button (which applies to the specific row or list item)?  I want the uploader to set a parameter to identify the particular row or list item, and upon completion want to modify  that specific row or list item.\n. Yes.  This will allow using \"this\" instead of hardcoding the ID in my callback.\n. I agree completely with how you made \"this\" point to the current uploader instance inside of a callback.  Just looking for a property or method of this which would get you back to the original div element.\nRegardless, I am sure there are workarounds, and very much appreciate all you have done.\n. Thanks Ray,\nI currently do not use the jQuery plug-in, but might do so in the future.  Would you potentially provide access to the \"value\" of the element, or to the DOM?  I am looking for the later as I wish to modify the page somewhere relative to the location of the button.\n. Absolutely!\n. Thanks Ray!\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Tuesday, March 12, 2013 7:24 PM\nTo: valums/file-uploader\nCc: NotionCommotion\nSubject: Re: [file-uploader] Desired Feature - Make DIV public (#543)\nThis has been implemented in 3.4-IP.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/543#issuecomment-14818125 .  https://github.com/notifications/beacon/2XY-qK9jn7qfN3zV0mH0MdB9vaW0ZR927k-7Rvw_0vohelcfFJnZ3S8wZuE32jzs.gif \n. ",
    "circulon": "I have a similar issue in that I needed to alter the attribs of a select box in my file template on a per file basis so the id & name are unique on the page.\nI fixed this by adding an onValidSubmit callback which is called directly after the onSubmit callback succeeds in the _uploadFile method  and supplies the same args (id, filename)\nThis allows access to the item AFTER it has been added to the DOM.\nI think this is what the OP was getting at but in any case it is an extremely useful addition. \nThanks\n. @rnicholus  YES most definitely!   I can email my changes if you like? it was very simple and easy to implement.\n. ok thanks\n. Yes that sounds good, this would even allow DOM modification (if needed) before the auto upload starts.\n. Much Appreciated.  Keep up the good work!\n. Sorry for the delay (seems I missed the repo change too ;)  in any case the code looks good but I cant test it at this stage.  Will wait for 3.4 and then test it thoroughly if thats ok?\nThanks\n. ",
    "pjfila": "Okay, sorry, so to be more detailed\nFine Uploader creates this element for each instance of FileUploader\n\nInstead of this, I need to have multiple \n \nthanks for response\nPavel\n. Well, the project is a huge one and I cannot refactor its logic as easily as to change a little JS script :) First I have to say that at the moment things are OK for me. I just updated the fineuploader.js very very slightly.\nThe server side processes a very very huge form full of variables, if it encounters two input fields with the same name displays error. As I see it, the simplest way how to avoid it is to change the name of the input. Not everything of the project is in my hands so I decided to allow this configuration of FU instead. And now it works fine :)\n. ",
    "phax": "Lol.\nI was assuming you would as something like this :)\nWell the scenario is as follows:\nI want to upload a file (required) and an optional set of attachments\nThe file goes to a different Java servlet (XML with validation) than the\nattachments (anything).\nBecause not using \"autoupload\" provides improved usability (the user can\ndelete an attachment before uploading it), we decided to send all files in\none form submission.\nSo the main XML upload is a regular file-input and the attachments are\nhandled with fine uploader.\nUpon form submit, I first want to send the attachments synchronously to\none servlet, wait until they are all uploaded, and than send the XML file\nto the other servlet using regular form upload.\nTo avoid having the \"onbeforeunload\" handler to interfere, I need\nsynchronous upload.\nHope you got my point.\n// Philip\n\nWhy on earth would you want the Ajax request to be synchronous?\nOn Dec 20, 2012 8:14 AM, \"Philip Helger\" notifications@github.com wrote:\n\nHi!\nBy default the jQuery version of FileUploader 3.1.1 uses asynchronous\ntransmission mode for XHR.\nCould you please either support the jQuery AJAX stuff or add support for\nsynchronous transmission.\nSimply replacing line 2356\nxhr.open(protocol, url, true);\nwith\nxhr.open(protocol, url, false);\nsolves the issue for us.\nSo a basic request option would be great :)\nKeep up the good work!\n// Philip\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/valums/file-uploader/issues/545.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11577488\n. Hi!\n\nThanks for the hint. I was not aware that this kind of calls is blocking.\nI'm now trying to build a solution as you suggested like this:\n$('#attachment-obj').on ('complete', function(id, fileName, responseJSON) {\n                                         if (responseJSON.success)\n                                           $('#finvoice').submit();\n                                       })\n                      .fineUploader('uploadStoredFiles');\nstill trying...\nThanks for your help anyway!!!\n// Philip\n\nI'm not sure I can explain all the reasons why synchronous ajax requests\nare a bad idea, because there are so many. The main reason is due to the\nfact that web browsers (for the most part) are single-threaded.  That is,\njavascript and rendering tasks all compete for execution on one thread.\nIf one of these tasks block, the UI becomes unresponsive and nothing else\ncan occur until the blocking task completes.  The one place where\nsynchronous tasks are acceptable is inside of a web worker, since web\nworkers execute on a separate thread (not the UI thread).\nUnless your code is running inside a web worker, you should NEVER utilize\nsynchronous ajax requests.  This is simply bad practice.  The problem you\ndescribed above can be addressed very easily by simply by registering a\nFine Uploader onComplete callback handler and performing whatever tasks\nyou want after the last file has been sent.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11580830\n. Sorry for being so lax. This all happens inside a function. And I finally\nmade it working:\nfunction _uploadBeforeSubmit ()\n{\n  $('#attachment-obj').on ('complete', function(id, fileName, responseJSON) {\n    var nInProgress = $('#attachment-obj').fineUploader('getInProgress');\n    if (nInProgress == 0)\n      $('#finvoice').submit();\n  });\n  $('#attachment-obj').fineUploader('uploadStoredFiles');\n}\n\nplus:\nSend\nThanks,\n  Philip\n\nYour current code, as listed in your comment, will initiate upload of all\nfiles immediately after initialization of the uploader.  Not sure if\nthat's\nwhat you want to do.\nOn Thu, Dec 20, 2012 at 11:04 AM, Philip Helger\nnotifications@github.comwrote:\n\nHi!\nThanks for the hint. I was not aware that this kind of calls is\nblocking.\nI'm now trying to build a solution as you suggested like this:\n$('#attachment-obj').on ('complete', function(id, fileName,\nresponseJSON) {\nif (responseJSON.success)\n$('#finvoice').submit();\n})\n.fineUploader('uploadStoredFiles');\nstill trying...\nThanks for your help anyway!!!\n// Philip\n\nI'm not sure I can explain all the reasons why synchronous ajax\nrequests\nare a bad idea, because there are so many. The main reason is due to\nthe\nfact that web browsers (for the most part) are single-threaded. That\nis,\njavascript and rendering tasks all compete for execution on one\nthread.\nIf one of these tasks block, the UI becomes unresponsive and nothing\nelse\ncan occur until the blocking task completes. The one place where\nsynchronous tasks are acceptable is inside of a web worker, since web\nworkers execute on a separate thread (not the UI thread).\nUnless your code is running inside a web worker, you should NEVER\nutilize\nsynchronous ajax requests. This is simply bad practice. The problem\nyou\ndescribed above can be addressed very easily by simply by registering\na\nFine Uploader onComplete callback handler and performing whatever\ntasks\nyou want after the last file has been sent.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11580830\n\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/valums/file-uploader/issues/545#issuecomment-11581503.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11582034\n. Sorry for bothering you again, but how can I easily determine, whether a\nfile is in the queue or not if autoUpload is false?\ngetInProgress always returns 0 and I have seen no possibility to access\nthe _storedFileIds array :(\n\nAny help is appreciated.\n// Philip\n\nYour current code, as listed in your comment, will initiate upload of all\nfiles immediately after initialization of the uploader.  Not sure if\nthat's\nwhat you want to do.\nOn Thu, Dec 20, 2012 at 11:04 AM, Philip Helger\nnotifications@github.comwrote:\n\nHi!\nThanks for the hint. I was not aware that this kind of calls is\nblocking.\nI'm now trying to build a solution as you suggested like this:\n$('#attachment-obj').on ('complete', function(id, fileName,\nresponseJSON) {\nif (responseJSON.success)\n$('#finvoice').submit();\n})\n.fineUploader('uploadStoredFiles');\nstill trying...\nThanks for your help anyway!!!\n// Philip\n\nI'm not sure I can explain all the reasons why synchronous ajax\nrequests\nare a bad idea, because there are so many. The main reason is due to\nthe\nfact that web browsers (for the most part) are single-threaded. That\nis,\njavascript and rendering tasks all compete for execution on one\nthread.\nIf one of these tasks block, the UI becomes unresponsive and nothing\nelse\ncan occur until the blocking task completes. The one place where\nsynchronous tasks are acceptable is inside of a web worker, since web\nworkers execute on a separate thread (not the UI thread).\nUnless your code is running inside a web worker, you should NEVER\nutilize\nsynchronous ajax requests. This is simply bad practice. The problem\nyou\ndescribed above can be addressed very easily by simply by registering\na\nFine Uploader onComplete callback handler and performing whatever\ntasks\nyou want after the last file has been sent.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11580830\n\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/valums/file-uploader/issues/545#issuecomment-11581503.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/valums/file-uploader/issues/545#issuecomment-11582034\n. \n",
    "Yahasana": ":+1: a valid JSON with an \"error\" property works like a charm.\n. ",
    "mkoch42": "Wow - glad I thought to post here.  You solved it with the above fix! Super easy...nice call.  We will probably switch it to our own modal now that you point that out but the alert() working is def a nice way to go for us for now.\nThanks again!\nMatt\n. ",
    "xoxoj": "Above, I have the server-side code paste out, you have a problem?\nand why in Firefox and Chrome is perfect?\n. ",
    "niceguyblue": "this in the  php code \nin server/php.php \nline number 244 \nif(!$replaceOldFile){\n            /// don't overwrite previous files that were uploaded\n            while (file_exists($uploadDirectory . DIRECTORY_SEPARATOR . $filename . $ext)) {\n                $filename .= rand(10, 99);\n            }\n        }\na rand number is added to the file name. This new file name is not provided in filename\n. ",
    "rmills": "Just a quite notice that method breaks drag and drop target. Ended up just\nusing to empty the UL. Would still be nice at some point to have control\nover the messages via the api.\nsetTimeout(function() {\n$(\"#drop-target\").find('.qq-upload-list').html(false); }, 2000);\nOn Thu, Dec 27, 2012 at 6:53 PM, Ray Nicholus notifications@github.comwrote:\n\nHello Ryan. The notice you are referring to is a part of the FineUploader\nUI. Since you are the first to request such a modification, and since this\nnotice can be hidden quite easily through your own code, it seems like\nadding another API function or option would add clutter to the library.\nYou can hide the file info at any time using javascript. Since you are\nobviously using jQuery, I'll provide a jQuery example:\n$('#myUploader').on('complete', function(event, id, filename, responseJSON) {\n   var fileItem = $(this).fineuploader('getItemByFileId', id);\n   setTimeout(function() {\n      $(fileItem).find('.qq-upload-file').hide()\n                 .end('.qq-upload-size').hide();\n   }, 5000);});\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/551#issuecomment-11724078.\n\n\n*Ryan Mills\nWeb Developer/Photographer\nCell: 509.869.1411\nhttp://ryanmills.net*\n. ",
    "teologov": "Found, this parameter is kept in uploader._handler._options.endpoint\n. Thanks for your answer.\nAnyway, I haven't found any better solution, which could solve this problem for my client-side module. It's because of RESTful backend. I need to initialize uploader before any additional data would be received. That is why I can't detect which endpoint would be required.\n. Thanks! I appreciate your work.\n. Yes, you are right, request method. That's because of my backend. My web application expects PUT for update operations..\n. Thank you!\n. @rnicholus Yes, I do. \nActually, the only way I found before using the Fine Uploader ( temporarily ), was form, but not with a PUT request. I catched the form submitting event, and than I used for file sending something like this: \nvar\n     xhr = new XMLHttpRequest(),\n     formData = new FormData(),\n     onReady = function( e ) { },\n     onError = function( err ) { };\nxhr.open( data.id ? 'put' : 'post', _url );\nxhr.addEventListener( 'error', onError, false );\nxhr.addEventListener( 'readystatechange', onReady, false );\n// here append data ...\n// than send\nxhr.send( formData );\nSo, as I understood, the only way is to change my server-side RESTful API service, and let in some cases to handle POST on update operations..\n. @rnicholus Yes, indeed. There is no sense to make any changes, because of older browsers. \nThank you a lot for your help. I appreciate it.\n. ",
    "stephanstapel": "Cheers, that exactly did the trick!\n. ",
    "spiraldev": "This is what the image looked like after uploading the image.\n\n. yes the server did not like \"application/octet-stream\" but it liked \"multipart/form-data\"\n. I believe that it is a bug with the server software.\n. ",
    "twig": "Hi Ray,\nI've applied and tested the #562 fix into my project.\nIt does indeed hide the processing graphic but the drag/drop functionality is still disabled when you try to drag/drop after the alert.\nIt'll also need the 1 extra line to re-enable the dropzone in #576\n. No problems. Working fine, thanks!\n. 1) Sorry about that. Should I make another pull request to the IP branch?\n2) Thanks, that fixed it for me.\n. Would love to help with debugging/patch but not sure where to start.\n. Ahh yes, forgot about that debug option.\nAnd you're right, the response is blanked out for some odd reason (even after forcing mimetype to be application/json)\nOther than that hiccup, the actual upload/save process seems to be working fine on Opera.\n. Hmm no luck, thanks anyway!\n. ",
    "udhamsattri": "Error shown in console is \n[FineUploader] Error when attempting to parse xhr response text (SyntaxError: JSON.parse: unexpected end of data)anonymous()fineup....1.1.js (line 156)\nanonymous()fineup....1.1.js (line 666)\nanonymous()fineup....1.1.js (line 2405)\nanonymous()fineup....1.1.js (line 2344)\nwindow.consolelevel;\nThanks\n. But I have not written any server side code to upload the files .\n. ",
    "buaziz": "try this on the server side \nASP .NET MVC 4\n```\n  \n  Public Function AttachmentsUpload(qqfile As String) As JsonResult\nDim errMessage As String = \"Error Message\"\nTry\n    Dim MyStream As System.IO.Stream\n    Dim FileLen = Request.InputStream.Length\n\n\n    Dim Input(FileLen) As Byte\n\n    ' Initialize the stream.\n    MyStream = Request.InputStream\n\n    ' Read the file into the byte array.\n    MyStream.Read(Input, 0, FileLen)\n\n\n    Dim record = New MyEntities.Attachment\n\n    record.Content = Input\n    record.Date = Now\n    record.Title = IO.Path.GetFileNameWithoutExtension(qqfile)\n    record.ContentType = IO.Path.GetExtension(qqfile)\n\n    ctx.Attachments.Add(record)\n    ctx.SaveChanges()\n\n    record = Nothing\n    Input = Nothing\n    MyStream.Dispose()\n\n    Return Json(New With {.success = True})\n\nCatch ex As Exception\n    errMessage = ex.Message\n\nEnd Try\n\n\nReturn Json(New With {.success = False, .error = errMessage})\n\nEnd Function\n```\n2 notes\n1.my DataContext as initialized somewhere else don't worry about that\n2. return has to be .success\n. ",
    "safr0": "well i'm facing the same issue. \npublic FineUploaderResult UploadFile(FineUpload upload, string extraParam1, int extraParam2)\nthis is what action asp.net mvc nuget package have on server controller i've not written any server code just testing it. \nand this is my endpoint \nendpoint: '@Url.Action(\"UploadFile\",\"Upload\")'\nits trying to make a following post \nPOST http://localhost:4247/Upload/UploadFile?qqfile=notes.txt 500 (Internal Server Error) \nqqfile is no where on server. i tried changing both String Param and FineUpload upload param names to qqfile but this doesn't work. do tell me if i'm missing something here\n. this code doesn't hit server controller... returning Json comes later... anyways whatver\n. or set them with the\nfine uploads options. can you tell me the name of the param i couldn't find any on samples \n. i used this code [HttpPost] public ActionResult ReceiveFile(FineUpload qqFile) \nand as you can see my error console \nits trying to make a following post \nPOST http://localhost:4247/Upload/UploadFile?qqfile=notes.txt 500 (Internal Server Error)\nqqfile is already in being posted the the link... let me what I'm doing wrong plz\n. ",
    "kleesman": "I am now successfully using the onValidate callback to keep a running total of file size and count as files are added. My only remaining problem is when a file is removed from from the queue. The onCancel event only provides the id and name of the file, but not the file object or fileData that would allow me to subtract the size of that file off of my running total. \nIs there a way around that now?\n. I added the following functions to qq.FineUploaderBasic in uploader.basic.js and was able to handle everything I needed and eliminate the need to calculate the total file size on the page. \nThanks for your help!\njavascript\n    getSize: function (fileId) {\n      return this._handler.getSize(fileId);\n    },\n    getStoredFilesTotalSize: function () {\n      var totalSize = 0;\n      for (var i = 0; i < this._storedFileIds.length; i++) {\n        totalSize += this.getSize(this._storedFileIds[i])\n      }      \n      return totalSize;\n    },\n. It did still happen to me on my site using 26 beta. I guess it could be\nsomething specific to my implementation. Do you have a public URL I could\ntry uploading a file to?\nOn Wed, Mar 20, 2013 at 10:30 AM, Uriah Carpenter\nnotifications@github.comwrote:\n\n@kleesman https://github.com/kleesman Thanks for the report!\nI was unable to reproduce your described behavior using Chrome Mac\n26.0.1410.33 beta. Could you please re-test with Chrome 26 beta to see if\nthis issue has already been resolved by the Chrome team?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/754#issuecomment-15182674\n.\n. You can try it at http://test.filestofriends.com/.\n\nOn Sun, Mar 24, 2013 at 12:15 PM, Ray Nicholus notifications@github.comwrote:\n\n@kleesman https://github.com/kleesman Please provide a link to your\nlive app where we can reproduce this.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/754#issuecomment-15363287\n.\n. \n",
    "dipcore": "Agree, it's a good idea. Thanks.\n. ",
    "bluesclues9": "I am not quite sure if I understood. I took the same demo code from fine-uploader site.\nI thought  $('#qq-upload-button2') is my element in jquery specification. not correct?\n. my bad. that did the trick. I am missing the event (first parm).\nI'have copied some of this code from my previous code based on 2.1 version.\nAppreciate your prompt responses.\n. ",
    "jayd3e": "Yah I just hit this barrier as well.  I made an issue about it.  It's definitely a deal breaker for me, and I'd be interested in seeing what your plans are.\n. @rnicholus, kind of both, first part at @TheSisb and second at you.  Basically, my dilemma is this, I liked FileUploader Basic b/c it very quickly an easily allowed me to provide file upload functionality by simply specifying a button and overriding all of the relevant callbacks.  I now need the ability to provide drag and drop file uploads.  So I'm considering just rolling my own file uploader that just accomplishes these two tasks(regular button based upload and drag and drop).  Fineuploader Basic is a great product though, and seeing as I paid for it, I would really like to leverage it's power/dependability in my project.  I'm definitely not going to use Fineuploader though, as it is more of a widget, and I feel as though taking the time to override all of the styles/templates would only need to later be replaced anyway.  So that's my user story.  I was just curious as to what you had in mind for moving drag and drop to Basic, or if you find it necessary all together.\n. I should mention that I could help with this, as it is actually a big need for my site which releases next week.  We could maybe work out a schedule if you like the idea of going through with it?\n. I completely understand the complexity of this library, I apologize if it sounded like I was trivializing the subject.  I was by no means talking about replicating FineUploader Basic, I was simply saying replicate a very small subset of the functionality, only what I need, which I have found in a few SO threads.  But that's besides the point, I would much rather mod Fineuploader Basic to do this.  I would just need to get a confirmation that if I shoot you a pull request that meets your code standards/testing needs, that you would accept it.  I basically just want to know if this feature request is on your road map.\n. If not, the option you gave me to use addFiles is also a good one.\n. Kk solid advice, thanks a lot.  I'll go with that route.\n. I like this idea.  Isn't it already possible with fineUploader by setting values in the 'paramsInBody' and 'params' options?  Found a blog post where someone used Jquery File Upload by placing the correct values in File Upload's 'formData' field.  Would 'formData' be the same as setting 'paramsInBody' to true and specifying the key/value pairs in 'params'?\n. I'm currently attempting to do it now.\n. @rnicholus if you have a chance to look at it today, can you let me know your findings.  I'm just really curious if there is any way at all to do it with fineuploader currently.\n. Yah I found that post and closed this issue, I probably should have made a note of it.  Thanks for your speedy response.\n. ",
    "TheSisb": "+1 jQuery plugin wrapper\n. +1 for #214 and #646\n. ",
    "samihalawa": "Ok I have received a mail sorry\n. ",
    "priyapanigrahy": "I am able to make it work for a single file. DnD and multiple file does not work for me. May be I need to spend some more time to make this work. But It would be great if it works using S3 rest api. It fails while generating the signature from StringToSign. One more thing, as S3 form multipart upload does not return any responseText, it always shows error in the UI where as the file uploaded successfully. \n\nfunction createUploader() {\n        var uploader = new qq.FineUploader({\n          element: document.getElementById('bootstrapped-fine-uploader'),\n          debug: true,\n          multiple : true,\n          request: {\n            endpoint: 'https://s3.amazonaws.com/%BUCKET_NAME%',\n            forceMultipart : true,\n            paramsInBody : true,\n            params: {\n               'key': getFileName,\n               'acl' : 'private',\n               \"content-type\" : getConntentType,\n               'AWSAccessKeyId' : getAWSKey,\n               'policy': getPolicyText,\n               'signature': getSignature\n            },\n            inputName : 'file',\n            uuidName : '',\n            totalFileSizeName : ''\n          },\n          text: {\n            uploadButton: ' Upload file(s) to S3'\n          },\n          template: %TEMPLATE%,\n          classes: {\n            success: 'alert alert-success',\n            fail: 'alert alert-error'\n          }\n        });\n      }\n\n. I mean using HTML5 File API (without introducing any server side component).\n. I dont know how to set the headers while specifying the signature endpoint. It would be great if you can update the above code. \n. Yes, you got it. I am assuming that the same fix would work for delete file endpoint and success endpoint. \n. yes, you are correct. same headers for all. \n. Thank you very much for the quick turnaround. \n. Seems like I put by mistake \n. Thank you very much. \n. ",
    "ww34ww34ww34": ":-)\n. ",
    "coreappdev": "quick comment. I tried an alternative solution to this uploader (unfortunatley doesnt work in IE9 and lower) but i found that when i supply the default s3 url (http://s3.amazonaws.com) it fails i need to supply the following url instead: https://s3-ap-southeast-1.amazonaws.com since my instance is there.\nIm not sure if that affects your implementation. I just looked at the options you are planning on having for the s3 and didnt see a bucket url option there (unless the bucket parameter you have there will accept the full URL).\nThanks and please keep up the great work! Looking forward to using the uploader to upload to s3!\n. ",
    "anovak": "Hi Ray\nAny guesstimate on a release date for this feature? I am looking forward integrating it when it becomes available.\n. ",
    "shehi": "+1: I desperately need this feature in my CMS as well. Priorly I was using JumpLoader Java applet for upload purposes, and it had this feature - it could send the hash of overall file at the start of upload, and once server said \"we don't have it, send it\", it sent file in chunks and during every chunk request it also hashed the chunks. I see this issue is like 3 years old - is there any plans to implement this feature please? Thanks.\n. I hate this. I need to practice programming in advanced JS and NodeJS :( So out of loop here regarding the jargon.\nI could actually work around this requirement with less subtle tactic: You said you can hash small chunks. That provided, I could use that to record the hash of first 2-3 chunks in database, and next time someone uploads a file, their chunk hashes could be cross checked against database, alongside with matching total file size.  Same hash of first 100 kilobytes, for the file with exactly the same size = I think these odds can't be beaten. What you think? Of course, I also check file magic signatures for their real types, so there exists that parameter for cross-checking as well. I use TrID for this purpose.\nhttp://mark0.net/soft-trid-deflist.html\n. Understandable. As I said, partial (as in few chunks) hashing should do the trick. And since it's small amount of data that needs hashing, who cares what algorithm is used? We are not hashing everything anyway - will be quick. Hashing could both be based on the number of chunks (instead of certain amount of bytes) or vice versa - in either case, that overall amount of data hashed should be limited for evident performance reasons.\n. It's either complete hashing, or it isn't. You already have been apprehensive regarding to implement the former, due to performance reasons alongside with some security restrictions certain browsers enforce. I don't think anyone would hesitate in doing that otherwise. \nThe other remaining approach is something limited, partial. And in this scenario you have plenty of data to cross-check file identity against:\n- File size\n- File magic signature (first few bytes of binary files and of certain text files are always the same)\n- Hashes\nFirst two options we can check easily, even in server side. The latter can be achieved if you hash and record certain predetermined byte-ranges of files and check against those records during subsequent uploads. I believe with these 3 types of data, file identity can accurately be determined. \nBut there remains one problem: certain files, mostly media files, may have so called \"header information\", a metadata at the end of the file (please correct me if I am mistaken). Video files and image files with metadata are good examples (have to check and ascertain the location of metadata in those files though, not sure). Two different files, even with same type and magic signature can also have same trailing metadata bytes. That makes it hard to rely on this particular method.\nNo matter what you devise though, I believe toggle-able bad feature is always better than no feature. You can receive more inputs from community if people toggle half-baked feature on and experiment with it. Your call of course. But like this, this issue will sit here for more years to come :)\n. Indeed, Plan-A sounds more reasonable.\nOn 02-10-2016 06:03, Ray Nicholus wrote:\n\n/duplicate detection\n. Yea, Alex has a point. This being client-side tech, there are plenty of \nways to spoof the data being sent. Nevertheless, we should have this \nfeature for those who are willing to opt for it.\n\nOn 02.10.2016 23:07, Alex Bouma wrote:\n\nWell if I upload file |foo.docx| with hash |123| (both examples \nofcourse). And given there are multiple users, then another user could \nsimply send |123| as a hash faking a upload with that hash and gain \naccess to my |foo.docx|.\nHowever as I mentioned above this might be a extremely low \"risk\" \nsince if I know the hash of |foo.docx| I probably already have access \nto it. Dropbox uses similair techniques to optimize their storage but \ngenerates hashes server side making them secure for users spoofing \nhashes.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub \nhttps://github.com/FineUploader/fine-uploader/issues/585#issuecomment-250992470, \nor mute the thread \nhttps://github.com/notifications/unsubscribe-auth/AAn5Ac4YKFENcpVckoVMbtirBNujXiMbks5qwA8ZgaJpZM4AW9EM.\n. @rnicholus , it is not about the weakness of your implementation, it's about client-side. Now imagine this scenario: Imagine some leaker, from within a company, leaks the hash of a file (e.g. hash = \"123\"). Mal-intended user, who receives this hash, manipulates client-side into believing that they are uploading a file with hash \"123\". The server side, seeing hash \"123\" already exists in its storage(s), cancels upload and just grants additional ownership access to that mal-intended user. Your code, being an open source solution, can easily be altered to make these hacks - I think we both can agree on this one. So, how can we make sure that we stop this potential threat of breach? \n\nI just did quick brainstorming and I concluded sending the hash of random byte ranges from the file being uploaded to the server side, like 10 of such byte-ranges (including the head range of 0-100 and tail range of 0-100 for initial magic signature verification) would be a strong protection against such breach. Server side, receiving the hash alongside with these byte-ranges could do additional verification. The would be thief can't possibly fake this unless they have the actual file.\nNow I don't know if it is possible to extract certain byte-ranges from the file, using client-side Jscript. If it is, good for us. Otherwise, it will be a challenge. \nAdditionally, all these sub-features (byte-range extraction etc) should be configurable (e.g. how long ranges should be, how many of them should be extracted etc).\nP.S.: When I first +1'ed this feature, I already explained why I did so. My reasons were clearly for multi-user environment. And I strongly believe this implementation of yours should address such environments as well, otherwise it will be a half-baked solution many of us won't be able to use due to security implications.\n. Ray, I totally understand you. All I asked for, were some facilities so \nthat I could actually pull off a secure application at the end. The \nreason I gave you that scenario sample was for you to understand under \nwhich circumstances I would use it, that's all. So question is, would \nyou, as a developer of this awesome package, give such capabilities to \nus? I understand that you are coding a capacity to your suite, for it to \nbe able to handle \"cancellations due to certain reasons/promises\"; what \nI am trying to say is that, there exists certain scenarios your suite \ncould be extremely useful, if it could do what it already does with a \nlittle bit of extra juice (in this case, hashes of random byte-ranges \nfrom uploaded file, to be sent along with full hash, to enable us to \ncreate awesome solutions - and open source ones at that). For this, do I \nneed to create an extra feature-request issue, or is it a \"won't/can't \ndo\" case?\nOn 03-10-2016 15:06, Ray Nicholus wrote:\n\n@shehi https://github.com/shehi I want you to understand that your \nare advancing a straw man argument. Hopefully you will be convinced \nafter reading my message below. Either way, I'd like this discussion \nto move back towards the specific items in \"plan A\" from this point \nforward instead of going on and on about a specific flawed \nimplementation of this that will never be part of Fine Uploader.\nThe server side, seeing hash \"123\" already exists in its\nstorage(s), cancels upload and just grants additional ownership\naccess to that mal-intended user.\nSimple: don't do this.\nWe're going in circles at this point. I've already mentioned, several \ntimes, that Fine Uploader isn't going to internally implement the \nhashing or duplicate file detection code. /You/ must do this. And you \nare free to take any security precautions you see fit when you do this \nbased on the nature of your project. Fine Uploader will /only/ be \nmodified to allow a file to be canceled with a \"reason\". That's it. \nNothing more.\nIf your project is coded such that it blindly serves up resources \nwithout appropriate permission checks, nothing can be done client side \nto fix that.\nOnce again, Fine Uploader will not generate the file hashes itself or \ncontact your server to determine if a file is a duplicate, based on \nthe hash. This is entirely up to you. As with anything, keep \n/appropriate/ security in mind as you code.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub \nhttps://github.com/FineUploader/fine-uploader/issues/585#issuecomment-251089881, \nor mute the thread \nhttps://github.com/notifications/unsubscribe-auth/AAn5AR6gxKmaDCLO6R6y-GyjByvdgtK1ks5qwO_DgaJpZM4AW9EM.\n. Wait, did I misread it? So FineUploader isn't going to calculate the \nwhole hash in parallel to uploading, and cancel when server tells it \n\"hey stop, we already have this one\"?\n\nOn 03-10-2016 15:06, Ray Nicholus wrote:\n\n@shehi https://github.com/shehi I want you to understand that your \nare advancing a straw man argument. Hopefully you will be convinced \nafter reading my message below. Either way, I'd like this discussion \nto move back towards the specific items in \"plan A\" from this point \nforward instead of going on and on about a specific flawed \nimplementation of this that will never be part of Fine Uploader.\nThe server side, seeing hash \"123\" already exists in its\nstorage(s), cancels upload and just grants additional ownership\naccess to that mal-intended user.\nSimple: don't do this.\nWe're going in circles at this point. I've already mentioned, several \ntimes, that Fine Uploader isn't going to internally implement the \nhashing or duplicate file detection code. /You/ must do this. And you \nare free to take any security precautions you see fit when you do this \nbased on the nature of your project. Fine Uploader will /only/ be \nmodified to allow a file to be canceled with a \"reason\". That's it. \nNothing more.\nIf your project is coded such that it blindly serves up resources \nwithout appropriate permission checks, nothing can be done client side \nto fix that.\nOnce again, Fine Uploader will not generate the file hashes itself or \ncontact your server to determine if a file is a duplicate, based on \nthe hash. This is entirely up to you. As with anything, keep \n/appropriate/ security in mind as you code.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub \nhttps://github.com/FineUploader/fine-uploader/issues/585#issuecomment-251089881, \nor mute the thread \nhttps://github.com/notifications/unsubscribe-auth/AAn5AR6gxKmaDCLO6R6y-GyjByvdgtK1ks5qwO_DgaJpZM4AW9EM.\n. My apologies, I totally missed (funny part upcoming) the bold text of \"You must do this in your own project.\" :) Man, I am supposed to read the bold part first... (or did you add those parts a few mins ago?)\n. I totally agree and thank you for all the hard work you are doing!\n. My bad. It should be part of request object. Works now, thanks.\n. \n",
    "khoran": "There are two features here that would be valuable to me. First is just to compute a checksum (md5 would be fine) for each chunk and send it along with the chunk. This way I can detect corruption during the upload right away and request that that chunk be re-sent. Secondly, sending the whole-file checksum upon successful completion of a file upload would allow me to verify on the server that all the chunks made into the right places in the file and give an end-to-end verification that everything was done correctly. Using SparkMD5, you could compute the overall checksum one chunk at a time while the file is uploading, so that very little extra time would be spend at the end. \n. Is there currently a way to use the per chunk checksum when using a traditional server (not S3)? That would be valuable to me. You are correct, the overall file checksum is not strictly required, just a little extra paranoia. I'd be happy if I could use the per chunk checksum with a traditional server. Thanks.\n. Great to see this being worked on. I was wondering though if you were \nstill planning to add the per-chunk checksum feature I had mentioned \npreviously (Feb 22)? I know that feature is available with an S3 \nbackend, but it would be useful to me to have it for the traditional \nserver as well.\n     My use case is people in togo, nigeria, and other parts of the \nworld that have very poor internet connections. They are uploading large \nfiles, usually greater than 2 GB. Network corruption is very common from \nthese areas. So it's a real pain to spend several days (in some cases) \nuploading the large file only to find that the checksum doesn't match at \nthe end. So checksuming each chunk would allow me to catch the \ncorruption right away and re-send the chunk.\n     I could probably compute the checksum in the onUploadChunk \nfunction, but is there any way currently to send the checksum to the \nserver along with the chunk? If not, that would be great to have.\nThanks.\nKevin\n. It was a message on this same issue, just scroll up (https://github.com/FineUploader/fine-uploader/issues/585#issuecomment-187515189). That sounds like a \ngood solution. I'll make a new issue for this request. Thanks.\nOn 10/03/2016 10:32 AM, Ray Nicholus wrote:\n\nwondering though if you were still planning to add the per-chunk\nchecksum feature I had mentioned previously\nI don't recall this feature. Do you have an issue number? At this \npoint, my hands are full with maintaining/supporting Fine Uploader, \nworking on this duplicate file detection case, working on React Fine \nUploader, and a number of other projects, and this is in addition to \nmy 9-5 work. So, I don't see the feature you speak of making it into \nFine Uploader anytime soon unless someone else contributes the \nchanges. Also, instead of baking this into Fine Uploader, I would most \nlikely mandate that Fine Uploader instead be modified to make this \npossible. In other words, make the |onUploadChunk| callback accept a \n|Promise| as a return value and allow for per-chunk parameters to be \nspecified via a new API method or a non-breaking update to an existing \none.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub \nhttps://github.com/FineUploader/fine-uploader/issues/585#issuecomment-251170698, \nor mute the thread \nhttps://github.com/notifications/unsubscribe-auth/ABRzuPAjG03wGnSSKNB1zXHM9pMDIp0Dks5qwTwhgaJpZM4AW9EM.\n. \n",
    "stayallive": "Wouldn't this allow anyone to add a file to their own uploads as long as the hash is known of any file on the server? I see how this is probably a bit of a stretch since if you have the hash of a file you probably have the file already too, but it might be something to take in consideration. \n. Well if I upload file foo.docx with hash 123 (both examples ofcourse). And given there are multiple users, then another user could simply send 123 as a hash faking a upload with that hash and gain access to my foo.docx.\nHowever as I mentioned above this might be a extremely low \"risk\" since if I know the hash of foo.docx I probably already have access to it. Dropbox uses similair techniques to optimize their storage but generates hashes server side making them secure for users spoofing hashes. \n. It's definitly an awesome feature to have. It might be possible to upload a small block of the file (say max. 1mb) and also save that hash server side so that if the file is already on the server the client can prove it has the file by uploading a small portion so that the section can be validated server side. Although that might add too much complexity but makes if more usable for multi-user systems. Although I'm not a security expert so that solution could be as insecure as the original. \n. Ah. I totally read that part wrong. I thought this would be part of FineUploader and totally missed that. Sorry about that :)\n. Well a spoofed hash cannot be detected by the server without the file correct? So if I know the hash of a file on the server I could link it to my user or something. \nBut This is ONLY in case of a multi-user environment or shared storage. For a single repository of files this is ofcourse irrelevant since there are no access controls in place.\nBut all of this is offtopic for the described changes. Sorry for misreading. \n. Well as I said this is only a concern in a multi user environment. Consider Dropbox for example. They use file hashes to deduplicate the files uploaded to them on the filesystem. If those hashes are client side they could possibly be spoofed by a client telling I have a file with hash foo without having the file (since it's all client side this could easily be done). Server finds the hash in the database and confirms it exists and completes the upload and \"links the file\" on the server to the spoofed upload of the client. \nI thought this was laying the groundwork for inplementing the client side of this mechanism that could lead to the above potentionally insecure server implementations as mentioned above. So yes, this is not a concern for the changes described above. \n. ",
    "dsoprea": "+1\nThoughts on future steps?. ",
    "headdab": "I would love this feature too.\nAny updates? status?\n. I tried to do that, but I couldn't upload my changes.\n. ",
    "bkempner": "That's the only js related to fineUploader, though there is nothing else significant.  Also, it's a blank html page, the only content in the body is:\nhtml\n<div id='upload'></div>\n<div id='upload-button'>Upload Photos</div>\nDoes this work for you?\n. ",
    "aphazel": "I'm not sure where else to leave feedback, but it kind of blows my mind that you would charge $15 for a .zip release download of your project. I'd have donated because it's very useful, but come on, a shortened URL that brings you right to PayPal when you click on Download? AND you have a \"donate\" button featured prominently on your site? Poor form. I've built my own and will not be donating.\n. The point is, it's a fantastic library and I really would have donated. I'm just making the point that trying to strong-arm \"contributions\" out of people may alienate your audience. I really do like the library, and I do appreciate the development effort that's clearly gone into it. Donations given voluntarily flow more freely than fixed-rate contributions, a.k.a. download fees.\n. I suppose I owe you an apology. I've been working with FOSS for years, and I make a point to contribute to good projects. I guess the paywall just really hit me unexpectedly at a very frustrating moment. I didn't really intend to take out my current frustrations on you or your project, so FWIW, I do offer my sincerest apologies.\n. ",
    "xblaster": "It's open source... but I need to pay to download a ZIP file and nothing to do a git clone or to click on \"zip\" on the github page...\nIs it a joke ? It's the first time I see that. If you want to be paid for your work... be honest and do not claim it's an open source project. \nIf you want an advice, read that http://www.webdesignerdepot.com/2009/07/9-marketing-tips-from-a-six-year-olds-lemonade-stand/\n. @rnicholus the definition is not important. How many time have you need to pay to download an open source project ? Only for yours.\nI can also fork your project and provide a free download page.\nDid you send money to person who contribute to your project ? \n. ",
    "andrewrcollins": "@xblaster If you want to download (or fork) this project, do so. However, your comments reveal your complete lack of awareness of how the real world of valuing social connection, understanding time and attention limitations, and the importance of making meaningful contributions. I try to avoid feeding trolls, but the stability and continued success of this project and its maintainer are important to me (not merely because of its relation to my future work), so this will be my first and only response regarding this matter.\n. After dinner I'll give your last long comment a fuller treatment.\nAnd, again: Thanks for your efforts.\nUpdate: Changes and response will have to wait until tomorrow morning.\n. :astonished: Oops, I actually still live in EST. I moved to Kalamazoo from Boston last June and for whatever reason thought I'd moved further to the middle of the country than I actually have.\n. All makes sense. I'll create a separate repository fine-uploader-examples for this code.\n. Hello @jackbouba, I'm responding from my personal account (instead of @andrew-kzoo):\nI think you've pretty much distorted my post into the exact opposite of what it actually states.\nHere are some first principles: Nothing is free. Good things come with skill and effort. Skill alone is pointless. Effort alone is idiotic. Meaningful and positive contributions (which are indicated by skill and effort) are a good thing. Distracting and pointless \"contributions\" (which are indicated by a lack of skill or effort) are a bad thing.\nWhile it is possible that the difference between these types of contributions is open to subjective interpretation, the actual time spent by anyone engaging in the actual activity of sifting the good from the bad is not minor and certainly not without value.\nIt is precisely this cost--actual time spent and actual skill applied separating wheat from chaff, that you are too quickly accounting as somehow \"petty and short-sighted.\" I call it living in the real world, one of time limits and time periods denominated in hours, minutes, and seconds.\nWhen contributions are higher quality the time spent harvesting wheat is more productive. With \"contributions\" the time spent is much less productive--sometimes even counter-productive.\nDo you know what RTFM means?\nSpecifically, look at the recent list of closed issues for this project.\nThe number of issues which have actual code attached is small. By contrast the number which involve folks not reading the documentation is large. Documentation is available and I believe people can read it. However, many choose not to and this choice is a clear indicator of a lack of skill (see RTFM).\nWhen I stated that it may be \"too easy\" for people to contribute I made certain to relate this to a discernible lack of actual skills on the part of the would-be contributor:\n\nIn my view this combination of highs (ambitions, expectations) and lows (skills, valuation of others efforts) leads to the situation that exists presently.\n\nSoftware development remains, at the end of every day, more a matter of skill, and far less one of desire. If that feels \"harsh\" or \"unfair\" ... well, :(){:|:&};:\n. @jackbouba Thank you for looking at the closed issues list. I recognize the value of small positive contributions. Such contributions indicate skill and effort, however small. For example:\nhttps://github.com/zurb/joyride/issues/67\nhttps://github.com/zurb/joyride/pull/68\nMy pull request involved changes of just a handful of lines, but it was meaningful to another person.\nHowever, I affirm that the raw cost of responding to even the smallest \"contributions\" (the unskilled and effortless issues highlighted in the aforementioned list) is more than 'particularly annoying,' it represents a vexing challenge to open source development.\nThe deficits of each individual \"contribution\" are not new (RTFM [not reading available documentation], lack of personal responsibility [not properly testing code on one's own time], poor individual discipline [posting issues which are not really issues], and related long-standing software development activities), it's the sheer volume.\nOur \"positions\" are actually very close.\nWe are both uncomfortable with 'too easy.' I am camped on the side of concern for long-term project stability (which requires a stream of positive contributions with fewer \"contributions\") and you are camping on the side of concern for individual access and participation (which prefers a sense of acceptance and recognition of contributions from any quarter).\nWe'd both like there to be 'necessary boundaries.' I see that burden placed reasonably on the would-be contributor: \"More signal, less noise, please.\" It appears you would have the project owners and collaborators take this on.\nPerhaps a clear set of guidelines should be presented to would-be issue posters that details acceptable and unacceptable issues?\n. Just found this:\n\nUpdating \"Producing Open Source Software\" for 2nd Edition\nIt's time to update my 2005 book \"Producing Open Source Software: How to Run a Successful Free Software Project\". Help me do it right.\n\nCopies of the 2005 edition Producing Open Source Software: How to Run a Successful Free Software Project are free: http://producingoss.com/en/producingoss.pdf\n. Thanks! :+1:\n. :+1: Thanks for your time and effort!\n. That is all fantastic news!\n. Re: precursor to #384 Yes, I see it. I hadn't noticed #384 before.\n. It's there to remove the <li> element in the user interface. That could probably be done without calling cancel(...)\n. No reason, I'll make the changes.\n. No problem. I may be overdoing copy-pasting as I'm been getting the overall structure and operation of the code.\n. ",
    "geovanimartinez": "Did a search on GitHub but was not able to locate it, do you have the Url?. Once i got the vs2012 version going I can put it up for others to use and reference.\n. \"It's in the server folder of this repo.\" - that is the same code on the nuget package that raises the exception.\n. thank you. I will convert it to c# and give it a shot. will try your example with VS2010 as well.\n. My email address is  geovanimartinez@yovasolutions.com . Have a great weekend.\nOn Jan 18, 2013, at 9:56 AM, Ch\u00e9 Letton notifications@github.com wrote:\n\nWhat is your email address. Mine is che@talk21.com \nOn 18 Jan 2013 00:43, \"Geovani Martinez\" notifications@github.com wrote: \n\nthank you. I will convert it to c# and give it a shot. will try your \nexample with VS2010 as well. \n\u2014 \nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/598#issuecomment-12400870. \n\u2014\nReply to this email directly or view it on GitHub.\n. \n\n",
    "xavadu": "this is the response of my server (get from chrome console):\njavascript\n{\"success\":true,\"filename\":\"f76095229e56493c86883ec47472befa3f84fb6d.jpg\"}\n. SOLVED\nwhen FineUploader work with-non IE do an AJAX Request, with IE do a POST NON-AJAX Request\ni was cheking in my server if there is ajax call no render the default template, when i try to upload from IE do a not ajax request them i render the template and there was the problem\nmaybe must be more detailied in the Documentation this issue\nthanks\n. ",
    "hulbert": "This change makes sense but the documentation seems incorrect now, right?* I'd send a pull request but not sure what the procedure for that is for things like this since you seem to only commit into master for releases?\n* That is, the default of paramsInBody is now true.\n. No problem, I realized my original post was a bit unclear so got the ninja edit in. I also can't run any of the gradle tasks without changing the js-gradle-plugin from 1.3 to 1.4.0, e.g.:\nbuildscript {\n    ...\n    dependencies {\n        classpath 'com.eriwen:gradle-js-plugin:1.4.0'\n    }\n}\nNot sure if this is specific to my setup or not. It was upped to 1.3 on 3.3-IP but I've never been able to build without 1.4.0.\n. Error on building (this is from latest master):\n```\n\n\ngradle createRelease\n\n\nFAILURE: Build failed with an exception.\n\n\nWhere:\nBuild file '/file-uploader/build.gradle' line: 6\n\n\nWhat went wrong:\nA problem occurred evaluating root project 'file-uploader'.\n\nCould not create an instance of type com.eriwen.gradle.js.JavaScriptExtension_Decorated.\n\n\n\nTry:\nRun with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.\n\n\nBUILD FAILED\n```\nGradle version FWIW:\n```\n\ngradle -v\n\n\nGradle 1.3\nGradle build time: Tuesday, November 20, 2012 11:37:38 AM UTC\nGroovy: 1.8.6\nAnt: Apache Ant(TM) version 1.8.4 compiled on May 22 2012\nIvy: 2.2.0\nJVM: 1.6.0_41 (Apple Inc. 20.14-b01-445)\nOS: Mac OS X 10.8.2 x86_64\n```\n. Updated to gradle 1.4 but still have the same issue. Can't do Java 7 yet but thanks for taking a look, hopefully that will resolve it.\n. @rnicholus yep, that seems to work. I modified the pull request.\n. ",
    "ciaobeau": "Confirmed, needed Java 7\n. ",
    "kavinyao": "@hulbert @rnicholus I'm using Gradle 1.4 on Java 1.6 and runs the build smoothly with the edit 'com.eriwen:gradle-js-plugin:1.4.0'.\n``` bash\n\ngradle -v\n\n\nGradle 1.4\nGradle build time: Monday, January 28, 2013 3:42:46 AM UTC\nGroovy: 1.8.6\nAnt: Apache Ant(TM) version 1.8.4 compiled on May 22 2012\nIvy: 2.2.0\nJVM: 1.6.0_43 (Apple Inc. 20.14-b01-447)\nOS: Mac OS X 10.8.3 x86_64\n```\n. ",
    "cederigo": "for me to :+1: \n```\n$ gradle -v\n\nGradle 1.4\nGradle build time: Monday, January 28, 2013 3:42:46 AM UTC\nGroovy: 1.8.6\nAnt: Apache Ant(TM) version 1.8.4 compiled on May 22 2012\nIvy: 2.2.0\nJVM: 1.6.0_43 (Apple Inc. 20.14-b01-447)\nOS: Mac OS X 10.8.2 x86_64\n```\n. ",
    "bgold0": "For those coming to this post a little confused, this is how you would effectively add params.\nvar upload_template = $(\"#upload_template\").fineUploader({ request: { endpoint: \"/upload\" }});\nupload_template.fineUploader('setParams', params);\n. I'm a google cloud user and I'd love to test this out. I'm a little confused on how to integrate it though using the s3 compatibility mode. Has anyone tried this or explain it a little more in depth?\n. It's far too confusing to set up a google cloud storage upload through the s3. If anyone is trying to, an easy alternative I found is the following (if you are using app engine):\n```\nrequire_once 'google/appengine/api/cloud_storage/CloudStorageTools.php';\nuse google\\appengine\\api\\cloud_storage\\CloudStorageTools;\n$options = [ 'gs_bucket_name' => 'bucket' ];\n$upload_url = CloudStorageTools::createUploadUrl('/upload-url', $options);\n```\nThen you'll want to store $upload_url into a variable like so:\n<script>var upload_link = \"<?php echo $upload_url; ?>\"</script>\nAnd then continue your fineuploader like normal. Notice the endpoint is the new upload_link variable.\n```\nvar upload_template = $(\"#upload_template\").fineUploader({\n    request: { endpoint: upload_link },\n    autoUpload: false, validation: { sizeLimit: 5000000, itemLimit: 1,  allowedExtensions: ['pdf'] },\n}).on('complete', function (event, id, name, responseJSON) {\n});\n```\nThen in your /upload-url have the following to move your new temporary uploaded file:\nmove_uploaded_file($_FILES['qqfile']['tmp_name'], 'gs://bucket/new_file.pdf');\nAnd boom, you've uploaded a file to your cloud storage to do whatever you want using fine uploader.\n. Realized I had to do onComplete: function (id, name, responseJSON). Sorry about that.\n. ",
    "ilya-k-v": "Actually its does. This exception triggers \"onError\" event. This is not correct behaviour, while we cancel uploading.\nAlso it triggers users \"onComplete\" event before \"onCancel\". If \"onComplete\" acts as \"onSuccessfullySend\" it can't be invoked here. If it acts as \"onEverythingDone\",  I think, it must be called after \"onCancel\".\n. Yes, its work.\n. OK, Sorry for my English =)\nWhen uploading is in progress (file1). We can start a new one instead of this by selecting another file (file2). Progress bar will be reseted and new uploading will be started.\nBut, uploading of first file will not be aborted as well. It will also triggers \"onProgress\", and some of it routines will log this:\nTypeError: element is undefined\nif (element.querySelectorAll){\nAlso, even all uploading is done, we cant just leave page. Because \"beforeunload\" is still binded to window, and we will be promted.\n. nope, autoUpload is default true. But #581 looks like is the same problem.\n. Correct. multiple=false\n. Now its works as expected. Thank U!\n. Yes\n. ",
    "supercool27": "thank you for your reply. my issue is when i am using 2time in the same view its able to upload but queryselectorall methods not getting the correct dom but first one is wokring perfectly but second one having queryselectorall problem. so i copied fileuploder.js to filuploader1.js.\n. ",
    "oldtinroof": "But it wasn't implicit nor clear - one of the guys on my team thought it could only contain the details written in the values above.  Our original response was the data set we wanted to handle in the onComplete callback - because we didn't have the success:true property it took a while to track down what was triggering the onError callback.\nJust wanted to add this for anyone else that might struggle to understand the implication.\n. ",
    "cajund": "Excellent, Thanks. I figured the master branch was the latest release, and that you were working on the 3.3-IP branch.\nHave you seen GitFlow? I'm about to implement it - using GitHub for the Master and Release branches. If you haven't seen the technique, check it out - it's quite helpful\nThanks again.\nOn Jan 27, 2013, at 1:44 PM, Ray Nicholus notifications@github.com wrote:\n\nIt could be updated, but I would have to change it every time a new version is released. You should be using the released, combined version-stamped js and css files found in the download/releases section and not the individual files found in the source tree. I'll update the documentation to indicate that the fineuploader.js file will include the version number in the filename.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "projekt01": ":+1:, this currently doesn't allow to return javascript code in response because it get evaluated in the iframe\n. ",
    "TheGAFF": "It works fine with knockout.js. What kind of support are you wanting?\n. ",
    "itsdrewmiller": "Here is a simple binding (I'm using the jquery version of fineuploader here, and only binding the params though you could bind the whole options object).  I haven't needed update yet but you might.  Bind like:\n<div data-bind=\"fineUploader: { fileSystemId: $parent.fileSystemId() }\" />\ncode:\nko.bindingHandlers.fineUploader = {\n            init: function (element, valueAccessor, allBindingsAccessor, viewModel, bindingContext) {\n                $(element).fineUploader({\n                    request: { endpoint: '/api/file', params: valueAccessor() },\n                    deleteFile: { enabled: true, endpoint: '/api/file' }\n                })\n            },\n            update: function (element, valueAccessor, allBindingsAccessor, viewModel, bindingContext) {\n                // This will be called once when the binding is first applied to an element,\n                // and again whenever the associated observable changes value.\n                // Update the DOM element based on the supplied values here.\n            }\n        };\n. ",
    "Snake85": "Hi Ray,\nI tried to solve it like you say but it still don't work...\nIs like I don't get the param qqtotalfilesize on server side...  ( just in explorer )\nI tried to solve it with your workaround 1.\nWhat's wrong?\nThanks\nSamuele\n. Hi Ray,\nThanks a lot for your fast response...\nHere the request in Chrome:\n------WebKitFormBoundaryaWBwAE4Mfs7uATHd\nContent-Disposition: form-data; name=\"qquuid\"\nf5f1891a-3e3b-400d-903b-f8528bd1177a\n------WebKitFormBoundaryaWBwAE4Mfs7uATHd\nContent-Disposition: form-data; name=\"qqtotalfilesize\"\n895551\n------WebKitFormBoundaryaWBwAE4Mfs7uATHd\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"e2c7e49567ef4c5d081c58041afd0fb5.3gp\"\nContent-Type: video/3gpp\nHere the request in Explorer 9:\n-----------------------------7dd182184040e\nContent-Disposition: form-data; name=\"qquuid\"\naa1058a4-3ad7-41d6-8f7a-eaa40aea1d22\n-----------------------------7dd182184040e\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"e2c7e49567ef4c5d081c58041afd0fb5.3gp\"\nContent-Type: video/3gpp\nAs you can see on Explorer the parameter qqtotalfilesize is NOT SENT.\nOn my server side ( like you suggest me ) in order to verify that the upload completed successfully and the upload was not cancelled, I check if the qqtotalfilesize and the file size are equal.\nThe problem is that I don't get the qqtotalfilesize on Explorer.\nDo you know how can I fix this problem on Explorer?\nThanks again\nSamuele\n. Oh no I'm sorry...  My english is not that great...   :)\nOk now I got it...   So just in explorer the qqtotalfilesize is NOT sent...\nOk how can I check if the upload ended successfully on server side?  ( PHP )\nI cannot use this way that you told me because Explorer is not sending me the qqtotalfilesize :\nhttps://getsatisfaction.com/fineuploader/topics/oncancel_still_execute_the_script_server_side\nThanks again\nSamuele\n. Hi Ray,\nI'm trying to use the $_FILES[..]['error'] in order to know if something went wrong during the upload.\nLooks fine..\nThanks again...\nSamuele\n. Maybe I wrong to put it here...  Is not an issue, is a question...\nLike is there an onSuccess instead of onComplete?\n. ",
    "bs-thomas": "Please continue to support IE7.  A lot of my clients from China still use that.  I've already paid for a version, and willing to continue to pay with new features if IE7 can be supported.\nThomas\n. @JonoB what effect will you have if IE7 is still being supported?  Maybe you should consider taking back what you say before developers who are required to still support this browser start challenging you.\n. I thought it would be really nice to have an exact size scaled actually.  For CMS developers like us, it's important to allow users to upload something of whatever size they want.  Then, we smart-scale the image to a thumbnail that would fit the layout.\nSince FineUploader by default offers image scaling, it would be nice to have this extra step of scaling it a little better.\nJust my thoughts here.\nThanks!\nCheers,\nThomas\n. Wow that was some quick response.\nThere are no noticeable issues.  I'm making a wrapper on top of this, so I wanted to make sure every single point goes clear and working the way it's supposed to be.  It could be my problem, but I kinda doubt it this time.\nI'm using the latest version I downloaded today.\n/!\n- Fine Uploader\n  \n- Copyright 2015, Widen Enterprises, Inc. info@fineuploader.com\n  *\n- Version: 5.1.3\n. Thanks Ray!\n. Hi Ray,\nI've created a forked fiddle, here it is:\nhttps://jsfiddle.net/beamstyle_thomas/heabz1bs/\nThanks!\n. Oh, I have 3 DIVs with class=\"file-trigger\".\nIn my JS script, I did $('.file-trigger').  So I guess that should query all 3 DIVs correct?  But only one gets captured.\nPerhaps, did I misunderstand anything about its usage?\nCheers,\nThomas\n. Ah yes you're right.  However, it returns JS error if I remove the [0].\nSo I can't do this in a bundle for some reason.\n. Ah, I think I got what you mean.  So you mean I cannot expect FineUploader to be iterating over my jquery object on either FineUploader versions (with and without the JQuery wrapper).  And I would have to first build something like this:\nvar myExtraButtons = [\n                {\n                    element: $('.file-trigger')[0]\n                },\n                {\n                    element: $('.file-trigger')[1]\n                }\n            ];\nand then passing this into the FindUploader options:\nFineUploaderS3({\n            ...\n            extraButtons: myExtraButtons,\n            ...\n});\nIt seems like the above is working for me.  But just to make sure, did I get your point correctly?\nCheers,\nThomas\n. Thanks Ray!  All good now and cleared out now.  \nJust one thought though, it might be nice to show an example or two on the documentation, especially for users who are using the JQuery wrapper, as they may tend to think they can simply just put in a JQuery object (of multiple elements) into that area.\nThanks again!\nCheers,\nThomas\n. Thanks for your prompt response Ray.\nYes that's correct, it simply directs to addFiles().  This is an example I got from the fineuploader website I believe.\nHere is the log I just did now according to your request:\n```\napp.js:1126 processingDroppedFiles\nall.fine-uploader.js:163 Grabbed 2 dropped files.\napp.js:1130 processingDroppedFilesComplete\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Received 2 files.\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Attempting to validate image.\napp.js:1105 onSubmit 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending simple upload request for 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Submitting S3 signature request for 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending POST request for 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Attempting to validate image.\napp.js:1105 onSubmit 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending simple upload request for 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Submitting S3 signature request for 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending POST request for 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending upload request for 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending upload request for 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Received response status 200 with body: \nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Simple upload request succeeded for 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Submitting upload success request/notification for 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending POST request for 0\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Received response status 200 with body: \nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Simple upload request succeeded for 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Submitting upload success request/notification for 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Sending POST request for 1\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Received the following response body to an upload success request for id 1: {\"fileId\":46}\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Upload success was acknowledged by the server.\napp.js:1073 onComplete 1 bbb.jpg Object {success: true, fileId: 46} XMLHttpRequest {readyState: 4, timeout: 0, withCredentials: false, upload: XMLHttpRequestUpload, responseURL: \"https://beamstyle-web-localhost.s3.amazonaws.com/\"\u2026}\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Received the following response body to an upload success request for id 0: {\"fileId\":45}\nall.fine-uploader.js:163 [Fine Uploader 5.11.10] Upload success was acknowledged by the server.\napp.js:1073 onComplete 0 aaa.jpg Object {success: true, fileId: 45} XMLHttpRequest {readyState: 4, timeout: 0, withCredentials: false, upload: XMLHttpRequestUpload, responseURL: \"https://beamstyle-web-localhost.s3.amazonaws.com/\"\u2026}\n```\nThank you again!\n. ",
    "devmondo": "please support IE 7, our clients in corporate environments, and in third world countries still use IE 7 in mass\nthanks in advanced.\n. thanks for reply,\nis it possible to keep support for IE 7 only for basic operation like the upload only, it is a good way to compromise.\nof course as you said at some point IE 7 will die for real\n. thank you man, you are very reasonable, all the best on your work and thank  you for offering us this library\n. @thomas83  this library is created by the developer and he has the freedom to do what ever he wants, what we should be grateful for at the first place is that he opened a topic to ask us our opinions and that is really kind of him, you can always pay him as you pay any developer to create custom functionality for you, but right now it is free product and we should accept it as it is and if the developer listens to us then that is more than enough.\n. ",
    "ruud": "Unfortunately, we still need to support IE7\n. ",
    "barneycarroll": "@rnicholus what's the IE7 maintenance overhead? My understanding is that core functionality is already performing in IE7 \u2014 so is this a proposal to strip that out as a slimming down exercise, or is there new functionality you want to add that would be nightmarish to implement in IE7?\nIn any case, for my 2 cents, cross-browser support is the raison d'\u00eatre for this plugin. The HTML5 File API polyfill is borderline trivial to implement single-handedly, whereas the appearance is something I'd overwrite anyway. Take out the difficult browsers and this just becomes a wrapper for the File API with a load of none-too-valuable bloat. Or am I missing something?\n. @rnicholus sorry if my second paragraph implied a dismissive attitude to the work concerned \u2014 that's really not at all what I wanted to convey. Perhaps it'd be better to ignore that and go back to the first paragraph: isn't core functionality already present for IE7? Is it a case of removing it to strip out inconsistencies, or code that acts to the detriment of the other browsers; or is it that you have more work planned which is simply not cost-effective (or impossible) to implement in IE7?\nJust to be absolutely clear: my interest in this project is precisely because of my appreciation of the work. I think it's wonderful and I'm only so involved in this topic because, as you guess, I have no intention of building a new library with this wide range of support myself: I have tried and found it immensely difficult \u2014 but the key point of difficulty was legacy browser support, which is why I would rather use file-uploader.\n\nPerhaps you are also confusing bloat with code required to ensure everything works properly, cross-browser.\n\nExactly the opposite: I'm saying that this is precisely what makes file-uploader worthwhile. But I also believe that \"Remove IE7 support\" and \"everything works properly, cross-browser\" are somewhat contradictory aims.\n. I think everybody's getting a bit carried away with this. It's Github \u2014 we're all free to fork file-uploader-legacy or somesuch and maintain as necessary, right? (for those who wish to keep legacy support going)\n. ",
    "drsii": "+1\n. ",
    "behigh": "It is a good idea, as it will be less support the faster it disappears.\n. Hi @rnicholus \nIt is not so important for me. You can use the code without any obligations to me.\n. ",
    "FastieSystems": "I recommend an objective measure. I'd like to completely ignore IE6 and especially IE7 for the Web sites I build, but my decision has to be based on the actual traffic results experienced by my clients. My own threshold is 2%. IE6 is now under 1%, so I give that browser only a passing nod. IE7 is at about 3%, which is higher than the global share by half a percent and above my threshold.\nIn short, I still pay attention to IE7 whether I want to or not.\nHere's another metric. Across the sites I've built about 20-25% of the visitors are using Windows XP. Microsoft support for XP ends 409 days from today. That should be the stake in IE6's heart and should go a long way to killing off IE7.\nConsider tabling withdrawal of support for IE7 for one more year.\n. @rnicholus  Don't get me wrong - I think dumping older browsers is a good idea. It's just a question of when. I know it will make your life easier when your code has fewer conditions to deal with, which will obviously save you time.\n. ",
    "rajasekarbee": "hi.\nIf u stop the support of ie7 it yucks n big headache for developers.Pls support until the ie11.\n. ",
    "rkorebrits": "Drop IE7! Just keep a download available that will work on IE7 for the people that need it.\n. China? How many Chinese people can read Engrish? The Chineses that can probably have better machines than ones that run on XP.\nIt's time to move on. Keep a legacy version for older browsers and develop for the future!\n. ",
    "shenhf": "Support IE7\uff01It's still widely used\u3002\n. @JonoB  Is this investigation includes China data? I think it's not. Where at least 40% people still use Windows XP, which default browser is IE 6.  An app not support IE 6 is unthinkable.\n. ",
    "itbra": "I would also ask for continuing IE7 support. It cannot be expected that all page visitors always use the latest versions of a browser. Not all websites are targeted to computer experienced people. Especially the mid-aged target group, which is mostly not experienced in upgrading anything with their computers, would be hit. They often bought their machines many years back with a Windows XP or Windows VISTA pre-installed and are yet using it until it dies, which is why IE6 and IE7 are yet to be found in our page access log files.\nIt is not very userfriendly to simply ignore them and block part of the page functionality #cuz they use outdated clients (in our devs points of view). I also thought about this problem and had the idea of client version dependet uploader switch in document head but but couln't find the time to try that out.\n. Can you make a guess, when this update will be published? I am currently working on the uploader implementation into my project and would like to implement the error handlers.\n. Thanks for that info. Will there be major changes on this cycle or was it safe to clone for dev usage?\n. Thanks\n. The problem is simple:\nYour extension validation function lacks a simple type check before regex creation. It tries to create regexes from function definitions (see the posted output form console created using \"console.debug('extRegex: ', extRegex);\").\nThis is not a browser issue. It is an implementation issue.\nMabe you have a look at the map() function mentioned as an alternative implementation as this works properly.\nForget about the browser support. This is a Chrome based browser and the issue happens with Chrome itself the same way (tested 1 minute ago).\n\nUsing a map()-like function for object iteration works well (see posted console output above). Check yourself using jQuery.map().\n. I extended my opening post and did some local investigation. Using a plain demo page with nothing else than a single div as target and your latest master repo files does not inject these extra items into the 'allowedExtensions' param. As mentioned i suppose jQuery to somehow somewhere somewhen touch and handle/interprete this param in some way on the project page giving it some of its \"special\" attributes. I definately define this param to contain only image file extensions on my project page, but see, what it looks like when debugging it onto the console.\n[\"bmp\", \"gif\", \"jpg\", \"png\", $family: function, $constructor: function, each: function, clone: function, clean: function\u2026]\nIt does not look so on the plain demo page. There the debug output shows what it should - an array containing only the 4 file extensions one can see in the above array.\nfileName: 73904.JPEG uploader.basic.js:629\nallowed:  [\"bmp\", \"gif\", \"jpg\", \"jpeg\", \"png\"] uploader.basic.js:633\nextRegex: /\\.JPG$/i uploader.basic.js:644\nextRegex: /\\.PNG$/i uploader.basic.js:644\nextRegex: /\\.jpg$/i uploader.basic.js:644\nextRegex: /\\.png$/i uploader.basic.js:644\nI will do some investigating to see where this extra data is merged into the allowedExtensions array and would report back if you like. My verdict is the jQuery.extend() method which i use to merge the uploader base config which is hardcoded into the javascript with project specific params, that are passed to the function that creates the uploader to extend its configuration with individual parameters. There is, so i suppose, the only logical place, where the allowedExtensions array might be modified by jQuery in some way. I have no other explanation.\nSince i cannot drop this part of individualisation i wonder if the method that validates the extensions could apply an additional check while iterating over the array items to check the current item is a simple string (a file extesions) or a function definition (contains the keyword 'function') and if so, drops its validation. Object extension is no uncommon task. And object extension using jQuery is neither.\n. Updated the last 2 paragraphs of my previous post while you were writing. ^^\n. Sure, please give me some time. I'm on it and will post some code as soon as i can reproduce it.\n. As of now i can say, that it is not jQuery but MooTools, that touches the uploader.\nI cannot yet reproduce, when and what is initiating this behavior. \nFor reproduction i can only suggest to install Joomla! 3, modify the active template to add your uploader target div somewhere in the body and add references to your script sources. When done, add these lines right above the doctype declaration to unlink the js-libs joomla is loading (MooTools, jQuery, Bootstrap).\n<?php\n$doc = JFactory::getDocument();\nunset($doc->_scripts[$this->baseurl . '/media/system/js/mootools-core.js']);    // This one is responsible for the trouble\nunset($doc->_scripts[$this->baseurl . '/media/system/js/core.js']);\nunset($doc->_scripts[$this->baseurl . '/media/system/js/mootools-more.js']);\nunset($doc->_scripts[$this->baseurl . '/media/system/js/caption.js']);\nunset($doc->_scripts[$this->baseurl . '/media/system/js/validate.js']);\nunset($doc->_scripts[$this->baseurl . '/media/jui/js/jquery.min.js']);\nunset($doc->_scripts[$this->baseurl . '/media/jui/js/jquery-noconflict.js']);\nunset($doc->_scripts[$this->baseurl . '/media/jui/js/bootstrap.min.js']);\n?>\n<!DOCTYPE html>\n...\nWith these lines added, the array is not modified and looks like this\n\nAs soon as you comment out the very first line, which unlinks the mootools-core lib, the array is manipulated again and looks like this\n\nI could reproduce this when i did nothing else but loading the index page, open the chrome console and type this:\n\nI don't believe that you are in the mood to investigate a cms to figure out where this manipulation happens, which is why i repeatedly suggest to extend the uploader.basic._isAllowedExtension() method to apply a type check while iterating the allowedExtensions collection. Mabe you can reproduce this with a demo page that loads MooTools besides your library files. The version used here is 1.4.5, which is also the current version on MooTools page.\n. Ok, here you go for a reproduction example. You need to download the latest MooTools lib from http://mootools.net/download as well as jQuery. As soon as the page has loaded, open the console and find the output from the screenshots above.\n```\n<!Doctype html>\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n   function getFileUploader()\n   {\n      var upl = new qq.FineUploader(\n      {\n         element: document.getElementById('uploader'),\n         validation: {\n            allowedExtensions: ['jpeg','jpg','png']\n         }\n      });</p>\n<pre><code>  console.debug(upl._options.validation.allowedExtensions);\n</code></pre>\n<p>}\n   getFileUploader();\n   \n\n```\n. Thanks for your sympathy ;-) Seriously, i absolutely agree with you and i know the Joomla! core developers are about to drop MooTools step by step. But until this is done, they must keep it part of the system as there are many dependencies from the past to be solved and ported to jQuery yet.\nI can't imagine this kind of type check together with a comment line why this is used would make anybody think \"WTF?!\". From my point of view this would look like code from a developer thinking in advance and taking the stupidity of others (other frameworks) into account to have its plugin working properly in an unreliable environment, wouldn't you agree? But you are right, it is not your responsibility to catch incompatibility issues caused by third party libs. I wonder why you did not argue like that as soon as i mentioned jQuery to be involved, which is a third party lib as well. ;-)\n. Of course i can test and report back if you like. I have to thank you for your understanding and your agreement to the compromise solution. Spending time on this is absolute ok since i wanna stay with your uploader and get my project bug-free. So it was our common interest to find the source for this issue.\nSo far, have a good one. :)\n. thanks for your prompt work on this issue. Let me suggest to make the check more specific, since function definitions are strings too, which makes the 'isString' validation not reliable. I would suggest to either check for the keyword 'function' or more reliably check for allowed characters (letters, numbers) and let it pass or forbidden characters (bracket, brace or curly brace, semicolon) that make the extension invalid as soon as either of these is found (see my screenshot in post https://github.com/valums/file-uploader/issues/735#issuecomment-14667830) where the patterns created from the faulty file extensions array are pretty clear shown. This more specific pattern should make simply file extensions as well as split files like winrar or zip archive abc.rar/zip, abc.r00/z0, abc.r01/z01 and so on pass.\nWouldn't you agree?\n. No, this is not, what i wanted to say. But i thought, as soon as the regex is created using the function signature as a another key in this allowedExtensions array, this would become a string. How else could it be these are used? But if you say, your isString function already checks for that, then i revoke my suggestion. :-)\nRegarding fix feedback, i am currently testing on it.\n. As of now i can confirm the function to work as intended. Did not get any errors anymore.\n. ",
    "aronwoost": "Drop it!\n. ",
    "dschmidthawk": "Unfortunately I have an older demographic of veterans and non-profit members who are not always up to date.  I would like to remove support but my clients have to accommodate their users.  Reduced functionality would be a good move.  Hopefully peer pressure will get them up to date on their machines.\n. Man, I suck at github.  Please close this issue and I'll take a darned class to figure out how to comment in a given area and to close a superfluous issue.\n. ",
    "iquabius": "Save a branch of the library with I7 support and move on with the master. This way people can continue to contribute to the old branch to fix bugs and such. And the ones that don't need I7 support can use the new version without worrying with the old version. Someday in the future the old branch can be deleted if nobody is using it.\n. ",
    "symbiat": "This has only been tested in the last few releases of Firefox (up to the latest, Firefox 18), Chrome (latest 23.0) and Safari  6. I do not have a means of testing with any versions of IE or older versions of the above browsers.\nAs far as features go, this is really just a very basic uploader using mostly defaults so there are no features such as handling parameters (in the form or as query strings), no chunking or resume, etc. The code does the basic streaming upload for HTML5 browsers if its an AJAX call or if its a regular request then the upload is handled in the usual HTTP POST way. Any developer using the Lithium framework should find it pretty easy to extend my example to add these extra features. For my purposes, this is for a B2B site with a very small audience of paid clients, so Im not so worried about older browsers. I hope that's OK.\n. Sure, not a problem, only Im not sure how to add that to this pull request (or would I create a new pull request?).\n. ",
    "eugenebunin": "Posted, thanks. \n. ",
    "GeorgeBailey": "TL;DR\n- Closure Compiler Simple Mode is of course probably going to work fine.\n- Closure Compiler Advanced Mode is not compatible with your code at the time of this post. It would be * cool * to make your code ready for Advanced compilation, but likely not worth the effort - especially in the case of refactoring of pre-existing code.\n\nIn a summary: Closure Compiler has a SIMPLE_OPTIMIZATIONS mode which is an advanced javascript minifier. It will even shorten variable names. It is completely non-breaking changes to you JS, generally, except for cases where you use eval (including setTimout with a string, etc).\nADVANCED_OPTIMIZATIONS goes a step further. The very names  qq and FineUploaderBasic would be shortened. \nAll the files, including my own app JS files would have to be combined to make sure they match up after being compiled. That of course means me, the webapp developer would have to run the compile script.\nUpon further review, the following are cases that have to be handled\n- If error were shortened, then the server-side would never know, and that would give a JSON response that was not compatible. Therefore, the use of response.error would have to be converted to response['error'], per Closure Compiler recommendation, to prevent it from being shortened. This also applies to success, and other similar situations. This does not apply to qq, and FineUploaderBasic which are names that can be shortened without breakage\n- I, the developer have to be sure to include a jQuery externs file so that your code and my code stay matched up with jQuery. (jQuery is not compatible with advanced mode)\n- There may be some other situations that require resolving.\n. ",
    "notmessenger": "Didn't pull against 'IP' branch as requested so re-submitting correctly.\n. While the 'b' flag is definitely recommended to ensure no problems are encountered in the future for the reason you posted, the real culprit was the use of a 'w' flag instead of a 'r'.  The 'w' flag opens the file for writing and truncates it to 0 bytes.  So the file was being truncated before being read when putting the whole file back together again.\nAs this flag only affects how the PHP fopen() function interacts with the file it's pointed at, there are no browser incompatibility concerns.\nAs far as support across platforms, to my knowledge the use of the 'b' flag has been supported in PHP for a very long time and does not carry with it any server platform concerns.\n. ",
    "erickhun": "How about MaxWidth  MaxHeight & MinWidth  MinHeight integration?\n. ",
    "wilanbigay": "Thanks.  I'll try to figure it out and update this thread.  But first, I need to figure out how to activate the console window :)\n. ",
    "bjornbos": "This used to be the case for Windows Phone 8.0, which doesn't support uploads. It has been resolved on WP8.1 though.\n. Anyone found out if the multiple attribute will be part of the new Android L?\n. We have tested this on a Nexus and were very disappointed to find out we still couldn't select multiple images.\n. Correct, on a Nexus 7\n. Did you hear anything back from Apple about this? Can't believe this hasn't been fixed by now, very annoying bug that drives my users crazy...\n. Maybe change the title of this issue? It's not limited to Safari or iOS6. I see it happening with all browsers on all iOS versions.. This issue has been open for about a year now. Any real plans on integrating this option? I have been waiting for it as well.\nWhat I actually would suggest is to be able to pass a function to the itemLimit on construction.\nitemLimit: function(itemCount) {\n    if(itemCount > 10) alert('more than 10');\n    else if(itemCount > 5) alert('more than 5');\n}\n. Fixes it for me\n. FineUploader 4.4.0\niOS 7.1.1\n. Life saver, thanks a lot.\nFunny thing this didn't cause any problems on desktop and android!\n. I would like to reopen this issue. Even without the typo, the following photo fails when using the scaling functionality:\nhttp://auto-expire.s3.amazonaws.com/bug/upload.JPG\n. Actually it's not 'just' this image, it happens quite often if we check our logs. I will try to get a few more photos with the same bug.\nHave you noticed that disabling the scaling functionality will successfully upload the photo?\n. Hmm, it looks like it has something to do with size. I converted another photo to exactly the same dimensions (2448x2448) and tried uploading that: it failed.\nFYI: This is the converted photo http://auto-expire.s3.amazonaws.com/bug/uploadBugTest.jpg\n. Changing the scaling property to 100 (instead of 2480) fixes the error. So it must be the relation between the photo size and the scaling size.\n. Downsampling didn't work (filesize changed from 2.09 MB to 672 kB)\n. I think you're right, changing the scaling property to 2289 fixes the upload error.\n. Confirmed\n. So what will be the workaround? Upload full size, or scale to maximum allowable dimension for device?\n. Would be nice to have both choices as an option. I can see cases where you rather have the high resolution (full) image than the (extra) scaled image.\n. In our case, we need 2480px images for 300dpi printing. To increase upload speed (and decrease bandwidth consumption) for high res images we use the scaling function, so I don't want to set the sendOriginal option to true. However, if I would need to choose, I'd rather have the high res image than the extra scaled one. You see my point?\n. What about creating a detection feature that we can use to check the maximum canvas size. That way, the user is in control of the resulting actions.\nFor instance, if qq.getMaxScalingSize() would give me 2289 back, then I can choose to use the scaling functionality or not, and if I do, what sizes to use.\n. I understand your argumentation. The fix will be good enough for us, we will optimize it for our own use.\nBy the way, I have been looking for the qq.ios() feature, but couldn't find a reference to it. Is this an undocumented feature?\n. Yes.\nThe docs also say that \"JPEG images larger than 2 megapixels are subsampled\u2014that is, decoded to a reduced size\". Do you know if this also applies to uploads? Will uploads of more than 2MP be download sampled when they are send to the server?\n. Is there a way to create a custom build from this branch?\n. We have tested it and the fix works for us!\n. Note: For everyone using the MegaPixImage library that is included in FineUploader, you should now use qq.MegaPixImage (we reuse the library for canvas drawing).\n. The customer told us that the 'file picker window' opens fine, but after selecting the file, the file picker closes but nothing happens (no upload start). Note that on that same device it did work with Chrome....\nBtw: we are using FineUploader 5.0.2 with S3, previews and scaling.\n. It's kind of hard to say what actually happens, because we can only see this error message coming back in our logs. I will try to build a test case that creates the same behavior. \n. Haven't been able to build a test case that reproduces this behavior, but I still see a lot of these error messages coming into our logs. It looks like the error is thrown in the function getXhrOrXdr() because of missing data. In this function it says:\nvar xhrOrXdr = requestData[id].xhr;\nWhere requestData[id] is undefined. As said before, happens only on iOS. Any thoughts?\n. I'm still seeing lots of these issues in our error log, I'm planning to dive into it this week. Do you already have any ideas where the problem comes from?\n. Here's the steps to reproduce the error:\n1. Start upload\n2. Navigate to different tab in browser\n3. Click back to tab with upload process. The moment you reactivate that tab, it start throwing these errors. \nMy guess is that it now tries to run the onComplete callback, but the requestData[id].xhr is no longer available.\n. Sorry for not getting back to you on this before, must have missed your question.\nAs far as I can tell it does not necessarily lead to any actual issues, it just throws these errors, but it looks like the callbacks are all invoked.\n. I have not yet seen any occurrences of this error on iOS8, so it looks like this only applies to iOS7\n. Do you know if it has been solved by Apple?\n. Wow, this sucks big time! How about adding a detection feature to FineUploader for iOS8 and Safari, so that we can ask users to switch to Chrome?\n. Even more strange: if you pin a website to your homescreen and then start it from there (run it as a single app), the upload works!\n. Yes I am aware of the Chrome issue(s), it was more of an example of a message to show. It could also be used to ask the user to pin the website to the homescreen, or just to point out the bug from Apple.\n. Works for me on an iPhone with iOS8 GM. Did you start it from the home screen icon afterwards?\n. Pinning works for me on an iPad with iOS8 GM as well...\nFYI, I use multiple attribute\n. Ok, looks like for the pinning to work, you need the following meta tag in your HTML (it needs to be present at the time of pinning):\n<meta name=\"apple-mobile-web-app-capable\" content=\"yes\">\n. It's still kind of buggy... I often get a forced page reload (crash) when uploading multiple items (iPad mini with 8.0.2).\n. I'm trying to figure out whether this is linked to browser uploading or that the new iOS crashes the device more often in general. I will play around with this some more over the weekend.\n. FYI: I never experienced the crash in the first upload session in the browser. For it to happen I selected multiple files, waited for these to be uploaded, and then started a new upload session without refreshing the browser.\n. Looks like there is difference between iPad and iPhone. On iPhone everything works smoothly, but on iPad the upload process crashes the browser frequently. I'm also getting this feedback from my users now...\n. I found out that it is not the upload process that crashes the browser on the iPad with iOS8+, but it's the image scaling. I now change the scaling option parameter to false for iPad iOS8+ users, but you might want to build this into the iOS8 workaround feature as default.\n. Check this JSFiddle:\nhttp://jsfiddle.net/usegz49v/8/\n. Confirmed duplicate. Well, at least you have a suggestion for a fix then :)\n. ",
    "mig007": "Awesome thanks I was looking all over for this, it may help to include this in the zip :)\nThanks again!\nThank you,\nMike Marshall\nVP of Technology\nP 801.704.3160\nC 801.234.9491\nE mike@namify.com mailto:mike@namify.com \nhttp://www.namify.com/Content/EmailRedirect.aspx?campaignID=NamifySigniture \nHow did I do? Click here mailto:chris@namify.com  to give your feedback.\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Tuesday, February 05, 2013 3:52 PM\nTo: valums/file-uploader\nCc: Mike Marshall, Namify LLC\nSubject: Re: [file-uploader] Upload Failed (#650)\nYes, you need to return a valid JSON response. This is explained in the \nserver-side readme: \nhttps://github.com/valums/file-uploader/blob/master/server/readme.md#response \n. \nOn Tue, Feb 5, 2013 at 4:47 PM, mig007 notifications@github.com wrote: \n\nI bought your tool and I'm trying to integrate it today, I am using \nasp.net, I created a page FileUploadHandler.aspx \nI added code to save the files \n//Uploaded File Deletion \nif (Request.QueryString.Count > 0) \n{ \nstring filePath = @\"c:\\DownloadedFiles\\\" + \nRequest.QueryString[0].ToString(); \nif (File.Exists(filePath)) \nFile.Delete(filePath); \n} \n//File Upload \nfor(int i=0; i < Request.Files.Count; i++) \n{ \nstring fileName = Path.GetFileName(Request.Files[i].FileName); \n//sb.Append(\"File: \" + (i + 1) + fileName + \"\\r\\n\"); ; \nstring location = Server.MapPath(\"~/Uploads/\") + fileName; \nRequest.Files[i].SaveAs(location); \n} \nThe files upload and save perfectly into the directory, but the \nFineUploader says that the upload failed. Do i need to return a code or \nwrite something that shows that I saved them? \n\u2014 \nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/650. \n\n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/650#issuecomment-13156905 . \nhttps://github.com/notifications/beacon/Jshd8sI44GVrKZBvymxqKNwtkbIPOaZAH6paLc86yKt-WSDUPn9W9gYC1sbH20sQ.gif \n\nNo virus found in this message.\nChecked by AVG - www.avg.com\nVersion: 2012.0.2238 / Virus Database: 2639/5583 - Release Date: 02/05/13\n. ",
    "johnnywell": "Why not make sense? Once I uploaded the file i need create  an object to manipulate it in my system. The python_django files just do the upload but don't return a object.\nI did not find any forum then I asked the question here, do you pass me the forum  link?\n. Not just create a file in server side, this is simple with a static file, but in this case i don't know how the file-uploader sends the file to server.  But that's ok.\n. Ok, thanks.\n. ",
    "programmister": "Can I download for test without payment?\n. Why?\n. Testing on IE 9, FF 18.0.1, Chrome 24.0.1312.57 (windows 7).\nHTML:\n<div id=\"manualUploadModeExample\" style=\"background:green;height:60px\"></div>\n<div id=\"manualUploadMode\"></div>\nJS:\n$('#manualUploadMode').fineUploader({\n    button:$(\"#manualUploadModeExample\")[0],\n    autoUpload: false,\n    request: {\n        endpoint: \"/upload/receiver\"\n    }\n});\nManually on FF set opacity to 0.5 of input:file.\nButton of input:file is only over right part of green div manualUploadModeExample, and over left part is test input on input:file. So I think button of input:file must be over ALL area of green div, because:\n- IE9- is require double click on text input of input:file to open dialog;\n- cursor on some browsers (FF, Chrome) is not pointer (if mouse is over text input of input:file).\n. I don't know how to explain another way. I wrote the code and what to do. Could you please test it?\n. Example:\nhttp://testing.1gb.ru/fineuploader/test/jquery.html\n. now I made it as I wrote above.\n$('#manualUploadMode').fineUploader({\nbutton:$(\"#manualUploadModeExample\")[0],\nautoUpload: false,\nrequest: {\nendpoint: \"/upload/receiver\"\n}\n})\nOr I didn't understand you?\n. yes, and what? What do you want to say?\n. This code\n    $('#triggerUpload').click(function() {\n        $('#manualUploadModeExample').fineUploader(\"uploadStoredFiles\");\n    });\nhas no relation to a problem.\nI deleted this code. Please look.\n. ",
    "davidwindell": "@andrew-kzoo thank you for your response to my comments, you make a good point, with which I certainly agree with.\nIt does pose the question, perhaps a organisation or sponsor could be found to support @rnicholus financially and with resources.\n. ",
    "jackbouba": "@andrew-kzoo and @rnicholus,\nI am not an active contributor to open source projects. One (or, more precisely, a few) of the reasons that I feel reluctant to add code to a project is a fear of judgement, skepticism, and criticism; an anxiety that I find justified by your argument. Don't get me wrong, I completely understand and sympathize with your positions; however, I have some difficulty relating to the concept that \"it may be 'too easy' for people to participate.\" @andrew-kzoo writes that \"[t]he set of personal skills required for involvement is now so exceedingly low: have email address and web browser...\" I think you've forgotten an important quality, however, which is the desire to contribute. I'd be nervous that a higher \"barrier to entry\" would scare off willing and excited participants who, like me, might be too intimidated to contribute because of a self-perceived lack of expertise. \nIn my opinion, this boon of contributors, this multitude of individuals of varying levels of skill and experience interested in volunteering their time to improve a project that, thanks to GitHub and to the culture of open source, belongs to the community, is a good thing. Of course there will be some contributions that are less helpful than others, but isn't that the beauty of GitHub? The project owner is ultimately in control of the the project, who has push/pull access, and which commits to merge in. As a person who is inexperienced in the world of open source, it is absolutely incredible to me that there are so many people willing to lend their time and energy to a project that will yield them, for the most part, no monetary gain. I find that absolutely, ceaselessly, amazing. To lament the work necessary to weed out the unconstructive contributions without acknowledging the overwhelming importance of all of the beneficial contributions seems petty and short-sighted.\nNow, this is somewhat unrelated to @rnicholus's reaction to developers who \"want [you] to do their jobs for them.\" Of course, anyone would find this frustrating. Ideally, everyone would know that a request like this is unfair and irresponsible, and wouldn't ever bother you with it. If I may suggest, perhaps you are not creating-if at all possible-the necessary boundaries. If you are indeed \"troubleshoot[ing] live code on a user's website,\" but then getting frustrated, there might be a way that you could be handling these requests differently. I'd argue that project owners and collaborators have absolutely no responsibility to help the user beyond what feels comfortable and reasonable.\nI apologize if I'm completely out of line - I'm relatively new to the field and to open source projects, so feel free to tell me to take a hike.\n. Oh boy @andrewrcollins - taking a look at the some recently closed issues is an eye-opener. I can plainly see that the task of answering questions and addressing concerns is overwhelming and must be particularly annoying when the questions could've been easily resolved by a quick look at the documentation. I apologize - it was not my desire to 'distort' your post, just to add my interpretation and two-cents; I tried to do that as respectfully of your time and effort as possible, but I was obviously not careful enough. I will, however, continue to be impressed not only by skilled contributors like yourself, but also by those whose contributions might be less than ideal.\n. ",
    "juliankrispel": "I won't repeat what I've said before because I don't want to spoil this thread but I'm sticking to it @rnicholus and I don't mean it in a bad way. I hope you could get something out of it/learn something from my reaction. Anyway, glad it sparked a seemingly useful debate! Cheers.\n. ",
    "alandurkin": "Hi. Thanks for your response. I can see that now in the readme although I didn't pick it up from my initial reading. I'll stick that in on the server side to resolve this. However, I'm still getting the error on your demo page. I'm on IE7 and WinXP.\n. I can do that, no problem. Unfortunately, I'm gone home from work for the\nweekend where I also don't have access to a 'real' ie7. Nor an XP box for\nthat matter! I'll take a look first thing Monday morning (I'm in Europe so\nI should be earlier than you). I was using visual studio to debug so I\nshould be able to see what's going on pretty clearly. I did get it working\non my own application however by both returning a success property and\nchanging the content type header to 'text/plain'.\nI'll let you know first thing Monday. Have a good weekend!\nOn Feb 8, 2013 3:16 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nI've repoened this case. I don't currently have a way to test on a _real_IE7 browser. I simply use IE9 or IE10 and set the browser to emulate IE7,\nwhich is usually good enough. If you are seeing an issue in a _real_version of IE7 on the demo page, I would be very interested in seeing the\ncontents of the javascript console, although that may not provide many\nclues since IE7 doesn't support the console object. I'm also curious if\nyou are seeing the same issue with your local code (after you have modified\nyour code to return a valid JSON response w/ a success property.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/661#issuecomment-13294527.\n. Yep, saw that in the docs. I'll send on all I can figure out Monday morning.\n\nOn Fri, Feb 8, 2013 at 8:34 PM, Ray Nicholus notifications@github.comwrote:\n\nAh yes, the content-type of your response MUST be text/plain. I would\nsuggest doing this for all browsers. This is also mentioned in the server-side\nreadmehttps://github.com/valums/file-uploader/blob/master/server/readme.md,\nas others have run into issues with other content-type values on their\nresponses. I think it's also in the FAQ, but I'd have to look.\nIf it is broken in IE7 only on the demo, then something may have happened\nwhen I recently updated the demo a week or so ago. Can you also list the\nexact demo page/url with the issue, in addition to the javascript console\noutput when you have time to reproduce this next?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/valums/file-uploader/issues/661#issuecomment-13309863..\n. Had a look this morning. This was a bit of a red herring. I'm still getting an error but it's because the corporate 'net nanny' is not passing the request to your server but is instead returning an html document saying 'this site could be dangerous' or some such. The 'getIframeContentJson' method is expecting back json, not html so an error is being thrown. Sorry about the confusion on this one, I should have realised that this was probably a local error as no-one else had complained of it. Anyway, I've left a donation as you've provided an excellent piece of software and are providing probably too much support to your community. :-)\nThank again, Alan.\n. \n",
    "krheinwald": "Can be done - did it. Does not fit the class based overall model, though.\n. ",
    "Jevin23": "thank you very much!\nit's worked!!!!\ni have another question for support: \"how can i place more whan upload forms on one page?\"\nWhat can ifind support form?\n. ",
    "softwaremills": "Thanks for the quick response! Doing that right now.\n. Oddly enough, when deployed, it doesn't seem to have this issue. Really weird. Thanks for listening anyway. :)\n. ",
    "fieldingwilsonintuit": "Thanks for the quick response.\nI'm using jquery.fineuploader-3.1.1\nHere's the complete code:\n```\n$('#uploadBtn').fineUploader({\n                request: {\n                    endpoint: '{{ share_files_url }}',\n                    paramsInBody:true,\n                    inputName: 'file'\n                },\n                debug:false,\n                multiple:!isMobile(),\n                dragAndDrop:{\n                    extraDropzones:[$('#uploadArea')],\n                    hideDropzones:false,\n                    disableDefaultDropzone:true\n                },\n                text: {\n                    uploadButton: ' ',\n                    dropProcessing:''\n                },\n                retry: {\n                    showAutoRetryNote:false\n                }\n              }).on('submit', function(event, id, fileName) {\n                  uploadCount++;\n                  $('.qq-upload-list').show();\n                  fileName = fileName.replace(/ /g, '_');\n                  $(this).fineUploader('setParams', {'name':fileName,'action':'{{ Action.UPLOAD }}','description': ''});\n              }).on('complete', function(event, id, filename, responseJSON){\n                    $('#boxBarFiles').fadeOut(200,function(){\n                        completeCount++\n                        if(responseJSON.success)\n                        {\n                            var url = \"{% url customer_share_files_list tax_response_id=tax_response.id %}\"\n                            var target = $('#fileWrap');\n                            $(target).load(url);\n                            $('#boxBarFiles').fadeIn(500);\n                            $('.qq-upload-success').hide(5000);\n                            if(completeCount+cancelCount==uploadCount){\n                                $('.qq-upload-list').hide();\n                            }\n                        }\n                    })\n                if(typeof _gaq!='undefined')\n                 _gaq.push(['_trackEvent', 'ShareFiles', 'Upload',filename]);\n          }).on('cancel', function (event,id,fileName){\n              cancelCount++;\n              if(completeCount+cancelCount==uploadCount){\n                $('.qq-upload-list').hide();\n              }\n          });\n\n```\nSTR:\n1. Select 6 files\n2. Files 1-3 upload, while files 4-6 are queued.\n3. Once the current uploads complete 4-6 start to process\n4. file6.txt is the first file of the second batch to complete\n5. file4.txt, file5.txt will all be recorded with the name- file6.txt \n\n\nThe database has a field for the file path (a link to the location of the file) and a field for the name (the name displayed on the webpage). The file path field reflects the correct filename but the name field reflects the duplicates. \n. I'll update to 3.2 and report back\n. Unfortunately, it looks like I'm still having the issue using 3.2\n. The demo page is working for me as well. I am not seeing anything in the console when testing my page.\nI am using Core mode with the following code:\njavascript\n$('#selectionhldr').fineUploaderDnd({\n    }).on('processingDroppedFilesComplete', function(event, files, dropTarget) {\n        $('.selectionbtn2').fineUploader('addFiles', files); //this submits the dropped files to Fine Uploader\n    });\n    //initialize the upload button\n    $('.selectionbtn2').fineUploader({\n        uploaderType: 'basic',\n        request: {\n            endpoint: '{{ share_files_url }}',\n            paramsInBody:true,\n            inputName: 'file'\n        },\n        validation:{allowedExtensions: allowedExt,\n            sizeLimit: allowedSize},\n        messages:{sizeError:'The file you selected is too large. The maximum file size allowed is 20 MB. You may be able to reduce file size by using the compression utilities available in Windows and OS X or by using a third party tool such as WinZip.',\n        maxConnections:50,\n        camera:{\n            ios: false\n        },\n        button: $('.selectionbtn2')\n    }).on('submit', function(event, id, fileName) {\n        fileName = fileName.replace(/ /g, '_');\n        $('#fileRows').prepend('<div class=\"filerow\" id=\"' + id + '\"><div class=\"colpreview\"></div><div class=\"colfile\"><div class=\"filetext1\" style=\"margin-top:.8em\">' + fileName + '</div></div><div class=\"colstatus\" id=\"colstatus-' + id + '\"><div id=\"progressbar-' + id +'\" class=\"fileProgress\"></div></div></div>');\n        $(this).fineUploader('setParams', {'name':fileName,'action':'{{ Action.UPLOAD }}','description': ''});\n    })...\nI tried placing a breakpoint in both the processingDroppedFilesComplete and submit callbacks but neither catch when the file is dropped.\n. The aforementioned code is inside a $(document).ready(function () {}) block but I will investigate further.\nI'm unclear as to why changing the document mode to IE10 compatibility mode would solve the problem though if the element doesn't exist.\n. ",
    "pinkfoot": "Thanks for getting back to me so quickly.\nYour 2 points:\n1. Filename check insufficient\nYou're right in general - but that's left to the developer entirely outside\nof FineUploader, and for my particular application it would be sufficient.\nI need to be able to warn the user that they are overwriting a file they\nhave already uploaded, and for multiple files it is more efficient to make a\nsingle http request for that purpose than making one per file using\nonValidate, and onValidateBatch seems to be an all or nothing test.\nThe call back is simply a means of passing the whole filedata array for\ncustom 'preflight' processing/checking whilst allowing asynchronous script\nexecution.\n1.  What does startLoading call?\nApologies for providing the entire code here - in uploader.basic:\nInsertion at line 27\ncallbacks: {\nonBeforeStart: function(fileList, startLoading){startLoading(fileList);},\nReplacement for lines 203 & 204 within addFiles():\nvar fileList = this._options.callbacks.onBeforeStart(verifiedFilesOrInputs,\nfunction(returnedList){\n if(Object.prototype.toString.call(returnedList) === '[object Array]' &&\nreturnedList.length > 0){\nself.log('Processing ' + returnedList.length + ' files or inputs...');\n self._uploadFileList(returnedList);\n}else{\n                self.log('Upload of ' + verifiedFilesOrInputs.length + '\nfiles or inputs aborted');\n        }\n});\nThen the integrator has 3 options within their implementation of\nonBeforeStart if, according to whatever test they apply, a file conflict is\ndetected:\nstartLoading(fileList) (overwrite by returning the original array)\nstartLoading(editedList) (skip conflicting files by removing them from the\nreturned array)\nstartLoading([]) (cancel upload by returning an empty array)\nThat's all there is, and I thought it might be of wider use than just my\napp.\nBILL ROBINSON  |  PHOTOGRAPHER\n+44 (0) 7973 184480  |  www.billrobinson.com\nFrom:  Ray Nicholus notifications@github.com\nReply-To:  valums/file-uploader\nreply+i-11026279-72215c59491e7bdf4f8d4c95d7335f096573b2ce-3594765@reply.git\nhub.com\nDate:  Friday, 15 February 2013 12:07\nTo:  valums/file-uploader file-uploader@noreply.github.com\nCc:  Bill Robinson bill@billrobinson.com\nSubject:  Re: [file-uploader] onBeforeStart callback, to enable 'Overwrite /\nSkip / Cancel' user options (#671)\nA few thoughts:\nFirst, i don't think a simple filename check is the best way to check for\nduplicates.  Surely two files can contain different content but have the\nsame name.\nAlso, what, specifically, does startLoading call in the existing code?\n\u2039\n Reply to this email directly or view it on GitHub\nhttps://github.com/valums/file-uploader/issues/671#issuecomment-13603763 .\n. Thank you very much \u00ad I will do, as soon as I'm up to speed with git.   Your\nproject is fantastic, and I do understand my original motivation may be an\natypical requirement (but as a professional photographer it's crucial) which\nis why I only modified uploader.basic to the limited extent specified in my\nprevious comment, leaving the actual conflict test outside.  I needed a hook\nwith the granularity of onValidate but with the potential increased network\nefficiency / usability benefit of onValidateBatch - either I or my clients\nmay need to upload multiple 100Mb+ files over domestic ADSL, the ability to\nget any individual conflicts dealt with all together at the start is\nextremely helpful.  In the interim, my very basic external javascript's\nconflict checking is, in outline\n1.send names of all the files specified within fileList  to the server in one\nrequest\n2.wait for server to send back list of conflicting names\n1. if no names in the response, carry on, i.e.  startLoading(fileList);\n4.if any names returned, offer user 3 options:\na) 'overwrite' , which simply calls startLoading(fileList);\nb) 'cancel', which calls startLoading([]);\nc) 'skip', which creates an edited array containing only the non-conflicting\nfiles, and then calls startLoading(editedFileList)\nIn any event, a massive thank you to yourself and your co-creators who have\ncreated an extremely Fine Uploader!\nFrom:  Ray Nicholus notifications@github.com\nReply-To:  valums/file-uploader\nreply+i-11026279-72215c59491e7bdf4f8d4c95d7335f096573b2ce-3594765@reply.git\nhub.com\nDate:  Friday, 15 February 2013 14:28\nTo:  valums/file-uploader file-uploader@noreply.github.com\nCc:  Bill Robinson bill@billrobinson.com\nSubject:  Re: [file-uploader] onBeforeStart callback, to enable 'Overwrite /\nSkip / Cancel' user options (#671)\nI think I see your approach here.  Generally speaking, I'd like to make\nthese sorts of tasks as easy as possible for users/integrators.  This means\ndoing most of the work in the Fine Uploader library, such as making the ajax\nrequest, parsing the response, etc, but perhaps allowing an integrator with\natypical requirements to override this behavior.\nI'd like to take a closer look at your code, and perhaps adapt it into a\nversion of Fine Uploader at some point.  I have been generally hesitant to\nprovide a \"duplicate file detection feature\" until I found a way to\nefficiently calculate a hash for a file client-side.  Until then, it may be\nprudent to provide some way for integrators to check for duplicate files\nbased on filenames.  I personally wouldn't find this useful in my projects\nthat use Fine Uploader, since filename comparisons are not enough to detect\nduplicate filenames in my apps, but others could potentially find this\nuseful.\nIf you could, please open up a pull request against the 3.3-IP branch.\n\u2039\n Reply to this email directly or view it on GitHub\nhttps://github.com/valums/file-uploader/issues/671#issuecomment-13608724 .\n. Thank you very much \u00ad I will do, as soon as I'm up to speed with git.   Your\nproject is fantastic, and I do understand my original motivation may be an\natypical requirement (but as a professional photographer it's crucial) which\nis why I only modified uploader.basic to the limited extent specified in my\nprevious comment, leaving the actual conflict test outside.  I needed a hook\nwith the granularity of onValidate but with the potential increased network\nefficiency / usability benefit of onValidateBatch - either I or my clients\nmay need to upload multiple 100Mb+ files over domestic ADSL, the ability to\nget any individual conflicts dealt with all together at the start is\nextremely helpful.  In the interim, my very basic external javascript's\nconflict checking is, in outline\n1.send names of all the files specified within fileList  to the server in one\nrequest\n2.wait for server to send back list of conflicting names\n1. if no names in the response, carry on, i.e.  startLoading(fileList);\n4.if any names returned, offer user 3 options:\na) 'overwrite' , which simply calls startLoading(fileList);\nb) 'cancel', which calls startLoading([]);\nc) 'skip', which creates an edited array containing only the non-conflicting\nfiles, and then calls startLoading(editedFileList)\nIn any event, a massive thank you to yourself and your co-creators who have\ncreated an extremely Fine Uploader!\nFrom:  Ray Nicholus notifications@github.com\nReply-To:  valums/file-uploader\nreply+i-11026279-72215c59491e7bdf4f8d4c95d7335f096573b2ce-3594765@reply.git\nhub.com\nDate:  Friday, 15 February 2013 14:28\nTo:  valums/file-uploader file-uploader@noreply.github.com\nCc:  Bill Robinson bill@billrobinson.com\nSubject:  Re: [file-uploader] onBeforeStart callback, to enable 'Overwrite /\nSkip / Cancel' user options (#671)\nI think I see your approach here.  Generally speaking, I'd like to make\nthese sorts of tasks as easy as possible for users/integrators.  This means\ndoing most of the work in the Fine Uploader library, such as making the ajax\nrequest, parsing the response, etc, but perhaps allowing an integrator with\natypical requirements to override this behavior.\nI'd like to take a closer look at your code, and perhaps adapt it into a\nversion of Fine Uploader at some point.  I have been generally hesitant to\nprovide a \"duplicate file detection feature\" until I found a way to\nefficiently calculate a hash for a file client-side.  Until then, it may be\nprudent to provide some way for integrators to check for duplicate files\nbased on filenames.  I personally wouldn't find this useful in my projects\nthat use Fine Uploader, since filename comparisons are not enough to detect\nduplicate filenames in my apps, but others could potentially find this\nuseful.\nIf you could, please open up a pull request against the 3.3-IP branch.\n\u2039\n Reply to this email directly or view it on GitHub\nhttps://github.com/valums/file-uploader/issues/671#issuecomment-13608724 .\n. A pleasure - very glad you thought it might have some merit.\nMany thanks again.\n. Lazy?  I doubt that :-)\n. Thank you - well, I hope my my rather un-tutored thoughts may be of use - and bearing in mind that my approach was to implement support for a capability, rather than the capability itself: \n1.  You're absolutely right, the name is very clunky, albeit descriptive. Preflight?  Tricky one this.\n2.  I'd defer entirely to your suggestion.  Although, if I've understood the promise correctly,  one issue does occur to me - wouldn't any implementation of a promissory callback have to block on an ajax request in order to return a processed list from the callback?  The approach I used was that neither FineUploader nor the callback need block - by calling startLoading (when any ajax request returns) the callback's implementation notifies FineUploader to carry on.. \n3.  A particular UI approach is clearly much more complex - which is why I made the changes in such a way as to leave it entirely up to the implementer of the callback.  The 3 options were obviously:\ni.   Entire filelist returned =  'overwrite'\nii.  Partial filelist returned = 'skip' (duplicate files have been removed from list to be uploaded)\niii. Empty filelist returned = 'cancel'\n1.  This seems an impossible task in the general case - in my case the duplicates could be simply deduced on the basis of filenames but, on a case-by-case basis, comparisons of filesize, creation/modification date etc might be relevant.  You mentioned previously having alreadyconsidered these issues, and I don't know if it is readily soluble in the general case.  If I had to plump, then I'd have an option (overwrite = true?) which governed the use of any checking function, and if option overwrite = false then require the integrator to implement the check.\n2.  I used a separate spinner myself whilst the duplicate check was underway.\nHope the above is of some small use\nBill \n. Your approach would clearly be more consistent with the framework as a whole - and avoids the clunky callback name!  I think leaving decisions re file-checking criteria to integrators is also consistent with your current callbacks.\nThanks very much - I'll revise my own app accordingly as/when necessary... have a good trip.\n. ",
    "sachintaware": "Hi rnicholus!!The details of the file I have are as follows\n/*\n- Ajax upload\n- Project page - http://valums.com/ajax-upload/\n- Copyright (c) 2008 Andris Valums, http://valums.com\n- Licensed under the MIT license (http://valums.com/mit-license/)\n- Version 3.6 (26.06.2009)\n  /\n  I was redirected to GIT after hitting this link http://valums.com/ajax-upload/!!\n  May be I am wrong but still,is there a Cross Domain implementation for this??\n. OOOHH!!Does the new one has the feature for cross domain??I haven't looked at it.Actually its already in use in an old application and I am currently working on the transition to reform it a bit.The new one would be of help if it does what I need!!\n. ",
    "rk": "Thanks. I skimmed right past that method.\nI wish there was API documentation. It's well written, but a handful of demos isn't sufficient to someone who has a little more than average requirements.\n. Sorry Ray, I seem to be reading past everything this morning. Sorry about that.\n. Works like a charm!\n. Hey Ray, my patch fixes more issues than just #641 lists. Yes it does include that, since I didn't see the change on the master branch.\nMy patch covers in addition to #641:\n1. Better Windows compatibility (all calls to fopen must include a 'b' flag), and use of the DIRECTORY_SEPARATOR constant instead of hardcoded slashes. Windows is compatible with the latter, but it's best to be consistent in case another OS is not.\n2. When deleting the chunks I noticed that the loop was opening the files before deleting them. This is unnecessary, and might leave PHP with orphaned file descriptors. I don't know if it'd cause a memory leak.\n. I've tested the code and can says that it works on Mac. I haven't finished testing it on the Linux development machine yet, but can promise that it'll work. It's primarily a Windows fix by forcing binary writes to file instead of letting Windows transparently rewrite \\n into \\r\\n; which could cause corruption of binary uploads. The DIRECTORY_SEPARATOR constant is a \"magic constant\" that is correct for whatever the current OS is, so adopting that can't break anything.\nIf you look at the documentation for fopen and check the note for the mode parameter you'll see what I mean about the 'b' flag.\nThe changes I made are pretty safe, and standard for PHP code.\n. Just finished testing on Linux, and successfully uploaded a file with 3 chunks.\n. ",
    "yairEO": "in the source code thee is a function names onAllComplete. there is no information on this in your website. can this callback be used in this case?\n. sorry, I must have missed it! I used google and it didn't find it so I assumed it was undocumented.  anyway, now whoever comes to this thread will know of this. Thanks a lot!\n. yeah I agree, that was a weird request coming from a weird user name from someone with a weird profile photo, who has an empty github profile.\n. why is there no \"disable\" method for fine-uploader? I want to give the user 3 items he can upload, and after he has done so, I want to disable any dragging or uploading of any sort, but the UI will remain the same. how should I do that? (i'm using the jQuery version BTW)\n. actually, you're right. is there a callback when itemLimit is 0 and someone is trying to upload? if you want a popup to appear, for example, or any other things that might happen at that point? \n. it can be rejected by many other things, other than the limit is set to zero, and I need only that case. \n. Thank you very much for your dedication, and patience. I work for a firm which is a paying customer btw and we thank you for your time.\n. Original Size:  74.97KB gzipped (352.15KB uncompressed)\nCompiled Size:  34.8KB gzipped (119.96KB uncompressed)\n. ok, so map qq to jquery, and extend jquery (or the new qq) with the functions you need, but I think, even if it's a wrapper, there should be a different version entirely for jquery..becuase the only reason to create a jquery plugin, and not a standalone one, is first the different in first size.. all that jquery does it save you code, so there is no benefit in just wrapping it and leave all this unseeded mess inside..now, I know it's a lot of work to clean it up and fork it entirely for jQuery, but the code is over 300k, which is a LOT. \nyeah 3k is not much..after gzip and all. I am just trying to think of ways to size down the code from it's 300+ KB\n. well, it's a fine-answer.\n. but it HAS to be a script, you say it in the docs. it cannot be be a rendered HTML, because the template in the form of a script which is evaluated internally.\n. very confusing. why would it be in styling? I went here, and this is what I see:\nhttp://docs.fineuploader.com/branch/master/api/options-ui.html#template\nI clearly understand from this that I must use script templates.\nhere also it's very misleading regarding the template:\nhttp://docs.fineuploader.com/upgrading-to-4.html\nit says again and again the <script> element like it's THE most important and only thing you must use as the template. If it's not, than the word the should be changed to a and it should mention that you can use just an HTML element node as the template.\n. this would be the most basic way, but in many situations, the template itself my be pre-compiled with dynamic data, and only then, the output DOM should be initialized as the fine-uploader's template, no now, after I compile my template in order to actually create it, I must wrap the output html string again with <script> tag, so again, it would get re-compiled...such a waste wouldn't you agree?\n. yes because it works on Chrome...As I said in my issue, this is a Firefox issue.\n. yeah well, I was assuming you will start testing in the exact same conditions under which I have mentioned, to make sure this issue is valid...I am patient, I know you guys are really nice people and doing your best on this great plugin. \n. \nIt might be anything...my graphic drivers even. who knows. I really hope it only happens on my machine and not on any other, but it's the only place I've ever seen this happens. with this script, so this is why I'm stating that. I've tried this with other uploading solutions I've found on google, such as http://www.dropzonejs.com/ and they preview works ok. So, logic suggests that this is a fineuploader issue.\n. yes, it is probably an extension. I've just tried to restart Firefox in safe mode and that black thumbnail hadn't occurred. As a developer, I have 20 addons right now, I am too lazy to disable each one and then restart Firefox and check which one is responsible for the issue, it is too time-consuming \n. | Name | version | enabled |\n| --- | --- | --- |\n| Adblock Plus | 2.6 | true |\n| BrowserStack Local | 5.2 | true |\n| ColorZilla | 2.8 | true |\n| CSS Reloader | 1.0.5 | true |\n| Download Status Bar | 9.9.1 | true |\n| Firebug | 1.12.8 | true |\n| Firebug Autocompleter | 1.4.1 | true |\n| Firebug Paint Events | 0.1.8 | true |\n| FireFontFamily | 0.1.2 | true |\n| FireQuery | 1.4.1 | true |\n| Free Memory | 0.95 | true |\n| Html Validator | 0.9.5.8 | true |\n| Image Zoom | 0.6.3 | true |\n| MeasureIt | 0.4.13 | true |\n| Screengrab (fix version) | 0.97.24c | true |\n| SelectBug | 0.1a4 | true |\n| Tab Mix Plus | 0.4.1.3.1 | true |\n| Text Font-Size Adjuster | 0.94.18 | true |\n| Web Developer | 1.2.5 | true |\n| X-notifier | 3.4 | true |\n| Adobe Acrobat - Create PDF | 1.2 | false |\n| Download Statusbar | 0.9.10 | false |\n| YSlow | 3.1.8 | false |\n. I've updated my initial report with additional data regarding your question.\n. it apparently was the file name that the camera generates, after manual change it worked. seems like the Android itself reads the images as jpg but fineuploader doesn't recognizes they have an extension at all...\nchecking like so:\nformatFileName: function(filename) {\n       alert( filename );\n}\n. well, the Android gallery app shows (via the \"details \" option) that the file do have jpg. I have no idea if that is real, or it thinks it's a jpg because it reads the data and decides this way. I need to connect it to a computer to actually see the file system itself.\n. your demos aren't big enough to show the problem. you need a container big enough that the default font-size you gave it won't be sufficient, thus the input field's button won't take all the space, like it should. I will try to prepare a demo page soon\n. Better to set the font-size using feature-detection so the right value will go to the right browser\n. I now see that that large font-size has a side effect in Chrome, where the hidden button doesn't get cursor:pointer so the pointer is actually the default. I think because the button itself is being bushed outside the area of \"interest\". This problem can be seen in large uploader areas like in my website. I can work around it by giving some parent of the hidden file input a cursor:pointer CSS value, but it's a very specific solution to the problem. doesn't work, the input file is above in the z-index obviously so it would be clickable...\n. not on my website (mentioned on the first post of this issue), the cursor in Chrome is normal default even though it's been set to pointer, that's because of the large font-size and the way Chrome defaults work (always worse than expected). I verified it. Chrome cannot show pointer cursor currently in certain setups like my own\n. But still, on Chrome (this is actually a new issue) the cursor cannot be pointer no matter what font-size is set to the file-input. the area is too large and quirks happen..so only a part actually gets the right cursor. I wonder if there's a way to simulate a click on input, without actually using it, since it's behavior is so unexpected cross-browser.\n. http://imgur.com/Q3cUg29\nseems there is no escape from sniffing browsers\n. it is imperative to know the reason of failure for me. whether on file size, dimensions or file type. different things happen on each.\n. you already wrote the method which gets a bolb or file and tell you the dimensions.. A person would have to write his own code to determine a file's width and height, obviously as a promise returned on the onSubmit event. \nyou comment didn't make much sense as to why not to expose it if it would help others in validating dimensions beyond the very limited, already exposed, way, then why not. \n. ",
    "mdafer": "I think it should be renamed in the documentation to AllComplete (upper case 'A')\n. ",
    "markotibold": "Oh this is so obvious, thanks for your quick reply!\n. ",
    "lgrz": "The default Content-Type of a multipart/form-data part is text/plain, so that should mean nothing is encoded. But if you have non-ASCII data it may be encoded if it does not match the default encoding.\nhttp://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.2\nIn my case I have field names with brackets so uri encoding these in the body of the reqeust results in two separate parameters and not an array of parameters.\n. Thanks for looking into this. I've done some more tests and to answer your initial question a little more, here is what I've found:\n\nWhy is this a problem, exactly? Parameter names or values with non-ascii characters will be mangled if they are not URI encoded.\n\nI guess it depends on the encoding you are using and the enctype used when submitting the form.\nMy example HTML document is set to utf-8, so that is the encoding of the page, by default this means that the form data submitted will be utf-8 encoded also. If you want to force a particular encoding then you can use the form attribute accept-charset.\nI've got a proxy in the middle and watching the data as it is sent from the browser to the server, the text data sumitted with non-ASCII characters is all garbled. But that is because the tool I'm using is showing me the data in Mac (OS Roman) encoding.\nWhen receiving the data on the server side, it is expecting the data to be utf-8 encoded, and since the data was sent encoded in utf-8 there is nothing that needs to be done.\nAnother thing to note is that forms submitted via POST default to application/x-www-form-urlencoded which is just like putting one big query string in the body of the request. Obviously this should be urlencoded. It is a little different for POST requests with an enctype of multipart/form-data, which according to the HTML spec states that the default Content-Type is text/plain and the default encoding seems to be 7BIT, unless specified via the Content-Type and Content-Transfer-Encoding for each part.\nPlease see this gist as the example I've used. This is a very simple example that just focuses on the encoding problem of non-ASCII characters.\nLet me know if there is any further information that I can provide that may help.\nAlso for clarity here is some screenshots of the same POST request, one sent with application/x-www-form-urlencoded and the other sent with multipart/form-data:\n\n\n. ",
    "laeubi": "It would be nice to have a gneral purpose object (maybe in qqUtil?) that represent what features are avaiable, (e.g. resume downloads, drag'n'drop etc...) so it is possible to present users a list of options the can use right now, and options they might can use with a more recent browser...\n. Yeah I see them, It just seems that they evaluate on each call so I just wondered if it would be possible to just calcualte it once and the present this via a general \"feature\" object, it would then ven be possible to assign messages to feature keys that could be presented to the user ... but thats just an idea that crossed my mind :-)\n. I just want to make sure that also user with \"old\" browsers (in fact its \nthe recent one in debian squezze distribution) can upload files.\nI understand that this can't be tested regular, just wanted to report \nthis since it worked in 3.2\nIf I enable debug I end up with identical output:\n[FineUploader] Processing 1 files or inputs...\n[FineUploader] Sending upload request for 0\n[FineUploader] Received response for 0\n[FineUploader] iframe loaded\n[FineUploader] converting iframe's innerHTML to JSON\n[FineUploader] innerHTML =  \nJust that the browser indicates, that it is still processing/loading in \n3.3.0, while in 3.2 everything is \"normal\".  (paramsInBody: false)\nIf I use the option 'paramsInBody: true' it works on 3.2 but never \nprocess the request in 3.3, it just hangs in the  'Sending upload \nrequest for 0' and the POST request is processing forever, but this \nmigth be related to that I have to upgrade the server side also to 3.3.0 ...\n. just a minor improvement to close the streams whatever happens...\njava\n    private File mergeFiles(File outputFile, File partFile) throws IOException {\n        FileOutputStream fos = new FileOutputStream(outputFile, true);\n        try {\n            FileInputStream fis = new FileInputStream(partFile);\n            try {\n                IOUtils.copy(fis, fos);\n            } finally {\n                IOUtils.closeQuietly(fis);\n            }\n        } finally {\n            IOUtils.closeQuietly(fos);\n        }\n        return outputFile;\n    }\n. I worked around this atm with the following code:\nJS\nvar input = fileForm.find(\"input[type=file]\");\nif (qq.isXhrUploadSupported() && typeof(input[0].files) !== \"undefined\") {\n    input = input[0].files\n}\nuploader.fineUploader(\"addFiles\", input);\nJust not sure how browser compatible this is... the code works with FF3.5 (no Xhdr) and FF 19 (with xhdr)\n. I'm using version 3.2 atm.\n. I'm using this on IE 8 without a problem, the problem only occurs if the browser supports the FileAPI but you try to hand over a plain input. (The Brwoser even must support XhrUpload, FF3.5 implements parts of the FileAPI for example, thus the additional check), so please elaborate what \"isn't going to work\".\n. This is a little bit superseeded by https://github.com/valums/file-uploader/issues/760\nBeside this, without contextual information IMO the function feature is to limmited to be usefull because the function has no idea\n a) how often per file\n b) for what file\nit is called.\nThe client code is part of a larger application, but I can try to outline it:\nThe Application has several sections, each section has it's own uploader. The UI consists (basically) of an , a  and a 'submit' button.\nWhat I do is, when the user hit the submit button, add the Input to the addFiles method, and when the method return I clear all inputs so the user can upload another file.\nThe \"function-params\" have access to the DOM element of the text-area and just fetch the text context to send along with the request.\nAs described, this wirks fine if the file is send as one big chunck, but when the file is splitted the following happens:\n- first chunck has all needed information\n- other chuncks have either empty, or unrelated information (e.g. the user types new text while an upload is in progress)\nIt might be possible to acomplish this with the onSubmit callback and use setParams there, but this would be more of a \"workaround\", since this actually let me do the \"creato-once-copy\" :-) and won't solve the general issues with function scoped params (see comment above...)\n. for 1: Its part of the UI and I must use this element 'as-is' \nfine-uploader seems to use 'hidden' inputs for example, I need a \n\"classic\" one\nfor 2: same problem as with issue #760 the callback might not hass \naccess to all context information, and before adding the file I don't \nknow the file-id\nAs mentioned above In this case I might can do this by use the \nonSubmit callback, but then I don't understand for what use cases the \nfunction params are usefull at all (even the example of fineloade with \nthe fileNum won't work, since in fact it assigns a chuckNum and not a \nfileNum), and even if I use setParam and the object contains functions \nwouldn't they be evaluated more than once in chunked mode?\nI have looked at the code and it seems that on each request the params \nare converted to an input and/or URL String instead of doing this once \nliek with the UUID...\n. Sure, if it's not too much hassle for you since I circumvented the problem by extending the code like described in #760 already.\nJust send me a mail to laeubi@googlemail.com and an aproximate time you are online tomorrow and I'll send you the URL to my current development version.\n. It would still be helpfull. I' not sure how #780 solves this....?\n. Yeah, currently I use a private hack for #760 to circumvent this, I still think it would make more sense to only evaluate parameter functions once.\n. setting it via the API would require the file id. What ID(s) are assigend to the submited files is an information I have no access to untill a callback is called. That callback on the other hand has no idea about the context in what addFiles was called so its a little bit a chicken egg problem :-)\n. Thanks, its a relative small change but very usefull IMO and should be 100% backward compatible.\n. ",
    "eric-wilson": "Thanks! sorry for that.  I missed that section... I'm new to github.  Great Product!\n. ",
    "dubiousdavid": "There isn't currently an api function that tells me how many files, or if any files have been added to the list at all.\nOn Feb 19, 2013, at 6:26 PM, Ray Nicholus notifications@github.com wrote:\n\nonSubmit: function() {\n   numFiles++;\n}\n\u2014\nReply to this email directly or view it on GitHub.\n. My use case is fairly simple, and not met elegantly by your proposed solution.  As far as the naming, that is largely arbitrary and not really the point.  The functionality is the key.  I'm just not sure why you wouldn't want to expose a public function which encapsulates this information.  It's very useful, and not dissimilar to the getInProgress function.\n\nDavid\nOn Feb 19, 2013, at 8:58 PM, Ray Nicholus notifications@github.com wrote:\n\nThere doesn't need to be. Use the code i provided. Adding a new api function or option to solve a simple problem is not the best solution. Besides, your function name is a bit vague at best and misleading at worst. It will only list files that are submitted when autoUpload is set to false. Utilizing the onSubmit callback is the best way to determine how many files have been submitted to the uploader.\n\u2014\nReply to this email directly or view it on GitHub.\n. The point is not whether you know this or that, the point is that the code enforces behavior which is not universally needed, and should be optional.  I just commented it out, since uniqueness is determined for me by other factors, and uploading a file with the same name has to override the previous.\n\nOn Mar 1, 2013, at 11:27 AM, Ray Nicholus notifications@github.com wrote:\n\nHow do you know you are dealing with the same file? Simply based on the name? I hope not. This is not solid logic. If you are accepting files from an IOS6 client, all files will have the same name, all the time. If the client sends a Blob in the request (as opposed to a file), the name is determined by a qqblobname param, which may or may not be unique. What if your user uploads two files with the same name from two different paths on their filesystem?\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "andres-torres-marroquin": "So, Is there a fancy way to know how many files are going to be uploaded?\nUse-case Pseudocode:\nIf there is any files to upload:\n    Upload files, after upload files:\n        collection.fetch()\nelse:\n    collection.fetch()\nIf it is not clear enough, please let me know.\n. \"As a result Fine Uploader grows at a rapid pace, bugs are addressed quickly, and the support I provide for users is second-to-none.\". Is the last part true?\n. You could have said that like 2 days ago. :) Thanks.\n. You could have said that like 2 days ago. :) Thanks.\n. @rnicholus It's cool, just as the text said \"second-to-none\", I expected that. It's a great project, I really do like it (that's why I'm using it), and IMO it would be nice to keep the \"number files function\"  that @dubiousdavid proposed, I'm thinking to add it on my local fineuploader library. Thanks again, and keep up the good work.\n. @rnicholus It's cool, just as the text said \"second-to-none\", I expected that. It's a great project, I really do like it (that's why I'm using it), and IMO it would be nice to keep the \"number files function\"  that @dubiousdavid proposed, I'm thinking to add it on my local fineuploader library. Thanks again, and keep up the good work.\n. ",
    "jeron-diovis": "But all works perfect in other browsers, and with another file types. How can problem be on server in this case?\nAlso, I tried one crazy idea  - to change file mime type manually before upload. And it works! Upload was successful even in Chrome. \n. Sorry for trouble. It seems, problem was with wrong source video files.\nAnd anyway, your plugin is great, thanks)\n. ",
    "six519": "Hi guys,\nJust revisited the code after two years.. got a busy schedule because of work.. :) Btw, the pull request should fix the mentioned bug... \n. yeah right... thanks nnmware for sharing your thoughts.. btw, i refactored my sample code again to handle chunking.... \n. hi.. welcome... i refactored my sample code to support chunking...my refactored code is almost exact replication of andrew valum's php sample code.  I only tested it on IE8 using virtualbox and google chrome linux.. Sorry for the late response.... Thanks...\n. Hi guys,\npushed another changes to the sample code... I updated the code to implement nnmware's handling of raw http request and to support upload deletion..\nThanks,\nFerdinand\n. You're welcome Ray and thanks to nnmware too.. ;)\n. Hi Ray, I noticed that I pushed unnecessary change to the #689  pull request under file-uploader/client/js/uploader.basic.js , line 15.. \nforceMultipart: false, <-- I set it to false..\nSorry about that...\nThanks,\nFerdinand Silva\n. ",
    "Mikou": "I just finished to update the code and came up with the same solution (chunk) without the backward support.\nI was going to update it and realize you already updated it. Thanks a lot.\n. should use \"and\" operator rather than \"or\"\nOtherwise the test fails if \".*\" is not part of self.allowedExtensions  \nif self._getExtensionFromFileName(filename) not in self.allowedExtensions and \".*\" not in self.allowedExtensions:\n. ",
    "nnmware": "In Django example fileSize = int(uploaded.im_self.META[\"CONTENT_LENGTH\"])\nBut it's not true.\nfilesize <> size of all content of sending data.\n. I answer too in pull request #694 May be Ferdinand too see code and have better idea.\n. Hi all.\nFerdinand i see you code, and not find how you read data if MPE request?\nI think you need add code block for store raw data from request(access for this as request.read )\n. I think - Ferdinand pull request, but he need add work with MPE-requests.\n. Yes, you right, sorry. For MPE requests content-length is file size. \nCode not need changed, 'cause in MPE - django handler read streaming data from request, while they proceed, and don't using 'qqtotalfilesize' parameter.\nI don't tested this code in IE and Chrome, cause don't have them, but same code normally work in any browsers with old versions of uploader.\n. If handle MPE request- in django i not using qqtotalfilesize. I only read raw data from request, and think when stream ended- file is full received. \nFor non-MPE requests - same situation, cycle read of file chunks and store in file.\nIn code i additionally check of size received data, and if value bigger then max limit- file deleted and ajax error reply.\nTested this in Ff 17-18-19 and FF 10 ESR(Tor version).\n. Ray, i sorry for dummy question. May be you quick answer me.\nI need have many uploaders on dynamically page(block made by ajax). I create loader in function after click on needed element(cause send in function act path etc). How i may delete uploader object from memory in onComplete or onCancel callbacks?\n. ",
    "neilchaudhuri": "Did AMD support ever happen for FineUploader? \nIf not, is it possible to mix RequireJS loading and FineUploader as a \"one-off\"? How have people made the two coexist?\n. What's the ballpark for the 5.5.0 release? Curious for my own migration planning purposes.\n. I have to explore further how video cameras actually generate data onto filesystems as they record, so I can't say I have much to offer in terms of details yet. To be honest, I thought about cheating by using a file watcher library to determine when a file is complete and then use FineUploader to do what I am already doing--uploading the video as a whole in a way that spares my client that manual step.\nBut of course I am open to ideas from the community on how this might work with real streaming. . I've never used a video camera before (My phone has always been good enough for me), so I assume the only choice is to ingest video on the local filesystem. Are there other options? How would you tackle the challenge at a high level (using FineUploader or otherwise)?. That's very helpful to know. Thanks.. ",
    "mrjoelkemp": "We're using the old version of qq (fileuploader) and trying to slowly migrate to FineUploader. Since both export qq to the global namespace, any pages that have both versions loaded will throw errors (as both objects get merged together).\nHaving a UMD wrapping would allow us to pull in the new version without conflicts.\ncc @mikesherov\n. Yes. Older features use fileuploader. Newer ones are starting to use Fineuploader.\nThe migration isn't very painful. The only real changes are to the options object passed to the uploader constructor. \nWithout amd support, we've had to manually change the export of the new version to something other than qq until we migrate the older features to the new uploader. This is not great as it breaks upgrade paths and forces the backend to adapt to new get params (used to be qqfilename, but is now qqqfilename). Yes, we could carefully find and replace, but there were almost 1000 instances of qq.\n. @rnicholus Will do. Thanks @feltnerm.\n. Not to litter this issue with +1s, but I'd also like to see a configurable method option. Ignoring the property in older browsers sounds great. \nFor now, I'll have to find a way of monkeypatching the internals of fineuploader to get around this limitation. @rnicholus Would you happen to know, off hand, a quick workaround for this with v5.0.x?\n. Thanks @rnicholus. To avoid modifying fineuploader, I'm thinking of possibly monkeypatching AjaxRequester's constructor to attach overrides (to whatever is passed as o) for validMethods and method since those overrides would get mixed in at https://github.com/FineUploader/fine-uploader/blob/178dcbf35a652c0a7505eb030c8c6a6005670dab/client/js/ajax.requester.js#L35. That's less invasive, but I'll test first and report back if that works.\n. I'm a maintainer of JSCS. I'll gladly integrate it for ya :) There will likely be a few style violations in the existing codebase that I'll have to patch up as well. Look for a PR soon.\n. Yay! Awesome job bringing it home. Feel free to suggest rules or\nenhancements to the JSCS repo. Glad to have you all using it :)\nOn Oct 2, 2014 11:01 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nAll style rule validations are now cleaned up and this is part of the\ndevelop branch.\nNote that I decided not to enforce styles in unit tests. There are far too\nmany style issues in the unit tests, and I'm not sure it's worth the time\nto clean those up.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1221#issuecomment-57745900\n.\n. Yes! Thanks so much. \n. > If you'd like to remove a specific file after it has been added to the list, you can always cancel it via the API.\n\nThanks for the tip.\n\nBut, I'm confused. multiple: false should only allow one original file to be selected/submitted.\n\nYes, that's true, you can't select multiple items. I was talking about subsequent attempts at uploading a single file. \nI now see that the uploader retains the invalid submissions, but only sends valid ones to the backend. I was incorrectly assuming the image I needed to process was always in the zeroth position.\n. @feltnerm @rnicholus Hey guys, this PR has JSCS incorporated. I have about 116 violations (out of 500+) to fix, but I'm concerned that patching all the violations would cause merge conflicts with other branches based on develop. \nI'm fine with putting the violation fixes in a separate branch and keeping this PR to simply incorporate JSCS into the build process. That will cause travis to fail, of course, but you guys could then patch the violations at your own pace \u2013 minimizing the risk of conflicting with other branches.\nPlease advise.\n. Thanks, guys :)\nSafe to close this PR and assume that you all will take care of the rest of the violations?\n. Yes, sorry. It's an upload request with form support being utilized. So there's an upload plus form data in the request.\n. I see the documentation for what you're saying: http://docs.fineuploader.com/branch/master/endpoint_handlers/traditional.html. Thanks for clarifying. \nI'm willing to close this since it's not a bug, unless you'd like to reword it into a feature request for the next major release.\nThanks a ton for the help.\n. Apologies, jquery wasn't an important part of the api (only habitually added it). Replace that with a dom node representing the form.\nGlad to hear there's value in adding the capability to core. Any foreseeable hiccups with implementing this? Any good place to start digging? I'll likely implement it in my fork (for immediate use in production) and potentially bring it to fineuploader core if it works. \nThanks for your speedy response and continued support. \n. Thanks for the details @rnicholus. I'll give it a go in my fork and report back.\n. Awesome work! Thanks.\nOn Jul 22, 2015 1:07 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nThis is complete in the develop branch - 5.3.0-7.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1334#issuecomment-123793876\n.\n. \n",
    "larslemberg": "I read your comment in case #439. My users' needs are very fundamental. The\nexact order that multiple drops appear is not important. Their normal mode\nof operation is to have several teams entering data and uploading files.\nThese uploading sessions last all day, so the lists get very long and they\nwish the recent entries were at the top. I think if the recent uploads were\n\"near the top\" no one would ever know nor care that the actual uploads may\nhave occurred in a little bit different order than displayed.\nRemoving old uploads might be OK, although I think they refer back to old\nuploads in the list from time to time to see \"did I upload this already?\"\nThey've been merrily uploading at several work sessions since I presented\nthem with the FineUploader, so this feature is certainly not a show\nstopper. If this is a lot of work for one user, feel free to punt on the\nidea once again.\nLars\nOn Thu, May 9, 2013 at 10:47 PM, Ray Nicholus notifications@github.comwrote:\n\nI remember attempting this a while back and giving up due to a few\nworkflows that were difficult to deal with. My attempt is documented in\ncase #439 https://github.com/Widen/fine-uploader/issues/439. If anyone\nis interested in this feature at all, please read my comments in #439https://github.com/Widen/fine-uploader/issues/439and comment here (or there, if you must). If I don't receive any comments\nin the next few days, I will move this into 3.7. If I don't receive any\ncomments after a reasonable amount of time into 3.7, I may close this\naltogether as \"will not implement\". I'd also like to see if more than 1\nuser is interested in this. A reasonable way to deal with a long list of\nfiles is to, perhaps, remove successfully uploaded files (as they complete)\nfrom the UI (via a display:none style or some sort of jQuery hide\nanimation), leaving only the in-progress and failed files.\nThoughts anyone?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/693#issuecomment-17701679\n.\n. Your \"something simple\" scenario would work fine for my users.\nOn May 12, 2013 10:21 AM, \"Ray Nicholus\" notifications@github.com wrote:\nI can see doing something (hopefully) simple, like prepending each batch\nof selected/dropped files to the list and not worrying about ensuring the\norder in which the files upload matches the order they appear in the UI.\nFor example: say a user drops 10 files, and the first 3 of that batch are\nin progress. Then, the user drops 5 more files. Then, the user drops 3\nmore. The upload order will be: the first 10 (in the order they appear),\nfollowed by the next 5, followed finally by the last set of 3. This, of\ncourse, will not match the order they appear in the UI anymore since the\nbatches will be prepended to the list in the UI. I can see this behavior\n(prepnding the batches) being controlled by an option specific to\nFineUploader mode (defaulting to \"off\").\nIs everyone ok/happy with this proposed behavior? Any comments? Or, would\nsome other behavior be more useful/appropriate?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/693#issuecomment-17778634\n.\n. \n",
    "andrewdmoreno": "My thoughts are similar to those of @larslemberg . In my workflow that initially caused me to open #805 , users can potentially upload many files and I have always personally thought it would be beneficial that the top of the list would contain files submitted more recently as opposed to having to scroll down a potentially long list in some cases/ui's to see what you have recently done.  Like @larslemberg mentioned I don't think it necessarily matters to display correct order of when files actually completed uploading or when dropping multiple files which comes first, etc. I think the main desired behavior is that top = more recent, bottom = older. Again not a show stopper on my end either, but would be a nice to have.\n. I can confirm that this error is also occurring in my project. Does not happen when using Chrome or Firefox.\n. @rnicholus Has any additional consideration been given to the ability to submit multiple files in one request as you mentioned above? I've mentioned before in other issues that we have a requirement where user selects a file, we prompt them for additional information categorizing/describing the file, and then submit the file. We rolled this out in Production a couple of weeks ago and one of the things we noticed right away is how many people have documents that span multiple pages, but each page is a separate file (probably created that way when scanning, etc). They are thus having to describe each page separately which is obviously not the optimal scenario, and it is then being stored/counted as a separate file when in reality it is an extension of the first one and can/should be \"grouped\" together. Would have been nice to be able to ask them in the modal if their document has additional pages/files, allow them to select the additional page files and then continue, sending all files in one request. Have not wrapped my head around how to proceed but perhaps if the feature was in place it would be an option. Thoughts?\n. @rnicholus , I was wondering if you had given thought yet to how the implementation of this feature would function, specifically when taking multiple files into consideration (as that is what triggered my original SO post). \nCurrently, when multiple files are added there is a loop that calls _upload for each file, which in turn handles triggering the onSubmit callback and getting the result. Is that where the promise would be implemented? Just wondering if the next file in the loop will wait to be passed to _upload until the promise for the prior file is resolved. \nIs my understanding correct.. or do I have it all wrong :P? \n. Would this solution still be possible if multiple files are simultaneously selected from the native OS open dialog or dragged into the dropzone?\n. I understand now, thank you for the clear explanation.\n. ",
    "onlyjazz": "Fair enough.   - we're chucking our current Flash code - have my hands full integrating FU into our project.\n. Yep. Interestingly enough - even though you would think that the back end code would not be affected - it is.  Since Flash runs in its own address space in the browser - and requires Flash variables to share data with the page - it's a very clumsy mechanism and not very secure.   We decided to decouple the Flash client from the rest of  the app and contrived a queuing mechanism where the Flash code uploads the file onto a queue and the back end picks it up and inserts objects into the db.     Looking at the code now - I am seeing a lot of opportunity for simplification and improved security. This is a \"good\" thing and why the web is going there...I think.\n. ",
    "VenubabuSunkara": "It is working for single file, If when i uploaded multiple files return false is not uploading remaining files that is wrong . \n                onValidate: function (id) {\n                    if (qq.indexOf(selectedFiles, id.name) === -1) {\n                        selectedFiles.push(id.name);\n                        return true;\n                    }\n                    else {\n                        return false;\n                    }\n                },\nI selected one existing file and 3 new files, above code not allowing new 3 files also\n. ",
    "sayanb": "Hi,\nJust checking if there is a plan to do this anytime in the near future? i.e. rotate before uploading? For the end user, it should ideally behave similar to the scaling (http://docs.fineuploader.com/branch/master/features/scaling.html) function which resizes the image based on config parameters before uploading. \n. Hi Ray,\nJust checking if you implemented this bit? \"and possibly add some code to detect support for this to the features module\". \nIs there some documentation for this fix somewhere?\n. Hi,\nRay informed me about this thread here- http://stackoverflow.com/questions/20236218/fine-uploader-s3-resize-image-before-uploading . Thanks Ray!\nBasically, applications like photobooks, user generated magazines etc. will want to resize the big image on client side and upload the smaller one first, so that the upload process finishes quicker and the user can continue to create content without having to wait very long. At the same time, the application would like to somehow \"remember\" the original large image so that it can be uploaded later/asynchronously/in the background without blocking the user. \nThe resized image will be used for the web application. However, certain business requirements (such as the requirement to print material) might necessitate having the larger original version as well\n. Yes, we would need to keep exif data for future usage for store.\nAs far as uploading all sizes are concerned,please consider this scenario:\n1. I need to upload 15 photos where each photo is somewhere around 5MB.\n2. Fine Uploader resizes the photos and starts uploading all at the same time.\n3. Once all the resized small photos have been uploaded, my client code should somehow be notified.\n4. Once the client \"knows\", it informs the user that photos have been uploaded. This information is not accurate as the main photos are still getting uploaded. However, the user can then navigate away from the upload page to another page where she can use the uploaded smaller photos the way she wants to.\nQuestion- if the user navigates away, will Fine Uploader stop the upload process for the larger main photos? If yes, uploading all at once might not be ideal. The whole idea is to not make the user wait for large uploads and let her move to other parts of the site while the large photos are getting uploaded. If Fine Uploader does not stop uploading the main photos once the user navigates away to another page, uploading all at once shouldn't be a problem.\n. Thanks. That makes sense.\nHave you all decided a release date for this yet? \n. Thanks for the information. Usually how long is one release cycle? Just checking so that we can plan our development of the feature around that :)\n. Hi,\nJust wanted to check if you are implementing this new feature for the present release and if so, when can end users expect the present release?\nThanks,\n. Hi,\nA quick question- if I want to decide whether to send the original or a\nsmaller scaled version based on the file size of the original, is there a\nway to handle this on the client side?\nThanks,\nOn Tue, Mar 11, 2014 at 1:53 AM, Ray Nicholus notifications@github.comwrote:\n\nClosed #1061 https://github.com/Widen/fine-uploader/issues/1061 via\n0dd3acfhttps://github.com/Widen/fine-uploader/commit/0dd3acf40afe0a9ca0d439526aadc8578738fc62\n.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061\n.\n\n\nSayan\n. Thanks for the clarification.\nWhat would happen if I specify say maxSize: 1000 and the original photo's\nwidth and height are both less than 1000px? Will it ignore the scaling\nrequest or could it result in an error?\nOn Tue, Mar 11, 2014 at 10:48 PM, Ray Nicholus notifications@github.comwrote:\n\nThe scaling options apply to all files and are not currently adjustable\nafter a Fine Uploader instance has been constructed. You can choose to\nhave all originals uploaded, or only upload all scaled versions.\nOn Tuesday, March 11, 2014, sayanb notifications@github.com wrote:\n\nHi,\nA quick question- if I want to decide whether to send the original or a\nsmaller scaled version based on the file size of the original, is there a\nway to handle this on the client side?\nThanks,\nOn Tue, Mar 11, 2014 at 1:53 AM, Ray Nicholus notifications@github.com\n<javascript:_e(%7B%7D,'cvml','notifications@github.com');\n\nwrote:\nClosed #1061 https://github.com/Widen/fine-uploader/issues/1061 via\n0dd3acf<\n\nhttps://github.com/Widen/fine-uploader/commit/0dd3acf40afe0a9ca0d439526aadc8578738fc62\n\n.\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/Widen/fine-uploader/issues/1061>\n.\n\n\nSayan\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-37265694>\n.\n\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-37291288\n.\n\n\nSayan\n. Hi Ray,\nI wanted to check what kind of compression is being used by the resizing algorithm. Basically, I tried to use this to upload a 5mb image (4901x3268)  \nhttps://cloud.githubusercontent.com/assets/3595665/3129936/dd393120-e7ed-11e3-86de-059e786731d3.jpg\nby setting a limit of 3508 for size. The result was much smaller in size (about 300kb)\nhttp://static.inkive.com/singapore/original/56327169-2a68-4fc3-8577-13df18844e12.jpg\nWith quality degradation and lower pixel resolution (from 300 DPI to 96 DPI).\nWould there be a way to do this by retaining the pixel density?\nThanks,\n. I see. In my case, the output was a jpeg though.\nAt the moment, the FineUploader image scaling API does not seem to have a\nparameter to adjust quality for jpegs. Would you be able to recommend a\nworkaround? We basically need to upload smaller images to save upload time,\nbut we are a photobook company, so printed photobooks need to have images\nof a decent quality.\nOn Sat, May 31, 2014 at 12:51 AM, Ray Nicholus notifications@github.com\nwrote:\n\nCompression is handled entirely by the browser, specifically, by the\n element\nhttps://github.com/Widen/fine-uploader/blob/4.4.0/client/js/scaling/scaler.js#L352.\nFurthermore, the quality of an image can only be adjusted when the output\nimage in a jpeg.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-44659549\n.\n\n\nSayan\n. Thank you. This might work for me. I'll set this to the highest quality\npossible and test.\nOn Sat, May 31, 2014 at 1:06 PM, Ray Nicholus notifications@github.com\nwrote:\n\nNote that I made a couple last minute edits to my above comment.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1061#issuecomment-44716365\n.\n\n\nSayan\n. ",
    "cds-zz": "Hi Ray\nThanks for the quick reply.\nI am 100% sure it\u2019s not being called \u2013 I put a breakpoint on it!\nAnyway, I\u2019ll put together a fuller example so send to you.\nThanks,\nCraig\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Monday, 4 March 2013 4:44 a.m.\nTo: valums/file-uploader\nCc: cds\nSubject: Re: [file-uploader] jquery plug in doesn't call my complete event in IE8, works fine in IE9 and other browsers (#710)\nAre you 100% sure your complete event handler is not called? My guess is that it actually is called, but something is failing inside of your callback in IE8, specifically. Have you looked at your javascript console? Surely there are errors there. You've only shared a portion of your code here, so I can't say for sure what is happening. Please provide a live example if you'd like me to investigate further.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/710#issuecomment-14348674 .  https://github.com/notifications/beacon/Urcnp-Be1yN_kh-VYieSThaarumrHECffGyodWNPFnqb5WixLyel6UjHv6FdWSbm.gif \n. Hi Ray\nI\u2019ve now tried to create a reproducer and that works! So there\u2019s something strange happening in my real page obviously.\nHere\u2019s my reproducer (my view using ASP.NET MVC):\n@model dynamic\nAttachments\n\n\n    $(document).ready(function() {\n\n        $(\"#fine-uploader\").fineUploader({\n            debug: true,\n            text: {\n                uploadButton: 'Select file'\n            },\n            request: {\n                endpoint: \"/MultiTrack/Issue/UploadFileFine\",\n                params: {\n                    desc: \"Attachment\",\n                    issueId: 31760,\n                    attachmentUploadId: 0\n                }\n            }\n        }).on('complete', function (event, id, name, responseJSON) {\n            console.log(\"Received complete callback from uploader.\");\n            if (responseJSON.success) {\n                console.log(\"Would process the response's attachment object here\");\n//                var attachment = responseJSON.attachment;\n//                vm.OnAttachmentUploadComplete(attachment);\n            } else {\n                alert(\"The attachment upload failed. Please try again.\");\n            }\n        });\n\n       $(\".qq-upload-button\").\n            addClass(\"btn btn-info\").\n            removeClass(\"qq-upload-button\");\n    });\n\nAnd this produces the following output on the javascript console (I turned debug mode on):\nLOG: [FineUploader] Processing 1 files or inputs...\nLOG: [FineUploader] Sending upload request for 0\nLOG: [FineUploader] Received response for 0\nLOG: [FineUploader] iframe loaded\nLOG: [FineUploader] converting iframe's innerHTML to JSON\nLOG: [FineUploader] innerHTML = {\n\"attachment\": {\n```\n\"Id\": 17478,\n\"IssueId\": null,\n\"SysUserId\": 1421,\n\"CreationTime\": \"2013-03-04T07:42:42.293\",\n\"Description\": \"Attachment\",\n\"MimeType\": \"application/octet-stream\",\n\"FileName\": \"log.20120819.log\",\n\"DataLength\": 108611,\n\"AttachmentUploadId\": 9612,\n\"Deleted\": false,\n\"_destroy\": false,\n\"Size\": \"106 KB\",\n\"Type\": \"File\"\n```\n},\n\"success\": true\n}\nLOG: Received complete callback from uploader.\nLOG: Would process the response's attachment object here\nWhen the real page executes the upload, I just get this output on the console:\nLOG: [FineUploader] Processing 1 files or inputs...\nLOG: [FineUploader] Sending upload request for 0\nLOG: [FineUploader] Received response for 0\nLOG: [FineUploader] iframe loaded\nLOG: [FineUploader] converting iframe's innerHTML to JSON\nLOG: [FineUploader] innerHTML = {\n\"attachment\": {\n```\n\"Id\": 17479,\n\"IssueId\": null,\n\"SysUserId\": 1421,\n\"CreationTime\": \"2013-03-04T07:46:49.503\",\n\"Description\": \"test\",\n\"MimeType\": \"application/octet-stream\",\n\"FileName\": \"log.20120320.log\",\n\"DataLength\": 150409,\n\"AttachmentUploadId\": 9613,\n\"Deleted\": false,\n\"_destroy\": false,\n```\n\"Size\": \"146 KB\",\n\"Type\": \"File\"\n},\n\"success\": true\n}\nAny clues on how I can figure out why my callback isn\u2019t being called?\nThanks,\nCraig\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Monday, 4 March 2013 6:25 a.m.\nTo: valums/file-uploader\nCc: cds\nSubject: Re: [file-uploader] jquery plug in doesn't call my complete event in IE8, works fine in IE9 and other browsers (#710)\nSounds good. I've tested this callback on the demo page w/ IE8, and all looks well to me. Perhaps you could try this as well. Go to the display image thumbnails http://fineuploader.com/fine-uploader-with-jquery-wrapper-demo.html  demo (near the middle of the page). Select a file that meets the listed requirements. If you see the stock image appear below the file listing (the child with a green and white shirt), then this signals that the \"complete\" callback handler has been invoked. This is using Fine Uploader 3.3, which, presumably, you are also using (since you haven't said otherwise). \n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/710#issuecomment-14350573 .  https://github.com/notifications/beacon/Urcnp-Be1yN_kh-VYieSThaarumrHECffGyodWNPFnqb5WixLyel6UjHv6FdWSbm.gif \n. Hi Ray\nSorry \u2013 by reproducer I simply mean and example that reproduces the bug J\nI\u2019ll see what I can do about getting a live example you can have a look at though I will probably persevere a bit here first as that would involve deploying the application I\u2019m building somewhere public.\nCheers\u2026\nCraig\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Monday, 4 March 2013 7:55 a.m.\nTo: valums/file-uploader\nCc: cds\nSubject: Re: [file-uploader] jquery plug in doesn't call my complete event in IE8, works fine in IE9 and other browsers (#710)\nHi Craig. Im not familiar with this term \"reproducer\". Is this something specific to ASP? Anyway, If you could provide a link to a running example with this problem, I can take a peek. \n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/710#issuecomment-14352340 .  https://github.com/notifications/beacon/Urcnp-Be1yN_kh-VYieSThaarumrHECffGyodWNPFnqb5WixLyel6UjHv6FdWSbm.gif \n. Hi Ray\nI\u2019ve now been able to determine the cause of the problem, though not fully \u201cwhy\u201d. \nI am using knockout.js on my page and the div that the file-uploader element was contained in had a knockout \u201cif\u201d databinding applied to it. This dynamically adds or removes the element from the DOM if the \u201cif\u201d expression evaluates to false. However, in my case, it was never evaluating to false, meaning that the div should always have been present in the DOM. (I changed the knockout databinding to data-bind=\u201dif: true\u201d). But somehow the callback wouldn\u2019t be called.\nI can fix my problem by replacing my knockout \u201cif\u201d databinding with a \u201cvisible\u201d databinding instead \u2013 this means that the div remains in the DOM but is hidden instead of being removed \u2013 this at least fixes my problem for now.\nThanks for your help.\nCraig\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Monday, 4 March 2013 7:55 a.m.\nTo: valums/file-uploader\nCc: cds\nSubject: Re: [file-uploader] jquery plug in doesn't call my complete event in IE8, works fine in IE9 and other browsers (#710)\nHi Craig. Im not familiar with this term \"reproducer\". Is this something specific to ASP? Anyway, If you could provide a link to a running example with this problem, I can take a peek. \n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/710#issuecomment-14352340 .  https://github.com/notifications/beacon/Urcnp-Be1yN_kh-VYieSThaarumrHECffGyodWNPFnqb5WixLyel6UjHv6FdWSbm.gif \n. Thanks Ray \u2013 I think there\u2019s probably still a problem there for you to look at, but I have a workaround which is the main priority for me.\nCheers\u2026\nCraig\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Monday, 4 March 2013 12:30 p.m.\nTo: valums/file-uploader\nCc: cds\nSubject: Re: [file-uploader] jquery plug in doesn't call my complete event in IE8, works fine in IE9 and other browsers (#710)\nStrange that this only caused a problem in IE8. Knockout was on my short list of javascript libraries to play with, but I have been wrapped up in AngularJs lately, and am loving it. \nI'll close this. If you would like to keep it open for some reason, let me know.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/710#issuecomment-14358169 .  https://github.com/notifications/beacon/Urcnp-Be1yN_kh-VYieSThaarumrHECffGyodWNPFnqb5WixLyel6UjHv6FdWSbm.gif \n. Hi Ray\nI\u2019ve had a good go at reproducing this stand-alone and also in jsfiddle \u2013 though I can\u2019t successfully run jsfiddle on IE8! Attached is a ZIP file containing my effort.\nHowever, I\u2019ve not been successful in reproducing this outside of my asp.net MVC solution \u2013 there must be something that\u2019s in addition to what I previously described. I\u2019m also using twitter bootstrap, and haven\u2019t put that into this test, but I don\u2019t think it would affect things.\nAnyway, probably best to close this now \u2013 it\u2019s obviously something very specific to me, and I have a workaround.\nThanks for your interest.\nCheers\u2026\nCraig\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Monday, 4 March 2013 12:55 p.m.\nTo: valums/file-uploader\nCc: cds\nSubject: Re: [file-uploader] jquery plug in doesn't call my complete event in IE8, works fine in IE9 and other browsers (#710)\nI would be interested in looking at this, but perhaps it would be easiest if you pasted any existing code required to reproduce this into something like jsfiddle and provide a link in this case. This way, I can look into this and potentially come up with a better solution without spending time attempting to reproduce this myself, since you have already successfully reproduced this issue. I'll re-open this case, pending a working example that I can spend some time examining. \n\u2014\nReply to this email directly or view it on GitHub https://github.com/valums/file-uploader/issues/710#issuecomment-14358648 .  https://github.com/notifications/beacon/Urcnp-Be1yN_kh-VYieSThaarumrHECffGyodWNPFnqb5WixLyel6UjHv6FdWSbm.gif \n. ",
    "swiharta": "I understand what you're saying, I agree that, ideally, it would be better to have a per-license fee. \n. ",
    "tvb": "Ray,\nI know, but I dont really understand the documentation at this point. I am sorry :( Yes, I know there is an API call for it and I understand I need to match the id with the uuid somehow but I am unable to figure out how to connect it all together..\n. Ok for the JS part:\n```\n$(document).ready(function () {\nCreateDropZone();\nCreateUploader();\n\n});\nfunction CreateDropZone()\n{\n    // CREATE THE DROPZONE AND STYLE IT WHEN ON HOVER OR DRAGOVER.\n    $(document).bind('dragover', function (e) {\n            \n    });\n// PREVENT DEFAULT BROWSER BEHAVIOUR FOR DROP AND DRAGOVER.\n$(document).bind('drop dragover', function (e) {\n    e.preventDefault();\n});\n\n// ADD DROPPED FILES INSIDE UPLOADER DIV TO THE FINEUPLOADER FUNCTION.\n$('#uploader').bind('drop', function (e) {\n    $('#uploader').fineUploader('addFiles', e.originalEvent.dataTransfer.files);\n});\n\n}\nfunction CreateUploader()\n{\n// VAR FOR THE UPLOAD STATUS MESSAGES.\n    $messages = $('#messages'); \n// UPLOAD FUNCTION\n    $('#uploader').fineUploader({\n      // DEBUG\n      debug: true,\n      uploaderType: 'basic',\n      button: $('.mybutton')[0],\n      request: {\n        endpoint: \"/endpointURL\"\n      },\n      validation: {\n        allowedExtensions: ['jpeg'],\n      },\n      deleteFile: {\n        enabled: true,\n        forceConfirm: true\n      }\n      }).on('submit', function(event, id, name) {\n          \n      }).on('upload', function(event, id, name) {\n          \n      }).on('progress', function(event, id, name, loaded, total){\n         \n      }).on('complete', function(event, id, name, responseJSON) {\n          \n            $('#file-' + id).html('Successfully saved ' + '\"' + name + '\" ()');\n\n      }).on('error', function(event, id, name, reason) {\n        \n      });\n};\nfunction deleteAttachement (id) {\n        var uuid = $('#uploader').fineUploader(\"deleteFile\", id);\n        //$.ajax({type: \"post\", url: \"delete.php\", data: { qquuid: uuid}}); \n}\n```\nI guess the deleteAttachement function need to match the id to the UUID of the uploaded file and then what?\n. @rnicholus Because I build my own drag and drop zone with CSS. The default DnD and upload button did not suit my needs.\nthe deleteAttachement function was my try to get one step in the right direction on deleting files after upload :)\n. Alright, so $('#uploader').fineUploader(\"deleteFile\", id); would work if I send the correct UUID with it? And I guess I have to set the endpoint: \"/endpointURL\" for it as well?\n. aha, that I do understand but can you show me on how the url for the delete link will look like? As apparently href=\"javascript:deleteAttachement(' + id + ');\" is not the correct way to do it.\n. Can I retrieve the UUID from the responseJSON?\n. Maybe I misunderstood your last reply then. I though the URL for the delete link should contain the endpointURL/UUID. I am building the delete link with my JS at the 'complete' part so getting the UUID from the responseJSON would simplify things.. but i guess I am thinking wrong here?\n. Ok, then this is the part I don't understand. How do I get a functional delete link after an successful upload which Fine Uploader recognises and when clicked triggers Fine Upload to delete the file?\n. Ok so in my case:\nHTML:\nhref=\"javascript:CreateUploader(' + id + ')\"\n```\nand the JS:\nfunction CreateUploader(id)\n....\n      deleteFile: {\n        enabled: true,\n        setEndpoint: \"delete.php\",\n        setParams: {params: id}\n      }\n....\n```\nright?\n. Well, could you please provide me the code base on how to call the API function separately. I am lost here :(\n. I see, makes sense. And I guess the delete callback codebase is not included in the example.php/ php.php / qqFileUploader.php as I could not find it so I have to write it my own?\n. ",
    "rlvandaveer": "Sorry for the duplication. I searched but didn't find the earlier request. I agree that browser support is an issue, but it's a diminishing issue. Thank you for considering it at any rate.\n. ",
    "radek": "+1 for supporting PUT\n. @rnicholus I think most of developers are aware of this limitation. I use fine-uploader in application that does not need to support IE, also as pointed before, it's a diminishing issue. \nI create photo with POST however photo's renditions are overwritable only with PUT and that's where fine-uploader has to be put aside at the moment.\n. ",
    "ayelkawar2": "+1 for PUT\n. I have single page AngularJS application where I want to be able to choose the between traditional or S3 uploader instance before creating it. The type of uploader is chosen based on the response of a GET request I send just before creating the uploader.\nHow do I download a custom build of fine-uploader containing both s3 and traditional uploaders? This was supported before but has been removed recently. \n. Thanks for the link. I can use the all.fineuploader.js until 5.3.0 version is released.\n. A possible alternative to changing the header would be to change the signature endpoint with each signature call. In this case, I will be able to send the bearer token in URL as a parameter.\n. Would you be able to give me a timeline for adding either of the features? If not, can you point me in the right direction on creating a workaround until the official release? \n. I thought about using cookies but the signature service does not use cookies to get the token as of now since we are trying to move away from using cookies. Is there any way to intercept the AJAX call being done by fineuploader and add the header to it?\n. I am now using a function for customHeader parameter and it seems to be working fine. \nsignature: {\n                    endpoint: signatureEndpoint,\n                    customHeaders: function (param) {\n                        return { headerName: Math.random() };\n                    }\n                }\nIt seems to be updating the header value if I change the value with each call. Do you see any issue with this approach?\n. I need to upload a 2 scaled images but not the original image. One would be max size of 1200 and other would be a thumbnail with max size of 350. I only want to show one image to the user since user doesnt need to know that 2 images are being uploaded for each image. Until now I was uploading the original image and a thumbnail image, so I could use the hideScaled option. Now I am not going to upload the original image at all. \nI honestly can't think of a reason for why I would want to show all the scaled images on the list. Showing multiple images would make the users think that they uploaded the same images twice by mistake.\n. Thanks Ray.\n. ",
    "LanceHaysom": "I don't doubt it.. Struggling to come up with anything though.. \nIf of interest, also behaves the same in FF18/19.\nI'll get you a live link tonight, have a show and tell soon.\nMy code to create at least is:\n``` javascript\n$(\".file-upload\").each(function()\n        {\n        jQuery(this).fineUploader(\n        {\n            //uploaderType: 'basic',\n            debug: true,\n            multiple: false,\n            mode: 'custom',\n            deleteFile : false,\n            display: {\n                fileSizeOnSubmit: false\n            },\n            request: {\n                endpoint: jqx.config.basePath + 'photo/upload'\n            },\n            failedUploadTextDisplay : {\n                mode : 'none'\n            },\n            retry : {\n                showAutoRetryNote : false\n            },\n            text : {\n                dropProcessing : '',\n                retry : '',\n                failUpload : ''\n\n            }\n        }).\n        on(\"submit\", function(event, id, filename) {\n            $(this).fineUploader('setParams', {\"user_id\": \"10\", 'photo_type' : $(this).attr('data-type')}, id);\n        })\n        .on('complete', function(id, fileName, responseJSON){\n            console.log(\"COMPLETE: id: \" + id + \", fileName: \" + fileName + \", responseJSON: \" + responseJSON);\n        });\n    });\n\n```\nAs an aside, is there a way to not display the name etc on successful upload?\n. Oh my.. Working fine. That make's me quite chuffed and miserable all at the same time. Thanks so much for spotting that, swear words go here. Oh yup it's also quite clear in the docs too.\nThe each() is a remnant I'd not yet removed from the last two versions of trying to get this mother sucker to work, not yours, uploadify and jQuery fileupload.\nHopefully equally as easy.. would you mind mentioning how I can remove all the output from a successful upload? I'm seeing: 4.png16.3kBRetryDelete next to the 'Upload a file' when really I need nothing there. I need to open a cropper thing in a modal, can't miss it.\n. Yes, correct.\n. Perfect thanks a lot. Got it to work with:\njavascript\n$($(this).fineUploader('getItemByFileId', id)).hide();\nYour plugin's easily the best out there man, great work.\n. ",
    "dipthegeezer": "Cool, thank you! They met and it was love at first sight :D\n. ",
    "Siyfion": "Oh sorry I hadn't seen that issue; but in effect, a properly supported directive would be the ideal solution. Angular's main concepts are that all DOM manipulation should be in a directive; the controller should have no knowledge of the DOM / view.\nThis could lead to the directive being quite a decent sized piece of code, if it were able to support all of the features that you provide.\n. I'm not sure that a new library would need to be created at all, simply a directive that wraps the library.\n. ",
    "sebastienros": "Adding some feedback. I think the code example for the ASP.NET MVC is actually misleading. It is not obvious that extra parameters are taken from the request.params option of the FineUploader object.\nTo solve this you should add some comment in the MVC controller explaining that extra parameters can be passed using request.params. And also remove the default extraParam1 and extraParam2 from the action method so that the default example work out of the box.\nMaking the second parameter nullable fixes the issue but even with that I would not have guessed what those parameters actually are.\n. Not at all, they are two different issues. #741 is that the default sample doesn't work out of the box, and is misleading. This one is specifically about using the Pasted blob feature (from the clipboard) in ASP.NET MVC. \n. Looks good to me as long as it is tested on different browsers and it works ;) Don't really know how you are handling your unit tests right now ...\n. ",
    "Maigre": "Ok thanks,\ni will dig it on my side and send you my ideas if i find interesting things.\nBest Regards,\n. ",
    "alexfrancavilla": "Well everything is working fine and as expected, calls are also correct but the plugin just don't execute the DELETE-Request so I think this is the plugins' issue.\n. \"click event does fire\" => It does work!!!\nJust the Request is missing.\n. The Javascript console does not show any messages when executing deleteFile, no debug messages from FineUploader and no errors. I've also double-checked all my parameters and variables, they're all correct.\n. Since I can't send you private messages through GitHub, would you kindly give me an e-mail adress where I can send login credentials and link of my application ? (It's private)\nThanks, odissea\n. I've sent you an email. Thanks for your help!\n. Non-minifed version is now active. Sorry for that!\n. Hi, thanks for your investigation.\nDo you think you could make the DELETE request configurable so one could use GET/POST requests instead?\nIt would be a problem else since our Software has to run on any kind of webserver and not depending on availabilty of DELETE requests. Again thanks for your quick help, much appreciated!\n. Okay I'll then have to Build my own workaround to use POST requests instead.\nIt's simply not possible to enable DELETE requests on all Servers.\nThanks for your help\n. @rnicholus You can use the same application and credentials from my last issue!\nKind regards,\nodissea\n. It's been a while - are there any results yet in fixing this problem?\n. Thanks @tellibus, I used the style on the anchor and it works for now.\n. ",
    "uriahcarpenter": "Downloadable ZIP releases are currently a per-version purchase -- see https://github.com/valums/file-uploader/wiki/Releases\n. @laeubi Thanks for the report. As Firefox 3.5.16 was released over 2 years ago on December 9th, 2010 it is not a browser that is normally tested when releasing new versions of Fineuploader. Typically, on the current release and LTS versions of Firefox are tested. However, as a regression, it's likely that this problem will be investigated further and, if possible, corrected in a future release of Fineuploader.\nIf you can provide any additional debugging information (console errors, etc.) it would be appreciated.\n. @laeubi Thanks for the additional information!\n. @laeubi Thanks for the suggestion. It's likely we will investigate this method for future improvement.\n. @laeubi Thanks for the report. Which version of Fineuploader did you encounter this issue with?\nI'll put this issue on the list for @rnicholus to review when he returns from holiday March 25.\n. The addFiles function expects a FileList or a File or an array of Files if the FileAPI is supported. You can get a FileList from an input element via the files property on the associated host object if the browser supports the FileAPI.\nIn the future we may improve the addFiles api function to allow an input element to be passed in any browser.\n. @ashkmehr Folder drop-and-drag is only supported when using the latest version of Google Chrome. I don't believe the folder name is pre-pended to the filename during upload.\nThe primary developer @rnicholus is currently on holiday -- but when he returns after March 25 he should be able provide you a definitive answer on how folder names are handled.\n. @ticketsource Turns out this is a limitation of IE 9. This issue, and others, are listed on the IE limitations documentation. https://github.com/valums/file-uploader/blob/master/docs/limitations-ie.md\nSorry I don't have a better answer then you need to check the size on the server-side.\n. @kleesman Thanks for the report!\nI was unable to reproduce your described behavior using Chrome Mac 26.0.1410.33 beta. Could you please re-test with Chrome 26 beta to see if this issue has already been resolved by the Chrome team?\n. You can create a free trial account at https://my.smartimage.com/\nSorry, at the moment we don't have a simpler test setup.\n. @odissea Thanks for the report!\n. @dtucke Thanks for the report. The primary developer is out on Holiday...\nAre you receiving a Javascript error before the file is sent or is the server is unable to parse IE upload submissions? For the later, IE needs some special handling -- take a look at the ASP examples in the server directory https://github.com/valums/file-uploader/tree/master/server\n. @sebastienros Thanks for the report!\n. @sebastienros Thanks for the report!\n. @ricick Thanks for the report. I'll put this issue on the list for the primary developer to investigate when he returns from holiday in a few days.\n. Looks like when has a few more async goodies -- including a defer. Could we namespace and include in a separate library?\n. Some of the risks and mitigations are described in a recent AWS blog post at http://aws.typepad.com/aws/2013/10/developer-preview-aws-sdk-for-javascript.html\nFor \"complete\" client-side workflow a developer would need to use WIF http://docs.aws.amazon.com/STS/latest/UsingSTS/CreatingWIF.html\nBut I also see a use case where a server app could provision the TSC and include them directly in the client-side configuration.\n. Link to native JSON docs\n. @ericmackrodt Ray is on vacation until January 20.\n. I may be able to provide some delegated S3 buckets from our corporate account to keep smoke tests viable. PM me if interested.. ",
    "andrejordao": "We had problems with cross-domain requests but with this new version it's fixed. Thanks!\n. ",
    "steve228uk": "The files API isn't supported by IE so this isn't going to work\u2026 Anyone have a work around?\n. ",
    "cvpsmith": "I am interested in using Fine Uploader and I'm curious about this as well.  I'd like to rephrase the question as such:  If using the latest version of Chrome, is it possible to use Fine Uploader to upload a directory recursively to a website, in such a way that the directory structure remains intact (sub-folders, etc.)?  The only place I've seen this actually work properly is with Google Drive and Chrome...  TIA...\n. Thanks for the info Ray!  I do think that this would be useful and important for many users.  In fact, from what I've seen from the bit of research I've done over the past few days, there are lots of web file upload scripts available out there, but NONE of them fully support directory uploads.  This would be a KEY standout feature...\nPS.  Hope you had a good holiday!\n. ",
    "kbubb": "Okay, thanks for the heads-up, Ray.  Definitely keep us posted if anything\nchanges.\n. ",
    "anishgarg": "Yes, this feature at least for drag and drop will be phenomenal.\n. Yup, I understand that it is relative to the top level folder, which is actually exactly what I need. I am working on a Django based web server as place holder for test results/reports. A user after he is satisfied with a test run, can directly upload all the files together in the directory structure they were created to the server. I want to avoid distributing a script to the vast user base which would act as inter-mediator with my server to upload reports one by one.\nSo, I was researching online for a probable solution but haven't found anything useful till now.\n. Thanks for you quick replies :).\nYes, what you have mentioned is exactly what I need.\nI know its soon. However, did you guys finalize about your plans when you are going to release with this enhancement? \n. ",
    "jdq22": "I'm not sure if this is the best place to ask, but is there any intention to add the qqPath property directly to the objects within the array returned by getUploads()? I'm using the setParams method, but I want to access a file's qqPath in other places besides the endpoint (like within the UI, for example, or a secondary endpoint).\n. Thanks. We've had several customers request it, but our use case is usually one user doing 100GB up a day.\n. ",
    "danielHalan": "Is there any option to enable, that the filepath is included in the filename when sent to the server \"upload\"-request-endpoint? in case a user would upload files with same name but in different sub-folders.. ",
    "FrankFan": "I faced with the same problem, validateion did not work in IE 9.\n. ",
    "yoks": "Sounds good, this will be most suitable soltution.\n. ",
    "disfated": "So, I would like to have \"old plain html form\" but 1) with file-inputs behaving in fineUploader manner, but only visually, i.e. not submitting anything to the server by their own 2) with sumbittion via an multipart ajax request (just don't redraw my page).\nFrom the server side request must look like it was sent by a \"script-less\" form submittion, except only for X-Requested-With header.\nIs it clear?\n. I'm ok with that. I've read the docs. The problem is when I have 2 or more file-inputs in a form - there's no way (as i can see) to \"combine\" multiple file-inputs in one request.\nSo here's what i actually want\nForm:\nhtml\n<input name=\"name\">\n... other inputs ...\n<div id=\"fineuploader1\" data-name=\"images\"/>\n<div id=\"fineuploader2\" data-name=\"docs\"/>\nJS:\njs\n$('#myForm').on('submit', function(e) {\n  e.preventDefault();\n  new qq.FormSubmittion({ // dreaming :)\n    elements: $(this).find(':input,#fineuploader1,#fineuploader2').toArray()\n  }).submit(function(err, data) { // submit just sends an old plain form (containing given elements) but via ajax\n    if (err) bla();\n    if (data.bla) bla();\n    //...any logic;\n  });\n})\nThe result is if we'd send this form\nhtml\n<input name=\"name\">\n... other inputs ...\n<input name=\"images\" type=\"file\" multiple/>\n<input name=\"docs\" type=\"file\" multiple/>\nin an ordinary way, but it is sent via ajax.\non the server (using node.js, express):\njs\napp.post('form/submit', function(req, res, next) {\n  // multipart data is parsed to `req.body`\n  req.body.name -> name input\n  // files parsed to `req.body.files`\n  req.body.files.images // -> array of uploaded images #fineuploader1\n  req.body.files.docs // -> array of uploaded docs #fineuploader2\n  // ...processing\n  res.json({ /* any data that will be recieved by my imaginary FormSubmittion.submit callback parameter */ })\n});\nMy problem is that i don't want to actually store files, just recieve them and send where I have to.\n. More correctly, multiple form-fields each one being able to have multiple files as a value\n. Oh I see the problem now. I thought that uploadStoredFiles() sends them in one request. Now it is clear that files are never sent together to be crossbrowser...\nThe good news is that I tested FU in IE8 - and it works perfectly. It's kinda miracle.\nSorry for bother. Thanks for detailed answer. I would advise you to mention this somehow in the docs for such devs that are not so aware of browser restrictions, as me.\n. ",
    "jnoer": "I was able to reproduce with 6,000 files.\n. ",
    "SStyler": "This would be a nice addition.\n. Sweet! Thanks. :-D\n. Thanks, I almost always use FireFox so this goes appreciated.\n. ",
    "samatcd": "I'd like to see paste support in Safari, Firefox & optionally IE, but most importantly Safari for us.\n. The main use case for us is to be able to paste screenshots which are saved directly into the clipboard on Mac.\nThis is typically how our testers send us bug reports. If they have to save the screenshot to their desktop it gets far too cluttered far too quickly.\nMac OS has a keyboard shortcut which allows saving a screenshot to the clipboard.\nSent from my iPhone\n\nOn 31/10/2013, at 3:20 am, Ray Nicholus notifications@github.com wrote:\nKeep in mind that this will require server-side cooperation from integrators like yourself who want this feature outside of Chrome. In short, you'd have to proxy pasted images from your own server if the image is from a different domain in many cases.\n\u2014\nReply to this email directly or view it on GitHub.\n. We can definitely do that in the interim, although it would be simplest for them if they didn't need to worry what browser they were reporting from\u2014the plan is to build a tool we can drop into our websites which logs bugs & screenshots to our system, without needing to have the system itself open.\n\nThis would also ideally be opened up to end users should they encounter an issue with the system.\n. Great, thanks for that, thats fantastic news.\n. Thanks for looking into this\u2014a shame that the browser vendors haven't fully implemented support yet, but I guess that's the way of things. \nIt looks like it would be best to shelve this for now.\n. Here's the current support as per caniuse:\nhttp://caniuse.com/#search=clipboard\n. ",
    "dfoor": "It looks like several browser support this now. Has it been addressed?\n. I see--thanks for looking into this; I got excited when I saw it on caniuse and just wanted to check.\nWould it be possible to convert the target on a browser case basis, and then use something like this to do the conversion? \n. ",
    "sergionegri": "Hello, any news on the subject? 2 years passed and was wondering if browser now fully support it. I have no experience of other browsers, but services like Slack or Trello do provide it regardless of the browser, or not?\nI've tried this example http://jsfiddle.net/FhUwn/392/ and it works in IE 11 as well. > Good question. Further investigation with backing evidence is the next step before going forward.\nI don't have enough knowledge to understand if Trello's or Slack's or the example I posted on JSFiddle solve the problem in the same way or not. By looking the code in JSFiddle are you able to determine if the solution put in practice will work because indeed the browsers are now fully supporting the feature, or if a workaround is put in place?. I checked caniuse and the situation seems to not have changed in regards to the need of having a content editable div. And that jsfiddle uses that. The question is: how on hell Trello/Slack/Jira and the myriads of other services do?. ",
    "Allandy": "My mistake html code on my part.\n. ",
    "worldspawn": "Your understanding is correct. I only want to leverage the fineuploader component for its nice UI. I would like to present the user with nothing more than a button to 'add a file' and just have the component keep appending file inputs to a container. \nI get that 95% of the functionality would not be used, however fine uploader does do a great job of providing a consistently styled cross browser compatible button to open the file selection dialog - just that part alone is quite a hard-to-do. (and yeh i need IE<10 support)\n. Sure. So I am building a form to create an entity. One required feature is for a user to be able to attach zero or more files to this new entity. Ideally there would be no file inputs unless the user indicated they wanted one. Now as this is part of a create operation I don't really want to upload the files as part of a separate request as there is nothing to associate it with in my relational database - i want to do it all in a single atomic operation. \nWhat works best (IMHO) in this situation is to just use a simple multipart/form-data post submit. I'll handle all the particulars on my own on the server side (incidently it's asp.net mvc).\nNow I could:\na) use an input type=file with multiple on it (perfectly fine for my up to date users)\nb) write out a number of input type=file (say 3) and call it \"good enough\"\nc) provide users with an 'add file' link that appends a file input to a container for my < IE10 users. I've written functionality like this before and it's not hard to implement but I was hoping for a good looking component that got the job done quickly (i'm on a depressingly tight budget, we can afford a license though ;) ).\n. The ability to submit multiple files on the same request would be useful, I found the separate requests blocked me from moving further with a scripted solution. \nI am surprised others haven't needed this. Most forms I create with files also have other fields on the form and it would be in most cases prudent to have all that information submitted at once as part of an atomic operation. Submitting files via ajax/fileapi is cool but it's not always needed. The component seems tailored towards scenarios where the user would want to upload files in isolation of other form data (yes setparams mitigates this but not completely).\nHave a good night.\n. Ok it seems this solution focus is on making it easier for the uploader to work an existing form with other values the developer would like to submit, also addressing the single/multiple post issue.\nHowever I am more interested in a solution that has the uploader manage creating of the html input elements and nothing else. I get that a bug chunk of this component is fancy submission of files but whether you realise it or not you've actually done a lot of top notch work just around managing file dialogs in a cross browser fashion. That work in and of itself has lots of value (to me at least) even in the absence of anything that manages the submission of the files.\nI understand where you coming from. what you have described above may technically achieve what I wanted to do but it's a lot heavier a solution that what I would prefer - namely i don't want to submit data using javascript (as anything that did that would need to play well with other form manipulating scripts) - also it's just more, it doesn't do anything that a vanilla form submission could also achieve.\n. Alright no worries.\n. ",
    "paolobroccardo": "I would like to second  worldspawn's request. \nTake a real world example: \nA user completes a form to create a photo gallery. That contains a gallery name, description and then some photos, which we'd like them to select using fine uploader. At this point, the gallery record has not been created in the database, so having fineuploader send the files to the server before the primary gallery record has been  created is useless. Rather, we would like to have FineUploader create form inputs for each of the selected photos / files and then submit it all together when the user clicks the \"Create Gallery\" button. That way, on the server side, we can create the gallery record, get the id of the new gallery, then add the files thereafter. \nI can't understand how this hasn't been raised more? It's a typical business process / use case. \n. Thanks,. Yes, I am aware of the features that will be lost when just using it as a UI tool. I see it is quite possible to accomplish what both myself and worldspawn want by using the html5 multiple attribute, including previews of the files (see: http://stackoverflow.com/questions/14069421/in-html5-how-to-show-preview-of-image-before-upload and http://robertnyman.com/2010/12/16/utilizing-the-html5-file-api-to-choose-upload-preview-and-see-progress-for-multiple-files/) however, your backward compatibility for browsers that don't support html5 is what makes yours so appealing still. \n. ",
    "zhandosso": "Hi, @rnicholus\nI am having trouble with form support feature:\nI want to validate firstly other form fields, like text inputs, drop-down lists and only if all of them validated, call uploadStoredFiles(). But fine-uploader intercepts submit and tries to uploadStoredFiles(). \nMy questions is: how can I cancel intercepting the submit. I have used option interceptSubmit: false, but it doesnt work. I have always \"true\" for interceptSubmit on creating form-support module:\n      _ qq.FormSupport = function(options, startUpload, log) {\n               \"use strict\";\n            var self  = this,\n            _interceptSubmit = options.interceptSubmit,\n            formEl = options.element,\n            autoUpload = options.autoUpload;\nissue #2:\nI want fine-uploader allow sending form data without file attachements. How could I disconnect(cancel) from fine-uploader once it is instantiated? \n. I am sorry, interceptSubmit = false solved. I realised that it must be passed as property of form:\nform: {\n    interceptSubmit = false\n}\n. hi, @rnicholus. i see you closed this issue here, but i do also require such feature. May be, you had done something until now?\n. For now, I want to send text inputs among with multiple files. These inputs of type text are not part of files, they are as independent information. For example: email, contact phone of sender and some screenshots.\nCan I realise it with FineUploader? if yes, could you pls provide some direction how to achieve this?\n. Thank u for quick reply, today i have read \"form support feature\", so i came to decision: send all files(seperately as your library offers) and in onAllComplete handler send other form data (non file). Cons of this approach: i have to store each uploaded file in server temporarily until onAllComplete sends other data (my server will not store data, it just sends to another service). What can u say about my understanding?\nAs you have experince already, could u please provide me to some important issues with cross-browser suport, if i will realise my own upload. For now, I know only that IE 9 does not support ajax upload(our requirement IE 9+). But that could be solved with  as far as i know. So, are there other risks that could I meet during development. Sorry, if i ask simple questions..\n. ",
    "curt2008": "Thanks for such a quick response, the following code i am attempting to use is as followed : http://pastebin.com/hqFtp6Cd\n. I have emailed the provided email, thanks for such welcoming support !\n. ",
    "number0": "No but I have the same problem\n. ",
    "hilobok": "I also need function to populate list of already uploaded files. Let say I have a document with attached images or archives (uploaded with fine-uploader). Would be nice to have ability to rename or delete, or view thumbnails of those attachments some time later.\nNow I can get list of already uploaded files with getUploads() function and store it in document entity in json format for later use. Something like setUploads() are missed.\n. When button.reset() called.\n. I'm seeing this when upload first file(s) (button.reset() called from _onInputChange() event handler) or when I call reset() api function directly on uploader instance.\n. ",
    "ironyee": "I agree handling previously uploaded files escapes the role of Fine Uploader.\nNevertheless, I think Fine uploader should provide a minimum way at least because It is an essential function to build some services.\nI succeeded in populate list of already uploaded files by support with server side and listElements option.\nNotwithstanding this efforts, Fine uploader couldn't notice a change of element-count, uuid etc.\nI'd just like to set status by using something like setUploads() or setUuid().\nI'm being actively considering using an alternative solution because of this issue.\n. I'm sorry for my parsimonious explanation.\nEnvironment:\n- Fine uploader, Python-django, S3 directly\nIf some users click edit button to edit their post, they are supposed to see Fine uploader again.(previous session)\nIn this case, they must enable to see previously uploaded files and also delete that files.\nBecause Fine uploader do not support this function, I try to set a status of Fine uploader by information from server-side on initialization.\n1. As above, I succeeded in populate list of already uploaded files.\n2. With the form restored with a previous session, I tried to upload new file.\n3. Fine uploader couldn't realize the form was restored on initialization.\n4. Fine uploader let file uploaded with duplicated index.\n5. An existing class \"qq-file-id-0\" replaced a new class because of duplicated index.\n6. Even upload over itemLimit was allowed.\nI'd like to see the right way to address these issues.\n. Let me say a common button to edit already uploaded image.\nIsn't it yet a full explanation ?\n\n. I just understand your question.\nI'm sorry for my poor understanding again.\nTo render previous uploaded files, FIne uploader should receive assistance from server-side.\nIn my humble opinion, there is a way to put endpoint for previous status on fineUploader constructor like S3 request.\nlike this.\nvar uploader = $( '#fineuploader-s3' ).fineUploaderS3( {\n...\n\u3000\u3000session: {\n\u3000\u3000\u3000\u3000endpoint: '/posts/1/images/'\n\u3000\u3000},\n...\n} );\nWhen Fine uploader is created, A request for session is sent to server asynchronously.\nand then '/posts/1/images/' returns previous uploaded files in json format.\n{\n\u3000\u3000{\n\u3000\u3000\u3000\u3000id: 0,\n\u3000\u3000\u3000\u3000key: \"6061ffa9-3c36-467b-ac2e-84cf1b3ba712.png\",\n\u3000\u3000\u3000\u3000uuid: \"6061ffa9-3c36-467b-ac2e-84cf1b3ba712\",\n\u3000\u3000},\n\u3000\u3000{\n\u3000\u3000\u3000\u3000id: 1,\n\u3000\u3000\u3000\u3000key: \"88529535-3684-4f12-8ab8-a4b8c6e4c599.png,\n\u3000\u3000\u3000\u3000uuid: \"88529535-3684-4f12-8ab8-a4b8c6e4c599\",\n\u3000\u3000},\n}\nReceiving information for previous uploaded files, Fine uploader act as upload is completed without actual upload.\nFinally, Fine uploader can be constructed with previous uploaded files.\nI hope you can understand I can't fill out a refined method.\nFine uploader isn't assembled on server-side and need to call constructor whenever a page is loaded like client-side template.\nBut I don't know exactly how to operate fineuploader constructor internally.\nBesides, I think Fine uploader is very dependent to client-side. So, I guess It is difficult for Fine uploader to integrate with server-side well.\n. ",
    "nick4fake": "Is there any progress? I switched from fineuploader as this is killer-feature for some workflows.\n. Sorry, any news on this?\n. ",
    "alphestdev": "Can the files be added without an ajax request? I need a simple way to add already uploaded file records for a common scenario:\n1. Files are selected and uploaded using Fine-Uploader\n2. The form is POSTed manually using submit button, but did not pass server side validation.\n3. Server returns the form still in edit mode, for the user to correct his errors. (Fine Uploader list is empty here.)\n?. An AJAX request for initial file list cannot be populated server-side because $_POST is already cleared in step 3\nIs there something like addFileRecord(files_array)?\nThis should be really simple, because this functionality is already written and works when AJAX request is processed.\nI tried \nvar id = uploader._addCannedFile({\n        uuid: 'some-test-uuid',\n        name: 'TEST FILE NAME.file',\n        size: 1000,\n        thumbnailUrl: iconPath +'Attachment_File_32.png'\n      });\n      uploader._addToList(id, uploader.getName(id));\nThe file record is added, but not fully functional. All the buttons like retry and cancel are visible and no events are attached. For example when I press delete, nothing happens. Can you explain how this can be done?\n. How can duplicate prevention be activated in 5.5.x?\n. @rnicholus I'll gladly implement and verify this as soon as it's released.\n. Hi Ray. The method you provided in v5.6.0.1 works well, but does not meet my needs because it doesn't return the id's of added files, which we use to maintain our list of added files to prevent duplicates (like you suggested somewhere on stackoverflow) and other needs.\nTake for example our current implementation:\nvar addedFiles = []; // Keep track of all added files\nvar uploader = ...;\n$$('.js-file-upload-initial-file[data-inputname=\"'+ inputName +'\"]').each(function(hiddenField){\n  var id = uploader._addCannedFile({\n    uuid: hiddenField.get('data-uuid'),\n    name: hiddenField.get('data-filename'),\n    size: hiddenField.get('data-size'),\n    thumbnailUrl: hiddenField.get('data-thumbnail-url')\n  });\n  addedFiles[id] = [hiddenField.get('data-filename'), hiddenField.get('data-size'), hiddenField];\n});\nuploader._templating.addCacheToDom();\nThis cannot be programmed using only addInitialFiles(files), because this function does not return id's even if the canned files are added one by one.\n. Using getUploads method I get the added file records with id's correctly. It's not performance friendly because now I have to use 2 loops instead of one, but it works.\n. \"forceConfirm\" can be interpreted in both ways: \n- force the confirmation dialog to appear\n- force the confirmation to Yes/Confirm, skipping the dialog\nJust saying.\n. @deviprsd21 I did the same thing using onStatusChange to remove attribute as early as possible but still appeared for a short time and could be visible when hovered. I ended up removing the line from the fine-uploader source as I don't use tooltip text on a button that already has text.\n. Tested 5.6.0-2. It works when explicitly defined as empty string. If the option is not set, it still appears as \"file input\".\n. I think this one cannot be overridden also:\n\"XHR returned response code \" + xhr.status\nfine-uploader.js line 2814\nand error messages inside drawThumbnail() function probably too.\n. I haven't investigated it further, but I doubt that the requests are being \"intercepted\". It would not make sense for KIS to let some through and block others from the same upload. The fact that it still happens when KIS is turned off, means that the requests are not being blocked on purpose. I think it's a bug in Chrome while handling parallel requests. \nI can contact Kaspersky or Google, but I don't think they will move a finger for that. Their products are working fine.\n. Very disturbing for all Firefox users. Still occurs in FF 56, FineUploader 5.15.0.\nRemoving 3 lines as suggested by SpassMarticus works for full js. It's more complicated removing this safely from a minified version.\nPlease fix.. @rnicholus \"... but if someone contributes a PR that fixes the issue ...\"? \nHow long are you going to wait? It's a major issue that blocks FF users from using Drag&Drop completely. \nMultiple people are reporting this and I've just tested from a fresh VM Windows7x64 with Firefox Nightly v58. The whole drop area flickers in a loop even without mouse movement and it does nothing on drop.. ",
    "ludofleury": "@alphestdev Ran to the same issue today, here the not so nice hack for fine uploader UI:\nvar uploader = ....\nvar id = uploader._addCannedFile({\n                uuid: 'an-uuid',\n                name: 'test.ext',\n                size: 1000\n            })\n            uploader._templating.addCacheToDom();\nbeware it call internal API and should not be trusted when you update the lib etc...\nI hope it could be implemented in the next version.\n. My bad, typo. @rbliss I confirm that with your informations, the upload is going smoothly through Cloudfront to S3. Thank you very much.\n. I have (for the first time) to handle massive upload through HTTP, found your lib and this crazy thread. I just wanted to say that your work is quite impressive and rest assured that if your product fit my needs, we will invest in license asap\n. :clap: :clap: \n. Basically, this totally override CloudFront PUT... except if you upload > 350TB per month. \npricing for PUT accelerate is like $0.04/Gb.\n. I was using the latest version of FineUploader.\nAbout #1016, I really think that this AWS accelerate feature remove the needs to do fancy thing with CloudFront \"PUT\". (On a side note, #1016 is actually working when configured without OAI).\nBut really, except if you upload more than 350 TB per month, I don't see a reason to not use accelerate instead of CloudFront.\n. Yes, I totally agree on this, #1016 becomes obsolete (as the feature implemented).\nI will try soon the accelerate feature with signed request (we have this requirement) and if I have any issue, I will get back there. \n. ",
    "arm1n": "yes as far as i could test it making a deep copy resolves the problem, thanks for fixing this!\n. ",
    "tejinderss": "I fixed this error by doing this:\nelem = document.getElementById('id_image').files[0];\nI am using Chrome Version 26.0.1410.65 on OS X with fineUploader 3.4.1.\nAlso Can you please tell me if it is possible to distinguish the file names at the server end? All the files are named qqfile for all the files passed to addFiles. How do i know which file belongs to while Input?\n. I fixed this error by doing this:\nelem = document.getElementById('id_image').files[0];\nI am using Chrome Version 26.0.1410.65 on OS X with fineUploader 3.4.1.\nAlso Can you please tell me if it is possible to distinguish the file names at the server end? All the files are named qqfile for all the files passed to addFiles. How do i know which file belongs to while Input?\n. setParams would set it for all subsequent calls. Suppose I set the input name of file using setParams and it sets too foo, now if the post request is the chunk of file bar, that would be wrongly interpreted as foo file. All i want is if I add additional files using addFiles, I must know what kind of files these are.\n. Yes I think it will solve my issue.\n. ",
    "raulferras": "How's the state of this?\nI'm trying to use fineuploader in a CommonJS environment and qq object evaluates to MegaPixImage.\n. I'll try to prepare a jsfiddle showing the issue\n. Ok, I think I've found the problem. I'll write it here just in case.\nI managed to reproduce it here: http://jsfiddle.net/c4tvZ/ (Please, I'm aware of the Access-Control-Allow-Origin issue). \nThe first file you select is properly detected and the upload tries to take place. After that, following selected files are completely ignored and the change event is never triggered.\nI think there's some king of incompatibility with Twitter's bootstrap button plugin. If the lines using it ($btn.button('loading') and $btn.button('reset')) are removed, everything works again.\n. Ok, exactly as I though.\nThank you very much.\n. I'm having this same problem when using fineuploader together with twitter bootstrap and the .btn-large style (a big button). Because bootstrap is setting input file to 30px heigth the file selector is only triggered if user clicks on upper part of the button.\nI had to add the following properties to the style of the input:\ncss\ndisplay : block;\nbottom : 0;\nheight  : auto;\nI'm not aware if this is compatible with older browsers though...\n. May be then this can be planned for a major version bump?. I respect your decision, but then, how will you name a new possible template? fine-uploader-new-2.css?\nEasy of usage is an important topic and good naming goes with it.\nJust my opinion.. ",
    "Ixonal": "Sorry to resurrect an old issue, but I think this needs to be looked at again. Fine Uploader is currently impossible to import if using Type Script, since there are no exports, and the compiler eliminates any import statements for which exported items aren't used. So, even if I require the file, that require statement is removed from the generated code.\nIt's the same sorta problem as this:\nhttp://stackoverflow.com/questions/16455211/typescript-import-module-with-only-statements\nI'm not sure about Babel or Traceur, they may or may not have this behavior when transpiling.\n. Sorry to resurrect an old issue, but I think this needs to be looked at again. Fine Uploader is currently impossible to import if using Type Script, since there are no exports, and the compiler eliminates any import statements for which exported items aren't used. So, even if I require the file, that require statement is removed from the generated code.\nIt's the same sorta problem as this:\nhttp://stackoverflow.com/questions/16455211/typescript-import-module-with-only-statements\nI'm not sure about Babel or Traceur, they may or may not have this behavior when transpiling.\n. All that should be required is some form of export, be it amd, umd, commonjs, or ecma 6 module syntax. Use feature detection to determine which module system is being used, and you should be able to just export the qq object. For example, if the \"System\" object exists in the global namespace, and \"System.import\" is a function, then you can assume ecma 6. If \"require\" exists in the global namespace, and \"require.amd\" is an object, then you can use amd. Etc...\nI can't imagine it'd take too horribly long to implement.\n. simplest solution would probably be to just wrap them all in a parent object and export that.\n. Sounds about right. Knockout has a pretty good example of doing that, if you want to take a look at it.\n. I can try it out and see, yeah. It shouldn't be much effort to set up some tests for this. At least, so far as browser-based loaders. CommonJs would require a node instance.\n. ",
    "powerbuoy": "This is something we would very much like to see too :) FYI.\n$ npm install fine-uploader --save-dev and var qq = require('fine-uploader') would be so nice to be able to do.\n. I've deleted the one on SO. Do you think it's safe to make the changes I suggested? Thanks\n. That sounds perfect. Any ETA on the fix? Or should I give it a go myself? Thanks for the extremely quick reply!\n. I will, yes. Thanks a lot\n. I'm sorry if I sound like a complete noob, but I couldn't find where to download the complete fine-uploader.js (minified or otherwise), perhaps I need to run grunt on the project myself?\nAnyway, I saw the change you made (unless I missed something) and applied it myself in 5.4.0 (changed document.createElement(\"span\") to document.createDocumentFragment() in two places (https://github.com/FineUploader/fine-uploader/commit/a0461a8d858f3c0f0ff186af79158cc988104d87)) and it completely fixes the problem I had.\nI can't say for sure whether it introduces some new problem, but with the testing I've done I haven't noticed anything out of the ordinary at least.\nBtw, you deserve some kind of medal for the speed at which you reply to (and FIX!) issues. Kudos!\n. Awesome work. Thanks!\n. ",
    "ozkarservices": "But it's never getting to the Function, I added a BreakPoint and it never hits the breakpoint.\n. Could it be related to this error message. This happen when I run my application\nSCRIPT5007: Unable to get property 'innerHTML' of undefined or null reference \niframe.xss.response-3.4.1.js, line 4 character 5\n. The page  is called Test.aspx and the function is called Upload\nI'm using ASP.NET\n. Thanks!! I'm sorry I've been busy..\n. Great!!  Do you guys have an estimate time when 3.5 will be release?\n. Ray,\nWhere can I make suggestions?\n. for future features?\n. Fine Uploader should give me a option to show the Delete icon. By default you guys will provide an image along with some CSS to make it look nice. If the user click on the Delete icon and it will need an endpoint where will handle the Delete method via code. Does this help?\n. Hi Ray,\nOn the DeleteFile method how can I get the UUID on my handler using .NET HttpContext.Current.Request? I spend hours searching but I can\u2019t seem to get to work.\n. For anyone who may need to this, below is the code I used to get the UUID using ASP.NET. The only reason why I passed a parameter was because .NET needs an extension to delete the file. \nOn the Client side I passed a Parameter as follow\ndeleteFile: {\n                        enabled: true,\n                        endpoint:  '/Upload.aspx?Extension=.pdf'\n                    }\nOn the Server side handler I used the below code to get the UUID and Extension\n'Create an Array to get the UUID from the URL\nDim URLArray()\nURLArray = request.QueryString(\"Extension\").ToString.Split(\"/\")\nDim FileName = URLArray (1) + URLArray (0)\nDim FileExists As Boolean\n        FileExists = File.Exists(\"C:\\Temp\\\" + FileName )\nIf FileExists = True Then\n        File.Delete(\"C:\\Temp\\\" + FileName )\n    End If\nNote: Once you are done doing the Delete you will need to pass the a JSon Result with \"success: true or success:false\"\nExample\n            Response.ClearHeaders()\n            Response.Clear()\n            Response.Write(\"{\"\"success\"\": true }\")\nThe array results are attached to this in case you need to see  the Output.\n\nCheers!!\n. Hi Ray,\nIts make sense what you suggested. I just wasn't sure on how to use it and retrieve the values on the Server side. So I decided to implement what you suggested and put sample code so other could use it .\nOn the Client side I used the following code. The only new code is the Params on the Request and DeleteFile action. I also deleted the parameters that I was passing through the QueryString since I'm going to pass it a different way.\n```\n               $('#FineUploader').fineUploader({\n                request: {\n                    endpoint: 'Upload.aspx',\n                    params: {\n                        type: 'Product',\n                        extension:'.pdf'\n                    }\n                },\n            multiple: false,\n            validation: {\n                sizeLimit: 5242880, // 50 kB = 50 * 1024 bytes\n                allowedExtensions: ['pdf'],\n                minSizeLimit: 1,\n                stopOnFirstInvalidFile: true\n            },\n            deleteFile: {\n                enabled: true,\n                endpoint: 'Upload.aspx',\n                params: {\n                    type: 'Product',\n                    extension: '.pdf'\n                }\n            },\n            showMessage: function (message) {\n                $('#FineUploader').append('<div id=\"dfpError\" class=\"alert alert-error\" style=\"max-         width:300px;\">' + message + '</div>');\n            }\n\n        }).on('error', function (event, id, name, responseJSON) {\n            $(\"#dfpError\").remove();\n        });\n\n```\nThe page  I created (\"Upload.aspx\")  will be handling many different request so I needed to keep track where the request was coming from and where to store the image that's why I'm passing the Type and Extension. As far as naming the file I used UUID to keep it simple.\nOn the server side I use the following code to retrieve the Params when uploading a file.\nDim Type as string = HttpContext.Current.Request.Params(\"type\")\nDim Extension as string = HttpContext.Current.Request.Params(\"extension\")\nTo retrieve the UUID when deleting a file I use the following code.\n'Create an Array to get the UUID from the URL\n Dim URLArray()\n URLArray = request.QueryString(0).ToString.Split(\"/\")\nThe results will look as follow\n\nLet me know what you think.\n. ",
    "EddGarciaG88": "No, I just I am exploring every options, I agree, that's a more simple way, but I like to view another options like  enabled/disabled, so, is this imposible?...I was reviewing the code, I've done changes for do this but I've not had succesfully....\n. Ok, gather it!..Thanks a lot...\n. By the way, the option \"button\" in FineUploadBasic, its default value is null, could you give me an example about the use of this option?..Thank you...\n. ",
    "tsvetelin-pavlov": "We have a dialog, where user had to make two choices and upload a file.\nThe file must not be uploaded without those options chosen.\nSince it is an Upload dialog, we want the uploader to be visible in order to visually hint, that the user is on the correct screen. So we need the enable/disable option.\nI've tried setting it with jQuery, the uploader renders as disabled, but even then I can upload files. How can I  disable uploading?. ",
    "cina2012": "thanx for your answer.\nwindows 8, 64bit\nIE 10.0.9200.16384\nalso:\nif i define fine uploader setup in jquery document ready, ie 8, 9, 10 do not call server function, but other in browser worked fine (setup like this http://fineuploader.com/#jquery-wrapper-demo).\nand\nif i define fine uploader setup in java script, only ie 10 do not call server function (setup like this http: http://fineuploader.com/#bootstrap-demo).\nthanx.\n. ",
    "martinmose": "I should found out that it hit the on('validate', function (file GetBlobData) twice where the second time the size is valid!\n. Okay thanks for your fast reply! Okay, but what i ment with 'vaild' was the size is not undefined the second time it hits the validate. Actually that was my problem because it messed up my validation. Sorry for confusing you.\n. The filesize was 20. I know it is, it's because I had to do a lot of workarounds because of \"autoUpload: false\". So I could use the fineUploader manually with: scope.manualImageUploader.fineUploader('uploadStoredFiles');. But maybe it's because I try to bind it with angular (scope) etc. It's hard to tell. And I have only showed you a part of the code. But anyway it's working now, so thanks :+1: \n. No :). Okay I see. Thanks.\n. ",
    "antixrist": "Oh, sorry. It's really my fail..\nThen ask one more thing, if you will - do you have any examples of handling a DELETE request on the php? :-)\nIn this repo no examples of this.\n. ",
    "antongorodezkiy": "I know that this is the old thread. But I have the issue with Cache-Control header when trying upload directly to Vimeo:\nHere is the error from Chrome console:\nXMLHttpRequest cannot load http://1511655198.cloud.vimeo.com/upload?ticket_id=69d.......ae231c. Request header field Cache-Control is not allowed by Access-Control-Allow-Headers.\nIf I comment the line with Cache-Control header the uploader works fine.\n. ",
    "ajschmaltz": "@andrew-kzoo how did you end up implementing this?  I'm something akin to:\nform = $(this).serializeArray()\nform.push({name: 'files', value: JSON.stringify(uploader.getUploads()) })\n. I just noticed something similar had been suggested:\nhttps://github.com/FineUploader/fine-uploader/pull/858\nI'm going to implement the code from that issue, but my use case is that I have an image placeholder that acts as an upload button.  When the limit is reached, I don't want the placeholder to keep appearing.  Anyway, I figure you won't be implementing this, but I'm going to leave it open and let you decide since it suggests a slightly different approach.\n. The most trouble I'm having personally is implementing the nodejs server s3 example.  It requires express which seems to be incompatible with Meteor.\n. ",
    "beldur": "Please review, if my change is a correct and appropiate solution. \n. ",
    "sergiodlopes": "Indeed, more information is needed to debug.\nMaybe header's Content-type with value \"application/json\" is missing from server-side response?\n. Maybe adding a \"disabled\" class (with respective styling) and while that class it's present in the element, FineUploader would ignore click event.\n. Maybe adding a \"disabled\" class (with respective styling) and while that class it's present in the element, FineUploader would ignore click event.\n. ",
    "BeyondME": "Ok, excuse me.\nim using fineuploader 3.5 , with the php server script from https://github.com/Widen/fine-uploader-server . Tried in firefox 20 and chrome under Windows 7.\nConsole debug: \nUncaught ReferenceError: createUploader is not defined /gestor/misarchivos.php:53\n[FineUploader] Error when attempting to parse xhr response text (SyntaxError: Unexpected token D) jquery.fineuploader-3.5.0.js:155\n[FineUploader] 'error' is not a valid property on the server response. \n. Uncaught ReferenceError: createUploader is not defined misarchivos.php:53\n[FineUploader] Processing 1 files or inputs... jquery.fineuploader-3.5.0.js:150\n[FineUploader] Sending upload request for 0 jquery.fineuploader-3.5.0.js:150\n[FineUploader] xhr - server response received for 0 jquery.fineuploader-3.5.0.js:150\n[FineUploader] responseText = \nDeprecated: Function split() is deprecated in /var/www/vhosts/docs.beyondweb.es/httpdocs/gestor/subidaajax.php on line 29\n{\"success\":true} jquery.fineuploader-3.5.0.js:150\n[FineUploader] Error when attempting to parse xhr response text (SyntaxError: Unexpected token D) jquery.fineuploader-3.5.0.js:155\n[FineUploader] 'error' is not a valid property on the server response. \n. ok, excuse me !!! split() deprecated function xD i was using it to extract alloweb extensions from a string... now using explode and is working perfect\n. ",
    "cotoadvance": "I have a form that allows me to upload multiples files at once, as well as filling up some other fields. After said form is submitted, I need to \"reset\" it so another registry can be submitted, and so on. I thought the reset() function could allow me to change the uploader back to its initial state, while I take care of the other fields\n. ",
    "Vanav": "Non-multipart upload and paramsInBody=false are required if backend doesn't support multipart uploads. Example of such backend is Nginx with \"client_body_in_file_only on\" and without 3rd-party Lua scripts.\n. ",
    "idjhuang": "I am using fine-uploader 3.3.\nFollowing is a fully functional test program:\n```\n\n\nTest multiple fine-uploader instances\n\n\n\n\nTest multiple fine-uploader instances\n\n\n\n\n\n\n    var uploaderList = [];\n    var uploading = false;\n    function setupFineUploader() {\n        $('#uploadFileList').append('<div class=\"fineUploader\"></div>');\n        var manualuploader = new qq.FineUploader({\n            element: $('.fineUploader')[$('.fineUploader').length - 1],\n            autoUpload: false,\n            disableCancelForFormUploads: false,\n            request: {\n                endpoint: '/api/UploadTest',\n                forceMultipart: false\n            },\n            deleteFile: {\n                enabled: false\n            },\n            text: {\n                uploadButton: 'Upload Button',\n                dragZone: 'Drop file at here',\n                cancelButton: 'Cancel',\n                retry: 'Retry',\n                failUpload: 'Upload failure',\n                waitingForResponse: 'Uploading...',\n                deleteButton: ''\n            },\n            failedUploadTextDisplay: {\n                mode: 'custom',\n                maxChars: 250,\n                responseProperty: 'error',\n                enableTooltip: true\n            },\n            retry: {\n                enableAuto: true,\n                maxAutoAttempts: 5\n            },\n            callbacks: {\n                onSubmit: function (id, filename) {\n                    this.fileList.push(filename);\n                    this.result.push(0);\n                },\n                onCancel: function (id, filename) {\n                    var index = $.inArray(filename, this.fileList);\n                    if (!uploading) this.fileList[index] = '';\n                    this.result[index] = -2;\n                    this.errorMesage[index] = 'Canceled';\n                },\n                onComplete: function (id, filename, response) {\n                    var index = $.inArray(filename, this.fileList);\n                    if (response.success) {\n                        this.result[index] = 1;\n                        this.errorMessage[index] = '';\n                    } else {\n                        this.result[index] = -1;\n                        if (response.error !== undefined) {\n                            this.errorMessage[index] = response.error;\n                        } else {\n                            this.errorMessage[index] = '';\n                        }\n                    }\n                    var allDone = true;\n                    for (var i = 0; i &lt; uploaderList.length; i++) {\n                        for (var j = 0; j &lt; uploaderList[i].result.length; j++)\n                            if (uploaderList[i].result[j] == 0) allDone = false;\n                    }\n                    if (allDone) {\n                        uploading = false;\n                        alert('All uploaded! Job done!');\n                    }\n                }\n            }\n        });\n        manualuploader.fileList = [];\n        manualuploader.result = [];\n        manualuploader.errorMessage = [];\n        uploaderList.push(manualuploader);\n    }</p>\n<pre><code>$(document).ready(function () {\n    $('#addBtn').click(function() {\n        setupFineUploader();\n    });\n    $('#sendBtn').click(function() {\n        uploading = true;\n        for (var i = 0; i &lt; uploaderList.length; i++) {\n            uploaderList[i].uploadStoredFiles();\n        }\n    });\n});\n</code></pre>\n<p>\n\n\n``\n. Well, I found the same problem as rnicholus said, and the problem exist on IE9 too.\nIn addition, if I start the next uploader after previous uploader finish uploading file, then all files could be uploaded, but the status of uploaders still be pending except first one. \nOn the other hand, if I start the next uploader before previous uploader finish uploading file, then previous file would be aborted.\n. @rnicholus As you said, I may use one fine-uploader instance to upload all files of all order items with order item information attached with the files. But I would like to use fine-uploader as file selector, for it could support multiple file selection and drag & drop. \nI may pass the files contains in these selectors to the uploader before upload all selected files. But fine-uploader API getFile(id) is not available on browsers not support File API, so I still get stuck on IE. Any suggestion to workaround?\n. Well, it's clear and straight for customer to select files for each order items with correspond file selection button. The placing order web page could contain many order items, so there will be many file selection buttons on the same page, as following page layout: \n![page layout](https://f.cloud.github.com/assets/4410296/496405/b09ae994-bbe1-11e2-9e86-991e402bf75f.jpg)\nI would use fine-uploader as file selection button, as it could support multiple file selection, drag & drop and show list of selected files.\nI was directly upload all files with these fine-uploaders, and got the problem on IE. Now, I may put all selected files from all file selection fine-uploader instances into one fine-uploader with order item info to upload. That's the reason to use getFile and addFiles method.\n. Well, it would be great if theaddFiles` API method could extract files from another fine-uploader instance.\n. It's OK on IE 7/8/9, IE 6 can upload but with style sheet issue. Thank you!\n. ",
    "PabloRosales": "Got it, sorry about that.\n. Got it, sorry about that.\n. ",
    "ollyculverhouse": "Yea, me too, I'm sure it worked before...\n. OK, thanks. Bit of a shame seeing that big block of red on the HTML5 form support table.\nThanks anyway.\n. Hmm, is that just for Android though, shouldn't Chrome for Android be a bit further along than that?\n. Looks like it doesn't. Just found this for Chromium: http://www.chromium.org/developers/web-platform-status/forms#TOC-Input-element\n. Looks like it doesn't. Just found this for Chromium: http://www.chromium.org/developers/web-platform-status/forms#TOC-Input-element\n. ",
    "anbarasuthresnathan": "Anyone found the solution how to select the multiple file in android L\n. ",
    "ruinunes": "Still unable to perform multiple uploads (with Chrome 43 and Android 5.0.2).\n. Seems to be up to the android browser app developers to enable a parameter in the intent call to grab multiple files instead of a single file, from an available OS file picker. AFAIK, this ability is enabled since android 4.4.4 (although we run our android tablet from 5.0.2) but not implemented by the browsers I have tested.\nYep, the web says Chrome 49 solves this, albeit, for Chrome only. I will do an OS and and Chrome update to our samsung tablet update soon.\n. Got multiple files upload this way on Android:\nHit your normal <input type='file' multiple> button. File picker appears: do a long press on a file to select it, then select other files. On the top bar an \"Open\" appears, select it and then multiple files are added to the files collection.\nNote: this may work fine with file pickers integrated with the OS. Those who come from third-party apps (including bundled Samsung apps like Photos/Gallery or Microsoft OneDrive ) which offer custom file picker views may not work, because of their implementation.\n. ",
    "jrsokolow": "http://fineuploader.com also doesn't work\n. ",
    "1c7": "in example.php \ni tryed:\n$result['uploadName'] = iconv('utf-8', 'gb2312', $uploader->getUploadName());\nstill not work\n. @tellibus \ni tryed that.. still not work.\n. ",
    "danielwalls": "+1 for this feature.\nI deleted the SO entry because it didnt suit the SO format - but I've copied it below:\n\nI just updated fine-uploader (http://fineuploader.com/) from v3.1.1 to the latest 3.7. The minified js file went from 37KB to 77KB.\nI appreciate that it's getting a lot more love and features are abounding - but it would be great if there was the option to choose the parts we need rather than the whole kit and caboodle. I'm trying to keep script KB to a minimum.\n\n. Having just implemented Fine-Uploader - I agree. The doco was a bit easy to get lost and sometimes I wasn't sure whether what I was reading applied to the mode I was using.\nAnother thought would be to add some more demos. The one I was looking for was using multiple instances of fine-uploader on the one page.\n. ",
    "jstayton": "Hey Ray,\nThanks for the quick response!\nMaybe a screen shot will help:\n\nThe text input field is populated with the file name (minus extension) if available. The user can also edit the name if they want. This is the name that's checked for uniqueness. If it's not unique \u2014 as the first file in the screen shot depicts \u2014 then the user is given the option to overwrite the existing file, or change the name to something unique. Until that happens, I'd like to prevent that file from being uploaded when the \"Upload Now\" trigger is clicked.\n\nCan you describe your app in some more detail?\n\nIt's a CMS with media file management.\n\nWhy do you want to keep the file around if you don't want to upload it?\n\nSo the user is given the option to overwrite the existing file, or change the name to something unique. I'd prefer to do this on the client-side, rather than having to upload the file and do the check on the server-side.\n\nAlso, what sort of specific user action coincides with the keyup event you are handling?\n\nI'm firing off an XHR request to check if the inputted name already exists or not.\n\nAlso, since you are using the file name to detect duplicate files, I assume you are not supporting any iOS6 devices at all, is this true?\n\nGood question. If the file name isn't available, I'd like to force the user to input a name for the file manually. Until they do, the file shouldn't be uploaded.\n. Hey Ray,\nThanks again for the quick response. You've saved me a lot of time where I'd otherwise be spinning my wheels.\n\nI take it your are using FineUploaderBasic mode and sending the file name as a custom parameter along with each file, correct?\n\nCorrect.\n\nI'm still a little fuzzy on this keyup event. What key is the user pressing here?\n\nAny key. Just like JS form validators that re-validate fields on keyup, I'm re-validating that the name is unique.\n\nIf autoUpload is set to \"false\", we could simply throw the file back into the internal array of \"stored\" (not yet in-progress) queue. A call to uploadStoredFiles would make another attempt at such files.\n\nAs I'm setting autoUpload to false, this is almost exactly how I pictured it working. Each time uploadStoredFiles is called, it would try to process all queued files. A callback would then be fired for each file to determine whether to upload the file or keep it in the queue.\n\nIf autoUpload is set to \"true\" however, it's not clear how another attempt can be made at uploading these files.\n\nYeah, this is less clear. From a UX perspective, I like the idea of the files showing up in the list, because then the developer can show a message explaining why the file can't be uploaded, or give a way for the user to resolve the conflict (as in my use case). This is more helpful than not adding/listing the files at all, because the developer then has to build in an alternate display/UI to accomplish the same.\n\nMaking such an enhancement to the library general-purpose enough to cover a number of workflows.\n\nAbsolutely. As my use case may even change slightly in the future, I'd like more general callback hooks that I can build my specific flow into.\n\nRepresenting a file that has been prevented from uploading in both the UI and internally.\n\nYeah. I don't feel knowledgeable enough on the codebase to give an opinion on whether the files should be considered \"failed\" or some new \"waiting\" or \"invalid\" state.\n. Sounds good. Thanks, Ray!\n. ",
    "jetheredge": "I did exactly what you suggested, blocking the click event with preventDefault, but that seemed to also break the uploader (in all browsers).\nMy issue is that it only does this in Firefox, so it feels like a bug.\n. Basically, the link is used as a checkin button for the document. So when the user clicks on the button it is simply asking them to select the file, then uploads it. I'm confused when you say I am using the anchor as the \"container\" and \"button\". I am simply declaring a qq.FineUploaderBasic and setting the button as the anchor. I didn't realize that the FineUploaderBasic needed a container.\nNow that I know that fine uploader is not handling the click event at all, I'm confused as to why disabling the click event stopped the uploader from working, I didn't stop propagation of the event, just the action itself.\nThe only reason I said it wasn't ideal was just because having an href on an anchor tag and pulling and using that value in an ajax request is pretty standard and we have abstracted it away. So, in this case pulling from the data attribute causes us to have to write a specific override in this one place.\n. Sorry, in my last comment I should have said that I see it is not an issue with FineUploader and instead is something that I need to work around (since you're not handling clicks at all). Thank you for your help!\n. I haven't tried it yet, I'll let you know.\n. Thanks for the quick response! I appreciate it.\n. Here is a link to a recording of it occurring: https://www.dropbox.com/s/rwt7jzi1chdtvve/FineUploaderProgressShowHide.mov\nAnd here is the client side code:\n```\nwindow.fineUploaderDefaults.s3DefaultUploader = function(element, options){\n  var uploader = $(element).fineUploaderS3({\n    request: {\n        endpoint: \"https://\" + options.clientBucket + \".s3.amazonaws.com\",\n        accessKey: options.accessKey\n    },\n    template: options.template || \"fine-uploader-template\",\n    button: options.button || $(\"#upload-files-button\")[0],\n    classes: {\n      buttonFocus: 'upload-button-focus',\n      buttonHover: 'upload-button-hover'\n    },\n    signature: {\n      endpoint: options.signUploadPath,\n      customHeaders: {\n        'X-CSRF-Token': $('meta[name=\"csrf-token\"]').attr('content')\n      }\n    },\n    uploadSuccess: {\n      endpoint: options.uploadSuccessPath,\n      customHeaders: { 'X-CSRF-Token': $('meta[name=\"csrf-token\"]').attr('content') },\n      params: options.uploadSuccessParams || {}\n    },\n    iframeSupport: {\n      localBlankPagePath: options.iframeSupportPage\n    },\n    chunking: {\n      enabled: true\n    },\n    resume: {\n      enabled: true\n    },\n    deleteFile: {\n      enabled: false\n    },\n    retry: {\n      enableAuto: true\n    },\n    autoUpload: options.autoUpload !== false,\n    thumbnails: {\n      placeholders: {\n        notAvailablePath: \"assets/not_available-generic.png\",\n        waitingPath: \"assets/waiting-generic.png\"\n      }\n    }\n  });\nuploader.on('complete', function(event, id, name, response) {\n    if (options.onComplete){\n      options.onComplete(event, id, name, response);\n    }\n  })\n  .on('submitted', function(event){\n    if (options.onUploadsStart){\n      options.onUploadsStart();\n    }\n  })\n  .on('allComplete', function(event, succeeded, failed){\n    if (options.onUploadsDone){\n      options.onUploadsDone();\n    }\n  })\n  .on('statusChange', function(event, id, oldStatus, newStatus){\n    if (options.onFilesQueued){\n      var filesHaveBeenQueued = $(this).fineUploaderS3('getUploads', {\n          status: [ qq.status.SUBMITTING ]\n      }).length > 0;\n  if (filesHaveBeenQueued){\n    options.onFilesQueued();\n  }\n}\n\n});\nreturn uploader;\n}\n```\n. And template:\n```\n  \n\nDrop files here to upload\n\n\nUpload a file\n\n\nProcessing dropped files...\n\n\n<div class=\"qq-total-progress-bar-container-selector qq-total-progress-bar-container\">\n  <h3>Total Progress</h3>\n  <div class=\"progress\">\n    <div class=\"qq-total-progress-bar-selector progress-bar\"></div>\n  </div>\n</div>\n<ul class=\"qq-upload-list-selector qq-upload-list\">\n  <li>\n    <div class=\"qq-progress-bar-container-selector progress\">\n      <div class=\"qq-progress-bar-selector progress-bar\"></div>\n    </div>\n    <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n    <img class=\"qq-thumbnail-selector\" qq-max-size=\"100\" qq-server-scale>\n    <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\"></span>\n    <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n    <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n    <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n    <a class=\"qq-upload-cancel-selector btn-small btn-warning\" href=\"#\">Cancel</a>\n    <a class=\"qq-upload-retry-selector btn-small btn-info\" href=\"#\">Retry</a>\n    <a class=\"qq-upload-delete-selector btn-small btn-warning\" href=\"#\">Delete</a>\n    <a class=\"qq-upload-pause-selector btn-small btn-info\" href=\"#\">Pause</a>\n    <a class=\"qq-upload-continue-selector btn-small btn-info\" href=\"#\">Continue</a>\n    <span class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n    <a class=\"view-btn btn-small btn-info hide\" target=\"_blank\">View</a>\n  </li>\n</ul>\n\n\n```\n. I replaced my total progress bar with the exact html you just gave me, and I'm still seeing this behavior. I'm uploading to S3, so I'm not sure if that makes a difference or not. I'll look to see if there is anything else that could be hiding this, but it is hiding and showing, which is bizarre.\nIf you could point me to the line in the fine uploader script that hides the total progress bar upon completion, I could verify whether or not this is actually getting called multiple times for me.\n. Thanks for the offer, but the app is not yet deployed. I have successfully traced this issue to this line:\nhttps://github.com/Widen/fine-uploader/blob/55166f33438e4915045f17d8c4e1adea008af19b/client/js/templating.js#L629\nBasically, we have an event handler on 'validate' that is attached elsewhere which calls back to the server and checks if a file that is uploading has a matching filename, if there is a matching file name then we prompt the user whether or not they want to keep both files, overwrite, or discard.\nFor small files, this call slows fine uploader down just enough so that the uploader finishes loading the already queued items and so the loaded bytes catches up to the total bytes and it hides the progress bar.\nOnce the call to the server completes, we call success() on the promise we returned form the validate event, and voila, the total progress bar is shown again because there is now a file queued up.\nSo I guess I'm left at the point where I'll just have to show my own total progress meter, and then use  the allComplete event to hide it when the entire batch completes, not just those that are currently uploading. Thoughts?\n. Thanks, I appreciate it. Now that I'm done complaining about my tiny bug, let me say that Fine Uploader is amazing. Thanks for creating such a great product!\n. I'd be happy to test this out, is there an easy way for me to get a build from a future version of fine uploader? Currently I just grab it from http://fineuploader.com/customize.html\n. Yeah, I tried to send you an email, I sent it to the last email address I got on a fine uploader email. I guess it did not make it through. Can you point me to an address to email you at?\n. Yep, that fixed it! Thanks!\n. I would also like to chime in and say that fine uploader cannot be used (in any region) to upload to S3 using keys from KMS until signature V4 is supported.\n. I would also like to chime in and say that fine uploader cannot be used (in any region) to upload to S3 using keys from KMS until signature V4 is supported.\n. Sorry, the Amazon Key Management Service. Basically a cloud hosted Hardware Security Module. Allows customers to do server side encryption with S3 but not have to use a shared key. Excellent for regulatory compliance. http://aws.amazon.com/kms/\n. Sorry, the Amazon Key Management Service. Basically a cloud hosted Hardware Security Module. Allows customers to do server side encryption with S3 but not have to use a shared key. Excellent for regulatory compliance. http://aws.amazon.com/kms/\n. Here are some more details: http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html\nI got as far as adding the correct headers into fine uploader but stopped once I ran up against the v4 authentication headers.\n. Here are some more details: http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html\nI got as far as adding the correct headers into fine uploader but stopped once I ran up against the v4 authentication headers.\n. Great, I saw that above, I just wanted to make you aware that there were other concerns than just usage within certain regions. Thanks!\n. Amazon has a pretty good example here http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-post-example.html The signature is put in and an additional X-Amz-Algorithm parameter with the value 'AWS4-HMAC-SHA256' is added. Does that help?\n. I might be misinterpreting the piece you are working on, but did you see the examples on this page? http://docs.aws.amazon.com/general/latest/gr/signature-v4-examples.html\n```\nfunction getSignatureKey(key, dateStamp, regionName, serviceName) {\nvar kDate= Crypto.HMAC(Crypto.SHA256, dateStamp, \"AWS4\" + key, { asBytes: true})\n   var kRegion= Crypto.HMAC(Crypto.SHA256, regionName, kDate, { asBytes: true });\n   var kService=Crypto.HMAC(Crypto.SHA256, serviceName, kRegion, { asBytes: true });\n   var kSigning= Crypto.HMAC(Crypto.SHA256, \"aws4_request\", kService, { asBytes: true });\nreturn kSigning;\n}\n```\nThey use the crypto.js library as part of the signature creation: https://code.google.com/p/crypto-js/#HMAC\nThe library is BSD licensed, so maybe you can use parts of it?\n. I've been meaning to follow up on this for a few days, but I think you are definitely correct in that at least the first piece of the file upload needs to be hashed, but then subsequent pieces look like they can be hashed using the returned hash from the previously uploaded part by looking at the 'X-Amz-Content-Sha256' header. Here is a link to the line in the v4 signer in the Amazon Javascript SDK which shows where they do this:\nhttps://github.com/aws/aws-sdk-js/blob/master/lib/signers/v4.js#L175\nThe license for this library is Apache, so you should be safe in looking at the implementation.\n. Yeah, I thought sure I saw the behavior documented somewhere, but I am not able to find it now. Anyways, the document you linked to seems very clear that the approach you're taking is correct.\n. Congrats! I know this has been a looooong time coming. Maybe you can send some documentation over to the AWS team? :-)\n. I would test this, but the project we were interested in this feature for has long since moved on and implemented in a different way. Unfortunately right now I don't have an easy way right now to setup and test this.\n. ",
    "mazapagic": "When you manually trigger uploads with uploadStoredFiles() there is no error message if you haven't selected any file. As you can see in first demo here: http://fineuploader.com/fine-uploader-with-jquery-wrapper-demo.html when you click on \"upload now\" before selecting files nothing happens. I think there should be \"noFilesError\" message.\n. ",
    "orloffv": "the issue is that the drop zone remains visible even after dragging the file out of the window, correct yes\n- Is this issue specific to FF 20? I can't reproduce with FF 21 (also on OS X).* I reproduce on 21.0 & two machines with OS X && 20.0\n. @rnicholus tnx\n. ",
    "erlendfh": "Good point! Maybe toggling a css class would be a better approach?\n. I think many of these suggestions grow out of a perspective of trying to modify somebody else's framework as little as possible to get the result one wants. Fixing this through onStatusChange sounds like a reasonable (and much more flexible) solution to the problem. Thanks!\n. ",
    "ianmstew": "Thanks, good call.  That would be nice and inline and do the job with less.\n. Just did. I applied the change you suggested and fine-uploader works perfectly in our application (without the extra jquery code).\n. Perfect, thanks!\n. Both are excellent options, thanks for explaining.  I see your point about multiple concurrent requests.  With that in mind, both of your suggested solutions are more robust than a simple toggle on the API method.  I'll consider both and likely go with one of them.  Thanks!\n. Sounds good to me.\n. Actually no, our javascript app and our upload servlet are operating on the same domain.  Does that make a difference?\n. Interesting.  Cors.expected is false by default and I'm not overriding it.  I'm using the provided Java servlet to receive files, and this configuration to init the client (nothing too tricky).\nwindow.fineUploader = new qq.FineUploader({\n    element: document.getElementById('uploader'),\n    dragAndDrop: {\n        extraDropzones: [ document.getElementById('dropzone') ],\n        hideDropzones: true,\n        disableDefaultDropzone: true\n    },\n    text: {\n        uploadButton: qq.supportedFeatures.fileDrop ? 'Choose files' : 'Choose file'\n    },\n    request: {\n        endpoint: 'upload'\n    },\n    deleteFile: {\n        enabled: true,\n        forceConfirm: true,\n        endpoint: 'upload'\n    },\n    callbacks: {\n        // display custom error message generated by server, which is any error message\n        // stating with \"userMessage:\".  fine-uploader by default does not display exactly\n        // why upload failed when server validation fails.  however, this shouldn't ever\n        // occur because we are now validating both max size and file type on client.\n        onError: function( id, name, errorReason, xhr ) {\n            window.alert( errorReason );\n            var clientMsgKey = \"userMessage:\";\n            if ( errorReason.substring(0,clientMsgKey.length) === clientMsgKey ) {\n                var errMsgEl =\n                    window.fineUploader.getItemByFileId(id)\n                    .getElementsByClassName(\"qq-upload-status-text\")[0];\n                setTimeout( function() {\n                    errMsgEl.innerHTML = errorReason.substring(clientMsgKey.length);\n                }, 0 );\n            }\n        }\n    },\n    validation: {\n        allowedExtensions: _allowedExtensionsCSV.split(\",\"),\n        sizeLimit: _maxSizeBytes\n    }\n});\nHere's what is triggering iFrame mode on the server Java servlet:\nboolean isIframe = req.getHeader(\"X-Requested-With\") == null\n        || !req.getHeader(\"X-Requested-With\").equals(\"XMLHttpRequest\");\nIt seems IE FineUploader is resorting to iframe mode out of the box, without cors mode enabled.\n. My issue is that with default FineUploader settings and the default Widen-provided Java servlet, I encountered a bug that prevented IE uploads from working.\nFor some reason, with default settings, the Widen Java servlet interprets default FineUploader IE uploaders as iframe requests.\nThe servlet interprets iframe requests in this manner:\nboolean isIframe = req.getHeader(\"X-Requested-With\") == null\n        || !req.getHeader(\"X-Requested-With\").equals(\"XMLHttpRequest\");\nAll my FineUploader IE requests, incidentally, do not have X-Requested-With header set, which is triggering the iframe handling on the servlet.\nAs a result, the servlet is responding with \"{\\\"success\\\": true, \\\"uuid\\\": \\\"\"+ requestParser.getUuid()\"\".  The iframe.xss.response.js is triggered a chain of events that results in a json parse error.\nThe client fineuploader code ultimately enters the getIframeContentJson() method, which is failing to extract the embedded json object from the iframe because the proper regex is not applied to the iframe innerHTML.  I fixed this as shown in my initial post above.\nDoes this make sense?  Could it be an anomaly of using the provided Java servlet?\n. Hmm, my html was filtered out.  The servlet is responding with:\n\"{\\\"success\\\": true, \\\"uuid\\\": \\\"\"+ requestParser.getUuid()\"<script src=\\\"fineuploader/iframe.xss.response.js\"\"\\\"></script>\".\n. You are absolutely right, that's what I did.  sheepish grin  In a cross-origin environment, with cors.expected, I'm guessing everything would work perfectly.  I had a non-cors client and a server acting like cors at once.\nI didn't/don't mean to use your issue tracker as a support channel, but I sincerely appreciate the help.  Really, thanks!\nIan\n. Aha, that makes perfect sense now--great explanation.  I believe I'm totally clear on the approach now.  This will be useful to know for a while, since IE8/9 aren't going anywhere fast.\n. ",
    "joero4": "Ok, I added the code above, and now I'm getting...\nError: Passed obj is not a File or BlobData (in qq.UploadHandlerXhr)\nSomething I should add is that the error I originally got was found in the console log  (The error returned was simply \"No files uploaded\").  With the added code above.  I'm not seeing anything in the console log related to FineUploader. , just the returned error above.  \nThanks.\n. The patched file solved my problem.  Thanks.\n. ",
    "tekamolo": "Sorry, I did not see that part.\nThanks\n. ",
    "mrmoriarity": "That sir, was exceptionally fast. Thank you\n. ",
    "a-ivanov81": "Sources from current master\n. Yes, you're right. I want customize UI and I'm  using example from https://github.com/Widen/fine-uploader/blob/master/docs/drag-and-drop.md\nThanks\n. ",
    "rionmonster": "Version 3.6.4\n. After testing with a few colleagues, it appears as though it is only occurring on Windows 8 machines running Chrome (at least so far that is the only environment I have been able to reproduce the issue in).\n. ",
    "pratikshelar87": "Mi,rosoft outlook\nOn Jun 19, 2013 5:49 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nWhich email client?\nOn Wednesday, June 19, 2013, pratikshelar87 wrote:\n\nHi,\nOne of my user tried to drag and drop a attachment directly from a email\nclient directly into the dropbox, expecting the file to be uploaded. But\nthe file did not get uploaded. But when he saved the file from email\nclient\nlocally and then tried to drag and drop it worked. Could you let me know\nthe issue here.\nThanks\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/Widen/fine-uploader/issues/896>\n.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/896#issuecomment-19680040\n.\n. \n",
    "AidasK": "Then user exceeds his space usage, i send preventRetry parameter, although resume cookie is set. For that reason i need preventResume parameter.\nMy response example \njson\n{\"errors\":{\"userId\":[\"Not enough space\"]},\"preventRetry\":true,\"preventResume\":true,\"uuid\":\"6d71b8b2-1039-4d29-9d2d-e0ab0922b1a0\"}\n. Yes, i already have client side validation, but it does not work on all browsers, because IE8 and IE9 does not support getSize method.  Also you can never trust client side validation.\nCurrently the only way to solve this is to pass success parameter and handle errors on \"onComplete\" callback. But i don't this is a proper way and this might cause some confusion.\n. - What does any of this have to do with the resume feature?\n  Actually there is no method or way to prevent file resume. Then you got error from server side, such as {\"error\":\"Space usage exceeded.\"}  , uploader saves cookie for a resume. \n  I think it would be reasonable to disable resume then the server returns  \"preventRetry\": true option.\n- Just reject the files server side, if you don't want to accept them?\n  Rejected uploads also have resume cookie set.\n- Or/and disable the Uploader client side if you don't want to accept any further files from a\n  user.\n  I can't because user can upload a smaller file, which does not exceed his space usage.\n. Then the user visits my page, i check if he has unfinished uploads with getResumableFilesData function. If he has, i prompt him with alert \"Hey, you have some unfinished uploads!\". Prompt also contains list of these uploads. The problem is that this list contains some rejected files (for example files with \"Space usage exceeded.\"). \nIn general: FineUploader should not store all rejected uploads for user to resume , because some of them can not be resumed.\n. Thanks, combination of \"preventRetry\" and  \"reset\" solved my issue.\nBut two more features left to discuss:\n- First of all there is api function of getting resumable uploads, but you can't cancel any of them after page reload because there is no such function. I have wrote \"cancelResumableFile\" function implementation above.\n- Secondly, it would be great to preserve endpoint and request params for resumable files. Currently cookie contains only file size, file name, uuid and part index. \n. What do you think?\n. ",
    "achung-miovision": "Are there any updates to getting this PR merged and released? . My apologies, there's a linked PR https://github.com/FineUploader/fine-uploader/pull/1673 that's been sitting around. . Unit tests have been added. I'm not sure what the CLA is for as I'm split between two github accounts right now and I've signed it on both. If it's a problem I can dig further to see what's happening there. . When files are uploading you see a progress bar, but if there's no bytes to upload then we're technically done, so we need to hide the rest of the icons. Oh I see, I was confused between promise done() and mocha async done for when the test completes.. updated as requested. . ",
    "adrianchung": "@rnicholus I've enhanced the PR and opened up a new PR here: https://github.com/FineUploader/fine-uploader/pull/1710. I decided to leverage the failed callback here to set the result. fine uploader seems to have its own promise implementation, so I can't actually call done(); from without the success/failure callbacks. I flipped the values and verified that the tests pass as expected. . Please ignore this comment. I understand what you mean now that I've looked up your example and your mocha reference properly. ",
    "carlituxman": "I don't try it, I'm looking for a wysiwyg editor to use with node.js backend to upload images.\nIt be interesant try fine uploader to upload and then use for example tinymce, its possible??\n. great! \nthis feature would be fantastic, I haven't found any wysiwyg with node.js support\n. yes, but it would be interesting use tinymce with the uploading images to a node.js (with express) server, and the only one that I've seen support node.js conector is fine-uploader.\nThen if we have the fine-uploader plugin tinymce it be wonderful\n. just now try it with successfully\nat node I configure app.get('/upload/image_list',function....\nthat returns json list of images, is great!\n. something new about this plugin?\n. ",
    "tdesmet": "Any word on creating a tinymce plugin? Before I try to create my own plugin, don't want to reinvent the wheel\n. ",
    "tyteen4a03": "Is this still being worked on?. ",
    "svscorp": "Okay, I expect id - is the actual uuid of the file. Otherwise why am I need this id?\n. Yeah.\nThanks for explanation :)\n. ",
    "hellvinz": "thanks for the answer, that's what I've done, it works :)\n. ",
    "wesleywong": "Hi rnicholus, basically Dropbox chooser API will return a absolute link (jpg, PDF, doc) and I would need a solution to add into existing fineuploader by API to upload. Based on the existing API documentation I still have no idea how's the addfiles and addblob API work, lacking of demo and can't find related article. Hope u can point me to a right direction. Thanks\n. I working on the module which people can upload a photos post (similar like fb) by uploading from (fineuploader) + additional feature to allow them to get their media from their Dropbox account. If I split them into 2 diff methods to upload that might confused. \n. ",
    "harssh": "getting error \n\n[FineUploader] Caught exception in 'onSubmit' callback - Method cancelAll does not exist on jQuery.fineUploader\nhttp://localhost:3000/assets/jquery.fineuploader-3.4.1.js\nLine 156\n\nwhen using \n\n$(this).fineUploader('cancelAll');\n. \n",
    "egucciar": "No these docs seem pretty clear. Finding them is the issue. Perhaps a seperate section on the docs nav bar that says 'developer' on it would be useful. All links to the docs go to the homepage, which has no info on build. It is not obvious one needs to scroll to the bottom of 'overview' to find what they are looking for.\n. Also a link to the developers page right from GitHub might just be the easiest way to fix it. I clicked on various links on the github readme's and they all just brought me to the doc's main page, where its not very easy to find the developers page\n. why was this issue closed without a resolution? Why cant we remove the cache control header from the request using an option? @rnicholus  I dont want to fork your repo just to do that.. Thanks for the quick response. I ended up forking and modifying the distribution and publishing to npm with our prefix to work around this critical issue, because I can't control what the server accepts. But this solution is bad because I modified the dist (I couldn't get the build to work) and now I'm formed from your repo. If I have time this week or next I'll see about making an option in the source, but not totally optimistic because I couldn't even run the build. . ",
    "bhattkrishna19": "I am got why this is not working. Actually I have added this fineuploader in a page where one form is already there. when I am uploading files seem other form getting submitted. can you help me how can I use fineuploader on this situation.\n. ",
    "jchu1": "\nFurther customization of where the user clicks to bring up the file input.  Above is a screenshot of the Google Plus photo upload window as an example.  The user can click (or drag a file) anywhere on the gray area to bring up the file input.\n(Unless of course I've missed something in the docs this enables me to do this.)\n. My bad, you're right.  Thanks\n. Actually, I think I spoke too soon, at least before I ask a few more clarifying questions (and let me know whether I should shift this over to StackOverflow).\nI'm having a bit of trouble with two things when I assign my larger clickable div to the button:\n1) The css style for my larger clickable div gets modified (I particularly need the position attribute to remain as 'absolute').  Is there a way to disable this? \n2) Parts of the div do not register a click.  I'm guessing my div is not covered completely by the file input underneath, so for example, when you click on the bottom 40%, it does not bring up the file selector.  This is not a problem when I make my div a label.\n. ",
    "soulteary": "thank you for your help~ :D\n. ",
    "berlindisplay-max": "ok, obviously it's not a pressing issue at all, since ubuntu users are so few, just thought i'd mention it. Thanks for the quick replies. \n. ",
    "alexmcmillan": "What if the client has a 100mbps upstream pipe, but a loadbalanced server setup is under strain and can only receive 20mbps per server?\n. What if the client has a 100mbps upstream pipe, but a loadbalanced server setup is under strain and can only receive 20mbps per server?\n. ",
    "rodneytamblyn": "We are trying to support users who may want to upload very large files such as mp4 videos or pathology images that could easily range into the hundreds of mb range.  Using chunking and load balancing we can upload files up to 500Mb successfully.  Multi-chunk upload would improve the efficiency of these uploads...\nRodney \nSent from my iPhone\nOn 8/08/2013, at 3:26 PM, Ray Nicholus notifications@github.com wrote:\n\nYes, I will agree that this particular scenario would benefit from sending multiple chunks at once. However, given the specific scenario you have outlined. However, the exact same benefit can be obtained by setting the maxConnections option to 5 and allow up to 5 files to upload simultaneously as well. It seems like a safe bet that most, if not all, web apps can expect to have users that select/drop multiple files at a time or nearly at the same time. In that case, why not just allow 5 files to upload at once? It's already possible with the current version of Fine Uploader (and has been possible for a long time). Is there something specific about your web app that would not make this a simpler and just-as-effective solution?\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi Ray,\n\nThanks for the responses.  A few more comments:\n\nA few things to keep in mind here:\nI'm going under the assumption that your users are going to upload more than one file at a time. Let me know if this is not true, and please provide details about your web app or customer base that would suggest this is the norm among users of your app.\nThey might upload multiple files, or they could be uploading a single, large file.  OB3 is a web application for online academic study.  It provides on-screen documents and users can drag and drop content from their desktop to the document.  So this could be a bunch of separate files (e.g. images, file attachments) or it could be a single large file (e.g. a 500Mb mp4 video)\nWith that in mind, let's go with @alexmcmillan's example again of a 100 Mb pipe with a load balance in front of, say, 5 servers with a maximum throughput of 20 Mbps per server. The load balancer distributes requests appropriately.\nOur backend comprises OB3 web application servers (NodeJS) running on multiple server instances.  Currently (in development mode) we are running 4 OB3 servers on 2 servers (running in Rackspace) behind a load balancer.  Uploaded chunks may be sent (by the LB) to separate instances, so we keep track of the chunks in our database and when all chunks have arrived we reassemble the file and shift it to CloudFiles for distribution.  This is now working and we have successfully tested uploading files up to 500Mb in size.\nLet's say a user submits or drops 5 files. What is the difference between uploading those 5 files simultaneously, but sending the chunks for each individual file consecutively, versus sending 5 chunks of the first file in parallel, then doing the same with the next file once the first file is done, etc? It's not clear to me what the advantage of the latter approach is, especially since the former approach is already supported by Fine Uploader.\n\nIN this specific instance you'd be right.  However they could drag in more than 5 files\u2026 so in this situation we'd be looking at potentially queueing files.  This will be the next evolution for us, implementing some type of upload manager.\nThere are two specific scenarios - the user is uploading several (or lots) of relatively small files, and the scenario where they are uploading one or more large to very large files (typically video).  \nAt the more extreme edge scenario - we've had users needing to upload Gbs of files - e.g. pathology images which can be up to 1Gb for each file...\n\nAlso, keep in mind that all browsers impose a maximum number of requests that can be executing per hostname at once. Chrome and most modern browsers have a limit of 6, I believe.\n\nThanks - and yes we're aware of that.  This can be solved by running separate upload domains.   \n\n\u2014\nReply to this email directly or view it on GitHub.\n. It's an interesting idea, but in the case of large files presumably the data is already highly compressed, so you may not get a lot of benefit in terms of reduced sizes.  Also I wonder what the performance hit of zip.js would be like on browser.\n. Michael, our lead developer, has come back with a couple of reasons why we want multi-chunk simultaneous upload:\n\nMissing the time between chunks and load balancing. We want to support smaller chunks for better resume support so spitting into 10 means a pause 10 times for x seconds... if you've ever watched a download it does not start at the max speed it can handle, it tends to work up to it, eg. it will not hit its peak for 10Mbps straight away, if you split it into 10 then it stops 10 times meaning it can't reach its peak.\nThis also means you cannot provide higher speed uploads by scaling with parallel servers, say you have 10mbps upstream per server but the client has 100mbps, say we have (for point of argument) 20 servers to handle load and no one else happens to be uploading. Even though we have 200mbps capacity the best the client uploading can hope for is 10mbps because that is the max that (single) server could offer it.\n. Ray, we have implemented chunked upload support in OB3 with server-side tracking of chunks - as each chunk can potentially arrive on a different server with load balancing,  using Fineuploader, so we could probably test this for you if it would help. Contact me if this would be useful for you guys.  Great to see this feature being added to the product.\n. :+1: for Rackspace Cloudfiles support\n. I\u2019ve submitted a Rackspace support ticket asking for ETA for resolution of this issue.  Let\u2019s see what the response back is.=\n. Rackspace support responded\n```\nAfter speaking with our operations team this fix has already been implemented.  If you are continuing to experience these issues could you please provide us with the following:\n\ncontainer\nexact object\n-specific request\n\nPlease let us know!\n```\nCan someone provide proof that this has not be resolved (if indeed it hasn't been) and I will followup with RS support.\n~ Rodney\n. Happy to take this further with Rackspace if someone can point me to a functioning use case example that I can use to prove the problem exists to them.\n. ",
    "michaelmitchell": "maxConnections only benefits multiple file uploads it is absolutely fine for that situation, the situation where parallel chunk upload would benefit would be for large file uploads therefore maxConnections does not solve the feature request.\nThe above two situations are the areas that this feature would benefit.\nParallel chunk uploading would allow uploads to reach higher speeds since a 1MB chunk is so quickly uploaded on a high speed connection it never reaches its peak speed.\nIt would also make scaling in large deployments more effective as above, the situation of limited speed per server or a server that is already under heavy load means the user is stuck uploading at whatever that single server can give it, allowing parallel uploads means the user has better luck of attaining greater speeds for a single large file Upload.\nmaxConnections does not solve the problem up uploading a 700Mb video as that file will always be limited to the upstream speed of a single server, maxConnections is only helpful for uploading lots of small files that probably don't require chunking anyway.\nBandwidth is an issue for scaling, this would help solve that problem... it is more cost effective to deploy lots of small servers to increase capacity rather than using larger single servers with massive upstream capacity.\n. No worries, I am aware of the complexities but we wanted to raise this as it is something we would like in the near future so would have to find a solution. 4 chunks in parallel would make a difference so it would be absolutely fine... BUT you can get around the browser limits fairly easily by using multiple domains. eg. upload1.yourdomain.com, upload2.yourdomain.com etc...\n. We use Rackspace CloudFiles.\nWhat are the security implications with uploading directly to a storage service like S3?\nWill it still support resuming? Also I'm not quit sure that feature would solve the small chunks problem as I mentioned above.\nWill you support cloudfiles?\nI will be interested to see what comes of this.\n. ",
    "i0nC4nn0n": "I'm sorry to address an issue that hasn't seen activity in the past 6 months, but this feature would be strongly appreciated. Regarding the point that you \"wouldn't see, how uploading multiple parts simultaneously would decrease the total upload time\" I could post some screenshots to prove the point, but instead might I suggest you to try to upload one single file of say 100Mb to Amazon S3 and than to upload 4 files of 25Mb each simultaneously (with multiple set to true) and you will see the difference in transfer speeds.\nI of course understand that you are busy, that this feature isn't highly requested, and that due to complexity issues it might never be done, but even if you won't implement it, might I ask for for some pointers? (although I'm not a js developer) I might be able to hack it in there somehow, and contribute something else back besides the 80 bucks.\n. ",
    "jasonshah": "We are attempting to use Fine Uploader to replacing our aging web-based uploader, and this is an issue for us. Many of our customers wish to upload multi-GB files. We wish to send those files straight to S3, ideally. However, without parallelized uploads, a single multi-GB file will require hours to upload.\n@rnicholus , I totally understand the complexity required in getting there. I just want to add my vote to seeing this feature.\n. @rnicholus yes, we would be interested in beta testing.\n. @rnicholus, unfortunately we haven't rolled out FineUploader yet, and are\nprobably a few months away from being able to slot this in. I will keep you\nposted.\nOn Tuesday, April 8, 2014, Ray Nicholus\nnotifications@github.com<javascript:_e(%7B%7D,'cvml','notifications@github.com');>\nwrote:\n\n@jasonshah https://github.com/jasonshah I think we're ready for beta\ntesting. All feature work has been merged into the develop branch. I've\nupdated the documentation as well. The concurrent chunking feature pagehttp://docs.fineuploader.com/branch/develop/features/concurrent-chunking.htmlis a good place to start. Also, there are breaking changes here (as this\nwill be a 5.0 release) so you will want to read the upgrading to 5.x noteshttp://docs.fineuploader.com/branch/develop/upgrading-to-5.htmlas well. Let me know when you would like to try this out and provide\nfeedback.\n\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/937#issuecomment-39895112\n.\n\n\nJason Shah\n312-933-1697\n. @rnicholus I was wrong, we are ready to beta test as well! Please send me details as well.\n. So, is it fair to say that simple uploads to Cloudfront are not yet supported? We are evaluating uploaders, and one of our customers wants to upload huge (multi-GB) files. Uploading to S3 with Fine Uploader is proving to be severely limited by their proxy, and I wanted to try uploads straight to Cloudfront.\n. @rnicholus the customer's proxy has some kind of bandwidth throttling in place. In one location, they get 3.5MB/s up (which is very acceptable), whereas in another they get <100K/s up (which isn't). Running some traceroutes and nslookups against the slow computer reveals a proxy server in the way, which is likely limiting bandwidth in some way. We've asked to see if there's a way to get in touch with their network engineers, but it's a huge company and they treat that as a last resort. So one theory is that perhaps uploading to Cloudfront might help speed this up.\n. @rnicholus that last issue seems to be the biggest one. The feature was announced four months ago, however I've yet to find a single example of how this might work from them (though perhaps I haven't looked hard enough).\nThanks for thinking of it. We'll keep looking to see if we can solve this problem another way.\n. @rnicholus Some interesting data, FYI: our customer demonstrated that using the Fine Uploader test to upload from NYC to US East (Virginia), he can achieve ~3-7MB/s. Using another product's uploader, which does a simple PUT to a CDN (EdgeCast in this case), he can achieve 55MB/s. The CDN can provide huge speed increases.\n. @pulkit-clowdy after setting up the OAI, you were able to use FineUploader to upload to S3 via CloudFront?\nIf yes, did you experience any performance improvements?\n. @rnicholus Our engineering team is super backlogged through the end of the year, but I'll try to see if we can squeeze in some tests. We're really excited about it!\n. @rbliss Have you had a chance to measure what kind of performance or stability gains you are seeing with uploads to Cloudfront vs. uploads to S3?\n. ",
    "thisiskell": "Ray, the multipart upload seems to be working great!  Here are my results for a 193MB file:\n10MB chunks, not concurrent:  1:08s\n10MB chunks, concurrent: 0:38s\n10MB chunks, concurrent, 10 maxConnections: 0:24s\nFrom your experience, what seems to be the sweet spot between chunkSize and maxConnections?\nI did run into a javascript error the first time i tried to upload:  \"TypeError: dataTransfer.items is undefined\"\nqq.isFolderDropSupported = function(dataTransfer) {\n    return (dataTransfer.items.length > 0 && dataTransfer.items[0].webkitGetAsEntry);\n};\nI changed the function to just return false, then everything started working fine.  I am testing from pc FF.\n. Hey Ray, everything has been working great, except i discovered an issue in ie8 on upload cleanup:  \"Object doesn't support this property or method\"\ns3.jquery.fineuploader-5.0.0-5.js, line 4276\nFor the time being, i have wrapped that statement with a try catch and it seems to be working.\n. Sure, in upload.cleanup(), there is this block of code which is causing the error:\nif (handler._getFileState(id)) {\n                handler._clearXhrs(id);\n            }\nI am testing using in ie8 VM, which can be downloaded here:\nhttp://www.modern.ie/en-us/virtualization-tools#downloads\n. Great, happy to help!\nI don't have any hard numbers at the moment, but from my tests a couple of weeks ago, the multiple simultaneous chunks seemed to have improved our upload speed anywhere from 50-100% over the standard chunking.  Very happy!\nI have yet to go back and tune my settings to find optimal performance, but am currently configured to have 10 maxConnections with 20MB chunks.\n. Hey Ray, discovered one more issue:  Safari Mac seems to be failing when uploading a file to s3 which is larger than 1 chunk.  It works fine when the file is exactly 1 chunk.\nHere is what amazon is returning after uploading the last chunk:\nxml\n<Error>\n  <Code>EntityTooSmall</Code>\n  <Message>Your proposed upload is smaller than the minimum allowed size</Message>\n  <ETag>12345</ETag>\n  <MinSizeAllowed>5242880</MinSizeAllowed>\n  <ProposedSize>0</ProposedSize>\n  <RequestId>12345</RequestId>\n  <HostId>12345</HostId>\n  <PartNumber>5</PartNumber>\n</Error>\nAnd here is what s3.jquery.fineuploader-5.0.0-5.js is reporting:\n[Error] [Fine Uploader 5.0.0-5] Complete Multipart Upload request for 0 failed with status 400.\n[Error] [Fine Uploader 5.0.0-5] Problem finalizing chunks for file ID 0 - Problem asking Amazon to combine the parts!\n. Strange, my xml error did not render properly in the comment...  I will send it to you separately in an email.\nWe have reproduced now it on 3 machines running Mac Safari Version: 7.0.3, and our fineuploader is currently configured to have 20MB chunks with 10 maxConnections.\nLet me know if you need any more details from me.\n. Alright, for the time being i'll go ahead and disable the multiple simultaneous chunks for Safari, then report back my results.  Thanks!\n. Confirmed, disabling multiple simultaneous chunks for Mac Safari did the trick.\n. ",
    "luissanchez0305": "It's weird because we were using a previous uploader (the one that uses flash, to avoid mention them on this forum) and it uploads the files the same choosen order. I tried the prependFiles display option but since the first batch it's not order then is no use to place the next batch on the top of the previous. I'll keep digging into this. Thanks for the help.\n. I asked because I received a .json file download response after my upload method ran succesfully. Any ideas how to fix this?\n. \nAs I said, It works in your demo... but not in my code and I set multiple to true\n. Oh sorry I didn't mention before. IE10... it should also work on my code right?\n. ",
    "chetanpatel": "There should be only one option for validation where script should check extension as well as respective mime type.\n. ",
    "starcub": "3.8.0 Jquery plug-in.\n. ",
    "firepol": "Hi, I both swapped to non minified and activated debug... hope this helps. Thank you.\n. Thank you, I removed the label with the $(\".qq-upload-button input\").trigger('click'); function associated to it... I'm looking forward for request #819 to be completed, then. Thanks again.\n. I checked your blog article. The attach(\"change\") function seems the one I'm looking for. Can you give me some help to style the \"cameraButton\" element (like in your blog), so that it will look like a text link (like in my customer case, \"choose a file\")? I haven't tested yet but I guess without style it will just look like a standard input file (input + browse button)? Thanks again.\n. Can you be a bit more specific? I'm using fine uploader jquery plugin. My code looks like this:\n$(document).ready(function () {\n        $('#file-upload').fineUploader({\n            template: \"qq-simple-thumbnails-template\",\n            thumbnails: {\n                placeholders: {\n                    waitingPath: \"/scripts/js/fineuploader/placeholders/waiting-generic.png\",\n                    notAvailablePath: \"/scripts/js/fineuploader/placeholders/upload-success.png\"\n                }\n            },\n            request: {\n                endpoint: '/Handlers/FileUpload.ashx'\n            },\n            multiple: false,\n            validation: {\n                allowedExtensions: ['jpg', 'jpeg', 'png']\n            },\n            text: {\n                failUpload: 'Error'\n            }\n        }).on(\"complete\", function (event, id, fileName, response) {\n            drawThumbnail(id, $('#preview'), 400, true);\n        });\n    });\nCaught error in Fine Uploader jQuery event handler: drawThumbnail is not a function.\n(I get the same error also when I call qq.drawThumbnail)\nHow/where exactly should I use the drawThumbnail function?\n. Never mind, got it working (googled fine uploader drawThumbnail and found some stackoverflow questions/answers that helped). This did the job:\n.on('complete', function (event, id, fileName, response) {\n            $(this).fineUploader('drawThumbnail', id, $('#preview'), 400, false);\n        });\nI had to call the function in a different way...\nAlso, the last parameter (fromServer) had to be false. I was wrongly thinking that the thumbnail was coming from the server (as I have a handler) but it's not the case (the handler returns just some json, doh'), it's all done client side, that explains why with some old browsers the preview doesn't work ;)\nCheers\n. ",
    "jmogera": "Looking to upload to S3. However I wanted to POST the file to our server, and then upload it to S3. I want to avoid going directly to S3.\nBased on this:\nhttps://github.com/Widen/fine-uploader-server/tree/master/ASP.NET%20MVC%20C%23\n.  $(element).fineUploader({\n                request: { endpoint: '/api/file', params: valueAccessor() },\n                deleteFile: { enabled: true, endpoint: '/api/file' }\n            });\nCauses the same error.\n. Sorry I was trying to test out all the functions and see if I would get different error. I used fn fineUploader and still get the same error.\n. ",
    "stokedout": "That's completely understandable and I think you should wait and see if this requirement grows in popularity before making any changes. Obviously I and another guy want this but I know it's no justification to make a change just for two people. I guess I'll watch this space ;-)\n. ",
    "Koroba": "Thank you very much for responding.  If you are unwilling to add this as a feature, could you by chance tell me how I can access _storedIds outside of the qq library so upon clicking submit I can check if it has _storedIds and thus accomplish the same task.\n. ",
    "anand4nk": "For having the button image to have Jquery button style, I am using the below styles inside fileuploader.css.\n``` css\n.qq-uploader { position:relative; width: 100%;}\n.qq-upload-button {\n    display: inline-block;\n    width: 24px;\n    height:24px;\n    font-family:Verdana,Arial,sans-serif;\n    font-size: 0.9em;\n    font-weight:normal;\n    border: 1px solid #448dae; background: #0078ae url(../scripts/images/ui-bg_glass_45_0078ae_1x400.png) 50% 50% repeat-x;\n    font-weight: normal;\n    color: #ffffff;\n    -moz-border-radius-topleft: 5px; -webkit-border-top-left-radius: 5px; -khtml-border-top-left-radius: 5px; border-top-left-radius: 5px;\n    -moz-border-radius-topright: 5px; -webkit-border-top-right-radius: 5px; -khtml-border-top-right-radius: 5px; border-top-right-radius: 5px;\n    -moz-border-radius-bottomleft: 5px; -webkit-border-bottom-left-radius: 5px; -khtml-border-bottom-left-radius: 5px; border-bottom-left-radius: 5px;\n    -moz-border-radius-bottomright: 5px; -webkit-border-bottom-right-radius: 5px; -khtml-border-bottom-right-radius: 5px; border-bottom-right-radius: 5px;\n    display: inline-block; position: relative; padding: 0; margin-right: .1em; text-decoration: none !important; text-align: center; zoom: 1; overflow: visible;\n    padding: 5px;\n}\n.qq-upload-button-disabled {\n    display: inline-block;\n    width: 24px;\n    height:24px;\n    font-family:Verdana,Arial,sans-serif;\n    font-size:0.9em;\n    font-weight:normal;\n    border:1px solid #cccccc;\n    background:#0078ae url(../scripts/images/ui-bg_glass_45_0078ae_1x400.png) 50% 50% repeat-x;\n    background-image:none;\n    background-color:#cccccc;\n    font-weight:normal;\n    color:#ffffff;\n    display:inline-block; position:relative; padding:0; margin-right:.1em; text-decoration: none !important; text-align: center; zoom: 1; overflow: inherit;\n    padding:5px;\n}\n.qq-upload-button-hover {border: 1px solid #448dae; background: #79c9ec url(../scripts/images/ui-bg_glass_75_79c9ec_1x400.png) 50% 50% repeat-x; font-weight: normal; color: #026890;}\n.qq-upload-button-focus {outline:1px dotted black;}\n```\nInside my jsp page I have defined  a div as \nI am invoking file uploader as below.\nvar uploader = new qq.FileUploader(qqUploaderOptions);\nInside options, I am passing label as \"Browse\".\n. ",
    "kitsunde": "Ah I see. I didn't know Github picked up the CONTRIBUTING.md file to be displayed like that, neato.\n. ",
    "mstuart": "Hi @rnicholus - did you file it in the developer forums or the bug tracker?  Can you share the link?  Not having the \"multiple\" attribute is a big burden... I'd like to follow the progress on this ticket.  Thanks!\n. ",
    "krankin": "Wanted to let you know we ran into this earlier today on IOS6. Tested with safari and chrome browsers on iOS6 as well as iOS7. In our haste we wrote our own iOS7 check method, and we're a few versions of fine uploader behind so I'm not sure if the iOS6 issue was resolved with another commit. All that to say, the workaround worked for us with Safari, but we are still having this issue with Chrome on both versions of iOS. \niOS-6.1.3\n. ",
    "Annodyne": "Interesting.  Thanks for the info.  We have an iPad 3 here in the office so I will be curious to try that out.\n. Works great.  Thanks again.\n. I do plan on upgrading some time soon, but for now I've just set a static false for the multiple attribute.  I don't want them handling more than one video at a time so it works out.\n. Hah!  Good ol\u2019 Apple.  Thanks for following up!\n. The iPad is version 7.0.2.\nWhen I try the demo under \"Manually Trigger Uploads\", it goes through a completely different process.  Instead of immediately choosing a file from the iPad gallery, it asks if I want to take a picture or video, or choose an existing.  I choose an existing and it does some compressing on the video and then shows me the modified filename.  When I hit Upload Now, the file box simply turns green.\nAlso, on a side note with the iPad on the website, the More Demos drop down disappears when I go to click a sub item.\n. ",
    "mikewebaphorism": "I just upgraded from custom.fineuploader-4.4.0.js to azure.fine-uploader.js and tested it on iPhone 5s and found same bug.....    wondering if anyone else has seen this issue / bug?\n. /! 2015-04-21 /\n. Thank You\n. ",
    "deweydb": "I just wanted to say i really love you for creating this 'issue'.  I've been trying to track down this chrome ios bug for WAAAAAAY too long.  You are my hero.\nEdit: also, this is still not fixed in chrome ios AFIK. ",
    "Bilge": "This isn't a big feature. The workload burden is placed on the third party to implement a parser. You merely need to provide an extension point.\n. Dropped.\n. ",
    "smcoll": "i'm interested in the ability to send a csrf token for S3 signature requests.\n. @rnicholus are you saying that some params sent to the signature url (like the token) would have to be ignored when generating the signature?  Which would be a server-side consideration?\ni was presuming it might be something like this:\nsignature: {\n    endpoint: \"<signature-url>\",\n    params: {csrftoken: \"<token>\"}\n},\n. Understandably.  Would any changes be required if the token could be send in the header instead?  That would be just as acceptable to me.\n. @rnicholus i really appreciate your timely response.  Using the non-jquery version fixes the issue for me.\n. ",
    "petermumford": "This still didn't work for me. I've found a different solution though using the validateBatch event. As you'll see I'm getting the total number of picture elements (<li>) in my container, called current_images_length. This gets updated when I add a new image via Fine Uploader and deleting an image, which is handled via RubyOnRails. validateBatch as you know will return all the images that have been selected from the dialog window. So all I did is a very simple check against that and my container. The the result returns false then show a message and don't upload anything. Also, using this method I've removed the itemLimit from validation option as this is doing the same thing.\nCan you see any drawbacks with this method?\njavascript\n$(\"#uploader\").fineUploader().on(\"validateBatch\", function(container, files) {\n  var current_images_length, result;\n  result = true;\n  current_images_length = $('.current-images li').length;\n  if (current_images_length >= 5) {\n    result = false;\n  } else if ((current_images_length + files.length) > 5) {\n    result = false;\n  }\n  if (!result) {\n    alert('Only allowed 5 pictures');\n  }\n  return result;\n});\n. ",
    "nickalbrecht": "I just took a closer look and you're right. I hadn't looked closely enough at the intended use of the file and when I encountered an error because of document.body being null I took it as being an error and decided to \"fix\" it. The primary purpose of the change was to avoid a null reference error in the console log but given that I wasn't using it correctly, I'm not sure if my suggestion is still valid.\n. ",
    "bolasblack": "@rnicholus Sorry, I selected master branch with a mistake. I will open a new PR and describe why require a non-200 response.\n. @rnicholus I have no access to control image service...I'm so sorry for my mistake, I'm too tired...\n. Becase the image service is private, so I can't show a document or url...\n. ",
    "SlaterD": "Awesome. It will be greatly appreciated. :)\nOn Mon, Oct 14, 2013 at 1:25 PM, Ray Nicholus notifications@github.comwrote:\n\nDue to a couple requests, I plan to make this part of 4.0.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1008#issuecomment-26285867\n.\n. \n",
    "borisreitman": "Sorry, it was something on my end.\n. \n. Sorry, it was something on my end.\n. I made this tool.  Let me know if there is anything that you need to help you integrate it.\n. I'll add GitHub submission support to the Proofreader, by next week. I will update this thread.\nThanks Andrew :) When I conceived it, I started integrating it closely with Tumblr, but GitHub support seems very appropriate.\n. That would be nice if it came included in the zip. Your demos page already has a bootstrap v2 example. Can you upgrade it to bootstrap v3? In your implementation, can you make sure that the progress bar is a bootstrap progress bar, and so are the alerts.\n. OK, I now understand that Total progress module is something that must be installed on the server.\nI don't want to do that. I want a progress bar for individual file. Can you point me to an example where your \"progress\" event is handled and a bootstrap 3 progress bar is updated.\n. I am not a license holder yet as I would like to see try integrating it first. How can I build that module given that I cloned the project from github and followed your build instructions.\nhttp://docs.fineuploader.com/branch/develop/contributing.html\nI am asking because totalProgress is not working for me even thought I have it in the template.\n. ",
    "pulkitjalan": "Amazon have now said that cloudfront does not remove the Authorization header on PUT, POST, PATCH, DELETE, and OPTIONS.\nhttps://forums.aws.amazon.com/message.jspa?messageID=528729#528729\n. I was testing this with fine uploader and I ran into another issue. It was to do with the fact that cloudfront adds the 'X-Amz-Cf-Id' header to the request. I got past this issue by using Origin Access Identities as outlined in this forum post: https://forums.aws.amazon.com/thread.jspa?messageID=345913&#345913.\nLooking forward it seeing this feature in fine uploader :)\n. I was able to upload via cloudfront and use chunking. Yes there was a significant improvement in performance considering my bucket is in the us-east-1 region and im uploading from the UK.\nDirect to S3 = ~1MB/s\nS3 via Cloudfront = ~4-6MB/s\n. At the moment its quite hacky to get this working, almost all security checks have to be disabled. \nIs this feature going to be implemented into fineuploader and if so, which version it is planned?\n. Ok, thanks for the update\n. ",
    "cybertrand": "First of all, thank you @rnicholus for building such a useful piece of software. I'm also looking to use Fine Uploader to upload content to S3 via CloudFront. I understand from this thread that this should be released in 5.1 and was wondering if you had an idea when that might be?\nThe company I work for is looking to implement a Web uploader with this specific feature. We might be able to contribute to the project to help develop it if that's something you're interested in.\n. Thank you very much for the additional information @rnicholus; makes sense about the S3 bucket name. It's great to hear that this should be straightforward to implement and that it should happen soon. On that last note, are you able to share any rough timeframes: are we talking about 1, 3, 6 months? I'm asking so that we can make the best decision on waiting vs. implementing now.\nI was also wondering: will the implementation of this feature include the ability to upload multiple chunks/parts of the same file in parallel? (to S3 via CloudFront). That's what we're after in order to accelerate file uploads and this would provide a really nice commodity solution, instead of having to buy and implement a UDP based transfer acceleration solution. Note: it would be really useful to have a similar solution for accelerated downloads, whereby your JS client would perform multiple HTTP Range requests to CloudFront/S3 in parallel do download a single large file (I believe both S3 and CloudFront support this).\nThanks again!\n. I did read about it @rnicholus and was wondering if it would be supported for uploads to S3 via CF and for a single file specifically.\nI ran some tests doing multipart uploads of single large files to S3 with 3-5 chunks in parallel via a native client app (Cyberduck, also open source) from Los Angeles to a S3 bucket in US Standard and can vouch for the fact that it yields huge gains in throughput (consistently reaching 90+Mbps on a dedicated 100Mbps). Similarly, although a single file/chunk upload to CF will yield much better throughput than one to S3 (since it's uploading to a local CF node), transfers could be further accelerated by allowing multiple chunks in parallel. I don't know how hard this would be to implement and if it requires a lot of changes compared to what you built for S3, just some food for thoughts..\nI can also say from my experience that your call to only implement this feature with chunking in order to allow pause/resume as well as the automatic retry of failed upload was a good call. We've had recurring issues uploading single large files to S3 via another CDN: some uploads to S3 fail, our CDN provider confirms a failed PUT to S3 but we're not get any additional information from Amazon...\nSorry, don't mean a nag, but are you able to share any timeframe for the release of 5.1? Thanks a lot for responding so quickly to everything!\n. Great. I'll watch the thread for updates on 5.1. Thanks again!\n. ",
    "cdanzig": "@rnicholus in the process of exploring chunked uploading to S3 via CloudFront. Were you ever able to get the pieces of the puzzle together?\n. ",
    "rbliss": "@rnicholus Talked to the CloudFront guys directly. They're now saying that ALL the headers should pass through appropriately. Can you still recreate the issue or have a curl command to recreate the issue?\n. @rnicholus Cool, yeah, seems like it has been a bit frustrating getting this worked out with CloudFront. I'm in direct contact with them, if you can tip me off with an example for re-creating the issue, I can follow up with them.\n. @rnicholus I'll give it a whirl and get back to you on this.\n. @rnicholus Good news! I believe I've gotten to the bottom of the issue, and am just waiting on hearing back from the Cloudfront guys.\nAppears the issue isn't a problem of Cloudfront failing to pass through headers, but of the S3 object's ACL properties being setup incorrectly when the object is both created through a Cloudfront endpoint  and the ACL is set specifically to private.\nThe test is straightforward: in FineUploader, try using a Cloudfront endpoint but setting the objectProperties.acl to public-read instead of FineUploader's default private. The object should be created properly, with the appropriate passed through meta data showing up on the object.\nFor some reason, only the multipart REST API uploads to S3 through Cloudfront with an ACL of private creates an improperly permissioned object where the owner does not have permission to access the object (except strangely, deleting it). Hence the appearance that the meta data headers are not passed through, because you are not allowed to read the meta data!\nAnyway, try that and tell me if I'm crazy. I do not know if other ACLs have similar problems.\n. Note: you can lookup the ACL setting on an object with:\naws s3api get-object-acl --bucket <bucket> --key <object key>\n. @rnicholus It appears to be working for other x-amz headers, I'll test more and see how it goes.\n. I've been testing the x-amz-meta-#### headers, and they're working great. Other headers appear to come through fine too.\nAfter further discussion with the guys at Amazon, it appears the specific issue I was having, where the headers don't appear to come through, is really due to setting up an 'Origin Access Identity' (OAI) on Cloudfront. You have to be very careful when you setup an OAI to understand what's going on. An OAI will cause Cloudfront to behave almost as if a different user (the OAI) is creating the S3 object, rather than the user whose access key you specify in FineUploader.\nAn OAI is optional, but If using an OAI, you should use the acl of bucket-owner-full-control instead of private to get an S3 object that resembles what would normally happen if you hit S3 directly.\nOther than that, I'm happy with the results I'm seeing from Cloudfront and it appears the earlier issues are no longer a problem.\n. Just a point of clarification: by signed requests, are you referring to the signed Authorization header required to authenticate a request in the S3 REST API, or signed urls used to restrict access to objects in S3?\n. Just wanted to double check. You do not need an OAI to send signed requests. In fact, if you turn off the OAI (or never set one up) on your Cloudfront distro, everything should just work like you were interacting with S3 directly. \n. @jasonshah I haven't had a chance. Anecdotally, it does seem faster\n@rnicholus Definitely give it a shot without OAI. Life will be glorious. \n. I do have to warn anyone attempting to use Cloudfront, Cloudfront is a bit fiddly in terms of configuration. If you're having issues, it's likely with how you've setup Cloudfront. I can write up configuration details if anyone is testing this.\n. Here are my notes on setting up a proper CF distribution:\nOrigin Settings\n- Restrict Bucket Access (shows up after you choose your S3 bucket) - Easiest if you choose No see Notes on OAI below.\nDefault Cache Behavior Settings\n- Allowed HTTP Methods - Must choose GET, HEAD, OPTIONS, PUT, POST, PATCH, DELETE else you can't create an S3 object.\n- Forward Query String - Must choose Yes, else chunked uploads will fail.\n- Restrict Viewer Access - Easiest if you choose No else you'll have to do a lot of tweaking to send a signed Cloudfront URL in addition to all the S3 url parameters.\nNotes on OAI: If you do setup an OAI, make sure to set FineUploader's objectProperties.acl to bucket-owner-full-control or appropriate equivalent. A Cloudfront distribution with an OAI setup on an origin pointing to a S3 bucket will cause Cloudfront to act as the OAI user when interacting with the S3 bucket regardless of the access key specified in FineUploader. Hence any objects with an acl of private will belong to Cloudfront's OAI user and not the access key's user.\n. @andreij Place it in AWS Cloudfront forums and I'll respond.\n. ",
    "cmwright": "It doesn't help anyone trying to use CloudFront, but we were able to get uploads via CDN working with Edgecast if someone is looking for a Fastly alternative.\n. ",
    "winzig": "I've been following this thread for a while with great interest. It sounds as if this is now working, but it's not totally clear what the procedure is to set CF up to use with FineUploader. Will this be documented?\n. ",
    "andreij": "I don't know if it's the right place to ask, but maybe your answers can help other people stuck like me.\nI have set up a basic uploader page, S3 + CORS and works as expected.\nWhen I switch to the CDN upload, the response is:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error>\n   <Code>MethodNotAllowed</Code>\n   <Message>The specified method is not allowed against this resource.</Message>  \n   <Method>POST</Method>\n   <ResourceType>OBJECT</ResourceType>\n   <RequestId>2B0507CBD403F9C3</RequestId>    \n <HostId>nEV/gHkAE3wTCKP+ZJzV/VQXNEvFP+/w2UZtyIwTrkkV+/i9aFK/Ap8qTfGfDZ+PAl2kAYD7vE4=</HostId>\n</Error>\nThe response header are:\nAccess-Control-Allow-Method POST, PUT, DELETE\nAccess-Control-Allow-Origin *\nAccess-Control-Max-Age 3000\nAllow GET, DELETE, HEAD, PUT\nConnection keep-alive\nContent-Type application/xml\nServer AmazonS3\nTransfer-Encoding chunked\nVary    Origin, Access-Control-Request-Headers, Access-Control-Request-Method\nVia 1.1 5d53b9570a535c2d94ce93c20abbd471.cloudfront.net (CloudFront)\nX-Amz-Cf-Id dw-N_pLmOmEqlbri-B2l7l2a6TGWm2_tAhr5y9_InMU8ZuHYunZSEw==\nX-Cache Error from cloudfront\nBelow the default behavior configuration:\n\nNo OAI set. \nWhat I have changed into fineuploader conf is:\nrequest: {\n  endpoint: 'dqu6rri____.cloudfront.net',\n},             \nobjectProperties: {\n  bucket: 'fineup____-test'\n},\nBucket policy:\n{\n    \"Version\": \"2012-10-17\",\n    \"Id\": \"Policy1447166234666\",\n    \"Statement\": [\n        {\n            \"Sid\": \"Stmt1447166228927\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": \"s3:*\",\n            \"Resource\": \"arn:aws:s3:::fineup____-test/*\"\n        }\n    ]\n}\nCors:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CORSConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n    <CORSRule>\n        <AllowedOrigin>*</AllowedOrigin>\n        <AllowedMethod>POST</AllowedMethod>\n        <AllowedMethod>PUT</AllowedMethod>\n        <AllowedMethod>DELETE</AllowedMethod>\n        <MaxAgeSeconds>3000</MaxAgeSeconds>\n        <ExposeHeader>ETag</ExposeHeader>\n        <AllowedHeader>*</AllowedHeader>\n    </CORSRule>\n</CORSConfiguration>\nThe bucket is located in Ireland.\nI'm quite clueless, so any help on how to track down the problem would help.\n. Dear @rnicholus if you think this is the wrong place I can remove it in order to not clutter the issue's conversation.\n. @rbliss Thanks! Here the follow up https://forums.aws.amazon.com/thread.jspa?threadID=219620\n. ",
    "nalbion": "@rnicholus @rbliss I'm getting an error when I try to upload large files to S3 through Cloudfront:\nxml\n<Error>\n  <Code>AccessDenied</Code>\n  <Message>There were headers present in the request which were not signed</Message>\n  <HeadersNotSigned>x-amz-cf-id</HeadersNotSigned>\n  <RequestId>123</RequestId>\n  <HostId>abc=</HostId>\n</Error>\nFineUploader config:\njavascript\nvar endpoint = 'mydomain.com';\nvar uploader = new qq.s3.FineUploader({\n            // debug: true,\n            element: el,\n            request: {\n                endpoint: 'https://' + endpoint,\n                accessKey: s3AccessKey,\n                params: metadata\n            },\n            chunking: {\n                enabled: true\n            },\n            objectProperties: {\n                bucket: bucket,\n                host: endpoint,\n                region: 'ap-southeast-2',\n                serverSideEncryption: true\n            },\n            signature: {\n                endpoint: domain + '/file-uploads/sign-request',\n                version: 4,\n                customHeaders: customHeaders\n            },\nCloudformation template:\n```yaml\nResources:\n  Distribution:\n    Type: \"AWS::CloudFront::Distribution\"\n    Properties:\n      DistributionConfig:\n        Aliases:\n          - !Sub files.${HostedZone}\n        DefaultCacheBehavior:\n          AllowedMethods:\n            - \"DELETE\" - \"GET\" - \"HEAD\" - \"OPTIONS\" - \"PATCH\" - \"POST\" - \"PUT\"\n          CachedMethods:\n            - \"GET\" - \"HEAD\" - \"OPTIONS\"\n          Compress: true\n          ForwardedValues:\n            QueryString: true\n          TargetOriginId: \"Upload Bucket\"\n          ViewerProtocolPolicy : \"redirect-to-https\"\n        Enabled: true\n        HttpVersion: \"http2\"\n        Origins:\n          - DomainName: !Sub ${BucketName}.s3-ap-southeast-2.amazonaws.com\n            Id: \"Upload Bucket\"\n            CustomOriginConfig:\n              HTTPPort: 80\n              HTTPSPort: 443\n              OriginProtocolPolicy: https-only\n        ViewerCertificate:\n          AcmCertificateArn: !Ref Certificate\n          SslSupportMethod: sni-only\nBucket:\n    Type: \"AWS::S3::Bucket\"\n    Properties:\n      BucketName: !Ref BucketName\n      CorsConfiguration:\n        CorsRules:\n          - AllowedOrigins:\n              - \"\"\n            AllowedHeaders:\n              - \"\"\n            AllowedMethods:\n              - \"GET\" - \"POST\" - \"PUT\" - \"DELETE\"\n            ExposedHeaders:\n              - \"Date\"\n              - \"ETag\"\nS3BucketPolicy:\n    Type: \"AWS::S3::BucketPolicy\"\n    DependsOn: Bucket\n    Properties:\n      Bucket:\n        !Ref BucketName\n      PolicyDocument:\n        Statement:\n          - Sid: DenyIncorrectEncryptionHeader\n            Action:\n              - \"s3:PutObject\"\n            Effect: \"Deny\"\n            Resource: !Sub arn:aws:s3:::${BucketName}/\n            Principal: \"\"\n            Condition:\n              StringNotEquals:\n                s3:x-amz-server-side-encryption:\n                  - \"AES256\"\n          - Sid: DenyUnEncryptedObjectUploads\n            Action:\n              - \"s3:PutObject\"\n            Effect: \"Deny\"\n            Resource: !Sub arn:aws:s3:::${BucketName}/\n            Principal: \"\"\n            Condition:\n              StringEquals:\n                s3:x-amz-server-side-encryption:\n                  - !Ref AWS::NoValue\n```. Okay... I changed \n- DomainName: !Sub ${BucketName}.s3-ap-southeast-2.amazonaws.com \nto\n- DomainName: !Sub ${BucketName}.s3.amazonaws.com\n(removed the region) and ...I've moved onto the next error: The request signature we calculated does not match the signature you provided. Check your key and signing method.\nThe error says that the CanonicalRequest included host:my-bucket.s3.amazonaws.com\n...oh - objectProperties.host should be my-bucket.s3.amazonaws.com, not endpoint - it's all working now :champagne: :tada: \n. @rnicholus thanks for the quick response. Can you explain the rationale behind providing an id param to the customHeaders (internal) function for deleteFile() (and not for the sign/uploadComplete)?\nI think I'll just settle for \"Plan B\":\njavascript\n    $rootScope.$watch('authHeader', (value) => {\n          console.info('...now we need to update uploader config with', value, uploader);\n          uploader.setDeleteFileCustomHeaders({Authorization: value});  // actually, I'd probably call the same `customHeaders()` function that I provide to the other endpoints`\n      });\n. Thanks @rnicholus. Actually, onSubmitDelete is called before showConfirm() - if the user cancels the delete operation I'd have to undo anything done in my animation.\nonDeleteComplete is too late to animate because qq.FileUploader,onDeleteComplete has called _removeFileItem() (the method I had to monkey-patch) before calling options.callbacks.onDeleteComplete.\nIf I do the animation in onDelete it looks okay, as long as the network operation succeeds, otherwise I'd have to undo everything done in my \"animation\" in onDeleteComplete(id, xhr, true) - which actually includes this.uploadedFiles.splice(i, 1) where i is not guaranteed to be equal to id.. Hi @rnicholus, getUuid() could be used to get the uuid, but it's available when showConfirm() is called, and I need to use the value.. hmmm... getNetUploads() is documented:\n\nGet the number of items that have been successfully uploaded and have not been deleted\n\n...What if a file has been uploaded but rejected?  (like my unit test was uploaded but rejected by Travis CI :wink: )\n...answering my own question: seems that it would only be used for restricting the number of successful uploads. thanks Ray!. Hi Ray,\nThanks for the offer - I think FineUploader is the first repo I've contributed to which has so many forks that GitHub can't show the graph. \u00a0Being a maintainer of a project with such a large following would certainly look good on my CV, but I think at the moment I need to focus on what I've already got on my plate.\nNick \nOn Thursday, 16 February 2017, 16:03, Ray Nicholus <notifications@github.com> wrote:\n\nSay, you've contributed quite a few PRs lately. I've been looking for a second maintainer for a while. I've been the only consistent maintainer of this library since 2012, and I could use a second dedicated person. Is this something you're interested in? If so, follow me on Twitter and we can discuss in more detail over DM.\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.  \n. I hope it's a good move for you. @rnicholus please review merge of #1802. Fine Uploader allows for an optional additional request.params object to be configured. For S3 uploads these are implemented as metadata fields on each S3 (file) object. \nI don't imagine that storing the request params would add much overhead.  While it may bring forward the quota exceeded scenario, that possibility of running out of space was always there. Perhaps the resume feature needs configurability of max age and record count?. I've monkey-patched this in my application code:\njavascript\n    const _addFiles = this.uploader.addFiles.bind(this.uploader);\n        this.uploader.addFiles = function(data, params, endpoint) {\n            let uploads = self.uploader.getUploads(),\n                remove = self.itemLimit - (uploads.length + data.length);\n            if (remove) {\n                data = data.slice(0, remove);\n            }\n            return _addFiles(data, params, endpoint);\n        };. done. ",
    "pwflanagan": "Azure Blob storage now supports CORS, as of Nov. 27, 2013.\nhttp://blogs.msdn.com/b/windowsazurestorage/archive/2013/11/27/windows-azure-storage-release-introducing-cors-json-minute-metrics-and-more.aspx\n. ",
    "angelsix": "\nCORS is now fully supported, as mentioned above.\nChunk upload is fully supported (you write a Block to a Blob. The Blob is the full fill, the Block is the chunk). See working code here http://msdn.microsoft.com/en-us/library/windowsazure/hh824678.aspx\nMPE - what is that? Either way I think supporting Azure even just for File API browsers would be greatly beneficial.\n. It appears MPE is supported. Check it out here http://blogs.msdn.com/b/yaohuang1/archive/2012/07/02/asp-net-web-api-and-azure-blob-storage.aspx\n. Yes if you could support Azure even for just modern browsers that would greatly help me out and save me having to change from FineUploader. I already use it and its great, but we now use Azure Storage so it isn't much use at the moment we have to upload to our server then to Azure from there, doubling the server load.\n\nIf you could add Azure support this would be great.\n. We use ASP.Net 4.5 with MVC backend and front end is HTML 5 and jQuery, with Azure Storage and SQL 2012 database.\nWe use FineUploader to currently send files to MVC then from their it uploads to Azure, so it would be great to be able to go straight from front end to Storage\n. Sounds fine. I would perhaps get FineUploader to send the initial request \nto upload to the server providing the ability for me to add extra fields \nvia jQuery so I can tag the file location this will be going. The server \ncan then confirm the user can upload to this location and provide the SAS \nto FineUploader. FineUploader could then confirm the progress to the server \nand upon completion inform the server also.\nLuke\nAngelSix Ltd\nOn 17 January 2014 20:23:35 Ray Nicholus notifications@github.com wrote:\n\nOk.  My plan at this time is to make a request back to the server for each \nblock/API request sent to Azure.  The server will need to supply a \nsignature for the request using a short-lived shared access key (SAS) for \nthe associated operation.  Fine Uploader Azure will then use this signature \nto construct a SAS URI to perform the REST call on the Blob Storage service.\nThoughts?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1022#issuecomment-32643028\n. Yes cool that will work\n. Cool that will do.\n\nI chose Azure over AWS. Amazons API, throttling and support all suck. \nMicrosoft are more expensive and not yet the same level as AWS but they are \nrapidly getting there and Azure is getting loads of improvements and \nfeatures added every month I can see it being the best choice for future.\nLuke\nAngelSix Ltd\nOn 17 January 2014 21:55:13 Ray Nicholus notifications@github.com wrote:\n\nWe will probably only include a .NET server-side example for Azure support. \n Unless you are locked into a Microsoft environment, I can't imagine \nchoosing Azure over AWS or Rackspace.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1022#issuecomment-32652188\n. What you find with Microsoft is their early released do tend to lack basic \nthings, but they update regular and often and never rest the product either \ncontinues to update or gets shut down. Look how far Entity Framework and \nASAP. Net have come in a few years.\n\nAzure is early for them but the last 6 months it's come on massively. Their \nsupport for live website debugging, tracing and editing in Visual Studio is \nlike nothing I have seen in the cloud before its so good.\nThe storage to me feels early and lacking at the moment but I bet they will \naddress issues very soon.\nFor viewing and managing blobs yes there is a UI it's un Storage then \nContainers then in there you can see any fully committed blobs but not ones \nyou have not submit the blob list to yet if it is a putblob upload.\nLuke\nAngelSix Ltd\nOn 17 January 2014 22:30:56 Ray Nicholus notifications@github.com wrote:\n\nAgreed on the support.  I've found forum support for AWS to be less than \nideal, to say the least.  I'm quite fond of the AWS API though, and found \nit and the documentation complete and intuitive when developing Fine \nUploader S3.\nI don't have any experience with Azure before today, and the last time I \nwrote any .NET code or worked in any sort of Microsoft environment was over \n5 years ago.  So, my impressions of Azure are only based on my very initial \nexperiences.\nMy first forray into this service was exploration of their CORS support.  I \nexpected this to be lacking, as Microsoft has historically made bad \ndecisions in this area.  Have a look at the XDomainRequest \ntransport \nin IE8 and IE9 for a prime example of this.  In addition to the apparent \nlack of API support for browser-based uploads in IE9 and older, I am \ntroubled by the measures required to simply manage CORS rules.  For \nexample, you can easily manage CORS rules via the console UI in AWS.  With \nAzure, you have to make use of their REST API.  It's odd that they would \nmake you do this, as it seems a bit unnatural to configure CORS for a \ncontainer programmatically.  In most cases, you would set the rules and \nnever touch them again, or perhaps add an origin at some point in the \nfuture.  I don't see a problem with allowing CORS configuration via the \nAPI, I just don't see why they would not make this configurable vi\n a the ad\n min console.\nIn fact, the Azure admin console looks fairly immature compared to AWS.\nOnly very basic operations are possible via the admin console.  Unless I'm \nmissing something, it looks like you have no way to manage or even address \nindividual blobs via the Azure admin UI.  Of course this is possible via \nthe API, but it's nice to not have utilize an SDK or an installed \napplication to, for example, take a peek at the objects in a container.\n...just my very initial impressions.  It's likely that I've just \noverlooking something and some of the shortcomings I've mentioned are \ninvalid.  This will very much be a learning experience for me.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1022#issuecomment-32657303\n. Yes that would be great. We release to beta soon so if we could implement \nthe new FineUploader before that it would be awesome\n\nLuke\nAngelSix Ltd\nOn 17 January 2014 22:41:06 Ray Nicholus notifications@github.com wrote:\n\nAh, I see.  Thanks for the info!\nIf you are interested in testing out Fine Uploader Azure in your app once \nit is functional but before we release, let me know.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1022#issuecomment-32658681\n. Cool I'll do that first thing in the morning\n\nLuke\nAngelSix Ltd\nOn 17 January 2014 23:10:19 Ray Nicholus notifications@github.com wrote:\n\nPlease send an email to the licensing address and we'll coordinate from their.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1022#issuecomment-32661509\n. Awesome. Sounds like its coming on nicely. Should I get time I might implement the SAS stuff on our server and could provide you with the code for that if needed. \n\nThe only thing I thought is providing the user with a download link to a private blob. How does this work in S3? How would you know when the user has finished downloading the file, or do you just open the link for a long time? I cannot think of a super secure way of doing this in Blob yet?\n. Ok so S3 is just as insecure in this aspect as Azure then. Both are vunerable. Our data is encrypted with users private keys anyway so the raw download would not exploit the users content, but I still think it is a poor system.\n. Not insecure on your end, insecure on the cloud storage vendors end.\nSay I infect a computer with a virus that extracts users cookies and web traffic. That link is viewable in the cache and not encrypted as it has come through SSL and stored unencrypted on the clients machine in the browsers cache. That contains the SAS link that anyone can access then.\nIf the virus went undetected a malicious user could keep accessing every file ever downloaded by the end user for as long as they liked.\nThe SAS link should be secured more than just STO (security through obscurity) and check the end users IP, Mac address and anything else they could. I know all of these are also capable of being faked but it adds more security overall.\n. The problem with the link is for downloading it that is just a stream handled by the browser, so if you are downloading 2GB on a 1MB connection, it would take 5 hours. So the link time needs to be long enough not to time out while the user is downloading.\n. Ah ok that is good if it is so. I guess the power is in the server sending the stream, to make sure that stream is the same one that originally requested access. I will confirm all this when doing security checks though.\n. Coming along good.\nFor filename, I would require the client FU to ask my server via an ajax call for the name of the file and the client (my code) would pre-attach the designed virtual save path as a params to the FU request. Is that possible?\n. Ok so my website will store files like a media library or dropbox would. So the user browsers the site and goes into these virtual folders. From there they drop a file to upload. At this time when the user drops the file, I get the virtual path, lets say it is \u201cmy docs\\my picture\\\u201d and the filename from the drop, so it could be \u201cmy docs\\my picture\\my image.jpg\u201d. \nThis virtual path would be added as a param to FU, then it would tell FU to upload that file. FU would then ask my server for a filename and container name, or whatever you need, and the serer would return a filename which is just an integer in my case. So all files that get uploaded go into a specific container, with an number as the filename. This number needs to be generated on the server and comes from the full virtual path.\n. Cool. So when is chunked upload support planned? I presume that is to support files larger than 4MB then? So does that mean currently FU supports up-to 4MB files right now?\n. Cool.\nBy the way will/can you implement multiple putblock requests from the file at the same time? You get much faster upload speeds if submitting multiple putblob requests at the same time due to the initial connection latency. \nI am unsure whether the browsers native file reading could support that though?\n. That\u2019s great, yes 3 is an ideal number anyway so it will be spot on for our purposes.\n. Sorry I\u2019m right in the middle of an Android app launch that is overdue I would love to test this but I guess I would have to wait until the next launch if anything was missing. I am sure I can make it work and from what I have seen and glanced over the code, it looks perfect for my needs so I am sure it will work fine.\nThanks for providing it in advance and sorry I could not test it soon enough as I liked, it is just poor timing on my side.\nRegards,\nLuke Malpass\nAngelSix Ltd\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: 05 February 2014 03:30\nTo: Widen/fine-uploader\nCc: angelsix\nSubject: Re: [fine-uploader] 13 - Support direct to Azure Blob Storage uploads from the browser (modern browsers) (#1022)\nOur goal is to release on Monday, so please let me know in the next 48 hours if there is a critical feature missing or some bug I missed. Once we are in the process of releasing, new features will have to wait until the next release cycle.\nNote that I think I still have to add some better logging to the Azure module.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/Widen/fine-uploader/issues/1022#issuecomment-34134619 .  https://github.com/notifications/beacon/4455939__eyJzY29wZSI6Ik5ld3NpZXM6QmVhY29uIiwiZXhwaXJlcyI6MTcwNzEwMzc3MSwiZGF0YSI6eyJpZCI6MTg5NTYyNDd9fQ==--46dcc83b4f89ad4d66ab2b9bb1f6b30b183a3ead.gif \n. Do you have a private email or area I can send you a link to a live dev site where you can see it in action (using developer tools to see javascript errors)?\nOn Aug 25, 2014, at 3:52 PM, Ray Nicholus notifications@github.com<mailto:notifications@github.com> wrote:\nI'm not able to reproduce this issue. Using Fine Uploader 5.0.3.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1270#issuecomment-53273991.\n. Very strange. Once I put it onto my live dev server it worked. I cleared cache and cookies and restart machine. Code never changed so must of been something funny going on.\nOn Aug 25, 2014, at 4:26 PM, Ray Nicholus notifications@github.com<mailto:notifications@github.com> wrote:\nSure. Just reply to the last email you received from us, such as your receipt email.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1270#issuecomment-53278901.\n. The my server. I basically upload files to azure with a name of the ID in the servers database, so before a file gets uploaded, I call the server to create the database entry and return the database entry ID. Then I want to send this ID on to the signature call on my server so when its generating the SAS it generates it for a blob named by this ID.\n. Ok. Right now there is no solution other than to use the filename to send your information to the signature endpoint and parse that.\nThe customHeaders is static unless you can set it after the initial setup declaration is it not? For example, I want to set the customHeaders in the submit function. Can that be done?\nOn Aug 25, 2014, at 1:50 AM, Ray Nicholus notifications@github.com<mailto:notifications@github.com> wrote:\nCurrently, you can specify custom headers when the upload is constructed via the signature.customHeaders optionhttp://docs.fineuploader.com/branch/master/api/options-azure.html#signature.customHeaders. The ability to specify additional parameters for the signature URL via query parameters is a requested feature not yet implemented. Please see #1224https://github.com/Widen/fine-uploader/issues/1224. We can probably include the ability to dynamically specify headers in that case as well.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53218112.\n. Ok thanks. Finally, as I have to alter the filename to pass in the file ID, when I get an error in the upload, all callbacks send the ID and changed name into a function. Is there any API I can call to get the original name before I called setName, or should I just track that myself before I change it?\nOn Aug 25, 2014, at 3:39 PM, Ray Nicholus notifications@github.com<mailto:notifications@github.com> wrote:\nYou are correct. As mentioned previously, we can include the ability to dynamically set/change headers for signature endpoints in #1224https://github.com/Widen/fine-uploader/issues/1224. This was not included in the initial development as the initial beta testers didn't seem to have an issue with the absence of this feature, and we didn't want to prolong the release of Fine Uploader Azure. As with Fine Uploader S3, we expect to evolve the Azure module over time as users request additional features.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53272270.\n. getUploads always returns undefined. Wherever I call it I just get undefined.\nIt is called like this:\nconsole.log('getUploads: ' + uploader.fineUploader(\u2018getUploads\u2019));\nI have tried calling it inside progress, totalProgress, complete, and allComplete. Everywhere returns undefined.\nOn Aug 25, 2014, at 3:49 PM, Ray Nicholus notifications@github.com<mailto:notifications@github.com> wrote:\nhttp://docs.fineuploader.com/branch/master/api/methods.html#getUploads\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53273557.\n. Sure I have a live site, but the URL is private. Can you provide somewhere I can send you a private message?\nOn Aug 25, 2014, at 3:57 PM, Ray Nicholus notifications@github.com<mailto:notifications@github.com> wrote:\nThere is definitely some issue with your code, but I can\u2019t tell what that issue is from one line.  You\u2019ll need to either share all of your code, or a link to a site where this can be reproduced.\nOn Mon, Aug 25, 2014 at 9:55 AM, angelsix notifications@github.com<mailto:notifications@github.com>\nwrote:\n\ngetUploads always returns undefined. Wherever I call it I just get undefined.\nIt is called like this:\nconsole.log('getUploads: ' + uploader.fineUploader(\u2018getUploads\u2019));\nI have tried calling it inside progress, totalProgress, complete, and allComplete. Everywhere returns undefined.\nOn Aug 25, 2014, at 3:49 PM, Ray Nicholus notifications@github.com<mailto:notifications@github.commailto:notifications@github.com> wrote:\nhttp://docs.fineuploader.com/branch/master/api/methods.html#getUploads\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53273557.\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53274384\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1271#issuecomment-53274590.\n. Perhaps a simple check if qq-hide-dropzone isn\u2019t set, don\u2019t do this? It works perfectly fine now I have comment out that line\n. Sure, I'm just working on fine uploader stuff today out of coincidence so I can check this out. Do you have a compiled js file for:\njQuery + Azure + DnD + Delete\nThat is the custom build I used IIRC\n. Ok so if the file gets to the point of the addFiles call for manual, or automatically via the add files button, then no matter what part of the process fails after that point (getting the SAS from the server, uploading to azure, and sending completion call to the success endpoint) the complete event will be called? \nIf so then thats ok I can surmise from the complete event to display an error or not\n. Ok. From testing it myself in all failure scenario's, I basically display an error only if the status is UPLOAD_FAILED. \nI could also do it on the complete event just the same. Any validation errors I display the error manually and that seems to cover all areas.\n. Not specifying a href means the styling doesn't work to act as a link. Specifying a href forces the page to reload.\nI have done this instead, where AddFilesButton is the primary button element\n$('[data-action=\"files-upload\"]').on('click', function (e) {\n```\n// Cancel usual click behaviour\ne.preventDefault();\n// Call Add files button\n$('#AddFilesButton').find('input').click();\n```\n});\nIt would be nice, and expected, if fu is taking over control of a button-like element that the user should click to upload items, that it handles canceling of the existing click events, just like the main button does.\n. You cannot use a # to prevent page reloads. It will add a hash to the page window url if not cancelled. As we monitor and use that url for ajax history and jQuery dynamic reloading its inappropriate, and also very bad practice and just an old style 'hack'.\nThe same goes for not using the correct tags for function. For many reasons you should use the tag that is expected to have a particular function. That for an action or link is an anchor or button, neither of which work in this scenario.\nFinally, why is submitting a click not going to work cross-browser? Tested on Mac, iPhone, Windows Phone, Win 7, Win 8 in Safari, Chrome, FF and IE and all works fine?\n. ",
    "joshdvx": "I'd also love to beta this.  Sending an email also! \nI have a bizspark membership to Azure, so I can donate a blob for testing if needed also.\n. Was there ever an answer to the if it will retain the chunking support?\n. Yay. \n. I'm drooling with anticipation. :+1: \n. I'm very much new to this but I'm getting an error while trying to run the C# example.\n\"The name 'CorsHttpMethods' does not exist in the current context\" I've added the Microsoft.WindowsAzure.Storage reference. What am I missing?\n. Comma missing in the \"Putting it all together\" section:\nhttp://docs.fineuploader.com/branch/develop/quickstart/02-setting_options-azure.html\nuploadSuccess: {\n            endpoint: '/success'\n        },<<<<<<\n. Thanks Ray,\nSo the first problem was solved by running install NuGet and adding windows storage azure through that, https://www.nuget.org/packages/WindowsAzure.Storage/  I was originally adding it through the IIS Web Installer which was giving me an older version.\nUltimately I know my inexperience is causing a problem trying to build it. So I'm hoping you can point me towards a 'for dummies' guide. As I have read and re-read the documentation.\n1. Am I able to keep these elements separate? I.E. keep the actual FineUploader Form inside of a default.html file that I'm editing with a program such as Coda or NotePad++, and then only build your signature example inside the Web Application Visual Studio project? \n2. Should the final signature file be a .dll file?\n3. What do I name the file so that when I call \"signature\" from my default.html it actually opens it. & Do I have to add or configure something in my IIS so that I can load that signature file?\n<script>\n    // Wait until the DOM is 'ready'\n    $(document).ready(function () {\n        $(\"#fine-uploader\").fineUploaderAzure({\n            request: {\n                endpoint: 'http://xxx.blob.core.windows.net/xxxcdn'\n            },\n            signature: {\n                endpoint: 'signature/'\n            },\n            uploadSuccess: {\n                endpoint: 'success/'\n            },\n            retry: {\n               enableAuto: true\n            },\n            deleteFile: {\n                enabled: true\n            }\n        });\n    });\n    </script>\n1. I created a Visual C# ASP.Net Web Application Visual Studio 2013 project to build the signature file. But should I actually have the entire form elements in this project file as well?\nIf this is too much to post here I can post on StackOverflow.  The only example that I was able to actually get going was the S3 Serverless example.  But the actual signature element is what has been throwing me off.\n. Ah ok, this is starting to make sense.\nAnd sorry wasn't attempting to copy your code verbatim for my application, my main goal of your sample code was to at least get it working so I could see what was actually happening and rewrite it accordingly. \nAnd I think I'm almost there, I came across this for cfm\nhttp://stackoverflow.com/questions/13372285/c-sharp-to-coldfusion-for-base64string-translation\nAnd I built the following but I'm getting a \"PUT request for 1 has failed - response code 404 \" if I remove the file I get an \"GET SAS request failed: Empty response. \" so I know it's the sig file.\nThe URL that fineuploader is generating looks like this in the console, which when I bring it down to bloburl2 shows up correctly with all the /'s.\nindex.cfm?bloburi=http%3A%2F%2Fframeglue.blob.core.windows.net%2Ffgcdn%2F2e55808d-487f-40d6-86b9-381dbd05d32a.png&_method=PUT&qqtimestamp=1391495691999\n```\n- Variables from Fine Uploader -\n\n\n\n- Convert DateTime from Epoch Millisconds -\n\n- Generate SAS -\n\n    savecontent variable=\"signatureString\" {\n        WriteOutput(\"GET#chr(10)##chr(10)##chr(10)##chr(10)#x-ms-date:#DateTimeFormat(a, \"E',' dd mmm yyyy HH:nn:ss z\")##chr(10)#/AzureStorageName/AzureContainerName\");\n    };\n    key = binaryDecode(\"THISISMYKEY\", \"base64\");\n    resultInHex = hmac(signatureString, key,\"HMACSHA256\");\n    signature.endpoint = binaryEncode(binaryDecode(resultInHex, \"hex\"), \"base64\");\ntheJSON = SerializeJSON({\"signature.endpoint\": signature.endpoint});\n    writeOutput(\"\"&theJSON&\"\");\n\n\n```\n. I can happily confirm that I have it working now and I haven't run into any bugs. \n. ",
    "petesankey": "Hi there,\nWe also REALLY want this feature to upload directly to rackspace from fineuploader.\nAny chance this could get developed?\nPete\n. ",
    "EugeneLiang": "I will be interested in this feature! \n. Amazing!!!\nAny sample code to go along ?\nBest.\nOn Thu, Oct 2, 2014 at 5:45 PM, Kieran Pilkington notifications@github.com\nwrote:\n\nIn the end, I finally got it working using custom AJAX code (not\nfine-uploader). You can't use POST, but you can use PUT, and provided\nyou've properly set the CORS headers, and send the data in the right way\n(namely as a stream (passing the file to the ajax PUT request) rather than\nusing FormData), then you can get files to rackspace cloud files using\nAJAX. Hurray!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1025#issuecomment-57605838\n.\n\n\nBest Regards,\nEugene\nhttp://www.liangeugene.com\n. ",
    "cayter": "I think the cheaper pricing(out-bound bandwidth) and easier CDN integration on Rackspace cloud storage could lead lots to choose it over Amazon S3.\n. ",
    "KieranP": "Sadly, Rackspace currently has a bug that prevents CORS requests via AJAX POST to trip browser security (specifically, the Access-Control-Allow-Origin header only gets returned in GET responses, not POST ones). Because of this, AJAX upload of files to Rackspace cloud files is currently not possible :-(\n. I did try a PUT request instead via AJAX, but got the same result.\n. In the end, I finally got it working using custom AJAX code (not fine-uploader). You can't use POST, but you can use PUT, and provided you've properly set the CORS headers, and send the data in the right way (namely as a stream (passing the file to the ajax PUT request) rather than using FormData), then you can get files to rackspace cloud files using AJAX. Hurray!\n. ",
    "TedAvery": "+1 but for Dreamobjects, which also uses the S3 API\n. ",
    "pratik60": "@rnicholus Any idea when work on this feature could resume?\n. ",
    "zmilan": "Hi @rnicholus ,\nI just play around to setup direct uploading to RS cloud files. I'm able to upload file directly using simple plain javascript, but for our need it will be great if I can setup fineuploader to do same. So I try to do it with fineuploader 5.2.2 using traditional endpoint with PUT method and RS tempUrl. I get file uploaded but it is corrupted.\nHere is example of original file content and uploaded file content:\nOriginal file content:\nThis is begining of note.txt\nThis is second line of note.txt\nUploaded file content:\n------WebKitFormBoundaryfBz63adwZDN4eB3c\nContent-Disposition: form-data; name=\"qquuid\"\n543a79c1-3659-4165-b01b-23b657b06860\n------WebKitFormBoundaryfBz63adwZDN4eB3c\nContent-Disposition: form-data; name=\"qqfilename\"\nnote.txt\n------WebKitFormBoundaryfBz63adwZDN4eB3c\nContent-Disposition: form-data; name=\"qqtotalfilesize\"\n61\n------WebKitFormBoundaryfBz63adwZDN4eB3c\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"note.txt\"\nContent-Type: text/plain\nThis is begining of note.txt\nThis is second line of note.txt\n------WebKitFormBoundaryfBz63adwZDN4eB3c--\nIs there anyway that I can configure fineuploader to escape this and keep file same like original? Do you have any other suggestion how I can use fineuploader to get this done?\nOne more thing is that fineuploader report failed upload in this case, even file exist on RS cloud files container.\nThanks for any help.\n. Hi @rnicholus , thanks for help. I try to force multipart with false, but it still send same data. I can't parse it on server because it directly upload it to RS cloud files.\nHere is last code what I try:\nvar uploader = new qq.FineUploader({\n            debug: true,\n            element: document.getElementById('fine-uploader'),\n            request: {\n                endpoint: '<?= $uploadUrl;?>',\n                method: 'PUT',\n                forceMultipart: false,\n                paramsInBody: false\n            }\n        });\n$uploadUrl is RS tempUrl with right signature and expiration date. So it success create file on right container and upload it, just I have this extra part that belong to request and not to file. There is also no change when I add forceMultipart to be false.\nAlso it return only HTTP 201 Created ,what I believe is enough, but I dont see any way to customize what FineUploader expect to get like result.\nIs there way to handle this with current FineUploader 5.2.2, or maybe option that RS will get official support in some close date?\nUPDATE\nSorry, I wasnt notice it was about cache. So current state is that I upload file work correct, only I need to find way to handle response, since FineUploader show that upload fail even everything was uploaded correct.\nSo only what I need is some help how to handle response from server to show right upload status. \nUPDATE 2\nOk, I make some fast patch for FineUploader to support only HTTP 201 status like success upload. I edit parseResponse function to be like this:\n```\nparseResponse = function(upload, xhr) {\n            var response = {};\n        try {\n            log(qq.format(\"Received response status {} with body: {}\", xhr.status, xhr.responseText));\n            if (xhr.status == 201 && !xhr.responseText) {\n                response = {success: true};\n            } else {\n                response = qq.parseJson(xhr.responseText);\n            }\n        }\n        catch (error) {\n            upload && log(\"Error when attempting to parse xhr response text (\" + error.message + \")\", \"error\");\n        }\n\n        return response;\n\n},\n```\nSo I add first to check is status 201 and responseText empty and in that case create manually response object with success true parameter. If that is not case I left it to do default parse.\nIt will be good if you can note me: \n- is there any issue that I can run into with this patch, that I not see at the moment?\n- is there any issue with big files that I can run into with forceMultipart = false?\nThanks for your help.\n. Hi @rnicholus thanks for fast response. I can understand this and I think making this what I make by patch to be option to setup in configuration will be enough good.\nFor our application, IE<10 is not an issue and also it will not be too hard to setup IE<10 specific version of upload (I think file uploading is not only one thing that you need to handle specially for IE<10 in today applications :))\nSo, if I can vote, I will give +1 to add configuration for accepting 201 status like success for uploading.\n. @rnicholus Is there any info about when we can expect configuration for accepting 201 status response like success for uploading?\n. @rnicholus yes, I understand this. I will create feature request and until 6.0 we will go with our patched version.\n. Ok, I understand this. In our specific case IE9&IE8 are not important, so we have much simpler case. Thanks for accept this.\n. ",
    "marbemac": "Sure thing, check out this fiddle: http://jsfiddle.net/CvFDt/. You can see the error in the console.\nI'm using the JS file produced by the build tool on fineuploader.com. Not sure if something weird is happening there.\n. Ahh, I had a feeling it was something in the build process! Ok well thanks for the prompt responses. I sent an email to the licensing address.\n. Great thanks very much Ray!\n. ",
    "nightwolfzor": "Thanks Ray! Sounds good, it would be great to see onChunkComplete in fine uploader. I realise that there is more work than the simple hacks in this pull. Can I ask how long you think this one will take?\n. ",
    "qobide": "Thanks for the quick response. \nI now also realize i had picked the jQuery option without needing it at all.\n. ",
    "xzyfer": "This simply replaces the existing instance (and it's event handlers) with a new one. \nIt does not unbind the event handlers and wholesale remove the uploader from page. This is important it you want to toggle the uploader.\nThe issue at hand is a .destory() method that removes all traces of the uploader, akin to the jQuery .remove() method.\n. For what it's worth the patch doe bower was just to get Travis passing.\nThe actual bug I'm fixing is rather crippling for us and worthy or a hotfix\nrelease IMHO.\nOn Jul 18, 2014 1:49 AM, \"Mark Feltner\" notifications@github.com wrote:\n\nThanks, @xzyfer https://github.com/xzyfer. And the tests pass [image:\n:beers:] !\nI'll check this out later today. In an in-progress branch, I actually\nremoved bower (4d92a2d\nhttps://github.com/Widen/fine-uploader/commit/4d92a2d468146710eff63183ccef0c0adde05ec8)\nso dd83522 https://github.com/Widen/fine-uploader/commit/dd83522 may\nnot be required.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/pull/1255#issuecomment-49325455.\n. I can confirm this is fixed in the hotfix/5.0.4 branch\n. \n",
    "floatrx": "still important! how to remove instance and unbind all event from js... \ncan't submit form without files... it's sucks!\n. @rnicholus \n<!-- HTML -->\n<form id=\"custom-form\">\n  <input type=\"text\" name=\"input\" value=\"val\">\n  <div id=\"fine-uploader-trigger\"></div>\n  <button type=\"submit\">Submit</button>\n</form>\n// js \n$(function(){\n  cfUploader = $('#fine-uploader-trigger').fineUploader({\n      template: 'qq-template-manual-trigger',\n      form: {\n          element: 'custom-form',\n      },\n  });\n})\nIssue\nWhen I try Submit form without files I see this message:\n\"No files to upload.\"\nIn my case, I want to receive empty value, if files not to been added, but fineUploader deny form submitting without files. How to fix it?\n. ",
    "mkucej": "Hi @rnicholus:\nPerhaps I can explain better, why uploader should have a destroy() method. Let's say I want to use FineUploader with a form that sends messages and allows attaching files to messages, but attaching a file is optional. Fine uploader throws an error, if no file is present. The way to deal with this situation is to create uploader instance only, if a file is present. That works fine. But if a user sends a second message without a file, the error is emmited, because there is no way to destroy uploader after the first message has been sent. I believe this is an important improvement and this issue should be reopen. Thank you much!. ",
    "FL0": "I personally have an other error.\nWith Safari and IOS8, file size is always zero ...\nAnd multiple is set to false ...\n. The last IOS 8 (GM), and actually all the other beta of IOS8 ...\n. Hmm weird ...\niPhone 5s\n. I'm running version 5.0.2.\nMaybe my code is wrong, but, it works with Chrome on the same IOS ...\n. I tested with an iPhone 4, IOS7, and it works ...\n. hmm it's annoying ...\n. Ok\n. Yeah, file input element seems busted in Safari IOS8. even in a simple form (no js) ...\n. IOS 8.0.1 fixes the problem!\n. ",
    "JW301": "Affects the most-used versions (10,11) of one of the most-used browsers (IE), and basically makes drag+drop break the whole page (when the drag zone is in front of other elements). \nPlease fix this for the next release\n. In enterprise environments, IE is the most used browser, because it requires very few maintenance. In these environments, IE is often updated to the highest available version by Windows Update, making it IE10 for Win7 and IE11 for Win8 or higher. I don't like it either, but it is an important browser for our clients. \nWhat I meant is that if the drop zone covers a large part of the page (like in my case, meaning position: fixed, z-index: higher than everything else, width and height nearly 100%), when the drag+drop-operation is aborted and the drop zone doesn't disappear, the page is useless and all you see is the drop zone, which you can't close or anything, and the rest of the page is hidden beneath it. \nThe only way to get the drop zone to disappear is to drag another file to the page and drop it there, or to reload the whole page. While this is not a complicated thing to do, most of our users don't know it or can't remember it even when told to.\nI managed to create a small workaround though: I added a window.onmouseout event to hide the drop zone as soon as the mouse leaves the window (although its effect will only show when the mouse re-enters the page). I also added a small \"close\" link to the top right of the drop zone that does the same, so the user has a more obvious way to dismiss the drop zone. Maybe this workaround will help someone encountering the same problem.\n. Too bad you can't fix this, it's really annoying.\nI also can't quite believe this is impossible to do, for several reasons;\nFirstly, it worked in IE when I was using FineUploader 3.x, upgrading to 4.x broke this for me in IE.\nSecondly, it does work correctly in IE on other pages using DnD, e.g. Google Drive works fine with IE 10 and 11.\nAlso, in my case the explorer window does not overly the document. I have a dual-screen configuration with maximized IE on the left and maximized Explorer on the right screen, so the windows do not overlap. Still have the error. And with Google Drive, even when the explorer window bounds are completely within the document bounds, Google manages to detect the DnD mouse leave properly. So I guess it must be possible somehow.\nStill, thanks for your help, I'll have to live with workarounds for now. \n. Ok, so my project was resting now for months, and I upgraded Fine Uploader from 4.2.2 to 5.0.3 only today.\nI tried whether the problem was solved, and as far as I can tell, it hasn't been fully fixed yet, so maybe you could give some feedback if the problem is just with me or what you guys think of it.\nI have Windows 8.1, two screens sitting next to each other, pretty normal working environment. \nImagine IE10/11 running on one screen (maximized), Windows Explorer running on the other screen (also maximized). I start dragging a file from Explorer to IE, but don't drop it as I accidentally dragged the wrong file, instead I move it back to the Explorer window and drop it there.\nExpected behaviour: The drop zone will disappear as soon as the mouse pointer leaves the IE window. (This is also how it works in Chrome.)\nActual behaviour: The drop zone stays visible, even after the drag/drop-action was finished (outside the IE window). The drop zone will stay visible until the mouse pointer enters the IE window again.\nNow I'm not quite sure, but as far as I remember this was working fine in all versions from 1.x - 3.x, it first stopped working in 4.x and now also doesn't work in 5.x\nI'm not sure if this is the behaviour to expect after your workaround, but it still feels kind of weird. Sorry to dig up such an old bug, I was just wondering if this is really the final fix ;)\n. Still not working in Edge. The drop-zone appears and immediately disappears when dragging a file onto the browser window, flickering when moving the file around. Dropping does not work.\nBUT, when I manually remove the \"display: none;\" from the drop-zone in developer tools, I'm able to drag a file onto it and have it uploaded, without any problems and no flickering of the drop zone. The drop zone then disappears after the upload as normal.\nAny chance you could fix this?\n. good news :) I checked the code myself and found a solution for DnD\nThe problem is not in the DnD module itself, that one is fully working. The problem is in the browser being incorrectly detected as Firefox, while not all Firefox features seem to work.\nThis same problem seems to have happened with IE11 in the beginning. See master/client/js/util.js line 554:\nqq.firefox = function() {\nreturn (!qq.ie11() && navigator.userAgent.indexOf(\"Mozilla\") !== -1 && navigator.vendor !== undefined && navigator.vendor === \"\");\n};\nHere you explicitly say it is not Firefox if it is also IE11. You just need to do the same thing with Edge\nSo I added another function to identify Edge and then changed the Firefox function as following:\nqq.edge = function() {\nreturn navigator.vendor === \"\" && navigator.userAgent.indexOf(\"Edge\") !== -1;\n};\nqq.firefox = function() {\nreturn (!qq.edge() && !qq.ie11() && navigator.userAgent.indexOf(\"Mozilla\") !== -1 && navigator.vendor !== undefined && navigator.vendor === \"\");\n};\nWith these lines changed, the DnD (and all other features I have used) work as expected.\nMaybe you can use this information to fix the DnD problem in Edge :)\n. ",
    "jacquescrocker": "sounds great, thanks!\n. I tried body first but it didnt respond to the drag event. document did\nthough\nOn Nov 14, 2013 8:35 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nAnother workaround would be to use the  element as your drop zone.\nOut of curiosity, why are you using the document, instead of, say, ?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Widen/fine-uploader/issues/1048#issuecomment-28546806\n.\n. \n",
    "craigrbruce": "Thanks @rnicholus for incorporating this. There seems to be an issue however. If I dynamically create table rows(nested folders to be used as drop locations) and then drag a file onto the main container div (to be dropped into the root folder) multiple files are sent to the uploader - kind of reverse of what was happening before this fix. So dropping on any of the table rows works perfectly now, but the root folder case is broken.\n. My company won't allow me to provide code... but I am using AngularJS and, as mentioned, our page is very similar to the DropBox UI. The scenario is this: \n- create a dropzone for the container div\n- create a table in that div\n- add a button that adds rows to that table\n- when the user clicks the button a row is created and the element is added to the uploader's addExtraDropzone function.\n- add several rows\n- drag one file onto one of the rows - success! a file is uploaded into that dropzone \n- drag one file onto the container div - fail! there are several (one for each row + the container) files uploading\nBefore this PR, dragging a file onto one of the rows caused the last step to occur. Now the problem is shifted to the outermost dropzone\n. It's also worth noting that this only occurs if a row is added dynamically. In other words, when the page is redrawn it works ok, adding a new zone by pressing the button screws it up again.\nAlso, I refactored to take advantage of the new getDropTarget function, which is great BTW. When reproducing steps above to failure, the uploader's onSubmitted event is called multiple times and on each getDropTarget yields the correct dropzone (the container dropzone)\n. OMG ... sorry! I have fixed this at my end .. it was a crazy bug in our application. I've tested the new version pretty extensively now and all seems good. Thanks again\n. No .. all good. If I find anything new I'll raise it in the issue tracker\n. OK ..thanks. I have another fix:\nOur app now requires dragging HTML elements which need to be untangled from file uploads. When an element is dragged over a dropzone and _prepareItemsForUpload (in uploader.basic.api.js) is called with an empty verifiedFilesOrInputs array, an error is thrown when the indexer is used.\n. The problem was dropping a HTML element onto a dropzone. An exception was getting thrown. If you are not experiencing the same, please hold off until I investigate further. Thanks\n. One example: Dragging a folder with lots of files sometimes uploads them all, sometimes only a few. Also, there are users who are dragging massive folders from their windows desktop which crashes the browser. \nAlso, non-technical users not understanding why IE does not support it at their work, but at home they can do it in Chrome.\nI would rather just disable the feature.\n. interesting comment you made about directory D&D potentially being dropped (https://github.com/Widen/fine-uploader/issues/1217)\nsounds like we just need to live with this for now. Thanks.\n. http://cdn.meme.li/instances/500x/53286848.jpg\n. yes, sorry - display.prependFiles needs to be set to true\nupdate === newly submitted file.\nupload tray === qq-upload-list\n. yeah, i had debug set to true, couldn't see anything funky happening. Seemed like a race condition. Happens when the submitted file count gets to ~20-30\n. yeah, i had debug set to true, couldn't see anything funky happening. Seemed like a race condition. Happens when the submitted file count gets to ~20-30\n. hmm... strange. Is this project using Angular or similar ?\n. Right. I wonder if when using some sort of templating engine the delay in updating the UI is enough to cause this. Our UI is pretty complex, many UI fragments, uses Angular, lots going on etc etc. We may just be an edge case though.\n. Hi Ray\nI have since changed companies and am no longer using Fine Uploader day to day. I don't remember seeing this issue with the latest version we were using, though I can not 100% verify this.\nGood luck.\n. Hi Ray\nI have since changed companies and am no longer using Fine Uploader day to day. I don't remember seeing this issue with the latest version we were using, though I can not 100% verify this.\nGood luck.\n. gah .. saw your comment after i edited.Thanks\n. ",
    "kevincampanella": "Hello,\nNo, I just have a single button, and I am setting the camera option to be the default, like this:\nvar $fub = $('#fine-uploader-basic', view);\n        this.uploader = new qq.FineUploaderBasic({\n            button: $fub[0],\n            request: {\n                endpoint: '/upload'\n            },\n            camera: {\n                ios: true,\n            },\nWith the above, an exception ends up being thrown in _handleCameraAccess due to optionRoot being null. Hopefully that makes sense, but let me know if it is still not clear.\n. 4.0.3\n. Thanks!\n. ",
    "luetn": "I would like to define each image of a exercise program in an ipad or desktop setting\n\nOne uploader and many images\nWhen i would like to replace an image with dragNdrop it is nessecary to know which image has to be replaced\n. Just noticed that it is not possible to dragNdrop on iPad\nis it ok to javascript\n$('.jquery-wrapped-fine-uploader').fineUploader({\n($({class}).fineuploader\nand during the session there will be hunderts of images\ncool would be to tap an image on iPad an the upload just shows in a modal dialog or what ever\nnot aside or underneath the image\n. ",
    "pierre-b": "+1 !\nIt is very important to resize pics on the client side to boost the upload process, mostly when the user sends a whole folder.\nWhat I would need are options like this:\n- resize: true/false\n- maxWidth: 960 (in px)\n- maxHeight: 960 (in px)\n- type: jpg/png\n- (optional) quality: 70 (in % for jpg)\nIt can also be useful to do multiple resizes on the client side (for thumbnails), options could be an array like this:\n[\n{name: \"small\", maxWidth: 100, maxHeight: 100, type: \"jpg\", quality: 70},\n{name: \"medium\", maxWidth: 500, maxHeight: 500, type: \"jpg\", quality: 70},\n{name: \"large\", maxWidth: 960, maxHeight: 960, type: \"jpg\", quality: 100}\n]\n. Ok, maybe this repo could interest you for doing this: https://github.com/blueimp/JavaScript-Load-Image\nBy the way, parsing EXIF is a must-have, the app I'm writing just now is kind of social network where location beside photos is very important. Thanks guys.\n. Actually I don't want to upload the original photo, just the resized one to save bandwidth and uploading time.\nDoes your resize function keep EXIF datas in resized photos ?\nIn anyway I will re-parse EXIF datas on server-side to support old browsers, so uploaded photos (resized ones) have to hold EXIF datas (location, orientation, date).\n. Ok great, if it's too complicated to re-add EXIF datas in resized photos, maybe it's simpler to give them all (not only the orientation) via the API and bind them in a json object along the request.\nSending resized photos only (with EXIF) is also critical on a mobile phone. Thank you for your help.\n. Hi Fine Uploaders team, as Im currently integrating the uploader into my app Im wondering when the resize feature will be implemented ? do you have any good news for us please ?\nthanks\n. Thx for the news, could you please confirm the resize with exif support will be in 4.4 and the average release date of it ?\nIf you cant confirm it, could briefly tell me how to implement it my own way please? Im wondering if buying a licence today was a good idea...\n. I fully understand your point of view, if you can do it it's nice, if you can't I still have to do it  :) unfortunatly people on earth don't all have fast bandwidths, moreover on mobile phones.\nSo, could you please tell me briefly how to implement this feature in the Fine Uploader workflow with an extra dependency ? With EXIFs datas in the request body to keep it simple.\nMaybe for a first version of this feature you could just provide EXIF datas aside and not inject them in resized pics.\nThank you\n. Thank you for your reply, will show you the result when the app will be in beta ;) Have a nice week.\n. ",
    "Eventect": "+1 on this feature. @rnicholus, I understand that this feature is behind others in your list, but bear in mind that jquery-file-upload already implements it and it comes for free... While your S3 direct upload approach is much clean than that of jquery-file-upload, at least this is my opinion, there is no much point in switching and paying for the licence as per today. I bought a licence but I overlooked the presence of this feature, unfortunately.\n. Terrific!\n. ",
    "wavetronz": "Thumbnail creation is a core feature for file uploaders (especially ones geared towards images).  Since most javascript-jquery lightboxes are built for thumbnail galleries, likewise, mainstream uploaders should contain thumbnail creation capabilities.  Pre-packaged lightboxes usually include examples with thumbnails that are 75x75 pixels and 3-5 KB.  If a fileuploader does not have easily accessible and customizable \"server side\" thumbnail saving, the uploader is not suitable for mainstream use.\nThumbnail-based Lightboxes\nPrettyPhoto\nMagnificPopup\nBlueimp's Lightbox Image Gallery\nBlueimp's Jquery Fileuploader comes with php and node.js server scripts with built-in thumbnail creation.  End-users can simply change directory locations by editing a few lines of code.\nBlueimp's UploadHandler.php has the following code for unsized image directories:\n'upload_dir' => dirname($this->get_server_var('SCRIPT_FILENAME')).'/files/',\n'upload_url' => $this->get_full_url().'/files/',\nFurthermore, end-users can uncomment two lines to start creating thumbnails in a specified location:\n'thumbnail' => array(\n// Uncomment the following to use a defined directory for the thumbnails\n// instead of a subdirectory based on the version identifier.\n// Make sure that this directory doesn't allow execution of files if you\n// don't pose any restrictions on the type of uploaded files, e.g. by\n// copying the .htaccess file from the files directory for Apache:\n//'upload_dir' => dirname($this->get_server_var('SCRIPT_FILENAME')).'/thumb/',\n//'upload_url' => $this->get_full_url().'/thumb/',\n// Uncomment the following to force the max\n// dimensions and e.g. create square thumbnails:\n//'crop' => true,\n'max_width' => 80,\n'max_height' => 80\nIn node, the options are in one segment at the top of the code:\noptions = {\ntmpDir: __dirname + '/tmp',\npublicDir: __dirname + '/public',\nuploadDir: __dirname + '/public/files',\nuploadUrl: '/files/',\nmaxPostSize: 11000000000, // 11 GB\nminFileSize: 1,\nmaxFileSize: 10000000000, // 10 GB\nacceptFileTypes: /.+/i,\n// Files not matched by this regular expression force a download dialog,\n// to prevent executing any scripts in the context of the service domain:\ninlineFileTypes: /\\.(gif|jpe?g|png)$/i,\nimageTypes: /\\.(gif|jpe?g|png)$/i,\nimageVersions: {\n'thumbnail': {\nwidth: 80,\nheight: 80\nPlease, please, please add the following easily accessible features to the upload scripts:\n$unsized_image_dir = 'files/unsized/';\n$thumbnail_dir = 'files/thumb/';\n$max_width_unsized = $native_image_width;  //can be restricted with int value\n$max_height_unsized = $native_image_height;  //can be restricted with int value\n$max_width_thumb = 75;\n$max_height_thumb = 75;\n$max_file_size_unsized =  10000000000;\n$accepted_file_types = array('jpg', 'jpeg', 'jpe', 'gif', 'tiff', 'tif', 'bmp', 'png');\n//available values txt, pdf, exe, jpg, etc. etc. etc.\nAlso, pierre-b is talking about something similar but different.  He wants to re-size images client side and then upload them, resulting with one scaled down image.  I am looking to upload images and then re-size them server side, resulting with two separate images for every image uploaded (a normal size and a thumbnail size).  I like large images in which users can click on to enlarge, similar to Imgur.  I also need the thumbnails for my image gallery.\n. You're right.  I can post this to fine-uploader-server if you like..\n. That's fine.  I think it would be awesome if the upload scripts could have these additions.  I like fineuploader more than Blueimp's Fileuploader because of the speed.  I have found that Blueimp's is a bit laggy since I have a slow computer.  Most pro programmers probably have fast computers and don't realize when something is minorly slow.  Anyway, I would more than happily pay the license fee if these things were added.  Currently I lack the experience to write the code myself.  Thanks.\n. ",
    "daniellwu": "Hello!  I was the user that posted this bug on stackoverflow (http://stackoverflow.com/questions/20230916/cannot-change-totalfilesizename-and-uuidname).  I see you wasted no time in tackling this!  Awesome :)\n. ",
    "bikash8gupta": "I am using fineuploader version 3.8.2\n. ",
    "robbat2": "@feltnerm \nDreamObjects is NOT based on Swift, rather the S3 provided by Ceph's RADOS gateway component.\n. ",
    "markphip": "This is sort of a duplicate of #1025 \nHopefully once you support Rackspace, SoftLayer will be easy to add as well since they both seem to use OpenStack to underly the service.\n. ",
    "mnicolas80": "I am using two different containers for files selection-preview and files progress. In details the steps are:\n1) The user adds files to a \"standby to upload\" html container (div) in a modal window.\n2) When the user clicks on \"upload\" button, I trigger the upload progress and show the progress of each file to another container. Technically, I \"copy\" the preview files list to another div element and using the progress callback, I update each file's progress. Everything works fine!\n3) If the use wishes to select and upload a new different list, when he clicks on \"upload\" button, I \"copy\" the preview list to the progress container. After that the progress status of each file conflicts. In details, the new qq-file-id-0 overwrite the progress of the old qq-file-id-0.  \nThank you\n. Yes, I re-initialize the uploader each time I open the modal. Every time the user wishes to add files, I show the \"preview modal\", which then closes when the user clicks on\"upload button\".\n. Due to html and css customizations it's difficult to provide only this part of code. I am using the version 4.1.1. The most simple implementation could be to use one button for each file in queue. Each button triggers the cancel method of each file:\ne.g.\nbutton-0 -> $('#fine-uploader').fineUploader('cancel',0);\nbutton-1 -> $('#fine-uploader').fineUploader('cancel',1);\nThe first time the buttons actions work (cancel specific files). Then, when I submit file to queue and call:\nqqUploader.fineUploader('uploadStoredFiles');\nthe files are not been uploading. I can cancel the files by clicking on their default cancel trigger (.qq-upload-cancel), but not from the buttons.\nIt looks like the command: $('#fine-uploader').fineUploader('cancel',0);\nconflicts with the upload queue.\n. I am using firebug on FF and seeing the net. Before a couple of days it was working, but now not.\nFor example a file with size 5MB requires on mac shows progress: 5%...20%..53%...100% and after 100% is completely uploaded. On windows it shows 1%...40%...100% in 2 seconds (which is impossible) and the network console still sends binary data on server.\n. Supposing that I need to upload multiple files. If the itemLimit is 2, the library will not allow me to select more than 2 maximum files, which is correct. For some strange reason, if one of the files is uploaded, I cannot add 1 more in queue. The library keeps that I always have 2 files in queue.\n. Yes! I have submitted 1 file and another file is stand-by. So, I should be able to send 1 more file, but the library keeps/stores that I have reached my limit (2).     \nHere is my code:\nvar qqUploader = $('#fine-uploader').fineUploader({\n        callbacks: {\n            onProgress: function(id, name, sent, total) {\n            },\n            onComplete: function(id, name, response) {\n            },\n            onCancel: function(id, name) {\n            },\n            onUpload: function (id, fileName) {\n                var Params = {\n                    param1: \"aaa\",\n                    param2: \"2222\"\n                };\n                this.setParams(Params);\n            }\n        },\n        element: document.getElementById('fine-uploader'),\n        request: {\n            endpoint: 'upload.php'\n        },\n        validation: {\n            allowedExtensions: ['jpeg', 'jpg'],\n            sizeLimit: 1024,\n            itemLimit: 2\n        },\n        maxConnections: 1,\n        autoUpload: false\n    });\n. In your example, select 3 files and try to add a Upload button (to trigger the uploading manually) and set the maxConnections = 1, you will see:\n1) The first file in queue will be uploaded (which is correct)\n2) Then will start the second file.\nSo, 1 file is uploaded, 1 is being uploaded and 1 waits to be uploaded. Practically, I should be able to select and upload 1 more file, because my queued files are 2 and this number is less than 3 (itemLimit).\nIt seems that the library does not remove the uploaded files from the total selected files array.\n. ",
    "afurculita": "To obtain the same experience that a contenteditable div offers we have to apply more CSS on the text input file. \nAlso i think we'll not need anymore qq.FilenameClickHandler if we have a contenteditable div.\n. ",
    "leipnik": "I just answered my own question. I had been building the S3 uploader, which was causing the problem. The full stack example requires the traditional uploader. \n. ",
    "alexington": "Ah, good to know.  Sorry for any confusion and thanks for the update.\n. ",
    "kfonce": "I have the same issue, I'm using jquery fineuploader version 4.1.1 in core mode with autoUpload set to false.\nIf I look at the uploadStoredFiles function it seems to me fineuploader tries to start uploading files with an id that has been cancelled and thus is not available in the _uploadData array.\nCode for the instantiation of the fineuploader:\njs\n$('#uploader-container').fineUploader({\n    uploaderType: 'basic',\n    debug: true,\n    chunking: {\n        enabled: true\n    },\n    button:  $(\"#uploader-btn-select\"),\n    request: {\n        endpoint: '/attachment/upload',\n    },\n    extraButtons: [{\n        element: $(\"#uploader-btn-select-text\")\n    }],\n    autoUpload: false\n});\nCode for cancelling a file: \n``` js\n$('#uploader').find('button.cancel-file').click(function (){\n    var $fileId = $(this).parents('.file-select-row').attr('qq-file-id');\nvar $file = $('#uploader-container').fineUploader('getUploads',{id: $fileId});\n$('#'+$file.uuid).fadeOut();\n\n$('#uploader-container').fineUploader('cancel', $fileId);\n\n\nif ($('#uploader-container').fineUploader('getUploads',{status: qq.status.SUBMITTED}).length === 0) {\n    $('#uploader-drop-area-text').prop('hidden', false).show();\n    $(\"#uploader-btn-select-text\").prop('hidden', true).hide();\n    $('#uploader-btn-upload').prop('disabled', true);\n}\n\n});\n```\nCode for uploading the submitted files:\njs\n$('#uploader-btn-upload').click(function() {\n    $('#uploader-btn-upload').prop('disabled', true);\n    $('#uploader-container').fineUploader('uploadStoredFiles');\n});\n. First I should say that I'm using the manual triggered upload (autoUpload set to false).\nNo I'm not trying to upload a cancelled file. I'm just trying to upload the submitted files by clicking the 'upload'-button. But before I start the upload I have cancelled, one or more, queued files.\nAs said the cancelling of the files works just fine (I think), because the console replies with the cancel message:\n[FineUploader 4.1.1] Cancelling 2\nBut as soon as I hit the upload button to initiate the uploads fine-uploader crashes when it encounters the cancelled IDs and gives me the error\n[FineUploader 4.1.1] 2 is not a valid item ID.\nThis error is caused because I have passed the ID of the file-to-cancel as a string. If I pass the ID of the file-to-cancel by taking it of the File Object, and the ID is thus a proper int, then fine-uploader reacts just fine.\nI hope its clearer now.\n. Yes true, but if you take the file id of the qq-file-id attribute it returns a string not an integer which can cause misunderstandings. \nIt did with me at least because I used the API methods and was still running into errors which I couldn't account for.\nMaybe a clearer error message can do the trick...\n. I'm not using the Fine Uploader UI but I'm running Fine Uploader in core mode and I added the qq-file-id attribute myself.\nI just expected this to work, getting the id of an attribute and passing int on the the Fine Uploader cancel method.\nI was not aware that retrieving the id of an attribute returned it as a string instead of as an integer.\nThe error message also didn't help to spot the error.\nThat's also why I thought it was a Fine Uploader error see #1083\n. An error stating the proper ID type is not passed would have helped me a lot.\nFor me this would be a good solution to the problem.\n. ",
    "dlin-me": "Hi, this may be relevant.\nI just found that the 'cancel' method does not clear the 'file list' stored internally. \nYou can replicate the problem by \n1. try upload a file\n2. before finish, cancel it\nif you call getUploads again, it will still show you the canceled file in the list\n. ",
    "chasevida": "This confused me somewhat as well. I thought when using cancel or delete that the file would be removed internally. So when I called uploadStoredFiles(), in order to get the id of the file selected, I was surprised to see all previous selections.\nFiltering through this list by status checking for cancelled cleared some of the confusion. I came across this thread while working through a related issue, specifically when multiple is set to false, it is still possible to upload multiple files. Hence when I was checking the uploadStoredFiles I wasn't sure why there was more than one listed. . ",
    "paulmelnikow": "Thanks!\n. Sounds good, thanks! That's unfortunate about chunked uploads.\nRegarding this:\n\nNote that you don't need to include any key-determination logic client-side, if you don't want to. The objectProperties.key option accepts a promissory function as a return value. This is most appropriate if you want to delegate key name determination to your server, via an ajax request.\n\nThat's a great point, thank you. I like letting the server specify the key.\nIt reminds me of another enhancement I'd really like, which is that the client pull the key from the signed policy. I'll open a separate issue.\n. I though the policy was just base64-encoded \u2013 am I getting that wrong?\n. Thank you! This is great!\n. Hi there,\nThis is working well when <ExposeHeader>ETag</ExposeHeader> is set on the bucket's CORS policy.\nWhen that value is not set the upload completes normally, but this message appears in the console:\nRefused to get unsafe header \"ETag\" s3.jquery.fineuploader.js:6995\nqq.extend._getEndpointSpecificParams s3.jquery.fineuploader.js:6995\nqq.nonTraditionalBasePrivateApi._onComplete s3.jquery.fineuploader.js:6626\nqq.uiPrivateApi._onComplete s3.jquery.fineuploader.js:4744\nqq.extend._onComplete s3.jquery.fineuploader.js:8870\noptions.onComplete s3.jquery.fineuploader.js:2041\nuploadCompleted s3.jquery.fineuploader.js:8392\n(anonymous function) s3.jquery.fineuploader.js:8327\n. If you don't need the ETag, is the console message expected?\n. Understood, thanks!\n. I should add: I had assumed Fine Uploader would always use HTTPS. I only noticed it didn't after I deployed to an SSL staging server, and Firefox (though not Chrome or IE) declined to upload, complaining about mixing secure and unsecure items.\nSo, it seems defaulting uploads to SSL \u2013 or at least matching the scheme \u2013 might also be more compatible.\n. Sounds great. Thank you!\n. Cool, thank you.\n. Awesome!\n. Ah, thanks for that!\nThe server I wrote doesn't handle chunked uploads at all. I don't need it immediately but would like to add it at some point. Probably the same is true of other integrators: some will need chunking; others will leave it off.\nStill, thanks for considering this for a future release. There's still a benefit for the integrator who only uses non-chunked uploads, which is that I can easily authenticate the success requests without storing any extra state information on the server, building an extra server endpoint, or requiring extra client configuration.\n. Hi Ray, it's your call of course, but I'd offer my thoughts.\nIf there are cases that don't work without SSL, maybe you can post something in the release notes, bringing people's attention to a breaking change which makes things secure by default, and noting the integrator can override the scheme in the endpoint. Though they'll take an extra step during the upgrade, they'll notice that the upload isn't using SSL.\nThere are a lot of good reasons to use it, and getting even 75% of integrators converted would be a big gain.\nI'm curious about the root cause in this case, if it's not a subdomain. Maybe certain browsers?\nI presume SSL doesn't work with a CNAME because the certificate domain doesn't match. I can see why integrators might want to use a custom domain name to download public files, but I would think they'd prefer to use the stock URL for their uploads if it gave them SSL for free.\n. Another possibility: it looks like HTTPS doesn't work when the bucket name contains a period, though here's a good explanation and workaround.\n. ",
    "atistler": "I need this because I want to have a select box that allows the user to set the canned ACL for the s3 upload.  I added:\nqq.basePublicApi = {\n    setACL: function (acl) {\n      this._options.objectProperties.acl = acl;\n    },\ngetACL: function () {\n  return this._options.objectProperties.acl;\n},\nStill need to test this.\n. ",
    "morgunder": "could you add this to the docs so its clear how to use it?\n. oh - yeah.  totally obvious now :)  thx\n. can you remove the main block from the dom while you\u2019re doing the manipulation and then put it back at the end?  sometimes that\u2019s the easiest way to speed up dom math.\n\nOn Sep 14, 2015, at 4:25 AM, Korijn van Golen notifications@github.com wrote:\nJust tested that; you are correct. It does look like that is going to be tough. :/\n\u2014\nReply to this email directly or view it on GitHub https://github.com/FineUploader/fine-uploader/issues/1466#issuecomment-139997584.\n. i had a function that recalculated things and reapplied classes on a couple of hundred elements and it was slow.  then i found a few articles that said that i should detach the dom element manipulate it then reattach it once i was done.  this sped up that function considerably.  i forget the exact amount, but at least 2x and maybe 5x.  \n\nsome other articles on that basic concept\nhttp://desalasworks.com/article/javascript-performance-techniques/ http://desalasworks.com/article/javascript-performance-techniques/\nhttps://learn.jquery.com/performance/detach-elements-before-work-with-them/ https://learn.jquery.com/performance/detach-elements-before-work-with-them/\n\nOn Sep 14, 2015, at 12:16 PM, Ray Nicholus notifications@github.com wrote:\nWhat, specifically, are you looking to temporarily remove from the DOM? Fine Uploader looks for elements given a reference element. That reference element is usually the file list container element - .qq-upload-list-selector. It does not use document as a reference element after the template has been initially rendered. So, that seems like it would work without issue.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/FineUploader/fine-uploader/issues/1466#issuecomment-140128997.\n. excellent news.  while i agree that this is the extreme case, i think that the end result will be much more polished feel for even the single file case.  its rare that you have a chance to streamline the DOM for your layout.  you might end up dropping a few elements and possible finding how to do some of the js logic in pure css for even more wins.  as i was looking at some of your samples, i wondered if making a version with font awesome icons vs the images you are currently using.  a switch to refer to fa fa-trash may make it possible to make all your buttons be one element vs two plus save on the img download entirely.  didn\u2019t try to prove it would be much faster.  but maybe someone can shed some light on this or other other performance tweaks.\nOn Sep 15, 2015, at 12:02 PM, Ray Nicholus notifications@github.com wrote:\nI spent an hour yesterday investigating further. I was able to reproduce the issue. I'm using a Macbook Pro late-2014 model w/ 16 GMB RAM, i7, etc, etc. I setup my endpoint to return an initial file list of 3000 entires, consisting solely of name and uuid properties. Initial load of the list took about 10-15 seconds. During this time, I was able to scroll, but the browser did not respond to any other actions.\nUsing Chrome's profiler, I identified a huge number of calls to qq.getByClass. These calls seemed to account for the bulk of the work. I ultimately identified 4 issues here:\nToo many DOM elements\nEach file entry in the DOM is made up of at least 20 elements. If the initial file list consists of 3,000 entries, this means 60,000 extra DOM elements! That is a huge number of elements, and this will likely have a noticeable perf impact on most selectors. Putting performance aside, you can't expect your users will want to scroll through 3000 files. IMHO,* your initial files endpoint should never return anything close to 3000 files*. Instead, consider providing a small subset of these files. If you really expect your users to page through all of the files, you should return them in pages. I realize this is not very easy with the current API, but this could be much easier if I added an API method that allowed you to either add more initial files to the list. You could then pull the first set on load via Fine Uploader's built-in code, and then request subsequent pages yourself on-demand, passing these into the new API method for Fine Upl oader to render.\nToo many elements selector calls\nFor initial file added to the list, there are perhaps a dozen calls to the document to select various parts of the file or file list. For a \"normal\" amount of files in a batch, this is likely not an issue. But at scale, this has to cause noticeable perf consequences. The best solution to this is probably to determine when we are handling a batch of files, and maintain a cache of file IDs to file HTML elements. The internal templating module selectors can grab from this cache instead of hitting the DOM. This cache will be cleared after we are done processing the batch.\nInefficient element selectors\nThere were quite a few calls like this: fileListEl.querySelectorAll('.someClass')[0]. All we want it the first match, but instead we are querying for all matches and throwing all but the first away. A simple fix would be to use fileListEl.querySelector('.someClass') instead.\nTo many page reflows/repaints\nIn a batch of 3000 files, each file is added to the DOM separately. This results in a huge number of reflows/repaints, which is a perf issue. Instead, perhaps the code can be adjusted to build up this list of file elements detached from the document, and then add the entire batch at once when we are done processing the batch of files.\nI am working to make the changes described above now. This will be a bit of work, but progress will be reported here as it happens. After all of the changes are complete, I'll make a new pre-release available for testing.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/FineUploader/fine-uploader/issues/1466#issuecomment-140442980.\n. \n",
    "mythodeia": "i am facing the same issue with @mnicolas80 \nbut i have determined that disabling avast antivirus makes the fineuploader work without issues.\nWhen i have it on the progress is messed up.\nI am also on windows 7 64bit.\n. ",
    "KRTac": "Oh, ok...I understood the documentation wrong. I'll make the corrections in my wrapper code. Thanks\n. Well, getInProgress() is documented as \"Returns the number of items that are either currently uploading or queued.\" So I assumed that if I submitted 4 files and ran getInProgress() it would return 4, since 4 files are queued.\n. Great. No more confusion now. Thanks\n. Oh...ok. I'll try to look into it myself tonight. It's a pretty bit problem for me because I'll have to do nasty workarounds if this doesn't work properly.\n. I'm making a custom upload UI and I want to determine if uploading is in progress when I add new files to the list of files that are currently uploading.\nNow uploading functions as follows: if I add files and start the upload process (uploadStoredFiles()) and then I again add files while the original files are still uploading, the newly added files won't be included in the upload queue and when the old files are done uploading, the new files will still be there. I want to detect if uploading is in progress. Now, I realize that there's the getInProgress() method, but it also doesn't work as described since it returns 1 (it count's only the files that are currently uploading) even though the queue contains more files.\nNow, I'll use this method for my implementation, but it's still a bug and I think it should be addressed.\n. I'm not able to get to the code ATM. I won't be able to check it till tomorrow.\n. Great, thanks for the quick response.\n. Now it works as expected. Thanks for the quick fix.\n. Is there any other way to add a file to the upload queue?\n. I add files with addFiles() to the uploader. I run uploadStoredFiles() and then I run addFiles() again while the previously added files are uploading and I want to add the new files to the upload queue so they begin uploading automatically after the original files are done.\nCould I maybe temporarily enable autoUpload and then disable it after all the uploads are done?\n. Because I don't want the files to be uploaded automatically.\n. If currently uploading is in progress newly added files should be added to the upload queue.\n. https://gist.github.com/anonymous/69c5f6d51ee5d60bb988\nAs I already said, I don't want to upload files automatically, but if files are being uploaded and other files are added to the uploader, then add the new files to the upload queue so they can also be uploaded.\n. ",
    "EZWrighter": "To follow up on that stack overflow post, it's not just important that the mapping is done before this, it's critical for any decision tree that uses the context of the button to decide if the upload submission is valid. \n. form input check combined with button choice.\n. Not a problem, I just adjusted your library and moved the button assignment into the upload event.  That seems to fix the issue for now and really shouldn't change my usage after a fix.\n. Thanks for the responses, so there are a few questions for me here.  \nFirst, I would define an 'upload' event to be after the upload has been submitted and confirmed and the first bit of data is beginning transfer.   I don't really see a use for this event if it can be triggered at such weird times as you define.  What good is it if you don't understand why the event was triggered. \nSecond, my use is around loading in dynamic data and changing the UI after the upload has commenced.  It's a one time process per upload, no matter how many times they pause/resume.\nI have worked around this bug by tracking current uploads outside your tool and skipping the init phase if it is already uploading.\nI would suggest you update documentation for clarity and rework this event to make it useful.  I doubt anybody actually uses it the way it is now.\n. Hmmm, all those cases seem like resumes...and you already have an event for that.\n. Ahh, then I would agree, a flag giving context to the upload event would probably be the most flexible and resolve my use case.\n. Personally, I would have preferred the events to be abstracted out into logical ones: uploadStarted/uploadCompleted, pause/resume, failed/retry.  Those are all things an application developer can use to take action on.   Right now you have a lot of event meaning overload that is very internal to the workings of your tool and obtuse to application layer developers.  I understand not wanting to have breaking changes,  but hopefully providing food for future thought :-)\n. Can this be re-opened to actually take care of the original posters issue?  Retry count should reset upon success.  I would say that is pretty standard upload behavior that I have experienced in the past for uploading.  There could be all kinds of reasons for network failure, but once the failures have stopped and you get a successful chunk or file uploaded, the old retry count is irrelevant.  You could even add it as a config option but I doubt anybody really wants continuous retry count.\n. The optimal solution from my perspective would be to have a setting be for minimum/default chunk size that is used for all files, unless that would cause more than 10000 parts to be created, then the chunk size would be file size / 10000.  The chunk size would get stored locally for resume.  This would be very similar to your second suggestion.. I took a look through that code, but not familiar enough with it to make code changes.  Seems like the tricky part would be to deal with chunk size in the persisted state.\nSimple unit test would attempt to transfer a 1MB file to Amazon S3 with minimum part size set to 100 bytes, which should break up into a little over 10000 chunks.. I assume any config change to partSize would break uploads waiting to be resumed.  Technically a modification like this wouldn't change partSize from the global configuration unless it was specified differently in localstorage for that specific file.  \nThinking this through,any destination could have a maximum part limit, so each extension of XhrUploadHandler should define this someplace and _getChunkData should use that limit to determine # of parts and actual chunk size if larger than maximum parts.\n. ",
    "Venorcis": "+1 for this feature, would save a request in the case of non-chunked uploads\n. ",
    "simshaun": "The .m2t file is about 12 MB.\nThe .mp4 is about 1 MB.\n. Thank you.\nSo if I understand correctly, the issue lies in our server-side policy generation for chunked uploads. Will take a look and update soon.\n. Perhaps the term I should be using is request signature? I guess that is different from the policy.\nOn the chunked upload, Amazon returns:\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nSignatureDoesNotMatchThe request signature we calculated does not match the signature you provided. Check your key and signing method.50 4f 53 54 0a 0a 76 69 64 65 6f 2f 76 6e 64 2e 64 6c 6e 61 2e 6d 70 65 67 2d 74 74 73 0a 0a 78 2d 61 6d 7a 2d 61 63 6c 3a 70 72 69 76 61 74 65 0a 78 2d 61 6d 7a 2d 64 61 74 65 3a 57 65 64 2c 20 30 35 20 46 65 62 20 32 30 31 34 20 32 30 3a 30 31 3a 32 38 20 47 4d 54 0a 78 2d 61 6d 7a 2d 6d 65 74 61 2d 71 71 66 69 6c 65 6e 61 6d 65 3a 68 75 73 6b 69 65 73 2e 6d 32 74 0a 78 2d 61 6d 7a 2d 6d 65 74 61 2d 75 73 65 72 69 64 3a 31 0a 78 2d 61 6d 7a 2d 6d 65 74 61 2d 76 69 64 65 6f 69 64 3a 31 31 37 0a 2f 64 6f 77 6e 6c 6f 61 64 73 2e 74 68 65 76 69 64 65 6f 65 78 63 68 61 6e 67 65 2e 63 6f 6d 2f 64 31 62 37 38 31 33 34 2d 34 37 64 65 2d 34 31 33 35 2d 62 64 30 39 2d 63 35 61 66 30 65 62 36 32 66 32 66 2e 6d 32 74 3f 75 70 6c 6f 61 64 73B44F8D72CDFCDDEC7jk8aB9YhJqHDr/3AHMLxcp5xZhbZDBWClHEHBWNmlG5EHovszbruGvNzt8wwHq42h/yNQjbtmzmw/rB85Xir8A0S24=POST\nvideo/vnd.dlna.mpeg-tts\nx-amz-acl:private\nx-amz-date:Wed, 05 Feb 2014 20:01:28 GMT\nx-amz-meta-qqfilename:huskies.m2t\nx-amz-meta-userid:1\nx-amz-meta-videoid:117\n/foobucket/d1b78134-47de-4135-bd09-c5af0eb62f2f.m2t?uploadsAKIAIO77RQL4CMEEY2XQ\n```\nStill, you are right, I'm sure. I'll try to fix the server-side code and then close this issue.\n. I found the issue.\nWe have two upload parameters configured in FineUploader:\n1. userID\n2. videoID\nThey are sent to our server as part of the headers for signing like so:\nx-amz-meta-userID:1\nx-amz-meta-videoID:118\nHowever, the headers string Amazon signs to compare with our signature contains:\nx-amz-meta-userid:1\nx-amz-meta-videoid:118\nSolution\nThe solution is to use all lower-case for upload parameter keys. On http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html, they mention that S3 stores user-defined metadata in lowercase.\nThoughts\nWould it be a good idea for FineUploader to automatically lowercase the upload parameter keys in the headers string?\nAt the very minimum, I think it should be documented.\n. Our request.endpoint is set to foo-bucket.s3.amazonaws.com. I'll try explicitly setting the scheme when I get to the office tomorrow.\n. @rnicholus Our bucket does have dots in the name, as a CNAME is setup to point to it.\nSo, that means SSL is the problem here.\nThe following request is shown as aborted in devtools:\n```\nhttps://test.foo.com.s3.amazonaws.com/\nOPTIONS / HTTP/1.1\nHost: test.foo.com.s3.amazonaws.com\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:26.0) Gecko/20100101 Firefox/26.0\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\nOrigin: http://foo.com\nAccess-Control-Request-Method: POST\nConnection: keep-alive\nPragma: no-cache\nCache-Control: no-cache\n```\n. Seems its a Safari issue.\nIt occurs on Win/Safari 5.1.7 and Mac/Safari 5.1.10.\nI tested on Mac/Firefox 28, Win/Firefox 28, Win/Chrome 33, Win/IE 11, and none of those browsers have this problem.\n. I understand. For reference, here is our current CORS config (domain intentionally masked):\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CORSConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n    <CORSRule>\n        <AllowedOrigin>http://foo.com</AllowedOrigin>\n        <AllowedMethod>POST</AllowedMethod>\n        <AllowedMethod>PUT</AllowedMethod>\n        <AllowedMethod>DELETE</AllowedMethod>\n        <MaxAgeSeconds>3000</MaxAgeSeconds>\n        <ExposeHeader>ETag</ExposeHeader>\n        <AllowedHeader>*</AllowedHeader>\n    </CORSRule>\n</CORSConfiguration>\n. Yes, we are still investigating the root cause. Still, I think the retry count should be reset after each chunk succeeds. Perhaps this is a feature request more than a bug report.\n\nRegarding the root cause, we just tested uploading nine separate 6GB files in Chrome and it didn't trigger that error even once. Firefox, however, is exhibiting the error quite frequently.\nI'm inclined to think this is an issue with Firefox, but I don't yet know how to tell if it's the browser itself or an issue with the code.\nDo you think there may be any part of FineUploader, chunking maybe, that could be leading to this problem only in Firefox?\n\nAdditional clues:\nThese errors begin occurring frequently when more than once file is being uploaded at once (multiple browser tabs, each uploading a file).\n. I've reproduced this error 5/5 times on two different PCs under two different ISPs/networks. Mine at our office, and through a VPN to a PC at our client's office.\n- Both PCs are running Win 7/Firefox 28.\n- For consistency, we are attempting to upload the same 1 GB file on both PCs.\nTo reproduce, we:\n1. Open an S3 upload page 3 times (3 different tabs). Chunked uploads enabled, Retry enabled (10 times max)\n2. Choose the 1 GB file on each page so that all 3 tabs are uploading at the same time.\n3. Wait. We sometimes begin seeing retries near the beginning of the upload, sometimes it takes a few minutes. It always happens eventually.\nUpload speed does not appear to have any effect. Our office connection is a meager 5 MB/s upload, but it errors. Our client's upload speed is pushing 800 MB/s, it errors as well.\n. FineUploader 4.3.1\n. We are receiving the error intermittently today just trying to upload a single file.\nSo, I've been researching the 400 RequestTimeout problem, and it seems we're definitely not alone in having this issue.\nhttps://github.com/aws/aws-cli/issues/454\nSolution: They just retry upon receiving 400 RequestTimeout.\nhttps://github.com/aws/aws-sdk-php/issues/29\nSolution: They just retry upon receiving 400 RequestTimeout.\nAdditional clue: If you continue to see this issue, please ensure that you are not sending an incorrect Content-Length header in your requests.\nhttps://groups.google.com/forum/#!msg/jets3t-users/_jr_8VXzSWU/3EWPjwrUoaYJ\nAdditional clues: S3 is pretty unforgiving about pauses during an upload and will return\nan error within a few seconds. But the most likely problem is simply an incorrect Content-Length value.\nhttp://www.plupload.com/punbb/viewtopic.php?id=3909\nNo solutions offered, but does give a little insight in to potential problems with Firefox.\n. The install of Firefox we are testing on at our client's office is a vanilla install. The only extension installed on it is Firebug.\n. That is fairly interesting. We disabled Firebug and are utilizing Firefox's built-in developer tools now.\nPerhaps it's coincidental, but whereas we were getting roughly 20-30 errors per upload (uploading 3 files at once) before, we only had at max 2 errors on the same files with Firefox disabled. We're still testing with additional batches of uploads to find out if this remains true, and I'll update when we find out more.\n. I think you've hit the nail on the head about Firebug.\nWe've uploaded 4 batches of 6 GB files (3 uploads at a time in each batch) with Firebug disabled. The first one is described in the comment above. The next 3 batches all completed without error.\nTried a 5th batch with Firebug re-enabled and the errors began appearing again. Waited until each upload hit 30 errors at only ~20% through and disabled Firebug again. Uploads quickly finished successfully without another error. This is definitely not a FineUploader issue as far as I'm concerned.\n\nWe are receiving errors in IE9 as well. Log from IE9 console:\nLOG: [Fine Uploader 4.3.1] Received 1 files or inputs. \nLOG: [Fine Uploader 4.3.1] onSubmit - waiting for onSubmit promise to be fulfilled for 0 \nLOG: [Fine Uploader 4.3.1] onSubmit promise success for 0 \nLOG: [Fine Uploader 4.3.1] Submitting S3 signature request for 0 \nLOG: [Fine Uploader 4.3.1] Sending POST request for 0 \nLOG: [Fine Uploader 4.3.1] Sending upload request for 0 \nLOG: [Fine Uploader 4.3.1] Received response for 0_17574c5e-5bee-4e8c-a8f3-8070f9281507 \n[Fine Uploader 4.3.1] Error when attempting to access iframe during handling of upload response (Access is denied.)\nLOG: [Fine Uploader 4.3.1] iframe loaded \n[Fine Uploader 4.3.1] Amazon likely rejected the upload request\nUsing Fiddler2 to inspect the request, we see the response from Amazon:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error><Code>MalformedPOSTRequest</Code><Message>The body of your POST request is not well-formed multipart/form-data.</Message><RequestId>5363D49F5B3E1150</RequestId><HostId>tyUziamtbIKB30oMbY+AVDeaDg4lL5vkr+r5AGeanX0fme/rWbUJhXRiwGI9lAHI</HostId></Error>\nIE9 succesfully uploaded a 1GB file then 2x 1GB files at once. It fails consistently with a 4.5GB file. Should I open a new issue for this?\n. Thanks for sticking with me through this.\nYou are correct. It appears IE9's upload limit is 4 GB per http://blogs.msdn.com/b/ieinternals/archive/2011/03/10/wininet-internet-explorer-file-download-and-upload-maximum-size-limits.aspx\nI think information like that would useful in the FineUploader docs, even though it's not really your responsibility. Would you consider it?\n. Happens in Win/Firefox 56 as well.. ",
    "jamessharp": "Yep - removing the line fixes the issue, and yep I'm using fine uploader core rather than the UI (I've got quite a complex web app)\n. I don't know what the deep cause of the problem is but this is what was happening:\nIn this function in handler.base.js\n``` javascript\nfunction determineHandlerImpl() {\n        var handlerType = namespace ? qq[namespace] : qq,\n            handlerModuleSubtype = qq.supportedFeatures.ajaxUploading ? \"Xhr\" : \"Form\";\n    handlerImpl = new handlerType[\"UploadHandler\" + handlerModuleSubtype](\n        options,\n        {onUploadComplete: dequeue, onUuidChanged: options.onUuidChanged,\n            getName: options.getName, getUuid: options.getUuid, getSize: options.getSize, log: log}\n    );\n}\n\n```\nnamespace is undefined (because the uploader has been initiated as qq.FineUploaderBasic()). This then puts handlerType as qq and (whether this should be the case or not) the S3 build doesn't have \"UploadHandlerTypeXhr\" or \"UploadHandlerTypeForm\" as properties of qq directly. They are however properties of qq.s3\nNot sure if this sheds any light or not...\n. That's fine with me - I've got it patched in my local copy so am happy to wait for 4.4 (though if another hot fix for 4.3 is released I'd appreciate it making its way into that one ;) )\n. ",
    "rushimusmaximus": "I understand that the errors are trying to provide meaningful info for debugging -- certainly better than \"error 7251\"!  I was just trying point out that many end users equate \"Amazon\" with retail shopping rather than a place to store data ;)\nThanks for the props on our site's facelift :)\n. Override options are of course perfectly acceptable too. Thanks!\n. We've been getting reports recently of +5GB files failing too (also with s3/concurrent chunk setup). Unfortunately I haven't been able to personally recreate the issue, after several attempts on multiple browsers. I did get some logs from someone that had the problem that I hope might be helpful. (This is in version 5.1.3.)\n[Error] Failed to load resource: The network connection was lost. (...S3 URL...)\n[Error] TypeError?: undefined is not an object (evaluating 'e.upload')\n_registerProgressHandler (anonymous function) s3.jquery.fine-uploader.min.js 17:5363\n(anonymous function) s3.jquery.fine-uploader.min.js 18:24101\neach s3.jquery.fine-uploader.min.js 15:8058\nsuccess s3.jquery.fine-uploader.min.js 15:12332\nI'm going to keep testing, seeing if I can get it to happen for me.\n. @rnicholus Yeah, I figured you'd say that ;) We're releasing an update with to 5.5 \"real soon now\". The line numbers might not be helpful to yo, but I was hoping the general error might provide some insight. Basically it seems like this may happen when there are network errors. I wasn't able to reproduce this today, but am in contact with someone who thinks they can do it reliably, so I'm going to work on getting you some better information.\n. ",
    "kevinrjones": "Would you like me to create a pull request for this, or for a quick change like this would it be simpler for you to update master?\n. ",
    "NickJorens": "Just came across this, this would be great for my project. I'm currently implementing this as something custom. I'd love to see this in fine-uploader. ",
    "LordFingle": "I have referred this to Amazon and they have acknowledged this as a problem.  So although your multipart encoded POST request is correctly formed, it won't work with the policy setting.  Their suggestion was to only use PUT.\nIf we want to use fineuploader it looks like we can't force clients to add the encrypt header on upload.\nI will update this issue if Amazon changes the behaviour.\n. Sorry, I no longer have access to the support issue or fineuploader (change\nof employer)\nOn Sun, Aug 14, 2016 at 2:22 AM, Ray Nicholus notifications@github.com\nwrote:\n\nAny idea if this has been fixed by Amazon yet?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1147#issuecomment-239629062,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACdWMjS9P7K2THdx54euqMiZGNwigP1tks5qfe84gaJpZM4Bk6cF\n.\n. \n",
    "sebastianzebrowski": "Directory/folder of file where it will be stored on S3.\n. ",
    "deanpcmad": "Ah, didn't realise there was a custom headers option, will try it.\n. ",
    "max-mykhailenko": "I already use code like you wrote, but I think that height style can improve code of another users. If another users asked similar questions  \u2013 just add this code. Thanks! \n. If I find good way to improve this solution, I will add it to comments.\n. +1\n. ",
    "bashu": "for now I just patched fineuploader.js:\njavascript\n/* globals qq */\nqq.supportedFeatures = (function () {\n...\n        folderSelection: supportsFolderSelection,\n        imagePreviews: false, //supportsImagePreviews,\n        imageValidation: supportsImagePreviews,\n        pause: supportsChunking\n    };\n}());\n. Well, what I want is to show thumbnail for uploaded image (server responds with thumbnailUrl).. right now uploader shows preview and then thumbnail from server response and it looks ugly:\n\nand then\n\nI would prefer to show placeholder image until response arrived..\n. ",
    "engagingcomms": "Has anyone done this before / have some sample code? As I have no idea :)\n. In particular with Google App engine you can't save locally at all, has to be direct to storage. \n. Yes that would be ideal. Upload to a Google Bucket with a unique file name, then return that filename to the Google APP. Not to sure where to start though. \n. Nice one cheers. \n. That would be awesome. The Google APP engine doesn't allow you to store directly to server so this would be a very valuable script.\n. I would be, do you have a working php sample I could try? \nR\n\nOn 7 Jan 2015, at 8:09 am, Ray Nicholus notifications@github.com wrote:\n@kngtr Have you downloaded 5.1? If so, are you interested in using it to upload directly to Google Cloud Storage?\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "kngtr": "Hi - How can I get a copy of the pre-release of 5.1.0?  Thanks.\n. Thanks rnicholus.  I will download and give it a try. \n. Not yet.  Hopefully I will let you know next week.\n. Ray - I gave a quick try this morning and ran into 'Invalid policy document or request headers!' error.  I  already replaced AWS-ACCESS-KEY with GOOG-ACCESS-KEY so I will debug more later.\n. ",
    "LusciousPear": "Has anyone tried this lately? \n. +1, I'd like to just exclude all .gifs from resizing. \n. Just adding my $0.02 as an App Engine user, this would be pretty helpful.\n. ",
    "nateweiss": "I was able to make this work (uploading to Google Cloud Storage using their interoperability feature), after making a few minor changes in s3.fine-uploader.js. Let me know if you would like details or a PR, etc.\n. Hi, submitted PR #1674. Feel free to adapt or ignore as needed. \nIf you like I could write up a short list of the steps one has to take on the Google Cloud Storage side to enable the bucket to actually accept the uploads. Basically you have to (1) enable the S3 interoperability feature (easy, it's in the admin console), and also enable CORS (not as easy to find, you have to use their \"gsutil\" command-line tools or enable it via their API). \nOnce those steps are done, the fine-uploader support seems to work fine with the google service. Perhaps there would be some advantage to having a separate GCS-specific module at the same level as the S3 one, but honestly I'm not sure that it would matter for most folks.\n. Hi @aaronjolson, I've typed up some instructions (as markdown), which I am pasting below. Hopefully this helps you get GCS uploads working. Because my PR isn't merged in at this point, you'll need to use my branch to get the couple of very minor changes to the fine-uploader code that are needed . To @rnicholus, I wasn't sure where to add these instructions in the docs, maybe the text below should be added to http://docs.fineuploader.com/branch/master/features/s3.html with an \"alert\" callout in  http://docs.fineuploader.com/branch/master/quickstart/02-setting_options-s3.html that points to the former? Also I wasn't sure if there was a build step needed for doc changes, the Makefile doesn't seem to include that unless I missed it.\nUsing Fine Uploader with Google Cloud Storage\nYou can use the S3 support in Fine Uploader to upload documents to Google Cloud Storage (GCS) buckets.\nThere are three basic steps:\n\nEnable the S3 interoperability feature. \nEnable CORS for your bucket.\nUse the normal S3 support in Fine Uploader to upload files to your GCS bucket.\n\n1. Enable the S3 interoperability feature.\nThis will allow Fine Uploader to communicate with GCS in the same way it normally talks to S3.\nIn the Google Cloud admin, navigate to Cloud Storage > Settings > Interoperability. \nThere you can generate the S3-style developer access key (and corresponding secret key) to provide to Fine Uploader. \nNote that your access key will start with GOOG. \nFor more details about this step, see simple migration in the GCS docs.\n2. Enable CORS for your bucket.\nWithout this step, your user's browser will refuse to post information to GCS due to the same-origin security policy.\nAt the time of this writing, there appeared to be no way to do this step in the Google Cloud admin, \nso you need to enable it using either the gsutil command-line tool or with their XML/JSON API. \nThe steps to take are explained pretty clearly under Configuring CORS on a Bucket in the GCS docs.\nNote that the examples in the GCS docs show granting GET, HEAD, and DELETE, while you want to grant HEAD and POST to enable uploading via Fine Uploader (GET and DELETE aren't needed).\n3. Use the normal S3 support in Fine Uploader to upload files to your GCS bucket.\nNow you should be able to take advantage of Fine Uploader's S3 support to upload files to GCS. \nFollow the instructions in the Fine Uploader documentation as if you were using an S3 bucket, except:\n\n\nFor endpoint in the request option, use storage.cloud.google.com where you see s3.amazonaws.com. \n\n\nFor accessKey, use your GCS-provided access key (starting with GOOG) that you created above.\n\n\nYou still need to implement a signature endpoint on your side to sign upload requests, as discussed here. \nAs you get that set up, note that you'll use the GCS-provided access/public key (starting with GOOG) and the corresponding private/secret key in the places where the docs show keys from AWS.. Hi @rnicholus, there are a couple of minor changes to the Fine Uploader code, which can be found here https://github.com/FineUploader/fine-uploader/pull/1674/files. If you think you're likely to merge those changes into master, I can add the instructions I provided in the comments above to the docs somewhere as part of the PR.. Hi, Aaron, I have been meaning to write up the steps that I took to get\nthis working. Will try and finally do that later today. I've found that\nthings work fine with GCS after a few esoteric config steps.\n\n\nNate\nOn Sun, Dec 4, 2016 at 10:50 AM Aaron J. Olson notifications@github.com\nwrote:\n\nI would really like to see this feature get merged in or have some\ndocumentation made available that instructed how to get this set up. I am\nvery interested in being able to upload files client-side directly to a GCS\nbucket.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/pull/1674#issuecomment-264711470,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABXZ4rIqVf1dcRpE-wVVkY4jkwVekbtbks5rEuFMgaJpZM4KZ9OZ\n.\n. Hi, I apologize for not getting this written up yet. The reason is that I found that the file does get successfully uploaded to GCS, but for some reason the file doesn't inherit the default permissions from the bucket. As a practical matter this makes it not work for my use case and I suspect others. \n\nI suspect the problem is that fine-uploader is providing a default policy document along with the upload, or something along those lines. I imagine the fix is simple, but the holidays took me away from it and I just haven't delved back in. I will try to do so. Sorry again about the delay. . ",
    "aaronjolson": "Has any progress been made on this issue?  I would like to have some documentation made available that instructed how to get this set up. I'm very interested in being able to upload files client-side directly to a GCS bucket via fineuploadler.\n@nateweiss You don't happen to have a blog describing how you did this do you?. I would really like to see this feature get merged in or have some documentation made available that instructed how to get this set up. I am very interested in being able to upload files client-side directly to a GCS bucket.. @nateweiss thanks again for your help with this! Have you had a chance to put that write up into the documentation? I think it would be awesome if this got merged.. ",
    "artfree": "Hi @rnicholus.  What's the status of this issue?  I'm totally new to Fine Uplaoder, but also need to be able to upload - directly - to Google Cloud Storage (GCS).  The instructions given by nateweiss, above, are a bit too complex for me.  Will you have GCS as a supported endpoint in Fine Uploader (just as you now have direct support for S3) ?   I'm in need of this feature currently.  How long before it's implemented?  Thanks much.  . Hello nateweiss.  Thank you so much for your (soon to be) writeup on direct upload to Google Cloud Storage.  You're a lifesaver !!\nI'm approaching GCS from the Google Firebase side of things.  Firebase has a storage solution - which is, in fact, GCS, but with slightly different credentials.  Do see any issues with uploading directly to Firebase's GCS?. ",
    "pankitgami": "I have created the demo repository using Laravel and Fineuploader to upload to GCS. \nhttps://github.com/pankitgami/fineuploader-gcs-example\nHeroku app: https://quiet-anchorage-26485.herokuapp.com/. Hello @nateweiss \nShall we know the status of this merge request?. ",
    "cj": "if you're using direct to s3 uploading is there a way to have amazon return the file size?  so that in older browsers we can get the file size before posting to the success url?\n. I'm also getting this error in chrome Version 33.0.1750.152 https://db.tt/fjUMQABG\n. @rnicholus sorry about that, I can submit it to develop and remove the getFile.  I think the fileSize should definitely be added though.  How would you add it to uploadSuccess.params as it doesn't take a func so you wouldn't know the size yet.\n. It also appears that in IE9 this.getSize(id) is always 20.\n. @rnicholus thank you.  how would you do that in jquery?  doing .on('submitted', function(id){  }) this is the element, so you can't do this.getSize(id)\n. I found the awnser in stackoverflow.  $(this).fineUploader(\"getName\", id) it might be good to add that to the docs... I can make a pull request later :)\n. think I also may have found a bug.  https://gist.github.com/0857e3a21271cb5047ce doing $(this).fineUploader('setUploadSuccessParams', params, id); does not set the params in IE9\n. I know :) $(this).fineUploader('setUploadSuccessParams', {moo: 'cow'}, id); that would not get set in IE9.\n. ah of course, I changed it to https://gist.github.com/9c2a765cfc88dbb4ada0 and it works just fine now.  Thank you so much for all your help!  It's been a long night/day/morning.\n. ",
    "dancarey": "oh so that's how that \"pull request\" thingy works... sure hold on and I'll see if I can make one of those.\n. ",
    "Irrelon": "No problem. I purchased a license for FineUploader as well to help fund your efforts.\nCheers.\nRob\n. Yes that is consistent :)\n. ",
    "crowjonah": "I'm not sure why this started happening to me, too, but running sudo npm install -g grunt-legacy-util fixed it for me, just in case anyone else is having this issue!\n. ",
    "beersy001": "npm update fixed it for me\n. ",
    "stefan-lz": ":+1:  npm update did the trick\n. ",
    "cfalguiere": "I got the same error when grunt is run from a project created with yeoman (yo angular and code lab options) and the app folder is under /vagrant. \nIt disappeared after a yo update (npm update -g yo) and the creation of a new project, even in /vagrant.\nvagrant@dev:~$ grunt --version \ngrunt-cli v0.1.13\n==> OK\nvagrant@dev:~$ cd /vagrant/\nvagrant@dev:/vagrant$ grunt --version \ngrunt-cli v0.1.13\n==> KO\nvagrant@dev:~/mytodolocal$ grunt --version \ngrunt-cli v0.1.13\n==> OK\nvagrant@dev:/vagrant$ cd mytodo/\nvagrant@dev:/vagrant/mytodo$ grunt --version \ngrunt-cli v0.1.13\nmodule.js:340\n    throw err;\n          ^\nvagrant@dev:/vnpm update -g yo\nvagrant@dev:/vagrant/mytodo2$ grunt --version \ngrunt-cli v0.1.13\n=> OK\nFull log of grunt --version ran within the project\nmodule.js:340\n    throw err;\n          ^\nError: Cannot find module 'grunt-legacy-util'\n  at Function.Module._resolveFilename (module.js:338:15)\n  at Function.Module._load (module.js:280:25)\n  at Module.require (module.js:364:17)\n  at require (module.js:380:17)\n  at Object. (/vagrant/mytodo/node_modules/grunt/lib/grunt.js:26:12)\n  at Module._compile (module.js:456:26)\n  at Object.Module._extensions..js (module.js:474:10)\n  at Module.load (module.js:356:32)\n  at Function.Module._load (module.js:312:12)\n  at Module.require (module.js:364:17)\n  at require (module.js:380:17)\n  at Object. (/usr/local/lib/node_modules/grunt-cli/bin/grunt:45:1)\n  at Module._compile (module.js:456:26)\n  at Object.Module._extensions..js (module.js:474:10)\n  at Module.load (module.js:356:32)\n  at Function.Module._load (module.js:312:12)\n  at Function.Module.runMain (module.js:497:10)\n  at startup (node.js:119:16)\n  at node.js:902:3\n==> Failed\nHere is the installation process I ran before\n--- installation process\nprovisioning shell ran from vagrant on an ubuntu/trusty64 box\nsudo apt-get update\nsudo locale-gen en_US.UTF-8\nsudo locale-gen fr_FR.UTF-8\nsudo apt-get -y install git\nsudo apt-get -y install nodejs\nsudo apt-get install nodejs-legacy # required on ubuntu to be able to run npm install\nsudo apt-get -y install npm\nnpm update\nsudo npm install -g yo bower grunt-cli\nsudo npm install -g generator-angular\ngrunt --version works fine in another vm I created from an angular-seed template, even when the commande is run  from within a project \n. ",
    "JamesVanWaza": "@feltnerm\nI ran npm update but kept getting the error. \n. ",
    "notken": "Was this ever put in to the codebase and I've just not found the setting? I'm putting in deliberate random failures to test, with a retry count of 3. When it gives up, if I click Retry it only retries once before giving up again. The retry count does need resetting to zero after either a successful chunk, or at the very least after a manual retry. I'm trying version 5.3.2\n(Sorry, I should point out I'm not using S3. Just a standard upload to server.)\n. I guess because it's not resetting after a successful chunk, it not resetting when you manually retry seems illogical. It just seems like it's totally ignoring the settings.\nWhen testing it with built-in random failures, if I click Retry I'd expect it to suffer 3 more random failures before stopping again. But in actuality, the moment it's successfully done one after a failure I'd be quite happy for it to keep recovering from occasional failure until it's completed, and only fail if it really couldn't get through at all.\nIt just seems odd to ask for an auto-retry count in settings, and then ignore it and go for a developer-decided number when you manually Retry. Maybe it all needs to be in the settings.\n. Yeah, I said on SO and in the first comment above that we're not using the code you saw any more. I'm using the UI with templating. I can repeat it with pretty much vanilla code, adding in only my own click handler. I've left Fine Uploader's button in the following template, which works fine. But if I click my own Cancel, which calls .cancel(id) on the the uploader, it doesn't restart the queue.\n Fine Uploader Thumbnails template w/ customization\n    ====================================================================== \n```\n    \n\n<script type=\"text/template\" id=\"qq-template-manual-trigger\">\n<div class=\"qq-uploader-selector qq-uploader\" qq-drop-area-text=\"Drop files here\">\n    <div class=\"qq-total-progress-bar-container-selector qq-total-progress-bar-container\">\n        <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-total-progress-bar-selector qq-progress-bar qq-total-progress-bar\"></div>\n    </div>\n    <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n        <span class=\"qq-upload-drop-area-text-selector\"></span>\n    </div>\n    <div class=\"buttons\">\n        <div class=\"qq-upload-button-selector qq-upload-button\">\n            <div>Select files</div>\n        </div>\n        <button type=\"button\" id=\"trigger-upload\" class=\"btn btn-primary\">\n            <i class=\"icon-upload icon-white\"></i> Upload\n        </button>\n    </div>\n    <span class=\"qq-drop-processing-selector qq-drop-processing\">\n        <span>Processing dropped files...</span>\n        <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n    </span>\n    <ul class=\"qq-upload-list-selector qq-upload-list\" aria-live=\"polite\" aria-relevant=\"additions removals\">\n        <li>\n            <div class=\"qq-progress-bar-container-selector\">\n                <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n            </div>\n            <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n            <img class=\"qq-thumbnail-selector\" qq-max-size=\"100\" qq-server-scale>\n            <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n            <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\" aria-label=\"Edit filename\"></span>\n            <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n            <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n            <button type=\"button\" class=\"qq-btn qq-upload-cancel-selector qq-upload-cancel\">Your cancel</button>\n            <button type=\"button\" class=\"qq-btn customcancel\">My cancel</button>\n            <span role=\"status\" class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n        </li>\n    </ul>\n\n</div>\n\n\n<style>\n    #trigger-upload {\n        color: white;\n        background-color: #00ABC7;\n        font-size: 14px;\n        padding: 7px 20px;\n        background-image: none;\n    }\n\n    #fine-uploader-manual-trigger .qq-upload-button {\n        margin-right: 15px;\n    }\n\n    #fine-uploader-manual-trigger .buttons {\n        width: 36%;\n    }\n\n    #fine-uploader-manual-trigger .qq-uploader .qq-total-progress-bar-container {\n        width: 60%;\n    }\n</style>\n\n Fine Uploader DOM Element\n====================================================================== \n\n Your code to create an instance of Fine Uploader and bind to the DOM/template\n====================================================================== \n<script>\n    var manualUploader = new qq.FineUploader({\n        element: document.getElementById('fine-uploader-manual-trigger'),\n        template: 'qq-template-manual-trigger',\n        request: {\n            endpoint: \"server/upload\"\n        },\n        thumbnails: {\n            placeholders: {\n                waitingPath: '/Scripts/shared/all.fine-uploader/placeholders/waiting-generic.png',\n                notAvailablePath: '/Scripts/shared/all.fine-uploader/placeholders/not_available-generic.png'\n            },\n            maxCount: 50\n        },\n        debug: true,\n        maxConnections: 10,\n        retry: {\n            enableAuto: true,\n            showButton: true\n        },\n        chunking: {\n            partSize: 1048576,\n            enabled: true,\n            mandatory: true,\n            concurrent: {\n                enabled: true\n            },\n            success: {\n                endpoint: \"server/success\"\n            }\n        },\n        resume: {\n            enabled: true\n        }\n    });\n\n    $(\"body\").on(\"click\", \".customcancel\", function () {\n        var $li = $(this).closest(\"li\");\n        var id = $li.attr(\"qq-file-id\");\n        manualUploader.cancel(id);\n    });\n</script>\n\n```\nThis is what I'm testing. If I have a large file as file id 0, and a second file queued up to go, and then cancel file 0 while it's in progress, file 1 never starts. If I drag a new image into the drag box, file 2 will upload, and when it's finished, file 1 will start uploading.\n(Edited to remove the fadeout at the end as I realised it's not necessary. But it's not altering my observations.)\n. OK, I can confirm this does fix it. The weird thing is, though, that it does actually cancel. It just doesn't carry on.\n. ",
    "ShaharTal": "I am getting this error as well, not just with Firefox, mainly Chrome actually. Only with large files, directly to S3, what info can I give to better help/investigate?\n. ",
    "innamhunzai": "Hi @rnicholus I am facing this issue in 2.15.0 release.. ",
    "fens": "Understand. So my users who do use Opera pre 15 simply have a file upload that continues for infinity. Is there no feature detection or workaround for this? \n. ",
    "herschel666": "I'm using v4.4.0. And the onprogress-callback on the xhr-object gets called without problems.\n. It's about version 4.4\n. Okay, then I'll have a look at other libraries \"messing\" around witzh XHR. Thanks for your help. If I find something interesting, I'll let you know.\n. ",
    "jwerre": "Ok... sorry about that. I'll give you more info when I get some more time.\n. Just to follow up with this I was placing my template into the HEAD dynamically before initializing Finuploader. It was working fine in all browsers except Firefox. I fixed it by upgrading to v5 and loading the template directly into the uploader (which I think is new feature in v5.0):\n```\nuploader = new qq.FineUploader({template:getUploaderTemplate() })\ngetUploaderTemplate = function() {\n   var div;\n   div = document.createElement(\"div\");\n   div.innerHTML = _.template(uploaderTemplate, {});\n   return div;\n }\n```\n. ",
    "victoriafrench": "This issue should not be closed because it still happens with the latest firefox and the latest build. If you supply a script tag as your template (string id or direct element) firefox will fail. Because the code attempts to grab innerHTML of that script tag. In firefox, unlike chrome et al, innerHTML on script is always a blank string. However requesting children on it will return the items.\nIn my code I have to explicitly create a new div, pull the children from the script and append them to the new div before sending it in to qq.. text/template. ",
    "cybermerlin": "\u0443 \u043c\u0435\u043d\u044f \u0434\u0432\u0430 \u0432\u043e\u043f\u0440\u043e\u0441\u0430:\n1- \u043a\u0430\u043a \u044f \u043c\u043e\u0433\u0443 \u0441\u043e\u0431\u0440\u0430\u0442\u044c fineuploader client (\u043c\u043d\u0435 \u043d\u0443\u0436\u0435\u043d \u0441\u043f\u0438\u0441\u043e\u043a \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0444\u0430\u0439\u043b\u043e\u0432 \u0434\u043b\u044f \u0441\u0431\u043e\u0440\u043a\u0438 \u0432 \u043e\u0434\u0438\u043d \u0431\u043e\u043b\u044c\u0448\u043e\u0439)\n2- \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0430 \u0434\u0435\u043c\u043e\u043d\u0441\u0442\u0440\u0430\u0446\u0438\u0439 (demos) \u043d\u0435\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u043e \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0435\u0442\u0441\u044f \u0432 winxp+ie8 (\u0435\u0441\u043b\u0438 \u0442\u043e\u0447\u043d\u0435\u0435, \u0442\u043e \u043d\u0435\u0442\u0443 \u043a\u043d\u043e\u043f\u043a\u0438 \"upload a file\"\n. ",
    "panique": "Can somebody please put a line on top of the demos that clearly says that these demos are \"broken\" ? I can imagine masses of people try these demos, see that they \"don't work\" and then close the tab and dismiss this wonderful script. Is the sourcecode of the doc pages / demos on GitHub as a repo ?\nI'll have a look, eventually I can donate a demo server.\n. @rnicholus Wonderful! A little note would be good to avoid confusion. Thanks for the awesome project!\n. ",
    "rmckeel": "I also have a need for this feature.  Currently, I'm trying to do it the 'manual' way.  I'm almost there, but it is tricky if autoUpload is true to begin with, changing that midstream when a 'pause' button is pressed.\nIf it's possible given the current v5.0.9 API, I would really appreciate a rough / pseudo-code method for pausing / unpausing that I could code up.\nP.S. FineUploader is incredible in what it does..!\n. Thanks Ray for the idea, I'll try it out.  Yes, autoUpload pausing is tricky, as is autoUpload false then unpausing to initialize the queue.  I've tried updating the sent options, but it doesn't seem to be 'responsive' to changes in the autoUpload except at variable initialization.\nEither way, I'll try tying that in to onStatusChange to pause. Thanks for reviewing!\n. Ray, this is what I ended up doing with autoUpload enabled.  Without the setTimeout, it is impossible to pause due to an error it can't pause (probably due to a synchronous call that happens shortly after the upload is triggered).\nI don't love this solution because of the unpredictable nature of timeouts on various machines, but it is a solution.\n.on(\"upload\", function(event, id, name) {\n        if(! uploaderRunning) {\n          setTimeout(function() {\n            uploaderObj.fineUploader('pauseUpload', id);\n          }, 100);\n        }\n      })\n. Hello, yes, this is an important feature for 'big uploads' that can take hours or days.  I have code that I use for this problem.  When a user pauses uploading, it clears out the array of samples.  Perhaps this will be good fodder for the blog entry (correcting/improving as you see fit)?  :)\nRyan\n``` ...\n.on(\"totalProgress\", function(event, totalUploadedBytes, totalBytes) {\n        var progressPercent = (totalUploadedBytes / totalBytes).toFixed(2);\n        if(isNaN(progressPercent) || progressPercent >= 1) {\n          $('#progress-text').text('');\n          if($progressBarContainer) $progressBarContainer.slideUp();\n        } else {\n          var progress = (progressPercent * 100).toFixed() + '%';\n      $('#progress-text').text(progress);\n      if($progressBarContainer) $progressBarContainer.slideDown();\n    }\n\n    // upload speed\n    uploadSpeeds.push({\n      totalUploadedBytes: totalUploadedBytes,\n      currentTime: new Date().getTime()\n    });\n    var minSamples = 6;\n    var maxSamples = 20;\n    if(uploadSpeeds.length > maxSamples) {\n      // remove first element\n      uploadSpeeds.shift();\n    }\n    if(uploadSpeeds.length >= minSamples) {\n      try {\n        var firstSample = uploadSpeeds[0];\n        var lastSample = uploadSpeeds[uploadSpeeds.length - 1];\n        var progressBytes = lastSample.totalUploadedBytes - firstSample.totalUploadedBytes;\n        var progressTimeMS = lastSample.currentTime - firstSample.currentTime;\n        // megabytes per second\n        //var MBps = (progressBytes / (progressTimeMS / 1000) / (1024 * 1024)).toFixed(2);\n        // megabits per second\n        var Mbps = ((progressBytes * 8) / (progressTimeMS / 1000) / (1000 * 1000)).toFixed(2);\n        //console.log(progressBytes, progressTimeMS, Mbps, uploadSpeeds.length);\n        if(Mbps > 0) {\n          $('#uploader-speed').text(Mbps + ' Mbps');\n        } else {\n          $('#uploader-speed').text('');\n        }\n      } catch (err) {\n\n      }\n    }\n  })\n\n```\n. Hello, incidentally I am investigating this same issue.  The client may have 3-4K files uploaded, but that could be even larger.  When the session/endpoint is pulled, it takes 30 seconds even on a MacBook Pro late 2013 model on Chrome's V8 engine.\nMy profile attempts through Chrome show that the hangup is primarily in the getByClass -> querySelectorAll function called by handleFileItems.  Perhaps that will help someone as they dive into the root cause.  (I have a slightly edited custom version of FineUploader, so line numbers will not match up perfectly).\n\nHope that helps ~\n. @rnicholus Ray, where is a good place to send a file to you privately? I can share with you my .cpuprofile (and custom fineuploader JS file) that you could load into Chrome. I can't upload anything but images here.\n. Thank you, Ray.  Excellent support.\n. @rnicholus Ray, my vote (on behalf of several clients sites that use FineUploader) is no interest in passing in lists of files after load.  There is no change that would warrant it in the single session.  I suppose group uploading would be a good reason to add that feature in, I just wouldn't expect group uploading to be that common! :)  Thanks ~\n. ",
    "Erazihel": "I created the PR #1584 as we need this feature in our current project.\nWe are generating thumbnails by adding photos to the traditional FineUploader queue. The thumbnails are then uploaded by a S3 FineUploader, and the photos using the traditional one. Thing is, we need to upload the thumbnails in priority, and thus pause the traditional upload queue (because of the browser limitation) that will be unpaused once all the thumbnails are sent.\n. A user can upload many photos to our servers that need to be analyzed to sort some informations out of it (which ones are similar or duplicate, which ones can be gathered by theme, etc.).\nAs soon as the user finish uploading his photos, he should be able to keep going during his experience as fast as possible, and this isn't possible until the thumbnails are generated, uploaded and analyzed.\nThe photos are not needed for the user to continue his experience (thumbnails are sufficient). They will be, however, needed for the final product that will be created by the user though. That's why we'll upload them once the thumbnails are all sent.\nNote that a user can upload thousands of photos. The waiting time will be way to long if we upload all these photos, it will be however acceptable for the thumbnails upload. I think you got the idea why we need to send the thumbnails first.\nAlso note that the user can upload photos multiple times. It means that if he selects, let's say 50 photos, the thumbnails are generated, uploaded and analyzed, then the photos start to be uploaded. If the user goes back to the photo selection and selects 50 new photos, we have to pause the upload of the photos, treat these 50 new photos, generate, upload and analyze the thumbnails, then unpause the upload of all the photos.\nNow, about the browser limitations, I invite you to visit this post. You can only have a certain amount of simultaneous connections to a server, depending on your browser. Average is 5 simultaneous connections/server.\nAs we need the thumbnails to be sent in priority, we can't afford the upload of the photos to use some of this simultaneous connection, as it will slow down the thumbnails upload. By using the maximum simultaneous connections/server for our thumbnails only, we could reduce the waiting time of the user twice. For thousands of thumbnails, it's not negligible.\nHere is the pseudo synchronous code we'd like to use once the user as selected all the photos he wants to upload:\n```\nuploader.addFiles(photosSelected);\nuploader.pauseQueue();\nuploader.generateThumbnails();\n// Use S3 Uploader\nuploaderS3.addFiles(generatedThumbnails);\n// Once the thumbnails are all sent\nuploader.unpauseQueue();\n```\nThank you for your time.\n. We are using two instances, 1 S3 and 1 traditional.\n. I thought about your solution, there is still a problem in the case I mentioned before:\n\nAlso note that the user can upload photos multiple times. It means that if he selects, let's say 50 photos, the thumbnails are generated, uploaded and analyzed, then the photos start to be uploaded. If the user goes back to the photo selection and selects 50 new photos, we have to pause the upload of the photos, treat these 50 new photos, generate, upload and analyze the thumbnails, then unpause the upload of all the photos.\n\nWe still need the pause feature for this.\n. Yes I've tested it manually and it works fine. But you're right, it works because the only reason the queue is paused is that new files have been stored (explaining why the uploadStoreFiles has an effect on the paused files). Bringing the modifications ASAP.\n. Hi @rnicholus, did you have the time to checkout my updated code?\n. Hi @rnicholus, any feedback on these unit tests would be appreciated\n. The only thing left to do is documentation so yes, you can start manual testing. I'll take care of the documentation and will come back to you if needed.\n. 1. Not yet, but we planned a release with these exact changes in production next week\n2. We hadn't the opportunity as we're not using any other related features\n. You're absolutely right, pausing the queue right after resuming it and so on will not reset the paused variables. I moved the unreachable code to the resumeQueue function and it works fine without concurrent chunking.\nHowever, I can't test the \"concurrent chunking\" feature because our servers don't support it. Can you give me any feedback on this ?\n. I manage to reproduce this issue from time to time. It appears that for some reason the connectionManager stops being available at some point. Calling the _uploadFile method with the this._pausedId will only result in adding the file to the queued files and thus doesn't resume the remaining ones.\nI'm not quite sure how to correct this issue. Any help would be appreciated.\n. FYI, we released these changes in production wednesday, so far so good.\n. @gavboulton I don't have any plans anymore since I've left the company I worked in where this feature was needed.\nIf you want to take a look at it, go ahead but I can't really help you out though.. Yup, my bad. Fixing it right now\n. ",
    "csquire": "Thanks, Ray.   I would say of the issues/features I submitted, this would be my highest priority as I was unable to find a suitable workaround.\n. ",
    "cavill": "Is there any documentation on how to implement this anywhere? (thanks)\n. ",
    "thiagoalvernaz": "Hello,\nI made a quick integration with dropbox using fineuploader.\nfineuploader-dropbox\n. ",
    "anbalaganM": "Hi\n\u00a0\u00a0\u00a0\u00a0Please find the attached client side code(NewDefault.htm) and corresponding error screen shot(ErrorPage.png)\n\u00a0\n\u00a0\nThanks\nAnbalagan.M\n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Monday, May 12, 2014 6:06 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nPlease provide some information required to reproduce the issue, such as: \n    * your client side code \n    * the exact components that make up your custom build.  A screenshot of the build page will suffice.\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi\nPlease find the attached zip file (have client side code(NewDefault.htm) and corresponding error screen shot(ErrorPage.png))\n\u00a0\nThanks\nAnbalagan.M\u00a0 \n From: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Tuesday, May 13, 2014 6:32 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nYou haven't actually included any code or a screen shot.  You will need to paste your code, properly escaped, and include information about your custom build.\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\n\u00a0\u00a0\u00a0\u00a0Pls find the code\n\u00a0\n\u00a0\n<!DOCTYPE html>\n\n\n\u00a0\u00a0\u00a0 \n\u00a0\u00a0\u00a0 \n\u00a0 \n\u00a0\u00a0\u00a0 Fine Uploader default UI\n\n\n\u00a0\u00a0\u00a0 \n\u00a0\u00a0\u00a0 \n The element where Fine Uploader will exist. \n\n\u00a0\u00a0\u00a0 \n\u00a0\u00a0\u00a0 \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 $(\"#fine-uploader\").fineUploader({\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 request: {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 endpoint: 'server/handleUploads'\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }).on('error', function(event, id, name, reason) {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // do something\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }).on('complete', function(event, id, name, responseJSON) {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // do something\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 });\n\u00a0\u00a0 \n\u00a0\u00a0\u00a0 \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <div class=\"qq-uploader-selector qq-uploader\">\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span>Drop files here to upload</span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 </div>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <div class=\"qq-upload-button-selector qq-upload-button\">\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <div>Upload a file</div>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 </div>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span class=\"qq-drop-processing-selector qq-drop-processing\">\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span>Processing dropped files...</span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 </span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <ul class=\"qq-upload-list-selector qq-upload-list\">\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <li>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <div class=\"qq-progress-bar-container-selector\">\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <div class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 </div>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\"></span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <a class=\"qq-upload-cancel-selector qq-upload-cancel\" href=\"#\">Cancel</a>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <a class=\"qq-upload-retry-selector qq-upload-retry\" href=\"#\">Retry</a>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <a class=\"qq-upload-delete-selector qq-upload-delete\" href=\"#\">Delete</a>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 <span class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 </li>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 </ul>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 </div>\n\u00a0\u00a0\u00a0 \n\n\n\u00a0\n\u00a0\nThanks\nAnbu\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Tuesday, May 13, 2014 11:15 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nYou cannot simply attach files you an email when posting to github issues.\nYou will need to paste your code, properly escaped, and include information about your custom build. \n\u2014\nReply to this email directly or view it on GitHub.\n. \u00a0Hi,\n\u00a0\u00a0\u00a0\u00a0During loading of page actually issue occurs in Custom.fineuploader-4.4.0.js, line 4060 character 9\n\u00a0\u00a0\u00a0\u00a0\"ScRIPT445:Object doesn't support this action\"\n\u00a0\n\u00a0\nTHanks\nAnbalagan.M\n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Tuesday, May 13, 2014 11:21 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nEverything looks ok here, but it's hard to tell what the error is.  Please provide a link to your app where this can be reproduced. \n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\n\u00a0\u00a0\u00a0\u00a0i don't how to attach files from this\u00a0id, already multiple time i attached \u00a0file but your side it is not reached properly\n\u00a0\nThanks\nAnbalagan.m\n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Tuesday, May 13, 2014 11:33 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nAnother option, suggested earlier, is to provide a screenshot of the custom build page from the website, so we can re-create your build and test. \n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\n\u00a0\u00a0\u00a0\u00a0I\u00a0need to set the web\u00a0environment in live, currently i'm testing with local environment,.\nTomorrow i will set the environment and send the link\n\u00a0\nThanks\nAnbalagan.m\u00a0\n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Tuesday, May 13, 2014 11:32 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nI'll need a link to your live web app.  A custom build is just that.  I have no way of determining what code is on line 4060 in a custom build.\n\u2014\nReply to this email directly or view it on GitHub.\n. \u00a0\n\u00a0\n\u00a0 \n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Tuesday, May 13, 2014 11:33 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nAnother option, suggested earlier, is to provide a screenshot of the custom build page from the website, so we can re-create your build and test. \n\u2014\nReply to this email directly or view it on GitHub.\n. \n. Hi,\n\u00a0\u00a0\u00a0\u00a0I attached the screenshot as per your instruction\n\u00a0\nThanks\nAnbalagan.M\n\nFrom: Mark Feltner notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Wednesday, May 14, 2014 12:02 AM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\n@anbalaganM, \nThe reason your attachments are not working is because you are replying via email rather than using the built-in editor here at #1205 . For instructions on adding an attachment, please see: https://help.github.com/articles/issue-attachments \n\u2014\nReply to this email directly or view it on GitHub.\n. Hi ,\n\u00a0\u00a0\u00a0\u00a0Already attached screenshot in the below link\n\u00a0\nPlease check the below url\n\u00a0\n\u00a0\nhttps://github.com/Widen/fine-uploader/issues/1205\n\u00a0\nThanks\nAnbalagan.M\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Wednesday, May 14, 2014 5:37 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nI asked for a screenshot of the custom build form.  Please let us know when you have a site we can visit that will reproduce this issue.\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\n\u00a0\u00a0\u00a0\u00a0I will uploaded into live one and send the link within 30 minutes\n\u00a0\n\u00a0\nThanks\nAnbalagan.m\n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Wednesday, May 14, 2014 6:16 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nIt looks like you are having some trouble understanding me.  I'm sorry but I won't be able to help any further without a link to a live site that reproduces the issue you are having. \n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\nFinally upload the test page in my web link .\u00a0Please the find the link\u00a0\nhttp://ayycon.com/ayycon/NewDefault.html\nThanks\nAnbalagan.M\n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Wednesday, May 14, 2014 6:16 PM\nSubject: Re: [fine-uploader] Using FineUploader Basic UI is not loaded throws errors (#1205)\nIt looks like you are having some trouble understanding me.  I'm sorry but I won't be able to help any further without a link to a live site that reproduces the issue you are having.\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\nThanks for response. As we mentioned in previous thread, already go through technical document but no where else mentioned how to create signature endpoints.\nAcutaly where to start whether i need to write the code in asp.net to get the signature point or through the amazon S3 link)\nThanks\nAnbalagan.M\n. Thanks for response, currently we are working with Amazon cloud system, is there samplelink for amazon instead of Azure\n. hi,\n Still i'm searching for help from \"s3 server side doc page\" but no where else mentioned the extract how to configure to signature endpoints. \nFrom past 10 days i tried for upload the simple files using fineupload s3 Basic but i'm unable to acheive.\nIt is very critical position for my commerical project to complete this activities.\nActual implementation in asp.net application we need ton consume the fineuploader to upload files\nNote:\nWe are using license version of fineuploader \nPlease help me for complete my task since it is delay for delivery date for my product.\nThanks\nAnbalagan.M\n. hi,\nStill i'm searching for help from \"s3 server side doc page\" but no where else mentioned the extract how to configure to signature endpoints.\u00a0\nFrom past 10 days i tried for upload the simple files using fineupload s3 Basic but i'm unable to acheive.\nIt is very critical position for my commerical project to complete this activities.\nActual implementation in asp.net application we need ton consume the fineuploader to upload files\nNote:\nWe are using license version of fineuploader\nPlease help me for complete my task since it is delay for delivery date for my product.\nThanks\nAnbalagan.M\n\nFrom: Ray Nicholus notifications@github.com\nTo: Widen/fine-uploader fine-uploader@noreply.github.com \nCc: anbalaganM anbalagan74@yahoo.com \nSent: Wednesday, May 21, 2014 11:11 PM\nSubject: Re: [fine-uploader] reg of signature endpoint (#1209)\nSorry, for some reason I assumed you were using Azure since you are making use of a .NET language.  We have S3 server-side examples in many languages, but .NET is not one of them.  Regardless, the required server-side tasks section of the s3 server side doc page should provide adequete details for handling signature requests.\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\n  As we mentioned in above mail thread i follow up with the other language reference(such as Java) convert into C#.\nHere my doubt is how to mentioned the path(signature endpoints) in between the my test and C#(server side handler ) . here is below my entire code as follows\nDefault.aspx\nfunction createUploader() {\n    var uploader = new qq.FineUploader({\n      element: document.getElementById('fine-uploader'),\n      request: {\n      endpoint: 'ayycon1.s3.amazonaws.com', /'ayycon1.s3-website-ap-southeast-1.amazonaws.com',/\n      accessKey: 'AKIAJEES4IXJIF5HPWMA'\n      },\n      signature: { endpoint: '/Uploaders1/S3Uploads' },\n      uploadSuccess: { endpoint: 'success.html' },\n      messages: {\n          typeError: '{file} has an invalid extension. Valid extension(s):  {extensions}.'\n          // other messages can go here as well ...\n      }\n    });\n  }\n  window.onload = createUploader;\nAsp.net Server code\nnamespace Uploaders1\n{\n    public class S3Uploads : IHttpHandler\n    {\n        // This assumes your secret key is available in an environment variable.\n        // It is needed to sign policy documents.\n        static string AWS_SECRET_KEY = \"AWS_SECRET_KEY\";\n        // You will need to use your own public key here.\n        static String AWS_PUBLIC_KEY = \"AKIAJEES4IXJIF5HPWMA\";\n        // Main entry point for POST requests from Fine Uploader. This currently assumes delete file requests use the\n        // default method of DELETE, but that can be adjusted.\n        public void doPost(HttpRequest req, HttpResponse resp)\n        {\n            if (req.Path.EndsWith(\"s3/signature\"))\n            {\n                handleSignatureRequest(req, resp);\n            }\n            else if (req.Path.EndsWith(\"s3/success\"))\n            {\n                handleUploadSuccessRequest(req, resp);\n            }\n        }\n```\n    // Main entry point for DELETE requests sent by Fine Uploader.\n    public void doDelete(HttpRequest req, HttpResponse resp)\n    {\n        String key = req.Params[\"key\"];\n        String bucket = req.Params[\"bucket\"];\n    resp.StatusCode = 200;\n\n    AWSCredentials myCredentials = new BasicAWSCredentials(AWS_PUBLIC_KEY, AWS_SECRET_KEY);\n    AmazonS3 s3Client = new AmazonS3Client(myCredentials);\n    DeleteObjectRequest request = new DeleteObjectRequest()\n    {\n        BucketName = bucket,\n        Key = key\n    };\n    s3Client.DeleteObject(request);\n}\n\n// Called by the main POST request handler if Fine Uploader has asked for an item to be signed. The item may be a\n// policy document or a string that represents multipart upload request headers.\nprivate void handleSignatureRequest(HttpRequest req, HttpResponse resp)\n{\n    resp.ContentType = \"application/json\";\n    resp.StatusCode = 200;\n    string documentContents; \n    using (Stream receiveStream = req.InputStream) \n    { \n        using (StreamReader readStream = new StreamReader(receiveStream, Encoding.UTF8)) \n        { \n            documentContents = readStream.ReadToEnd(); \n        } \n    }\n    String contentJson = documentContents;\n    string headers = req.Headers[\"headers\"];\n    JObject response = new JObject();\n\n    String signature;\n\n    try\n    {\n        // If this is not a multipart upload-related request, Fine Uploader will send a policy document\n        // as the value of a \"policy\" property in the request. In that case, we must base-64 encode\n        // the policy document and then sign it. The will include the base-64 encoded policy and the signed policy document.\n        if (headers == null)\n        {\n            String base64Policy = base64EncodePolicy(contentJson);\n            signature = sign(base64Policy);\n\n            // Validate the policy document to ensure the client hasn't tampered with it.\n            // If it has been tampered with, set this property on the response and set the status to a non-200 value.\n            response.Add(\"policy\", base64Policy);//response.addProperty(\"policy\", base64Policy);\n        }\n\n        // If this is a request to sign a multipart upload-related request, we only need to sign the headers,\n        // which are passed as the value of a \"headers\" property from Fine Uploader. In this case,\n        // we only need to return the signed value.\n        else\n        {\n            signature = sign(headers);\n        }\n\n        response.Add(\"signature\", signature); \n        resp.Write(response); \n    }\n    catch (Exception e)\n    {\n        resp.StatusCode = 500;\n    }\n}\n\n// Called by the main POST request handler if Fine Uploader has indicated that the file has been\n// successfully sent to S3. You have the opportunity here to examine the file in S3 and \"fail\" the upload\n// if something in not correct.\nprivate void handleUploadSuccessRequest(HttpRequest req, HttpResponse resp)\n{\n    String key = req.Params[\"key\"];\n    String uuid = req.Params[\"uuid\"];\n    String bucket = req.Params[\"bucket\"];\n    String name = req.Params[\"name\"];\n\n    resp.StatusCode = 200;\n\n    resp.Write(String.Format(\"Upload successfully sent to S3! Bucket: %s, Key: %s, UUID: %s, Filename: %s\",\n             bucket, key, uuid, name));\n}\n\nprivate String base64EncodePolicy(string jsonElement)\n{\n\n    String policyJsonStr = jsonElement.ToString();\n    byte[] toEncodeAsBytes = System.Text.ASCIIEncoding.ASCII.GetBytes(policyJsonStr);\n    string base64Encoded = System.Convert.ToBase64String(toEncodeAsBytes).Replace(\"\\n\", \"\").Replace(\"\\r\", \"\"); ;\n    return base64Encoded;\n}\n\nprivate String sign(String toSign)\n{\n    System.Text.UnicodeEncoding encoding = new UnicodeEncoding();\n    byte[] keyByte = encoding.GetBytes(AWS_SECRET_KEY);\n    System.Security.Cryptography.HMACSHA1 hmacsha1 = new System.Security.Cryptography.HMACSHA1(keyByte);\n    byte[] messageBytes = encoding.GetBytes(toSign);\n    byte[] hashmessage = hmacsha1.ComputeHash(messageBytes);\n    return System.Convert.ToBase64String(hashmessage);\n}\n\n#region IHttpHandler Members\npublic bool IsReusable\n{\n    get { throw new NotImplementedException(); }\n}\n\npublic void ProcessRequest(HttpContext context)\n{\n    throw new NotImplementedException();\n}\n#endregion\n\n}\n```\n}\nThanks \nAnbalagan.m\n. Thanks for response,\nI changed what ever you mentioned in the above mail thread,\nOnce i  uploaded the files thrown error as \"Upload failed\" and check with console output from F12 option shown as below\n[Fine Uploader 4.4.0] Error when attempting to parse iframe upload response (Invalid character) \nFor reference i upload the test page in portal as   http://ayycon.com/ayycon/TestPage.htm\nThanks\nAnbalagan.M\n. Hi,\nFurther debug the code using  debug mode in fine uploader (debug:true) .\nSample url  as http://ayycon.com/ayycon/TestPage.htm\nThe following error as occur in console output from F12 option shown as below\n[Fine Uploader 4.4.0] Parsing template \n [Fine Uploader 4.4.0] Template parsing complete \n [Fine Uploader 4.4.0] Rendering template in DOM. \n [Fine Uploader 4.4.0] Template rendering complete \n [Fine Uploader 4.4.0] Received 1 files or inputs. \n [Fine Uploader 4.4.0] Sending upload request for 0 \n [Fine Uploader 4.4.0] Received response for 0_f529c9ec-bdfc-4c41-9edc-a0256998dd8f \n [Fine Uploader 4.4.0] iframe loaded \n [Fine Uploader 4.4.0] converting iframe's innerHTML to JSON \n [Fine Uploader 4.4.0] innerHTML = Server Error\n\n\n404 - File or directory not found.\nThe resource you are looking for might have been removed, had its name changed, or is temporarily unavailable.\n\n\n[Fine Uploader 4.4.0] Error when attempting to parse iframe upload response (Invalid character) \n. ",
    "murilopolese": "In the project I'm working right now I'm overriding many error messages to make the user get more friendly responses from an audio uploader.\nWhen the server returns a status code 200, I am available to override many error messages and this is great! It makes my code way more elegant, uniform and compact than check the response object in the error callback.\nAnyway I am experiencing some situations where the server crashes due timeout or even (so far) untracked issues and I would like to provide my user a seamless experience. It's pretty bad to return him a message like \"XHR returned response code 0\", for example.\nI can catch the XMLHttpRequest on error callback but since we have a property to override default response errors and avoid this check, I think I should be able to do the same with unexpected server responses in the same way.\n$( '#upload-tracks-box' ).fineUploader({\n    \u2026\n    text: {\n        defaultResponseError: 'An error occurred but the server returned 200',\n        defaultXhrResponseError: 'Another error occurred and I can handle it'\n    },\n    messages: {\n        typeError: 'Invalid extension detected in file, {file}.',\n        sizeError: '{file} is too large, maximum file size is {sizeLimit}.',\n        ...\n    }\n})\ninstead of\n$( '#upload-tracks-box' ).fineUploader({\n    \u2026\n    text: {\n        defaultResponseError: \u201cAn error occurred but the server returned 200\u201d\n    },\n    messages: {\n        typeError: 'Invalid extension detected in file, {file}.',\n        sizeError: '{file} is too large, maximum file size is {sizeLimit}.',\n        ...\n    }\n}).on( 'error', function(e, id, file, error, xhrOrXdr) {\n    if( xhrOrXdr.status != 200 ) {\n        error = 'Another error occurred and I can handle it';\n    }\n    // Append the error message\n});\n. Thank you for your attention discussing it. It really helped me to understand better the situation. \nAnyway I keep thinking this option make as much sense as the defaultResponseError. Maybe in a smarter way but still, if there is a way to automatically catch and override a response error, why hard code this specific one?\nI am using the error handler to customize the error message style (not the message itself) and to chain some events. Do more than styling the error or chain events there seems for me a code smell (don't take me wrong). I will need to repeat, again in my opinion, unnecessarily this errors handlers (500 or 503 for example) every FineUploader call. But it can also be a fail on my code design, even I had discussed it with some friends and seems reasonable use this declarative default property I am proposing instead.\nSo far I will keep using the fork with this extra property since it will, apparently, make my code looks more consistent. \nThanks a lot anyway! :D\n. ",
    "Korijn": "Imho, not prefixing keys passed into setParams should be fine? Overwrite an existing header: no problem... it's apparently the developer's choice.\n. Or provide an option to toggle auto prefixing of params?\n. :+1:\n. I went ahead and created a pull request, as I'm eager to start using the validation mechanism provided by Content-MD5.\n. :+1: was also looking for this feature.\nAnother example:\n``` javascript\nfunction handleFailure(xhr, promise) {\n        var azureError = qq.azure.util.parseAzureError(xhr.responseText, log),\n            errorMsg = \"Problem sending file to Azure\";\n    promise.failure({error: errorMsg,\n        azureError: azureError && azureError.message,\n        reset: xhr.status === 403\n    });\n}\n\n``\n. Semi-related question: is this supposed to trigger the callbackonError? We're attached a logger and it's not logging anything. :) If not, how do I hook in to this?\n. Is there any plan to complete this item?\n. No problem, I just wanted to know. :) Thanks for your quick reply. We've been using FineUploader for about a year now for transfers of 250-1000 MB datasets, and it's working out great; we're very content. Not being able to customize an error message is only a minor annoyance. We might open a PR for it ourselves at some point.\n. I tried to sign the CLA but clahub just barfs \"something went wrong\" after I fill in the form and submit.\n. Admittedly, I was in a rush. I took the time to carefully test it now though. TheContent-MD5request header can be set usingsetParams({ 'Content-MD5', base64_hash }, id)`. Tested in IE11, Firefox 37 and Chrome 42.\n\n. How's this?\n. Agreed. :+1: \n. I think the PR is done now.\nI could include some more headers from the Microsoft docs but I think you already handle a bunch of them specifically, so I kept the PR restricted to the ones I could test in my setup.\n. I just rebased it on the latest develop (I think) so should be ready to merge if the travis build passes.\n. For anyone else viewing this thread:\nuploader = new qq.azure.FineUploader({\n    callbacks: {\n        onStatusChange: function (id, oldStatus, newStatus) {\n            if (newStatus === qq.status.UPLOAD_FAILED) {\n                uploader.retry(id);\n. Can you retrieve the retry count?\n. When I use uploader.retry(id); the retry does start but the Retry button also remains visible, even if the upload succeeds afterwards. Bug or am I missing a configuration setting?\n. I'll file a bug tomorrow and subsequently submit a  PR to fix it...\n. After some initial inspection of the source, I think the onRetry event handler in uploader.api.js is not being called when a retry is scheduled programmatically, since it only appears to be wired up to the UI click event of the retry button.\nThis is the onRetry handler, which updates the UI:\njavascript\nonRetry: function(fileId) {\n    qq(self._templating.getFileContainer(fileId)).removeClass(self._classes.retryable);\n    self._templating.hideRetry(fileId);\n    self.retry(fileId);\n},\nIt looks like my hypothesis is correct when looking at the _manualRetry method in uploader.basic.api.js:\n``` javascript\n/\n * Conditionally orders a manual retry of a failed upload.\n \n * @param id File ID of the failed upload\n * @param callback Optional callback to invoke if a retry is prudent.\n * In lieu of asking the upload handler to retry.\n * @returns {boolean} true if a manual retry will occur\n * @private\n /\n_manualRetry: function(id, callback) {\n    if (this._onBeforeManualRetry(id)) {\n        this._netUploadedOrQueued++;\n        this._uploadData.setStatus(id, qq.status.UPLOAD_RETRYING);\n    if (callback) {\n        callback(id);\n    }\n    else {\n        this._handler.retry(id);\n    }\n\n    return true;\n}\n\n},\n```\nI'm not sure how to call the event handler from this piece of code, or alternatively how to trigger the event manually. Can you give me a hint, @rnicholus?\n. Should be good now?\n. Yes, I'm already using a temporary build sucessfully in production (we really needed the feature).\n. Awesome, thanks for the help.\n. That's OK, I might have a look at it myself before then, otherwise, I'll hear about it later. Thanks for the (incredibly) quick response!\n. The files are added using a callback options.addFileRecord in fine-uploader/client/js/session.js.\nThat callback is filled in by _addCannedFile in fine-uploader/client/js/uploader.basic.api.js. This is the source of that method:\n``` javascript\n        _addCannedFile: function(sessionData) {\n            var id = this._uploadData.addFile({\n                uuid: sessionData.uuid,\n                name: sessionData.name,\n                size: sessionData.size,\n                status: qq.status.UPLOAD_SUCCESSFUL\n            });\n        sessionData.deleteFileEndpoint && this.setDeleteFileEndpoint(sessionData.deleteFileEndpoint, id);\n        sessionData.deleteFileParams && this.setDeleteFileParams(sessionData.deleteFileParams, id);\n\n        if (sessionData.thumbnailUrl) {\n            this._thumbnailUrls[id] = sessionData.thumbnailUrl;\n        }\n\n        this._netUploaded++;\n        this._netUploadedOrQueued++;\n\n        return id;\n    },\n\n```\nSo there are three methods being called here, the first is _uploadData.addFile, and the other two methods just set endpoint and params.\n``` javascript\n        addFile: function(spec) {\n            var status = spec.status || qq.status.SUBMITTING,\n                id = data.push({\n                    name: spec.name,\n                    originalName: spec.name,\n                    uuid: spec.uuid,\n                    size: spec.size == null ? -1 : spec.size,\n                    status: status\n                }) - 1;\n        if (spec.batchId) {\n            data[id].batchId = spec.batchId;\n\n            if (byBatchId[spec.batchId] === undefined) {\n                byBatchId[spec.batchId] = [];\n            }\n            byBatchId[spec.batchId].push(id);\n        }\n\n        if (spec.proxyGroupId) {\n            data[id].proxyGroupId = spec.proxyGroupId;\n\n            if (byProxyGroupId[spec.proxyGroupId] === undefined) {\n                byProxyGroupId[spec.proxyGroupId] = [];\n            }\n            byProxyGroupId[spec.proxyGroupId].push(id);\n        }\n\n        data[id].id = id;\n        byUuid[spec.uuid] = id;\n\n        if (byStatus[status] === undefined) {\n            byStatus[status] = [];\n        }\n        byStatus[status].push(id);\n\n        uploaderProxy.onStatusChange(id, null, status);\n\n        return id;\n    },\n\n```\nThe code doesn't look inefficient (constant running time), except for perhaps the call to uploaderProxy.onStatusChange:\n``` javascript\n                onStatusChange: function(id, oldStatus, newStatus) {\n                    self._onUploadStatusChange(id, oldStatus, newStatus);\n                    self._options.callbacks.onStatusChange(id, oldStatus, newStatus);\n                    self._maybeAllComplete(id, newStatus);\n                if (self._totalProgress) {\n                    setTimeout(function() {\n                        self._totalProgress.onStatusChange(id, oldStatus, newStatus);\n                    }, 0);\n                }\n            }\n\n```\nI guess the setTimeout is the culprit. It should only be scheduled once.\nSince we process all n files in a loop, the setTimeout callback gets scheduled to run n times, but only after all the files have been added. So I think only 1 call should suffice as well, and give the UI thread more time to update.\n. I tried solving that with this little adjustment:\njavascript\n                    if (self._totalProgress && self._totalProgressTimeoutId === null) {\n                        self._totalProgressTimeoutId = setTimeout(function() {\n                            self._totalProgress.onStatusChange(id, oldStatus, newStatus);\n                            self._totalProgressTimeoutId = null;\n                        }, 0);\n                    }\nBut that doesn't help at all.\nSo, I decided to run the profiler in IE10 and it turns out 99% of the time is spent inserting all the items into the DOM (specifically appendChild(), insertBefore() and set textContent). The trick to speeding this up big time is to update all of the HTML in one go, so that only one reflow & repaint operation has to be performed by the browser.\nI must admit, I don't know how to tackle that one. Any advice?\n. Just tested that; you are correct. It does look like it is going to be tough. :/\n. I'm not sure about the design of the templating module FineUploader uses, so I can't predict if it can handle the detached DOM node (for example it might query the DOM in an intermediate step). @rnicholus can you shine some light on this (valuable) suggestion?\n. I didn't think so either. A hacky way would be to add the files in small batches using a recursive setTimeout strategy but that doesn't really solve the underlying problem.\n. Maybe we can cache the selector results in some places? We could also switch to id's for unique elements.\n. In my case, I also use the list of files to filter duplicates/prevet files from being uploaded twice, using md5 hashes. So I do need the whole list. But, I could just not add them to the UI as you say. Excellent changes by the way. Looking forward to the release!\n. Besides the situation you described earlier, such a method could also be used to push files through WebSockets so multiple users (perhaps not even FineUploader but some other process) can upload files into the same container and see eachother's uploads as they're coming in.\n. To answer your question, I would probably not use it in the near future, if your current work already fixes the current issue at hand. Perhaps the requirement will come up later though.\n. That was clear IMO.\n. Sounds great!\n. Just wanted to let you know that we've confirmed this issue as fixed on our testing servers, and we'll go live with it soon. Thanks for the excellent support!\n. When you use the Azure FineUploader, by default it will upload files using uuid's as the blob name. If the file you upload has no extension, FineUploader appends \".undefined\" to the uuid.\nAlso see the PR #1480 I submitted, it's pretty obvious.\n. I just confirmed my custom build with the PR included as working on our testing servers, as we needed to get this live quickly.\n. Yeah, sorry about that. It's so natural for me that I forgot to mention it. :)\n. Sure, we'll merge upstream into our custom builds until it's included. Thanks!\n. I think I had to sign something when I first sent you a PR? But the form was broken, so I agreed textually in the PR discussion.\nSo, again, agreed!\n. See: https://github.com/FineUploader/fine-uploader/pull/1404#issuecomment-100174281\n. OK, then it's probably my own code that is creating the problem. Thanks for the info.\n. Just an FYI for others looking at this:\nScaling calls createObjectURL but it never calls revokeObjectURL, so be careful about that.\nOtherwise, you can do:\nonComplete: function (id, name, responseJSON, xhr) {\n                    this._handler.expunge(id);\n                },\n. Sure. I'm not actually using scaling feature though, I just concluded that from a search through FineUploader's source.\nTurns out we're simply the victim of a browser bug present in every single browser. :( For example, here's Chromium's bug, and here's an overview of the limits/bugs per browser. Hope this helps anyone who stumbles upon this thread.\n. I guess this if-else-tree might cause some unexpected behavior... what if the value is a function \u00e1nd the parameter name matches an azure parameter? I'll improve upon it next Monday, if you agree with me.\nI think it should be more like this:\n``` javascript\nvar headerName = qq.azure.util._getPrefixedParamName(name);\nvar value = null;\nif (qq.isFunction(val)) {\n    value = String(val()));\n}\nelse if (qq.isObject(val)) {\n    qq.extend(headers, qq.azure.util.getParamsAsHeaders(val));\n}\nelse {\n    value = String(val);\n}\nif (value !== null) {\n    if (qq.azure.util._paramNameMatchesAzureParameter(name)) {\n        headers[headerName] = value;\n    } else {\n        headers[headerName] = encodeURIComponent(value);\n    }\n}\n```\nI'm kind of surprised the unit tests didn't catch this?\n. I'm a bit short on time, can we postpone the adjustment by 2 months?\n. ",
    "simondebaecke": "What is the status of this issue ? I test the code from #1258 but it seems to not work correctly ... right ?\n. ",
    "placeposition": "Could this issue have been \"TypeError: Attempted to assign to readonly property.\" which is what I am getting in Safari only? \nThis happens when initiating fineuploader with the jQuery plug in, works fine in all other browsers in strict mode- Safari (and iPads) all 'freeze' at this js error. Im debugging now, I tried to solve by updating from FU 4.x to latest build (5.0.1) the prompt is -custom.fineuploader-5.0.1.js, line 427\n```\nqq.extend = function(first, second, extendNested) {\n    qq.each(second, function(prop, val) {\n        if (extendNested && qq.isObject(val)) {\n            if (first[prop] === undefined) {\n                first[prop] = {};\n            }\n            qq.extend(first[prop], val, true);\n        }\n        else {\n            first[prop] = val; //this is line 427\n        }\n    });\nreturn first;\n\n};\n```\nI'm not done working through this yet but I know I dont have any readonly attributes on fields in this page, but maybe i'm taking that too literally.\nIts instantly solved by removing \"use strict\"; but I guess thats not a great answer\n. ",
    "kapouer": "Reproduced with the fine-uploader jquery plugin 3.5.2 in epiphany 3.18 (which embeds webkitgtk).\n. Did i say 3.5.2 ? I meant 5.3.2 of course !\n. Linux ! debian/stretch gnome 3.18 / epiphany 3.18.\nIt seems to be a well known bug in webkit, see\nhttps://github.com/jrburke/requirejs/commit/d09afa77cc956ae5062a76350bd4db6302c7e873\nand\nhttps://bugs.webkit.org/show_bug.cgi?id=49739\n. Debugging it, actually that is not caused by \"use strict\". It's caused by\ncontainer.innerHTML = templateHtml.template\nwhere container is null.\nInstead of writing \"container is null\" the error message is \" Attempted to assign to readonly property.\" which lead to another problem.\n. ha damn, it was me passing button option instead of element. Sorry for the noise.\n. ",
    "adeperio": "Hi Ray thanks for getting back to me.\nSo I need to be able to use fineuploader in an angular directive. Here is my original code:\nangular.module(\"myApp\")\n    .directive(\"fineUploaderS3\", function() {\n        return {\n            restrict: \"ECMA\",\n            controller: 'FaceCardEditCtrl',\n            replace: true,\n            link: function($scope, element) {\n```\n            element.fineUploaderS3({\n            Fine uploader uptions...\n        });\n    }\n}\n\n});\nThis works fine using jQuery, but im trying to decrease the foot print for my mobile web app so I'm looking to eliminate the jQuery dependency. Is there any other way to initialise the fineUploader module on the givin/injected element in the directive?\n```\n. Ahh ok thanks for your help. I'll post on stackoverflow with the proper tags. Bythe way I just tried that and Im still having issues. I'll detail them in an SO question. Thanks again. T\n. so i actually ended up using this:\nI have a nodeJS backend which interfaces with the s3 sdk. \n======= My code ======================\nfunction bindToRenderedTemplate($compile, $scope, element) {\n    $compile(element.contents())($scope);\n}\nangular.module(\"cDeckApp\")\n    .directive(\"fineUploaderS3\", function() {\n        return {\n            restrict: \"ECMA\",\n            controller: 'FaceCardEditCtrl',\n            replace: true,\n            link: function($scope, element, $compile) {\n```\n            $scope.uploader = new qq.s3.FineUploader({\n                element: element[0],\n                request: {\n                    // REQUIRED: We are using a custom domain\n                    // for our S3 bucket, in this case.  You can\n                    // use any valid URL that poidddnts to your bucket.\n                    endpoint: \"my.s3.endpoint\",\n                // REQUIRED: The AWS public key for the client-side user\n                // we provisioned.\n                accessKey: \"MYACCESSKEY\"\n            },\n            objectProperties: {\n                acl: \"my-acl-property\"\n            },\n            template: \"qq-template-bootstrap\",\n\n            signature: {\n                endpoint: \"/s3handler\"\n\n            },\n            scaling: {\n                sendOriginal: false,\n                sizes: [\n                    {name: \"small\", maxSize: 200}\n                ]\n            },\n\n            uploadSuccess: {\n                endpoint: \"/s3/uploadSuccessful\"\n            },\n\n            // USUALLY REQUIRED: Blank file on the same domain\n            // as this page, for IE9 and older support.\n            iframeSupport: {\n                localBlankPagePath: \"success.html\"\n            },\n            validation: {\n                allowedExtensions: [\"gif\", \"jpeg\", \"jpg\", \"png\"],\n                acceptFiles: \"image/gif, image/jpeg, image/png\",\n                itemLimit: 1,\n                sizeLimit: 1000000\n            },\n\n            thumbnails: {\n                placeholders: {\n                    notAvailablePath: \"assets/placeholders/not_available-generic.png\",\n                    waitingPath: \"assets/placeholders/waiting-generic.png\"\n                }\n            }\n        });\n\n        bindToRenderedTemplate($compile, $scope, element);\n\n    }\n}\n\n});\n======================\nMy current error is : \n```\nTypeError: object is not a function\n    at bindToRenderedTemplate (http://localhost:9000/scripts/directives/fineUploaderDirective.js:4:5)\n    at link (http://localhost:9000/scripts/directives/fineUploaderDirective.js:70:17)\n    at nodeLinkFn (http://localhost:9000/bower_components/angular/angular.js:6579:13)\n    at compositeLinkFn (http://localhost:9000/bower_components/angular/angular.js:5986:15)\n    at compositeLinkFn (http://localhost:9000/bower_components/angular/angular.js:5989:13)\n    at compositeLinkFn (http://localhost:9000/bower_components/angular/angular.js:5989:13)\n    at nodeLinkFn (http://localhost:9000/bower_components/angular/angular.js:6573:24)\n    at compositeLinkFn (http://localhost:9000/bower_components/angular/angular.js:5986:15)\n    at publicLinkFn (http://localhost:9000/bower_components/angular/angular.js:5891:30)\n    at http://localhost:9000/bower_components/angular-ui-router/release/angular-ui-router.js:2805:9  \nand this occurs in the line:\n    $compile(element.contents())($scope);\nin the bindToRenderedTemplate function\nCan you see anything wrong with this implementation? \n. Hi Ray thanks for that. I tried that and it also doesn't work. I've posted a question here on SO regarding this... https://stackoverflow.com/questions/23903502/fineuploader-in-angular-directive-with-no-jquery\n. ",
    "hyzhak": "@rnicholus \nI mean, for example we have such template:\nhtml\n<ul class=\"qq-upload-list-selector list-unstyled\">\n  <li>\n    <div class=\"hidden-xs hidden-sm\">\n      <!-- other controls -->\n      <div class=\"qq-progress-bar-container-selector progress\">\n        <div class=\"qq-progress-bar-selector bar progress-bar-success\"></div>\n      </div>\n      <!-- other controls -->\n    </div>\n    <div class=\"visible-xs visible-sm\">\n      <!-- other controls -->\n      <div class=\"qq-progress-bar-container-selector progress\">\n        <div class=\"qq-progress-bar-selector bar progress-bar-success\"></div>\n      </div>\n      <!-- other controls -->\n    </div>\n  </li>\n</ul>\nin this case only 1st progress bar will work, the same situation for other elements.\nSo I'd like that 'fine-uploader' processes all DOM elements which has specific class, but this lib work only with 1st one.\n. @rnicholus No. I have duplication elements because I'm using media queries (from bootstrap3).\nThe reason, because for different screen sizes I have completely different design and as follow different html structures. Sure it is possible to squeeze different designs in one html-structure, but it is definitely bad practice because in this case html won't reflect design structure and semantic, and it will be very hard to make any changes.\nI just wasn't show whole pages because my example is enough to reproduce problem.\n. @rnicholus thanks\n. @rnicholus Is there any docs how to implement 'qq-upload-button-selector' by core?\n. @rnicholus I have 1 button and one link, each should open upload dialog.\n. @rnicholus Does it works for links or only for buttons?\n. @rnicholus it there no any way to add extraButtons after fineuploader has been created? I need to add extrabutton from template.\n. I have found the way to add extra button, after fineuploader has been created:\njavascript\n $scope.uploader._initExtraButton({\n                                element: elm,\n                                validation: {\n                                    acceptFiles: [],\n                                    allowedExtensions: []\n                                }\n                            });\nit will be great if we have same function for other controls.\n. @rnicholus \nanyway it is still the same:\nMaximum number of parts per upload  10,000\n. @rnicholus yes, if we will have callback which call with file id and wait for partSize, it can be much easier.\n. any type of files\n. @rnicholus I try to decapled from template engine inside of Fine Uploader and done everything by angularjs. The reason - that my case can't be covered by current template engine of Fine Uploader and I think there is no a lot of sence to try to set on all chairs. So If you can decaped Core of Fine Uploader and give posibility to handle setStatusText, it can be much easier to customize visualization.\n. @rnicholus \n\nIf you really want to use Fine Uploader UI, in this case, just omit the selector class on the status element and update the text when appropriate for this element via the dom.\n\nbut is there any way to get callback of setStatusText, without monkey patching?\n. @rnicholus \n\nI would suggest you not \"monkey patch\" the code.  The internals can change\nat any time, without announcement.\n\nsure, but how can I get when Fine Uploader API change status text? And what state of status? Without using template.\n. @rnicholus yes, but it is not alway in a syn with statusTest. \nFor example: \n- status: 'retrying N/M'. How you can get how many time it was retried by status 'retrying upload'?\n- status: 'Problem signing the chunk!'. How can you get what was the reson of upload failure by status: 'upload failed'?\n  and so on.\n. @rnicholus I just want to get current status text and show it by myself without template engine of FineUploader. Sure I can handle status change, count how many times it was retried, and so on. But what is the sence, when Fine Uploader already has all these information, and it will be much easier to get it by API from FineUploader.\n. :+1: waiting for this features\n. @rnicholus hm, return false inside of onSubmitted callback doesn't work to me. Files continue to upload as usual.\n. @rnicholus it is bind with other bug https://github.com/FineUploader/fine-uploader/issues/1327. I try to upload huge among of files >1k and if user cancels uploading there are still some among of files that still in 'submitting' status and I try to catch them after cancelAll() in onSubmitted callback to prevent uploading the tail. Finally I have found solution for fix current bug - I use timeout - but I got other bug (that comes after while): \nTypeError: Cannot read property 'status' of undefined\nSo current bug doesn't critical to me - I can circumvent it. but  https://github.com/FineUploader/fine-uploader/issues/1327 really toughie\n. hm, strange - I'm using same version. Is there any CDN with FineUploader - I can create sample with jsfiddle to reproduce this bug.\n. I'll try it is a part of big app, but what about another bug: https://github.com/FineUploader/fine-uploader/issues/1327 it is more critical to me.\n. I add large number of files (>1k) all those files put in queue of submitting files and one-by-one converting in submitted state. But it is not comes in once but in some seconds. I need to get moment when all files were submitting. How can I get it with existing API?\n. @feltnerm I'm trying to add 10k files and after that my Chrome (win or MacOS never-mind) is stuck for a minutes, sometimes ever crash and its happening on submitting phase. it is before uploading - so I have just split those files in a chunks and add them chunk-by-chunk. And need to get promise when files in a chunk will be submitted. I have found solution - I'm listening onSubmitted callback.\nSo my idea that - it will much better to have promises for all async commands. Like we already have for drawing thumbnails. It will be much more predictably and convenient. \n. ",
    "jakob-fuchs": "I hope it's not bad etiquette to post in this old issue here, but it seemed to be the most fitting one. I need to disable this resize behavior. For my use case I'd rather not display the preview image at all instead of resizing it. Also, does anyone know if these restrictions are still in place in newer iOS devices? \nI am aware that I can implement my own code for thumbnail generation, but the fine uploader implementation is really fast and performant.. ",
    "nasaorc": "I changed my code into this one:\njavascript\nonSubmitted:function(id,name){\n    var file = uploader.getFile(id);\n    $.each(uploader.getUploads(),function(){\n        if(file.name == this.name && file.size == this.size){\n            uploader.cancel(this.id);\n            return false;\n        }\n    });\n}\nbut still same:\n[Fine Uploader 5.0.1] Caught exception in 'onSubmitted' callback - Cannot read property 'parentNode' of undefined\nand I try to use the getUploads function with filter:\njavascript\nconsole.dir(uploader.getUploads({name:file.name,size:file.size}));\nconsole.dir(uploader.getUploads()) can display all queue files\nfile.name file.size can show the name and size correctly\nbut when put it together it just return undefined\n. Thanks a lot!!\n\u2014\nOn Wed, Jun 11, 2014 at 1:41 AM, Ray Nicholus notifications@github.com\nwrote:\n\njavascript\nonValidate: function(file) {\n    var matches = $.grep(this.getUploads({status: qq.status.SUBMITTED}), function(recordedFileItem) {\n        return file.name === recordedFileItem.name && file.size === recordedFileItem.size;\n    });\n    return !matches.length;\n}\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/Widen/fine-uploader/issues/1233#issuecomment-45647029\n. \n",
    "wideawakening": "Sure, reseting the limit on every 'allComplete' callback (regerdless of the succeed and failed items), could be a workaround.\nWould this be easy to implement (if not available yet)? Could give it a try to a patch.\nHave tried the reset method but it does reset everything, including the configuration of the component. I'm not familiar with the component yet nor confort with JS so I may have skiped something.\nBeen looking the code and thinking about a new validation item, like 'itemBatchLimit' that would be checked just before the start of the batch. \n. Thx @rnicholus with the onValidateBatch it worked like charm :)\n```\ncallbacks: {\n    onValidateBatch: function(data){\n        console.log('batch length: ' + data.length);\n        if (this.user_settings.file_queue_limit > 0 && data.length > this.user_settings.file_queue_limit){\n            var tooManyItemsError = \"Too many items ({netItems}) would be uploaded.  Item limit is {itemLimit}.\"\n                        .replace(/{netItems}/g, data.length)\n                        .replace(/{itemLimit}/g, this.user_settings.file_queue_limit);\n        setTimeout(function() {\n                       window.alert(tooManyItemsError);\n        }, 0);\n        return false;\n    }\n\n},\n... // rest of the callbacks\n```\nthis.user_settings.file_queue_limit contains the limit I want to use.\n. Had to change the suggested impl because it didn't work with the drag&drop, neither with the 'autoupload:false' configuration.\nIn case it might help anyone,\nonValidateBatch: function(data){\n    return this.checkItemLimit(data);\n},\nonComplete: function(){\n      this.items_queued = 0;\n}\n/*\n * ext uploader\n */\nthis.uploader.checkItemLimit = function(to_queue_items){\n    if (this.items_queued == undefined){\n        this.items_queued = 0;\n    }   \n    if (this.user_settings.file_queue_limit > 0 && this.items_queued + to_queue_items.length > this.y31.baseOptions.file_queue_limit){\n        var tooManyItemsError = \"Too many items ({netItems}) would be uploaded.  Item limit is {itemLimit}.\".replace(/\\{netItems\\}/g, this.items_queued + to_queue_items.length).replace(/\\{itemLimit\\}/g, this.user_settings.file_queue_limit);\n        setTimeout(function() {\n        window.alert(tooManyItemsError);\n    }, 0);\n        return false;   \n    }else{      \n        // inc queued\n        this.items_queued += to_queue_items.length;\n        return true;\n    }\n}\nUsing the multiple UI param might also help with this issue.\n. ",
    "Manidipa": "Thanks for your quick response. I have checked the features in the document and you have added drag and drop of folder support for Chrome and Opera which is good. But we are looking for folder selection in all the HTML browsers. I did not find the folder selection feature for all the browsers in the feature list. Can you please help me on this.\nThanks in advance for your help.\n. Hi Ray\nI have checked your feature support matrix and multiple file selection is allowed in windows safari. In demo also I was able to select multiple files and able to upload. But when we are trying in our application then we are getting the error message attached above. Please let us know how to fix this\nRegards\nManidipa \n. what do you mean by any location. is it cloud location please explain in detail.\n. Hi Ray\nWe are using win 10 licensed version 10.0.10586. As per Microsoft drag n drop is supported in edge browser but when try with fine uploder then it is not supported. \nhttp://mspoweruser.com/windows-10-build-10565-microsoft-edge-gets-support-for-file-drag-and-drop-tab-previews-and-more/\nPlease let us know what changes needed for this in fineuploader.\nRegards\nManidipa\n. ",
    "skoona": "My setup is very basic using jquery-1.8.3.  I added the 'scaling:' method to the options set and wha-la, it worked for images.  At this point I happened to try uploading a PDF and it failed. changing 'sendOriginal: true' restored the pdf upload ability, but has the side effect of sending both scaled and original images.\nThe following is the snippet used to initialize fineUploader on a list of elements.  Scaling is enabled, and sendOriginal=false because my patch is applied.\n```\nfunction attachmentHandlerForPolicyAndQuotes(keys) {\n    var svcId,\n        csrfToken = $('meta[name=\"csrf-token\"]').attr('content'),\n        lobName = $('#lob').val();\nkeys.each(function(index, elem) {\n    var qId = $(elem).data().fileId,\n        fTarget = 'fineUploader-' + qId,\n        svcId = $(elem).data().svcId;\n\n    /*\n     * initialize fineUploader on this Div\n     * - scaling seems to want to scale every file, hence a pdf will cause an error of no files being uploaded\n    */\n    $(elem).fineUploader({\n        button: $(\"#\" + qId + \"-action\"),\n        debug: logEnabled,     // true in rails development mode\n        request: {\n            endpoint: '/attachments/' + svcId + '/file_upload',\n            customHeaders: { 'X-CSRF-Token': csrfToken },\n            params: { authenticity_token: csrfToken, question_id: qId, lob_name: lobName }\n        },\n        deleteFile: {\n            enabled: true,\n            endpoint: '/attachments/' + svcId + '/file_delete',\n            method: 'POST',\n            customHeaders: { 'X-CSRF-Token': csrfToken },\n            params: { authenticity_token: csrfToken, question_id: qId, lob_name: lobName }\n        },\n        template: 'qq-template-attachments',\n        classes: {\n            success: 'alert alert-success',\n            fail: 'alert alert-error'\n        },\n        validation: {\n            acceptFiles: allowedFileMimes,\n            allowedExtensions: allowedFileTypes,\n            sizeLimit: 12000000\n        },\n        scaling: { // This feature is supported on all browsers other than IE9 and older, Android 2.4 or older, and Safari 5.1 or older.\n            sendOriginal: false, // FIXME  This may be preventing other files from uploading\n            includeExif: true,\n            hideScaled: false,\n            sizes: [\n                {name: \"scaled\", maxSize: 1600}\n            ]\n        },\n        showMessage: function(message) {\n            $('#' + fTarget).append('<div class=\"alert alert-error\"><a href=\"#\" class=\"close\" data-dismiss=\"alert\">&times;</a>' + message + '</div>');\n        }\n    }).on(\"complete\", function(event, id, name, responseJSON, xhr) {\n        if (responseJSON.success) {\n            addToTextFieldValue('#' + qId + 'z1', responseJSON.name);\n            addToTextFieldValue('#' + qId + 'z2', responseJSON.fqfn);\n            $('#upload-ok-button').removeAttr('disabled');\n            // 1+ files already, hide attached-previous-cb\n            if ( $('#' + qId + 'z1').val().split(',')[0].length &&\n                $('input[name=\"files[' + qId + '-attached_previous]\"]').length) {\n                $('input[name=\"files[' + qId + '-attached_previous]\"]').parent().slideUp().removeAttr('checked');\n            }\n        }\n        $( event.target).find('li[qq-file-id=\"' + id + '\"] div.qq-progress-bar-container-selector').slideUp();\n        questionLog(\"attachmentHandlerForPolicyAndQuotes(complete) id=\" + id + \", name=\" + name + \", response=\" + JSON.stringify(responseJSON));\n\n    }).on(\"deleteComplete\", function(event, id, xhr, isError) {   // isError does not work, only works if controller return non-200 code\n        var index = removeFromTextFieldValue('#' + qId + 'z1', $(this).fineUploader(\"getName\", id));\n        removeFromTextFieldIndex('#' + qId + 'z2', index);\n        // 0 files already, unhide cb\n        if ( $('#' + qId + 'z1').val().split(',')[0].length === 0 &&\n            $('input[name=\"files[' + qId + '-attached_previous]\"]').length ) {\n            $('input[name=\"files[' + qId + '-attached_previous]\"]').parent().slideDown();\n        }\n        questionLog(\"attachmentHandlerForPolicyAndQuotes(deleteComplete) id=\" + id + \", isError=\" + isError + \", name=\" + $(this).fineUploader(\"getName\", id) + \", xhr=\" + JSON.stringify(xhr.response));\n\n    }).on(\"error\", function(event, id, name, errorReason, xhr) {\n        questionLog(\"attachmentHandlerForPolicyAndQuotes(error)  id=\" + id + \", name=\" + name + \", errorReason=\" + errorReason + \", xhr=\" + JSON.stringify(xhr.response));\n    });\n});\n\n}\n```\nThese are the UI templates used to contain upload results and guide the user.\nvar attachTemplates = {\n    miscItem: '\\\n    <div class=\"control-group <%= item.qid %> misc-docs well\">\\\n        <ul class=\"breadcrumb span12\">\\\n            <li><strong><%= item.type %></strong><span class=\"divider\">/</span></li>\\\n            <li><%= item.section %><span class=\"divider\">/</span></li>\\\n            <li><%= item.description %></li>\\\n            <li class=\"pull-right span1\">\\\n                <a href=\"#\" class=\"btn btn-mini misc-plus\" data-description=\"<%= item.description %>\"><i class=\"icon-plus-sign\"></i></a>\\\n                <a href=\"#\" class=\"btn btn-mini misc-minus\" data-description=\"<%= item.description %>\"><i class=\"icon-minus-sign\"></i></a>\\\n            </li>\\\n            <li class=\"pull-right span3\">\\\n                <a  id=\"<%= item.qid %>-action\" href=\"#\" class=\"btn btn-primary\" data-file-id=\"<%= item.qid %>\">\\\n                    <i class=\"icon-upload  icon-white\"></i>\\\n                    <span> Select Files</span>\\\n                </a>\\\n            </li>\\\n        </ul>\\\n        <input class=\"text\" id=\"<%= item.qid %>z1\" name=\"files[<%= item.qid %>z1]\" type=\"hidden\" value=\"\"/>\\\n        <input class=\"text\" id=\"<%= item.qid %>z2\" name=\"files[<%= item.qid %>z2]\" type=\"hidden\" value=\"\"/>\\\n        <div id=\"fineUploader-<%= item.qid %>\" class=\"fineUploader\" data-file-id=\"<%= item.qid %>\" data-svc-id=\"<%= item.svcId %>\"></div>\\\n    </div>',\n    missingItem: '\\\n    <div class=\"control-group <%= item.qid %> well\">\\\n        <ul class=\"breadcrumb span12\">\\\n            <li><strong><%= item.type %></strong><span class=\"divider\">/</span></li>\\\n            <li><%= item.section %><span class=\"divider\">/</span></li>\\\n            <li><%= item.description %></li>\\\n            <li class=\"pull-right span3\">\\\n                <a  id=\"<%= item.qid %>-action\" href=\"#\" class=\"btn btn-primary\" data-file-id=\"<%= item.qid %>\">\\\n                    <i class=\"icon-upload  icon-white\"></i>\\\n                    <span> Select Files</span>\\\n                </a>\\\n            </li>\\\n        </ul>\\\n        <input class=\"text\"  name=\"files[<%= item.qid %>]\" type=\"hidden\" value=\"<%= item.detailId %>\"/>\\\n        <input class=\"text\" id=\"<%= item.qid %>z1\" name=\"files[<%= item.qid %>z1]\" type=\"hidden\" value=\"\"/>\\\n        <input class=\"text\" id=\"<%= item.qid %>z2\" name=\"files[<%= item.qid %>z2]\" type=\"hidden\" value=\"\"/>\\\n        <div id=\"fineUploader-<%= item.qid %>\" class=\"fineUploader\" data-file-id=\"<%= item.qid %>\" data-svc-id=\"<%= item.svcId %>\"></div>\\\n    </div>',\n    missingBldgItem: '\\\n    <div class=\"control-group <%= item.qid %> well\">\\\n        <ul class=\"breadcrumb span12\">\\\n            <li><strong><%= item.type %></strong><span class=\"divider\">/</span></li>\\\n            <li><%= item.section %><span class=\"divider\">/</span></li>\\\n            <li><%= item.description %></li>\\\n            <li class=\"pull-right span3\">\\\n                <a  id=\"<%= item.qid %>-action\" href=\"#\" class=\"btn btn-primary\" data-file-id=\"<%= item.qid %>\">\\\n                    <i class=\"icon-upload  icon-white\"></i>\\\n                    <span> Select Files</span>\\\n                </a>\\\n            </li>\\\n            <li>\\\n                <label class=\"checkbox pull-left\">\\\n                    <input class=\"checkbox\" name=\"files[<%= item.qid %>-attached_previous]\" type=\"checkbox\" value=\"yes\" /> Attached to a previous building\\\n                </label>\\\n            </li>\\\n        </ul>\\\n        <input class=\"text\"  name=\"files[<%= item.qid %>]\" type=\"hidden\" value=\"<%= item.detailId %>\"/>\\\n        <input class=\"text\" id=\"<%= item.qid %>z1\" name=\"files[<%= item.qid %>z1]\" type=\"hidden\" value=\"\"/>\\\n        <input class=\"text\" id=\"<%= item.qid %>z2\" name=\"files[<%= item.qid %>z2]\" type=\"hidden\" value=\"\"/>\\\n        <div id=\"fineUploader-<%= item.qid %>\" class=\"fineUploader\" data-file-id=\"<%= item.qid %>\" data-svc-id=\"<%= item.svcId %>\"></div>\\\n    </div>',\n    noSelection: '<p><strong>You must first select/check items from the <strong>Missing Items</strong> table, only checked items will be listed here.</strong></p>',\n    regularSelection: '<p><strong>Please provide descriptive file names and limit file types to PDFs or Images.</strong></p>'\n};\nThe modal which contains the above: rails 3.2 erg file.\n<%# Upload Attachments Modal %>\n<div id=\"upload-attachments-modal\" class=\"modal hide fade\" tabindex=\"-1\" role=\"dialog\" aria-labelledby=\"upload-attachments-label\" aria-hidden=\"true\">\n    <%= form_tag action_target, :id => \"upload-attachments-form\", :class => \"modal-form form-horizontal\", :remote => false, :method => :post, :multipart => :true do %>\n        <div class=\"modal-header\">\n            <h3 id=\"upload-attachments-label\" class=\"text-left\">Attach Documents</h3>\n        </div>\n        <div id=\"upload-attachments-body\" class=\"modal-body\" data-lob-id=\"<%= lob_id %>\" data-lob-cis=\"<%= lob_cis %>\">\n            <div class=\"alert alert-block span12\">\n                <span id=\"banner-message\" data-opt-quotes=\"<%= opt_quotes_bool %>\" class=\"text-center\">Please provide descriptive file names and limit file types to PDFs or Images.</span>\n            </div>\n            <fieldset><legend></legend>\n            </fieldset>\n            <input id=\"lob\" name=\"lob_name\" type=\"hidden\" value=\"<%= lob_name %>\" />\n            <div id=\"general-error-div\" class=\"control-group\"></div>\n        </div>\n        <div class=\"modal-footer\">\n            <%= button_tag \"Save\", type: :submit, name: 'process_upload_modal_action', value: 'save', class: \"btn btn-primary\", id: \"upload-ok-button\" %>\n            <a id='upload-cancel-btn' href=\"#\" data-dismiss=\"modal\" class=\"btn\">Cancel</a>\n        </div>\n    <% end %>\n</div>\nA snippet of js code to create an Misc entry in the modal.\n/* add misc doc type, with plus/minus keys */\n        mItem = {\n            qid: 'misc-1',\n            type: 'Miscellaneous Documents',\n            section: lobName,\n            description: 1,\n            svcId: lobName + '-' + lobId + '-9999',\n            detail_id: '0'\n        };\n        mBody.append(_.template(attachTemplates.miscItem, {item: mItem}));\n        mBody.find('a.misc-minus').last().remove();\nI hope this is want you need?\nJames,\n. Thanks, I will watch for the update.\n. It works for me.  I tried uploading two files, a pdf and a jpeg.   With hideScaled: true, no update was driven (no filename displayed) to the UI, but upload the scaled image; kinda thought it would show the original filename.  Instead is showed nothing and uploaded the scaled image.  Switching back to hideScaled: false, caused the UI to update with the scaled filename; which is fine for me.\nI used this config:\nscaling: { \n                sendOriginal: false, \n                includeExif: true,\n                hideScaled: false,\n                sizes: [\n                    {name: \"scaled\", maxSize: 1600}\n                ]\n            }\nAs far as I can tell, it seems to be working for me.  Thank you for the quick update.\nJames,\n. Yes, PDFs were always shown regardless.  \nNot really concerned about the blind UI updates, as long as the :complete callback is called, and/or there is a local listing of uploaded files.  I will check this out over the weekend.\nJames,\n. I've covered all my bases, everything I need it to do is working as expected.  Thanks for the quick turn around, and a great package.\nJames,\n. ",
    "RunRyder": "Above I show scaling parameters with blank name. If the name is blank and there is only one scaled version then do not add \" ()\" to the file name.\n. This scenario uploads one (scaled) image file.\nRunRyder's gallery engine creates the thumbnail.\nhttp://rc.runryder.com/helicopter/gallery/1/?all=photo\n. Thanks \nI do show \"sendOriginal: false\" in the opening post. :-)\n. This was my first post here. I now see \"Parsed as Markdown\" as the formatting engine. Good to go and thanks again.\n. What's the easy way to download your pre-release?\n. Thanks\n. It's online and good to go. Thanks\n. It is only unique for a particular uploader instance.\nYes and I use it to de-increment file time on the server. My galleries are displayed in reverse date order. The new parameter is used in conjunction with a passed time parameter. The modified JavaScript code above works good. \n<input type=hidden name=TM value='$curTIME'>\n. In other words, I want to know the selected order for each upload session. \n. For jQuery....\n$(\"#RR-UP\").on(\"upload\", function(event, id, name) {\n  $(this).fineUploader(\"setParams\", {fileId: id}, id);\n});\nThanks again.\n. Thanks\n. Fine-Uploader is working well for many thousands of my forum membership. It is not feasible to get this one end user to participate in troubleshooting. I will ask him to upgrade his browser. Thanks for the feedback.\n. Thanks\n. Thanks\n. ",
    "PauloCelso": "The thing is we do not see it failing, it looks like we possibly do not get the \"Success\" response in a timely manner due to server side processes,  at that point it uploads the file several times  I have only been able to prove this via iis logs, where i can see the request made in intervals of 5 minutes.\nSimilar to the following, \nhttp://stackoverflow.com/questions/16631078/fineuploader-restarts-the-upload-in-case-of-delayed-server-response.\n. Hello,\nI have found a way to replicate the issue. Before returning the result\nresponse to the instance of fineuploader I added a sleeper thread. Adding a\nbreakboint at the sleeper.\nOnce the code landed there I used fiddler to abort the session at the\nendpoint, immediately after continuing from the break point.\nOnce I did this the endpoint is called again and in fiddler you can see it\nreprocessing and creating the duplicates.\nReally appreciate it if you could assist with this.\nKindly\nPaulo.\nOn 7 Jul 2014 15:17, \"Ray Nicholus\" notifications@github.com wrote:\n\nClosing, but we can re-open if a live example required to reproduce is\nmade available.\n\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1245#issuecomment-48183714\n.\n. Hi,\n\nYes the upload is being repeatedly processed somehow and I do have the\ndebug set to true but nothing in either console or network which suggests\nthe retry. We have autoretry set to false.\nUnfortunately I am off on leave tomorrow so cannot post the code. I have\npreviously submitted in the ticket.\nIs there anyway you can confirm by attempting to simulate the break in\nconnection.\nOn 17 Jul 2014 17:01, \"Mark Feltner\" notifications@github.com wrote:\n\n@PauloCelso https://github.com/PauloCelso -- are you saying that Fine\nUploader is attempting to retry the upload when the connection fails, even\nthough you have set autoRetry: true?\nI'm not really sure what settings you are using. Do you have any code I\ncould look at? Is there any information in the javascript console or\nnetwork tab? Adding { debug: true } to your Fine Uploader constructor\nshould log more information too.\n\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1245#issuecomment-49327138\n.\n. \n",
    "sweet-watermelon": "Table is the most convenient way of presenting information without any cost vrmena writing a new style for displaying information.\n\nYes, at first, i opened the discussion in StackOverflow, after I found this repository and written the question here.\n. I load additional data for each selected file to upload, and for me to be more practical use for this tables... \nMaybe you think about replacing template engine to mustache (or another) and fix handler of templates?...\n. Mustache is just 3Kb ;)\n. ",
    "Partho-paul": "I too faced the Same issue with Huwaie mate 9 stock browser..\nFile picker window' opens fine, but after selecting the file, the file picker closes but nothing happens (no upload start).\n\n\n. ",
    "rquast": "Just a note if it is of any use to anyone else in future.. I have this issue on firefox 49.0.2 for mac. Using FineUploaderBasic like this..\nthis.fu = new qq.FineUploaderBasic({\n      button: this.file_upload_button,\nNo problems on any other platform/browser, though haven't tried Windows firefox. Don't know how to easily reproduce, may try if it becomes annoying.. ",
    "feryardiant": "Thanks @rnicholus for your fast responds.\nSorry if in this case I made \u200b\u200ba mistake and I have no plans to make my own version or do a customization of the original repo. In the repo I just wanted to provide a copy of any alternative. Recently I realized that the main script FineUploader in the lib/modules.js (is that true?) But maybe because I'm still just learning so I am not aware of it.\nAs you say \n\nIMHO, especially for a project like Fine Uploader, where your built version can vary greatly depending on the features you are interested in.\n\nI made this repo because my personal needs, but there may be others who also need it (I do not know).\nSo may I maintain ~~this~~ my repo for few time?\nThank you :smile: \n. Actually I'm working with cygwin, spesificly on babun.\n. I think the problem is here, which is npm bin command will return bin directory for our current project. On linux of course it will return something like /some/project/node_modules/.bin but on windows it will return D:\\some\\project\\node_modules\\.bin which is \\ (backward slash) will be escaped by POSIX it self, in that case if we call $(npm-bin)/jscs will return D:someprojectnode_modules.bin/jscs instead of D:\\some\\project\\node_modules\\.bin/jscs.\n. Thanks for addressing my issue, unfortunately I can't test it yet because I'm on Linux and had completely remove my windows but I'll try to test it on vm tonight (GMT+7) and back to you soon.. Actualy I have tried using $OSTYPE to detect my system. Sadly, it seems not working when I use it inside script but when I simply echo $OSTYPE from my terminal, it print cygwin. I have no idea afterward.. ",
    "fschwahn": "It's not really an option in my case, because I'm working against an existing API. Is there another method I could use to adjust the uploadSuccessEndpoint?\n. Yes, that's what I ended up doing - it was pretty easy. I cloned the behavior of uploadSuccessParams, i.e. creating a store, and retrieving the values for the correct file id.\nThanks for your support.\n. Ok, the problem was that I had a CSS rule which applied bottom:0;left:0 on the input element. The reason was that the upload button is quite big (in height), and in Chrome the input did not span across the complete height - you had to click the top portion of the button to hit the input. I have removed the left:0 part, because it was unnecessary for what I was trying to achieve, and caused the problems in IE. So this issue is application specific, sorry for the wrong report.\nAnyway, maybe it makes sense to include bottom:0 in the default styles applied to the input field to work around the issue, if it doesn't introduce other problems.\nAll the best,\nFabian\n. The same happens in Safari 8.0 (and probably other versions), though here it is SecurityError: DOM Exception 18: An attempt was made to break through the security policy of the user agent.\n. Sorry if I wasn't clear enough, this only happens when cookies are disabled. I don't have any plugins installed in Safari, I have installed some in Firefox, but I suspect it has nothing to do with it.\n. Well, the problem is that checking for the resume option here https://github.com/FineUploader/fine-uploader/blob/master/client/js/features.js#L96 already triggers this error.\nThat means it is impossible to upload any file if cookies are disabled. You can check this behavior on http://fineuploader.com/demos.html\n. I solved this by rewriting the check for the resume option as:\nsupportsResume = supportsAjaxFileUploading && supportsChunking && navigator.cookieEnabled && !!window.localStorage;\nThis allows me to use fineuploader when cookies are disabled.\n. Yes, that's the better solution, although it seems to be widely supported.\n. Hi,\nI just want to add that I would also be interested in this - at least a build with and without the UI component would be great.\nAll the best,\nFabian\n. First of all, the only thing I changed was fineuploader, everything else is identical. Were there any breaking changes between 5.0 and 5.1? I couldn't find anything on the blog, but maybe I missed somewhere else?\nAs for the line, in my version of fineuploader the string handlerModuleSubtype + \"UploadHandler\" just comes up once, in upload.initHandler in qq.UploadHandlerController.\nMy setup is that I do a direct upload to s3 in development/production, and traditional upload in my test environment for integration testing. This worked in the past without a problem. I just switched my development environment to the traditional uploader, and now I'm seeing the same error in Chrome.\nSo the traditional uploader does not work for me anymore in 5.1, while the same setup worked in 5.0. Maybe I was always doing something wrong, but came by in the past? I'm using the jQuery-plugin, maybe it is connected to that.\n. In my effort to reproduce the problem outside my application I downloaded fineuploader again from the homepage and when I saw the download page I realized that the traditional uploader is not part of the s3 package I downloaded. I just assumed that the traditional uploader is always part of the package. In earlier versions I just used the builder to include both.\nI realize that this was entirely my fault, but a message at least in debug mode if you are trying to use an endpoint which is not included would go a long way.\nSorry for wasting your time.\nAll the best,\nFabian\n. Thanks @rnicholus , we'll do that.\n. We are seeing the same issue with some of our users, but unfortunately I cannot contribute much. The error occurs here: https://github.com/FineUploader/fine-uploader/blob/339a80a99f08dbc9408b3f8960d59dfca8ecc99d/client/js/ajax.requester.js#L94, with requestData[id] being undefined.\nAlso, one of the users who got this error also triggered an error here https://github.com/FineUploader/fine-uploader/blob/339a80a99f08dbc9408b3f8960d59dfca8ecc99d/client/js/upload-handler/xhr.upload.handler.js#L293 with handler._getFileState(id) returning undefined.\nIt seems that all users seeing this issue had very bad connectivity, it may be related to that. For some of them the upload succeeded nonetheless.\nOur configuration looks like this, we are using version 5.5.1:\njavascript\n...\n  function() {\n    this.FileUploader = function() {\n      function e(e, t) {\n        null == t && (t = {}), this.el = e, this.options = t, this.setupUploader()\n      }\n      return e.prototype.setupUploader = function() {\n        var e, t;\n        return t = this, e = null, this.el.fineUploaderS3({\n          uploaderType: \"basic\",\n          button: this.el,\n          multiple: this.options.multiple,\n          maxConnections: this.options.maxConnections || 3,\n          validation: {\n            acceptFiles: this.options.acceptFiles || null,\n            sizeLimit: this.options.sizeLimit || 0,\n            minSizeLimit: this.options.minSizeLimit || 0,\n            allowedExtensions: this.options.allowedExtensions || []\n          },\n          request: {\n            endpoint: \"https://xxx.s3-eu-west-1.amazonaws.com\",\n            accessKey: \"XXX\"\n          },\n          objectProperties: {\n            acl: this.options.acl || \"public-read\",\n            key: function(e) {\n              var n, i, r;\n              return r = \"production/\" + qq.getUniqueId(), i = this.getName(e), n = t.options.extension || qq.getExtension(i), void 0 !== n && (r += \".\" + n), r\n            }\n          },\n          signature: {\n            endpoint: \"/upload_signatures\",\n            customHeaders: {\n              \"X-CSRF-Token\": $(\"meta[name=csrf-token]\").attr(\"content\")\n            }\n          },\n          uploadSuccess: {\n            customHeaders: {\n              \"X-CSRF-Token\": $(\"meta[name=csrf-token]\").attr(\"content\")\n            },\n            endpoint: this.options.endpoint,\n            params: this.options.params || {}\n          },\n          chunking: {\n            enabled: !0,\n            concurrent: {\n              enabled: !0\n            }\n          },\n          resume: {\n            enabled: !0\n          },\n          iframeSupport: {\n            localBlankPagePath: \"/upload_success.html\"\n          },\n          retry: {\n            autoAttemptsDelay: this.options.autoAttemptsDelay || 5,\n            maxAutoAttempts: this.options.maxAutoAttempts || 20,\n            enableAuto: !0\n          }\n        }\n....\n. Ok, I tracked this down, it is a regression which was introduced in 5.14.5 - there was only one change in this release: https://github.com/FineUploader/fine-uploader/compare/5.14.4...5.14.5 - this was a bugfix for edge.\nThis broke chunked uploads for Safari 9. Safari 9 seems to replace the empty content type with a single comma. Maybe the content type should only be set if it was detected that edge >= 15 is used?. @rnicholus I forgot to mention that I replicated the issue with the exact code from https://fineuploader.com/demos.html#amazon-demo, and the php endpoint from https://github.com/paulmelnikow/fine-uploader-server/blob/master/php/s3/s3demo-thumbnails-cors.php, so I'm sure it is not my environment causing this.. ",
    "franzk": "OK, that's good to know. I am using the pauseUpload and continueUpload methods as mentioned on the \"Pause In-Progress Uploads\" feature page.\n. ",
    "sixlettervariables": "@rnicholus, my apologies on that one. I was reasonably certain I branched from the right spot but obviously not!\n. You're welcome. This was by far and away the easiest to integrate uploader\nwhich worked with S3. I've backported this successfully to 5.0.3 and am\nusing it in a QA environment now.\nOn Fri, Jul 25, 2014 at 11:07 AM, Ray Nicholus notifications@github.com\nwrote:\n\nThanks for this. We'll sort out the build failure in the develop branch\nand take a closer look at this when we begin work on the next release.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/pull/1258#issuecomment-50162354.\n\n\nChristopher A. Watford\nchristopher.watford@gmail.com\n. @rnicholus, Let me know if you need me to rework this against 5.0.4.\n. @stevenringo, Amazon includes those as allowable un-prefixed headers, so they're included without the Amazon prefix.\n. @rnicholus: +1 from me.\n. ",
    "stevenringo": "Have noticed some issues with this:\n- parameters are URL encoded, resulting in headers with values such as attachment%3B%20filename%3Dfile.txt. You definitely don't want that.\n- I don't get why the default is to have x-amz- prefixes?\n- These seem never to get caught, as the name is munged into content-disposition for example:\ncase \"Cache-Control\":\ncase \"Content-Disposition\":\ncase \"Content-Encoding\":\nThanks!\n. These are not custom headers. These are standard http headers as per rfc2616. Ideally then there should be two parameters; one for bona fide custom headers, that are not part of the spec (i.e. needs x-amz-), and one for headers that are part of the HTTP spec, respectively.\n. > Also, not sure what this comment means...\n_getPrefixedParamName: function (name) seems to pass name as content-disposition (lowercases the actual header)\n. https://github.com/sixlettervariables/fine-uploader/blob/fe4586d26badaa52f3cde61002b281b3e8da1788/client/js/s3/util.js#L65\n. @sixlettervariables They should also not be URL encoded.\n. ",
    "arnoldad": "@rnicholus, excellent work. This is going to save us some considerable SS overhead. \nI'll experiment with the dev build on my own, but for the benifit of others: \n1) Do I assume correctly we will be able to set the content-disposition header with a call to the setCustomHeaders() method from within the onSubmitted callback?\n2) Had you given any thought to a boolean configuration option to set the content-disposition header on s3 automatically using the supplied filename? (this would look really good on your feature list, and probably covers most users' needs for setting s3 object headers)\n. @rnicholus, the devel branch has a slight issue (that I was easily able to work around).\nin _getPrefixedParamName at fine-uploader/client/js/s3/util.js:73 \nSince the header names are coming in after being transformed with toLower() the switch cases with capitalization don't match.\nI understand that this is to prevent signature mismatches, but when i correct the issue by creating an alternate case without capitalization, the uploads work flawlessly with the header set using the following code. \n```\n                onSubmitted: function () {\n                  // get the filename of the most recently submitted file\n                  var currentFileId = this._totalFilesInBatch - 1;\n                  var filename = this.getName(currentFileId);\n              // add filename to amazon content-disposition header\n              var customHeaders = {\n                \"Content-Disposition\": \"attachment; filename=\\\"\"+filename+\"\\\"\"\n              };\n              this.setCustomHeaders(customHeaders, currentFileId);\n\n            },\n\n```\n. Sure, I'll create a pull request after running unit tests. The Current workaround is a bit hacky. Do with it what you will. A more permanent solution might be to apply the toLower() after the param names are filtered with _getPrefixedParamName. (EDIT - The latter won't work as aws headers are case sensitive, and a lower-cased Content-Disposition header doesn't work in most browsers)\n. Keep up the good work- I spent several hours today going through the same struggle. My team is waiting to buy a license when the v4 signatures are supported.\n. ",
    "Alexey837": "That's all I read \nI do not understand your very direct answer \nExplain what you mean this link \nthank you\n. ",
    "KratosGemini": "That's interesting. I figured it was extra functionality. And actually, I'm using it at the moment in order to be able to validate folder paths when a folder is dragged and dropped. This allows me to do things like ignore files within any folder named __MACOSX to help keep our uploads clean. I suppose I can move my validation code to the onSubmit callback since that gets passed an id that I can use to look up the qqPath. Thanks for the heads up so I don't get surprised during a future update.\n. @rnicholus I confirmed that this is fixed in the hotfix/5.0.4 branch. The data object in the onValidate callback no longer has qqPath set for any file.\n. ",
    "PaulParker": "Also, any chance there's an easy workaround?\n. To find the cancelable files, you would look at the .status field, correct?  Or is there something like IsCancelable()?  Also, if I run getUploads on status change, will I be guaranteed to have the current statuses?\n. Sure.  I don't have a application in production yet but I can test out some of the expected use cases.\n. It looks like there is an intermittent issue with the currently-uploading file not getting cancelled when chunking and concurrent uploads are enabled.  WIth those settings, if I drag a bunch of files and cancel them, sometimes the first one will not be cancelled.  It seems like it's probably a timing issue or something.\nIf I disable concurrent, the issue seems to go away.\n. Yeah I figured.  Note that I am only seeing the issue when the currently-uploading file is not big enough to be chunked for S3 upload.  For a file > 5mb, the 'cancel all' seems to work fine, even with the concurrency.  However, if the file is < 5mb, the 'cancel all' will not necessarily cancel the current upload.\n. No, see edit.\n. Yeah, it is surprising.  Though I only have guesses as to how this is working internally - I have not inspected the source.\n. Sure, I'll take a look. Remind me where I can get 5.0.4-5?\n. Not yet. I should be able to get to it tomorrow.\n\nOn Aug 22, 2014, at 5:21 PM, Ray Nicholus notifications@github.com wrote:\n@PaulParker were you able to verify the fix?\n\u2014\nReply to this email directly or view it on GitHub.\n. Ok I think the fix worked and I haven't seen any other issues.\n. I agree with your thoughts about jQuery plugins.  However, I don't really want to re-write and re-test all my fine uploader-related code at this point.  It's important for us to be able to keep up with the fine uploader updates (there have been a number of important ones in V5 alone), and with this breaking change we'll have to rewrite a bunch of stuff in order to stay current.\n. Ok, thanks for the detailed response. I'll take a look at the the things you mentioned.\n\nThanks,\nPaul Parker\n\nOn Nov 2, 2014, at 1:55 PM, Ray Nicholus notifications@github.com wrote:\n@PaulParker There shouldn't really be any rewriting involved if we were to remove the jQuery plug-in wrapper. There are only a few adjustments you'll need to make, at most (possibly only 1 or 2 in reality):\nConstructing\nInstead of $('#fineUploaderContainer').fineUploader({...});, you'll need to construct like this:\nnew qq.FineUploader({\n   element: $('#fineUploaderContainer)[0],\n   ...\n});\nPassing elements into Fine Uploader's API\nYou'll need to pass in an HTMLElement instead of a jQuery object. So, just add a [0] to the end of all portions of your code that construct a jQuery object that interfaces directly with Fine Uploader. For example, if you are setting the button option now as button: $('#myButton), you would simply change this to button: $('#myButton')[0].\nCallbacks\nIf you are using jQuery event handlers for Fine Uploader events/callbacks, you'll need to refactor a small amount of logic.\nFor example, the jQuery way:\n$('#myFineuploaderContainer').on('complete', function(event, id, name, response, xhr) {\n   ...\n});\nWithout relying on jQuery event handlers, you'll declare your callback handlers during construction, like this:\nnew qq.FineUploader({\n   callbacks: {\n      onComplete: function(id, name, response, xhr) {\n         ...\n      }\n});\nThe latter approach is recommended over jQuery event handlers anyway. Why? Well, it's more intuitive efficient. You can (and should) be using the 2nd approach now, even if you are using the jQuery plug-in wrapper.\nAPI calls\nThe jQuery way looks like this: $('#myFineuploaderContainer').fineUploader('getName', fileId);. Pretty awkward, IMHO.\nThe native JavaScript way looks like this: uploader.getName(fileId);. I really prefer this syntax. The jQuery syntax is odd and unnecessary.\nIn the long run, no longer depending on jQuery is a good thing for everyone. When you look at jQuery critically and compare it with what's already provided by the Web API in modern browsers and other micro libraries, jQuery seems unnecessary.\n\u2014\nReply to this email directly or view it on GitHub.\n. Oops, I just noticed there's a demo here that's exhibiting the issue I'm experiencing:\nhttp://fineuploader.com/demos.html#amazon-demo\n\nBut the main demo at the top does not seem to have the issue.\nWish I'd scrolled down the demos page a little further before spending time to debug the issue on my test platform!\n. Ok, it would be great to enable multiple video upload on newer iOS Safari if the issue is no longer present.  \nWe get a good amount of traffic from iOS/safari but we have never seen anybody even try to access our website from iOS/chrome.\n. Is there a way that I can force it to be enabled somehow? I have an iOS/safari multiple upload requirement with a short deadline.\n. Great, thanks Ray for the workaround and for the prompt reply (as usual)!\n. ",
    "dmichael": "We are finding similar behavior when attempting to cancel Azure uploads via fineUploaderAzure('cancelAll'). Nothing happens and the file continues uploading.\n. Yes, thanks\nOn Aug 12, 2014 8:11 PM, \"Ray Nicholus\" notifications@github.com wrote:\n\nTurns out that unit testing this is tricky due to the timing required to\nproperly execute the cancelAll in order to reproduce. Tests that rely on\ncareful timing/setTimeouts are usually bad news. I've performed some manual\ntests in a few browsers, and all looks good. @dmichael\nhttps://github.com/dmichael and @PaulParker\nhttps://github.com/PaulParker Are you interested in verifying this fix\nin your apps, since you both reported this issue?\n\nReply to this email directly or view it on GitHub\nhttps://github.com/Widen/fine-uploader/issues/1262#issuecomment-51994973\n.\n. Hi Ray - seems to work for us, thanks\n\nOn Aug 18, 2014, at 3:41 PM, Ray Nicholus notifications@github.com wrote:\n\nAnyone get a chance to test this out? I'd like to release as part of 5.0.4 soon.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "KajanSiva": "Yes, because after the selection of the images, I make a redirection to an \"upload progress\" page where I list the selected files with a progress bar for each and a global progress bar at the top.\nFurthermore, if I remove \"sendOriginal\" option, everything works correctly.\n. Ok, thanks for your reactiveness :+1: \n. Yes, it's what I am doing actually but it makes my total progress bar go up to 100% when a file did just finished to upload. Then it goes down when the next file starts.\nI will try to make an approximate computation, based on the number of files and the progression of each.\n. Because we will mainly use the uploader for images, and we want to keep their order while uploading the images. And apparently, on the previous version of the website I am working on, they had some order issues when they used a maxConnections superior to 1.\n. Ah yes, that will be easier, thanks. I didn't saw the setParams method before, it will be useful.\nThanks again for you feedbacks.\n. ",
    "vladgolubev": "@rnicholus just stumbled upon this issue.\nSince it's 2 years after, is the browser situation better now and it's worth implementing?\n. Whoa! \nCool solution @nadeesha! . ",
    "khalidsalomao": "Status code: 200\nFine Upload version: 5.0.3\n. Thanks for the fast response!\nOK, but where is this description?\nCould you update the documentation in http://docs.fineuploader.com/branch/master/endpoint_handlers/traditional.html ?\nThere is no mention for this response code.\nI will test and keep you posted!\n. It worked! Thanks for the assistance!\nI would insist that the documentation on Servers > Traditional (http://docs.fineuploader.com/branch/master/endpoint_handlers/traditional.html) be updated, since it is missing this important information.\nAlso thanks for the great library!\nRegards\n. ",
    "voodoo709": "Once you have selected the image can you successfully upload it?\nI\u2019ve now tried a few websites and when an image can be selected the upload still doesn\u2019t work, it hangs for a long time before saying something along the lines of:\n \u201cthe server doesn't understand the request\u201d\nI did my own test using the code below and in iOS7 and it works fine and the properties of the file are displayed as seen in the attached image but again in iOS8 it just hangs and the upload wont complete\nUpload.html\n<form action=\"process.php\" method=\"post\"\nenctype=\"multipart/form-data\">\n<label for=\"file\">Filename:</label>\n<input type=\"file\" name=\"file\" id=\"file\"><br>\n<input type=\"submit\" name=\"submit\" value=\"Submit\">\n</form>\nprocess.php\n<?php\nif ($_FILES[\"file\"][\"error\"] > 0) {\n  echo \"Error: \" . $_FILES[\"file\"][\"error\"] . \"<br>\";\n} else {\n  echo \"Upload: \" . $_FILES[\"file\"][\"name\"] . \"<br>\";\n  echo \"Type: \" . $_FILES[\"file\"][\"type\"] . \"<br>\";\n  echo \"Size: \" . ($_FILES[\"file\"][\"size\"] / 1024) . \" kB<br>\";\n  echo \"Stored in: \" . $_FILES[\"file\"][\"tmp_name\"];\n}\n?>\nThe issue is also present in Chrome on iOS8 so seem to be an issue with iOS8 rather than just Safari\n\n. Yes just checked and adding multiple to the input type=\"file\" field results in not being able to select an image in my code above. With the multiple removed an image can be selected but the upload doesn\u2019t work in both Safari and Chrome in iOS8 but is fine in iOS7.\n. I\u2019m using the current generation iPad Air and Mini\u2019s below:\n1. iPad Air 16GB Model: A1474\n2. iPad mini 32GB Model: A1489\nBy the way adding multiple=\"false\" to my code above still results in the image not being selectable, only when multiple is not present at all can I select an image.\nAnyway it\u2019s good to hear you have FineUploader working correctly with the quick modification as I\u2019m looking to use it on my website.\n. ",
    "ChaplinWang": "Hi rnicholus,\nThis issue seems no longer valid in newer ios 8 version, IOS 8.1+ etc, I have found this fix is introducing new problems for later versions,\nIn my phonegap app, having multiple in my input field is preventing accessing camera on ios 8+\nCheers,\nChaplin\n. Thanks @rnicholus for quick response,\nshould the ios8BrowserCrashWorkaround, only be applied to ios 8.0.0 rather than all ios 8 versions? since apple has already fixed the crash issue on later versions.\n// Temporary workaround for bug in in iOS8 UIWebView that causes the browser to crash\n        // before the file chooser appears if the file input doesn't contain a multiple attribute.\n        // See #1283.\n        if (options.ios8BrowserCrashWorkaround && qq.ios8() && (qq.iosChrome() || qq.iosSafariWebView())) {\n            input.setAttribute(\"multiple\", \"\");\n        }\nsetting ios8BrowserCrashWorkaround to true in my case disable ios 8.1.2 from using camera, but setting it to false will almost gurantee it to crash on ios 8.0.0.\nmaybe it should be :\nif (options.ios8BrowserCrashWorkaround && qq.ios800() && (qq.iosChrome() || qq.iosSafariWebView())) {\n            input.setAttribute(\"multiple\", \"\");\n     }\nCheers,\nChaplin\n. ",
    "PatrickBK": "I experience the same issue with iOS 8 GM as well as the previous beta. I see it happening on an iPhone 5s as well as an iPad Air\n. ",
    "JeremyWeir": "Another plot point... uploading/FileReader works on IOS8 Safari on the simulator on all hardware profiles.\n. ",
    "karpitsky": "Video upload is still not working in iOS 8.0.1\n. ",
    "scrummitch": "Hey everyone, looks like 8.0.2 has been released, tested on my device and it all seems back to normal. They're also providing 8_0_2 as the userAgent so it will be a good idea to keep up the warnings for people stuck on 8.0 still.\n. ",
    "anazar": "@rnicholus - any eta on the 5.0.7 release?  5.0.6 blocks uploading on ios 8.0.2... we'd like to re-enable uploading since it's supported now. \n. ",
    "jkodroff": "@rnicholus What's your feel on the issues with iOS8?  Have they been largely resolved with 8.latest, or are they still present?\n. ",
    "ddekster": "And leave message to all 1000000 users??\n. ",
    "dswittkamp": "Actually I just did and I am getting the same results.\nHere is my code block, thank you..\n```\n        var sContent = [  '',\n                          '',\n                      '<script type=\"text/template\" id=\"qq-simple-thumbnails-template\">',\n                      '<div class=\"qq-uploader-selector qq-uploader\">',\n                      '<div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>',\n                      '<span>Drop files here to upload</span>',\n                      '</div>',\n                      '<div class=\"qq-border\">',\n                      '<div class=\"qq-upload-button-selector qq-upload-button\">',\n                      '<div>Upload a file</div>',\n                      '</div>',\n                      '<span style=\"width:250px;clear:right;\">Drag and Drop your images onto the &quot;Upload a file&quot; located to the left, or simply paste your image from the clipboard by pressing Ctrl-V.</span>',\n                      '</div>',\n                      '<span class=\"qq-drop-processing-selector qq-drop-processing\">',\n                      '<span>Processing dropped files...</span>',\n                      '<span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>',\n                      '</span>',\n                      '<div style=\"border:1px solid #ccc;width:100%;height:380px;overflow:auto;\">',\n                      '<ul class=\"qq-upload-list-selector qq-upload-list\">',\n                      '<li class=\"qq-text\">',\n                      '<div class=\"qq-progress-bar-container-selector\">',\n                      '<div class=\"qq-progress-bar-selector qq-progress-bar\"></div>',\n                      '</div>',\n                      '<span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>',\n                      '<div class=\"qq-image\">',\n                      '<img class=\"qq-thumbnail-selector\" qq-max-size=\"40\" qq-server-scale>',\n                      '</div>',\n                      '<span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\"></span>',\n                      '<span class=\"qq-upload-file-selector qq-upload-file\"></span>',\n                      '<input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">',\n                      '<span class=\"qq-upload-size-selector qq-upload-size\"></span>',\n                      '<a class=\"qq-upload-cancel-selector qq-upload-cancel\" href=\"#\">Cancel</a>',\n                      '<a class=\"qq-upload-retry-selector qq-upload-retry\" href=\"#\">Retry</a>',\n                      '<a class=\"qq-upload-delete-selector qq-upload-delete\" href=\"#\">Delete</a>',\n                      '<span class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>',\n                      '</li>',\n                      '</ul>',\n                      '</div>',\n                      '</div>',\n                      '</script>',\n\n                      '</div>'].join('');\n\n    var cjcUploaderDialog = $('body').uiDialog(\n                        {\n                            id: \"cjcUploaderDialog\",                                                                                //\n                            caption: \"Uploader\",\n                            content: sContent,\n                            width: 400,\n                            height: 560,\n                            overlay: true,\n                            duration: 500,\n                            sliderDuration: 0,\n                            buttons: [\n                                {\n                                    \"label\":\"Cancel\", \"class\": \"default\", \"callback\": function () {\n                                        cjcUploaderDialog.close();\n                                        if (typeof settings.onOk === 'function') {\n                                            var cb = settings.onOk;\n                                            cb();\n                                        }\n                                    }\n                                }\n                            ],\n                            onLoad: function () {\n                                setTimeout(function () {\n                                    $('#thumbnail-fine-uploader').fineUploader({\n                                        debug: false,\n                                        multiple: false,\n                                        template: \"qq-simple-thumbnails-template\",\n                                        thumbnails: {\n                                            placeholders: {\n                                                waitingPath: \"/includes/jQuery/FineUploader/loading.gif\",\n                                                notAvailablePath: \"/includes/jQuery/FineUploader/processing.gif\"\n                                            }\n                                        },\n                                        validation: {\n                                            allowedExtensions: ['jpeg', 'jpg', 'png'],\n                                            itemLimit: 10,\n                                            sizeLimit: 5000000\n                                        },\n                                        request: {\n                                            params: {\n                                                TransactionId: CloserNS.TransactionId\n                                            },\n                                            endpoint: '/includes/jQuery/Photos/Upload.ashx'\n                                        },\n                                        showMessage: function (message) {\n                                            return alert(message);\n                                        },\n                                        validation: {\n                                            allowedExtensions: ['jpeg', 'jpg', 'gif', 'png']\n                                        },\n                                        paste: {\n                                            targetElement: $(window)\n                                        }\n                                    }).on('complete', function (event, id, fileName, response) {\n                                        if (response.success) {\n                                            var paramsObj = {\n                                                rsid: CloserNS.rsid,\n                                                TransactionId: CloserNS.TransactionId,\n                                                ActionFlg: \"GetImages\"\n                                            }\n                                            images_load(paramsObj);\n                                            cjcUploaderDialog.close();\n                                        }\n                                    });\n                                 }, 300);\n                            }\n                        }\n                    );\n\n. I wouldn't be able to provide a live demo (we're in a secure environment) .. It's behaving as if it has multiple bindings. is there a way to property destroy the uploader con completion?\n. Thinking that Destroying could/would release an previous bindings. Nope, a Ctrl-V or ( edit | paste) is the only thing that causes the issue. File select and drag and drop uploads work like a dream!\n. It's the first paste after a page load (sorry I wasn't clear)  ... \n. I'm still experiencing this issue. I'm,calling fineUploader inside of a dialog. When I close the dialog, I remove all elements; however the event listeners remain. Opening the dialog a second, third or more times causes multiple uploads on paste. The same number as the number of event listeners. How can I destroy/remove these?\n. I am calling it; however the event listeners still remain bound.\n. Thank you. That's explains it. I've been using a targetElement of window or document as I have not been able to get paste to work using any other DOM elements. By that I mean pressing Ctrl-v does not create a paste event when bound to any other element. Any ideas?\n.\nvar uploaderPlugin = $('#thumbnail-fine-uploader').fineUploader({\n    debug: false,\n    template: \"qq-simple-thumbnails-template\",\n    multiple: true,\n    thumbnails: {\n        placeholders: {\n            waitingPath: \"/includes/jQuery/FineUploader/loading.gif\",\n            notAvailablePath: \"/includes/jQuery/FineUploader/processing.gif\"\n        }\n    },\n    validation: {\n        allowedExtensions: ['jpeg', 'jpg', 'png'],\n        itemLimit: 10,\n        sizeLimit: 5000000\n    },\n    request: {\n        params: {\n            TransactionId: CloserNS.TransactionId\n        },\n        endpoint: '/includes/jQuery/Photos/Upload.ashx'\n    },\n    showMessage: function (message) {\n        return alert(message);\n    },\n    validation: {\n        allowedExtensions: ['jpeg', 'jpg', 'gif', 'png']\n    },\n    paste: {\n        defaultName: 'pasted_image',\n        promptForName:false,\n        targetElement: $(window)\n    }\n}).on('complete', function (event, id, fileName, response) {\n    if (response.success) {\n        var paramsObj = {\n            rsid: CloserNS.rsid,                                                              \n            TransactionId: CloserNS.TransactionId,\n            ActionFlg: \"GetImages\"\n        }\n        images_load(paramsObj);\n    }\n}).on('statusChange', function (event, id, oldStatus, newStatus) {\nif (newStatus === qq.status.UPLOAD_SUCCESSFUL) {\n\n    var paramsObj = {\n        rsid: CloserNS.rsid,\n        TransactionId: CloserNS.TransactionId,\n        ActionFlg: \"GetImages\"\n    }\n    images_load(paramsObj);\n}\n\n});\n```\n. Thank you, that did the trick!\n. ",
    "HugoCrd": ":+1: \n@allegrem developed this PR cause we need it at Melusyn, we would be very pleased to see this merged :)\nMany thanks for your work!\n. Nice! Thanks\n. ",
    "allegrem": "No problem! Actually, we would appreciate if this code could be merged and released as soon as possible, so that we can use the official builds again.\n. True! Actually I was wondering why setUploadSuccessParams was redefined here.\n. ",
    "skrivanos": "This method should be made available in the traditional uploader API as well.\n. @rnicholus See: http://docs.fineuploader.com/branch/master/api/options.html#chunking.success.endpoint\nSlightly different, but very similar. The onComplete event might work, even though it'd be nice to be able utilize the already built in support.\n. @rnicholus Yes, and there should be a way to specify that endpoint per file. For instance, the API I'm working against expects a request to /uploads/:id/commit after all chunks are uploaded. I could definitely make this request manually in the onComplete event handler, but as I mentioned before it'd be nice to be able to handle it with the built in support.\n. ",
    "sjelfull": "I totally understand, and while it's probably going to take a while, that's great feedback any way. Seeing that the other issue is from 2013, I guess you haven't had the time to work on this, but do you know if this is something that is high on your roadmap now - or will it continue to be pushed off?\nWhat is the difference between having it on GitHub and npm, in terms of licensing enforcement? You can define a license on npm, right? \n. ",
    "benjamindulau": "Did you guys manage to make FineUploader work with a browserify-shim ? I definitely don't figure out how to make it works properly.\n. Well, I took a pause, scratched my knee, and after that everything is working ;-)\njson\n{\n  \"browser\": {\n    \"fineUploader\": \"./app/Resources/assets/vendor/fineuploader/custom.fineuploader-5.0.8.min.js\",\n  },\n  \"browserify-shim\": {\n    \"fineUploader\": \"qq\",\n  },\n}\n``` javascript\n// uploader.js\n'use strict';\nvar $ = jQuery = require ('jquery');\nvar fineUploader = require('fineUploader');\nvar createUploader = function(chunkUrl) {\n    var progressBarUpload = document.getElementById('progressBarUpload');\n    var uploader = new fineUploader.FineUploaderBasic({\n        ...\n    });\n};\nmodule.exports.createUploader = createUploader;\n```\n``` javascript\n// app.js\nvar $ = jQuery = require ('jquery');\nvar _ = require('underscore');\nrequire('./routing');\nvar uploader = require('./uploader');\njQuery(document).ready(function() {\n    if (jQuery('#selectFileUploadButton').length) {\n        uploader.createUploader(Routing.generate('videos_upload_chunk'));\n    }\n});\n```\n. ",
    "rylwin": "I first noticed this behavior when cross-browser testing our app (upgrading from 4.1.1 to 5.0.7). After a while attempting to debug our app, I went to the demo page in IE8 and noticed the same issue on the demo page. Since the issue replicated on the demo page I assumed it wasn't an issue with our app.\nThe specific issue we're seeing is identical to how the orange \"Test me now and upload a file\" appears as a grey box in IE8 (see above screen). This grey box appears to be an overlaid  field. When I use the IE8 js inspector and remove the overlaid input, I see our button behind it (the equivalent of the orange button) but clicking on it does not trigger the \"choose file\" dialog (since the input has been removed).\n. The CSS you provided works great. I've included it conditionally for IE8 and it resolves the issue. This workaround is probably sufficient for us if a permanent fix is not imminent. \nP.S. Thanks for the quick responses! \n. ",
    "svbergerem": "FYI there is now https://github.com/FineUploader/bower-dist so you can use the FineUploader with rails-assets.org.\n. ",
    "haandol": "i use 5.0.7 and below is the my usage flow and code, \nI fixed it by manipulating policy document from server side for now. but I think it will be unnecessary if Fineuploader is fixed.\non endpoint.js\njavascript\n    var uploader = new qq.s3.FineUploader({\n        debug: false,\n        autoUpload: false,\n        multiple: false,\n        element: $('#report-file-wrapper')[0],\n        request: {\n            endpoint: awsReqEndpoint,\n            accessKey: awsAccessKey\n        },  \n        objectProperties: {\n            acl: 'public-read',\n            key: function() {\n                return 'group/'+groupId+'/xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n                    var r = Math.random()*16|0, v = c == 'x' ? r : (r&0x3|0x8);\n                    return v.toString(16);\n                }); \n            }   \n        },  \n        signature: { endpoint: '/s3/policy' },\n        uploadSuccess: { endpoint: $('#add-report-form').prop('action') },\n        chunking: { enabled: true },\n        callbacks: {\n            onCancel: function(id, name) { ... },  \n            onComplete: function(id, name, responseJSON, xhr) { ... },  \n            onError: function(id, name, errorReason, xhr) { ... }\n        }\n    });\nand this is server side code for generate signature ('/s3/policy/'), it wrote in Python and this works fine so far.\n``` python\ndef s3_policy_endpoint(request):\n    if 'GET' == request.method:\n        raise Http404\nformat = 'json'\ntry:\n    policy_document = json.loads(request.POST.keys()[0])\nexcept ValueError:\n    return get_error_response(request, 830, format=format)\n\nfor condition in policy_document.get('conditions', []):\n    if 'x-amz-meta-qqfilename' in condition:\n        condition['x-amz-meta-qqfilename'] = urllib.quote(condition['x-amz-meta-qqfilename'].encode('utf-8'), safe='()')\npolicy_document = json.dumps(policy_document)\npolicy, signature = get_policy_signature_pair(policy_document)\nreturn HttpResponse(json.dumps({'status': True, 'policy': policy, 'signature': signature}))\n\n```\n. i think server side code should be below, but it occurs error as I mentioned before. because the 'x-amz-meta-qqfilename' value does match with POST's.\n``` python\ndef s3_policy_endpoint(request):\n    if 'GET' == request.method:\n        raise Http404\nformat = 'json'\ntry:\n    policy_document = json.loads(request.POST.keys()[0])\nexcept ValueError:\n    return get_error_response(request, 830, format=format)\n\npolicy, signature = get_policy_signature_pair(policy_document)\nreturn HttpResponse(json.dumps({'status': True, 'policy': policy, 'signature': signature}))\n\n```\noh, It has unicode filename problem also.\n. oh, I think I'm using in serverless, because I upload a file to my S3 bucket 'serverless' and use my server for merely updating results.\nand actually that is the hole code related to using uploading.\non same 'endpoint.js' without percentageEncoding at server, it occurs error.\n(if filename is unicode, utf-8 encoding is also required.)\n. as I said, all I want to do is removing below code from my server.\npython\nif 'x-amz-meta-qqfilename' in condition:\n            condition['x-amz-meta-qqfilename'] = urllib.quote(condition['x-amz-meta-qqfilename'].encode('utf-8'))\nfor that 'x-amz-meta-qqfilename' value should be quoted(percentageEncoded) when \njavascript\nsignature: { endpoint: '/s3/policy' },\nfineuploader passes the policy_document contents to '/s3/policy/'\n. quoting solved my problem in my case,\nbut If I did something wrong using this finest library, please let me know.\n. ",
    "andrewk": "Removal of the jQuery wrappers prior to shipping a packaged module (AMD, CJS, ES6, UMD.. i don't care which) would be a bad move. Currently the only way we can use Fine Uploader at all with Webpack is by using the jQuery plugin. This is due to FU's var qq = declaration, and the assumption that the code will be executed at window scope. Remove jQuery, but please do it the release after you fix one of these -https://github.com/FineUploader/fine-uploader/issues?q=is%3Aissue+AMD\n. ",
    "grrowl": "Needed to be invoked with the new keyword, sorry. Closing.\n. ",
    "Biggytv": "Absolutely would love to test. \nKyle Borg\nBiggyTV\n310-651-8207\n\nOn Dec 17, 2014, at 2:39 PM, Ray Nicholus notifications@github.com wrote:\n@Biggytv I've added this enhancement to the 5.1.0 version being staged in the develop branch. Are you interested in testing to make sure it satisfies your requirements before we release? If the format is not quite to your liking, and this is discovered after the release, any changes will have to wait until a major release.\n\u2014\nReply to this email directly or view it on GitHub.\n. I did a straight drop in of the new build into my code, pointing to the new directory.  I received this message: TypeError: $(....).fineUploaderS3 is not a function.  Is there any change in how I should declare the function?\n\n```\nQuery(document).ready(function ($) {\n        $('#fineuploader-s3').fineUploaderS3({\n            request: {\n                accessKey: \"\"\n            },\n        template: \"qq-template\",\n\n        signature: {\n            endpoint: \"/finesig/\"\n        },\n\n        forceMultipart: {\n            enabled: true\n        },\n\n        uploadSuccess: {\n            endpoint: \"/btvChannels/s3_form_meta.php\"\n            },\n\n        debug: true,\n\n        callbacks: {\n        onComplete: function( id, name, response ) {\n            if (response.success)\n                { location.href = 'https://www.biggytv.com/response'; }\n            }               \n        },\n\n        cors: {\n            expected:true,\n            },\n\n        resume: {\n            enabled: true\n        },\n\n        objectProperties: {\n            acl: \"public-read\"\n        },\n\n        validation: {\n            itemLimit: 1,\n            sizeLimit: 270000000,\n            acceptFiles: \"video/mp4, video/quicktime, video/x-flv, video/x-ms-wmv\",\n            allowedExtensions: [\"mp4\", \"mov\", \"flv\", \"wmv\"],\n        },\n\n\n\n    })\n\n});\n\n\n```\n. Thank you for the email, I implemented the DOMContentLoaded option.  The script debug stops here:\ntypeError:  container is null; container.innerHTML = templateHtml.template; line 7180, col 12 in the s3.fineuploader-5.1.0-12.js  I am not great at debugging so hopefully this isn't frustrating, but will test functionally as long as you need.\n. I had some typos.  Tested it multiple times in multiple configurations and it does exactly what I need it to do.   I can't thank you enough.  I would be happy to test the S3 CDN / CloudFront function also if you can give me some direction on the parameters.  If not, I'll look for the release of 5.10.  I appreciate all the hard work you put into this product!  Kyle\n. ",
    "vikynandha": "We just want to keep the status codes consistent with other API endpoints, which follow proper CRUD. But yes, allowing 201 and 202 should be good enough in this case.\n. That's awesome! Thanks.\nOn Sat, Jan 24, 2015, 3:48 AM Ray Nicholus notifications@github.com wrote:\n\n5.2.0-5 adds the same support to PATCH and PUT requests.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1314#issuecomment-71276148\n.\n. \n",
    "juukie": "You're welcome. Indeed I did, you can read minds ;).\n. ",
    "joeenzminger": "Good to know.  Sorry for submitting against the wrong branch.\n. Would you like me to resubmit the PR to the develop branch (easy to do)?\n. Weird.  For this fix I just forked today and edited inline on Github\n\nRay Nicholus mailto:notifications@github.com\nNovember 6, 2014 at 4:41 PM\nSure. Also noticed that your branch is quite far behind. May want to \nfetch first.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/FineUploader/fine-uploader/pull/1319#issuecomment-62065051.\n. I have figured out what was causing the CSRF mismatches - the cookie library I was using was urldecoding the CSRF cookie on the client.  All appears to be working as expected in your library.\n\nSo my reason for needing this feature is kaput.  However, I still think it would be a good improvement to the library.  It would be nice to be in full control of all interactions with the server.\nHere is a snippet of my current implementation:\njavascript\n$element.find('.uploader').fineUploaderS3({\n    uploaderType: 'basic',\n    request: {\n        endpoint: $attrs.endpoint,\n        accessKey: $attrs.accesskey\n    },\n    signature: {\n        endpoint: $attrs.signature ? $attrs.signature : '/upload/signature',\n        customHeaders: function () {\n            return {\n                RootCSRF: $.cookie('RootCSRF')\n            };\n        }\n    },\n    uploadSuccess: {\n        endpoint: $attrs.success ? $attrs.success : '/upload/UploadS3',\n        customHeaders: function () {\n            return {\n                RootCSRF: $.cookie('RootCSRF')\n            };\n        }\n    },\n    iframeSupport: {\n        localBlankPagePath: $attrs.blankPagePath ? $attrs.blankPagePath : '/upload/blank'\n    },\n    objectProperties: {\n        key: function (fileId) {\n            var p = new qq.Promise();\n            $scope.$apply(function () {\n                adminAPI.GetKey()\n                                    .then(function (result) {\n                                        p.success(result.Result);\n                                    }, function (err) {\n                                        p.failure();\n                                    });\n            });\n            return p;\n        }\n    },\n    validation: {\n        allowedExtensions: $attrs.extension ? $attrs.extension : [],\n        acceptFiles: $attrs.accept ? $attrs.accept : [],\n        itemLimit: $attrs.itemLimit ? ParseInt($attrs.itemLimit) : 1\n    },\n    retry: {\n    },\n    chucking: {\n        enabled: typeof $attrs.chunk === undefined ? true : $attrs.chunk,\n        concurrent: {\n            enabled: true\n        }\n    },\n    resume: {\n        enabled: typeof $attrs.resume === undefined ? true : $attrs.resume\n    },\n    camera: {\n        ios: typeof $attrs.camera === undefined ? true : $attrs.camera\n    },\n    //template: qq.supportedFeatures.fileDrop ? 'qq-template-with-drop' : 'qq-template',\n    extraButtons: extraButtons\n});\nand what I would like to be able to do in the future\njavascript\n$element.find('.uploader').fineUploaderS3({\n    uploaderType: 'basic',\n    request: {\n        endpoint: $attrs.endpoint,\n        accessKey: $attrs.accesskey\n    },\n    signature: {\n        endpoint: function (tosign, asheader) {\n            //return thenable object\n            return adminAPI.Signature(tosign, asheader || false);\n        }\n    },\n    uploadSuccess: {\n        endpoint: function (key, uuid, name, bucket) {\n            //return thenable object\n            return adminAPI.UploadSuccess(key, uuid, name, bucket);\n        }\n    },\n    iframeSupport: {\n        localBlankPagePath: $attrs.blankPagePath ? $attrs.blankPagePath : '/upload/blank'\n    },\n    objectProperties: {\n        key: function (fileId) {\n            var p = new qq.Promise();\n            $scope.$apply(function () {\n                adminAPI.GetKey()\n                                    .then(function (result) {\n                                        p.success(result.Result);\n                                    }, function (err) {\n                                        p.failure();\n                                    });\n            });\n            return p;\n        }\n    },\n    validation: {\n        allowedExtensions: $attrs.extension ? $attrs.extension : [],\n        acceptFiles: $attrs.accept ? $attrs.accept : [],\n        itemLimit: $attrs.itemLimit ? ParseInt($attrs.itemLimit) : 1\n    },\n    retry: {\n    },\n    chucking: {\n        enabled: typeof $attrs.chunk === undefined ? true : $attrs.chunk,\n        concurrent: {\n            enabled: true\n        }\n    },\n    resume: {\n        enabled: typeof $attrs.resume === undefined ? true : $attrs.resume\n    },\n    camera: {\n        ios: typeof $attrs.camera === undefined ? true : $attrs.camera\n    },\n    //template: qq.supportedFeatures.fileDrop ? 'qq-template-with-drop' : 'qq-template',\n    extraButtons: extraButtons\n});\n. Hah.  Thanks for catching that.  Pre production :)\n. Ray - just bumping this to see if you guys are still considering making the endpoint properties accept functions that return promises rather than just strings (so we can implement our own xhr, etc rather than having fineuploader do it internally).\n. No.  The promise would resolve to the data that you'd expect to currently be returned from the endpoint.  This is a somewhat contrived example, but something along these lines should work:\njavascript\nuploadSuccess: {\n        endpoint: function (key, uuid, name, bucket) {\n           var p = new qq.Promise();\n           setTimeout(function() {\n              p.success({});\n           }, 1000);\n           return p;\n        }\n    }\nThis has the advantage of allowing us to have a bit more flexibility into how our API is structured - for instance (and again contrived), if we wanted to use a Websocket in the above example rather than xhr we could do it.\nI'm not talking about endpoints that talk to services outside our control (like the S3 endpoints - obviously you have to manage that internal to the uploader).  I'm talking about the endpoints you specify that are integration points with our application (uploadSuccess, getKey, signature, etc.).  Promises would give us more flexibility in implementation.\n. I'll start the lobbying process :).  Not urgent for us, either - just something I thought might be a good idea.\n. Hi Ray - \nThat's what I thought, too, but this happens regardless of where we are testing from (my home, office, or cellular networks).  It is 100% repeatable.  If it were a network problem, I would think it would be intermittent.\n. I had a chuckle at \"almost definitely\".  I just upgraded to 5.1.3 to see if the problem disappears - it didn't.  I will look more closely at the status of the xhr requests and try to get you more info.  To be clear - I've tried to do everything I can to eliminate the network as a possible cause before I wrote up the issue.  But I will keep digging.\n. I hear you.  I don't think that's the case here (I actually don't run any of that on my dev machine).  \nHere is a log with XHR request logging turned on (up to the hang), along with a screenshot of the network tab.  No pending network requests....\n\n[Fine Uploader 5.1.3] Received 1 files.\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Attempting to validate image.\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending chunked upload request for item 0: bytes 1-5242880 of 26535399\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending chunked upload request for item 0: bytes 5242881-10485760 of 26535399\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending chunked upload request for item 0: bytes 10485761-15728640 of 26535399\nangular.js:10071 POST:/upload/getkey\nangular.js:8560 XHR finished loading: POST \"http://nibl.joe.ijjc.co/upload/getkey\".\nangular.js:10071 RESPONSE RECEIVED: /upload/getkey\nangular.js:10071 RESPONSE: /upload/getkey\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Submitting S3 signature request for 0\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending POST request for 0\ns3.jquery.fine-uploader.js:3878 XHR finished loading: POST \"http://nibl.joe.ijjc.co/upload/signature\".\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Submitting S3 initiate multipart upload request for 0\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending POST request for 0\nXHR finished loading: POST \"https://nibl-joeenzminger-scratch.s3.amazonaws.com/4d9df851-1f76-4f01-ba84-f2b4adb49f3f?uploads\".\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Initiate multipart upload request successful for 0.  Upload ID is gCS3lWmmKXRQjwMPyoWX6MBI4f_M2G7BJAx2_mBjbU4JZwRo.WSCR_Fpa.r4hWdQCjQynDZQD3NUVUgVsb3ruY.NFcCvXxEDT2VaYSz6kCPC7FYRT20LgYi8czHN7uU.\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Submitting S3 signature request for 0.2\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending POST request for 0.2\ns3.jquery.fine-uploader.js:3878 XHR finished loading: POST \"http://nibl.joe.ijjc.co/upload/signature\".\nXHR finished loading: PUT \"https://nibl-joeenzminger-scratch.s3.amazonaws.com/4d9df851-1f76-4f01-ba84-\u2026_Fpa.r4hWdQCjQynDZQD3NUVUgVsb3ruY.NFcCvXxEDT2VaYSz6kCPC7FYRT20LgYi8czHN7uU.\".\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunked upload request succeeded for 0, chunk 2\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunk 2 for file 0 uploaded successfully.\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending chunked upload request for item 0: bytes 15728641-20971520 of 26535399\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Submitting S3 signature request for 0.3\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending POST request for 0.3\ns3.jquery.fine-uploader.js:3878 XHR finished loading: POST \"http://nibl.joe.ijjc.co/upload/signature\".\nXHR finished loading: PUT \"https://nibl-joeenzminger-scratch.s3.amazonaws.com/4d9df851-1f76-4f01-ba84-\u2026_Fpa.r4hWdQCjQynDZQD3NUVUgVsb3ruY.NFcCvXxEDT2VaYSz6kCPC7FYRT20LgYi8czHN7uU.\".\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunked upload request succeeded for 0, chunk 3\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunk 3 for file 0 uploaded successfully.\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending chunked upload request for item 0: bytes 20971521-26214400 of 26535399\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Submitting S3 signature request for 0.4\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending POST request for 0.4\ns3.jquery.fine-uploader.js:3878 XHR finished loading: POST \"http://nibl.joe.ijjc.co/upload/signature\".\nXHR finished loading: PUT \"https://nibl-joeenzminger-scratch.s3.amazonaws.com/4d9df851-1f76-4f01-ba84-\u2026_Fpa.r4hWdQCjQynDZQD3NUVUgVsb3ruY.NFcCvXxEDT2VaYSz6kCPC7FYRT20LgYi8czHN7uU.\".\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunked upload request succeeded for 0, chunk 4\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunk 4 for file 0 uploaded successfully.\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending chunked upload request for item 0: bytes 26214401-26535399 of 26535399\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Submitting S3 signature request for 0.5\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Sending POST request for 0.5\ns3.jquery.fine-uploader.js:3878 XHR finished loading: POST \"http://nibl.joe.ijjc.co/upload/signature\".\nXHR finished loading: PUT \"https://nibl-joeenzminger-scratch.s3.amazonaws.com/4d9df851-1f76-4f01-ba84-\u2026_Fpa.r4hWdQCjQynDZQD3NUVUgVsb3ruY.NFcCvXxEDT2VaYSz6kCPC7FYRT20LgYi8czHN7uU.\".\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Received response status 200 with body: \ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunked upload request succeeded for 0, chunk 5\ns3.jquery.fine-uploader.js:244 [Fine Uploader 5.1.3] Chunk 5 for file 0 uploaded successfully.\n. Note, this is now using 5.1.3\n. Yes.  Give me a few minutes to set it up.\n. I leave entirely open the possibility that we are doing something stupid :)\n. Great, thanks.  If it turns out to be a problem on our end, let me know and I'll purchase a support ticket.\n. Fantastic.  We will disable concurrent chunking for now.  Always like being the special case.  We can now also support generating the key on the client side, so I may try that as well.\n. Generating the key client side does indeed work around the issue.  Thanks for taking the time to run it down.\n. ",
    "ajeeshpu": "+1 \n. ",
    "quisse": "+1 \n. ",
    "sedouard": "+1\nIn my scenario I'd like to control how the success request is made, rather than conforming to what fileUploader wants to do.\n. ",
    "dalejomen": "my code\nhtml\n\n\nTest Page\n\n\n<!-- jQuery\n====================================================================== -->\n    \n Fine Uploader JS\n====================================================================== \n\n\n        $(document).ready(function () {\n            $('#thumbnail-fine-uploader').fineUploader({\n                element: document.getElementById('fine-uploader'),\n                template: \"qq-simple-thumbnails-template\",\n                thumbnails: {\n                    placeholders: {\n                        waitingPath: \"waiting-generic.png\",\n                        notAvailablePath: \"not_available-generic.png\"\n                    }\n                },\n                maxConnections: 3,\n                request: {\n                    endpoint: 'ImageUploaderChunking.ashx'\n                },\n                validation: {\n                    allowedExtensions: ['jpeg', 'jpg', 'gif', 'png'],\n                    itemLimit: 6,\n                    sizeLimit: 5120000 // 50 kB = 50 * 1024 bytes\n                },\n                deleteFile: {\n                    enabled: true,\n                    method: \"POST\",\n                    endpoint: \"/s3-upload\"\n                },\n                chunking: {\n                    enabled: true,\n                    partSize: 512000,\n                    concurrent: {\n                        enabled: true\n                    },\n                    success: {\n                        endpoint: \"ImageChunkingDone.ashx\"\n                    }\n                }\n            });</p>\n<p>```\n    });</p>\n<p>\n<!-- Fine Uploader CSS\n```\n====================================================================== -->\n    \n Fine Uploader DOM Element\n====================================================================== \n\n\n<div id=\"fine-uploader\">\n<noscript>\n    <p>Please enable JavaScript to use Fine Uploader.</p>\n    <!-- or put a simple form for upload here -->\n</noscript>\n\n<!-- Fine Uploader template\n====================================================================== -->\n    \n  <div class=\"qq-uploader-selector qq-uploader\">\n    <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n      <span>Drop files here to upload</span>\n    </div>\n    <div class=\"qq-upload-button-selector qq-upload-button\">\n      <div>Upload a file</div>\n    </div>\n    <span class=\"qq-drop-processing-selector qq-drop-processing\">\n      <span>Processing dropped files...</span>\n      <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n    </span>\n    <ul class=\"qq-upload-list-selector qq-upload-list\">\n      <li>\n        <div class=\"qq-progress-bar-container-selector\">\n          <div class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n        </div>\n        <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n        <img class=\"qq-thumbnail-selector\" qq-max-size=\"100\" qq-server-scale>\n        <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\"></span>\n        <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n        <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n        <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n        <a class=\"qq-upload-cancel-selector qq-upload-cancel\" href=\"#\">Cancel</a>\n        <a class=\"qq-upload-retry-selector qq-upload-retry\" href=\"#\">Retry</a>\n        <a class=\"qq-upload-delete-selector qq-upload-delete\" href=\"#\">Delete</a>\n        <span class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n      </li>\n    </ul>\n  </div>\n    \n\n\n. if the previdualizacion of pictures, have a solution for that show?\nand one mistake is not hard to onComplete\n. previdualizacion error in the images for android 2.3.3\nthe question is has any solution to display the image?\n. The other mistake is that I use the onComplete function and android 2.3.3 not enter that function.\n. version of Fine Uploader using  is fineuploader-5.0.8.min\n. ",
    "JaapKooiker": "I'm wondering where we are on this issue. I had everything working but now I use Frankfurt and it's broken. I there a way to make a separate 'hotfix' just for Frankfurt (or whatever V4 region)? I really need this... (have a license)\n. ",
    "kaurranjeet12": "Hi rnicholus,\nWhen are you planning to release fineuploader version 5.4?\nThanks,\nRJ\n. Do you have any timeline as we are planning to buy the licence.\nEmail me on ranjoo12@gmail.com\nThanks,\nRJ\n. ",
    "e-tip": "Hi, i've used the develop version and i can confirm that, for non chunked version, it works perfectly.\nI 'm facing issues with chunked upload but i guess it's because i still have to understand how it works ! thanks\n. Thanks for your interest. As i said i need to change my php signer due to parameters changing when i enable chunk as i get this \nphp\nobject(stdClass)#1 (1) {\n  [\"headers\"]=>\n  string(136) \"AWS4-HMAC-SHA256\n20151103T141556Z\n20151103/eu-central-1/s3/aws4_request\n362cd6989ac712fe9384998e8b3860c7d43758d7a7bb53d5765a1e245fbfb133\"\n}\ninstead of what i've used with non chunked uploads... but i didn't read the amazon docs about that \n. Thanks\n. I've changed my signer copying the v4 part from the example but now amazon is not happy with one header\njavascript\n[Fine Uploader 5.4.0-5] Received response status 400 with body: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error><Code>XAmzContentSHA256Mismatch</Code><Message>The provided 'x-amz-content-sha256' header does not match what was computed.</Message><ClientComputedContentSHA256>4ea5c508a6566e76240543f8feb06fd457777be39549c4016436afda65d2330e</ClientComputedContentSHA256><S3ComputedContentSHA256>acee8d78a765fc20deeb7240c1361f15dfcf563b09141c88664f454ecf159d63</S3ComputedContentSHA256><RequestId>6A9EF29F43FB367D</RequestId><HostId>zKzyniveR3VpFm5wcJcdCB2csFVO5kHPKiO2UzPH5/CQH+YcPz1jbBWMiZdvcA4lB9sMRzwflHs=</HostId></Error>\n. @rnicholus i can send you the whole project but zip files are not allowed here\n. ok, let's try\ni've started a s3.fineUploader\njavascript\nthis.options =  {\n        s3_bucket : 'xxxxx-eu-upload',\n        region : 'eu-central-1'\n    }\nthis._fineUploader = new qq.s3.FineUploader({\n            element: document.getElementById('fine-uploader-s3'),\n            template: 'qq-template-s3',\n            debug: true,\n            dropZoneElements : [document.getElementById('fine-uploader-s3')],\n            signature: {\n                endpoint: \"signChunk.php\",\n                version : 4\n            },\n            chunking : {\n                enabled : true\n            },\n            objectProperties: {\n                bucket: _self.options.s3_bucket,\n                acl : 'public-read',\n                region : _self.options.region\n            },\n            request: {\n                accessKey : \"AKIAINVUVMHTTQQXSDOQ\",\n                endpoint: \"http://\"+_self.options.s3_bucket+\".s3-\"+_self.options.region+\".amazonaws.com\"\n            }/*,\n            uploadSuccess: {\n                endpoint: \"success_upload.php\"\n            }*/\n        });\ni've added a file on the upload and the request to signChunk.php is ocmpleted, the upload begins and when it's time fo tinalize the first chunk i get the error i've reported \n``` php\nefine('S3_BUCKET', 'xxxxx-eu-upload');\ndefine('S3_KEY',    'xxxxx');\ndefine('S3_SECRET', 'xxxxx');\ndefine('S3_REGION', 'eu-central-1');        // S3 region name: http://amzn.to/1FtPG6r\ndefine('S3_ACL',    'public-read'); // File permissions: http://amzn.to/18s9Gv7\nsignRequest();\nfunction signRequest() {\n    header('Content-Type: application/json');\n    $responseBody = file_get_contents('php://input');\n    $contentAsObject = json_decode($responseBody, true);\n    $jsonContent = json_encode($contentAsObject);\n    $headersStr = $contentAsObject[\"headers\"];\n    if ($headersStr) {\n        signRestRequest($headersStr);\n    }\n}\nfunction signRestRequest($headersStr) {\n    $response = array('signature' => signV4RestRequest($headersStr));\n    echo json_encode($response);\n}\nfunction signV4RestRequest($stringToSign) {\n    $pattern = \"/.+\\n.+\\n(\\d+)\\/(.+)\\/s3\\/.+\\n(.+)/\";\n    preg_match($pattern, $stringToSign, $matches);\n    $dateKey = hash_hmac('sha256', $matches[1], 'AWS4' . S3_SECRET, true);\n    $dateRegionKey = hash_hmac('sha256', $matches[2], $dateKey, true);\n    $dateRegionServiceKey = hash_hmac('sha256', 's3', $dateRegionKey, true);\n    $signingKey = hash_hmac('sha256', 'aws4_request', $dateRegionServiceKey, true);\n    return hash_hmac('sha256', $stringToSign, $signingKey);\n}\n```\nas you can see it's just a very basic project just to test if i'm able to get it work\n. I've tested with Chrome 46 , Firefox 41.0.2  and Safari 9.0.1 on a mac. I'm getting this error with all browsers, and with every file i try ( i've tried with a zip and a .avi file )\n. The first POST request works. i got the error when the first chunk is uploaded\nThese are the files i've included ( i've downloaded it from github download button )\nhtml\n    <script src=\"js/util.js\"></script>\n    <script src=\"js/error.js\"></script>\n    <script src=\"js/version.js\"></script>\n    <script src=\"js/features.js\"></script>\n    <script src=\"js/promise.js\"></script>\n    <script src=\"js/blob-proxy.js\"></script>\n    <script src=\"js/button.js\"></script>\n    <script src=\"js/upload-data.js\"></script>\n    <script src=\"js/uploader.basic.api.js\"></script>\n    <script src=\"js/uploader.basic.js\"></script>\n    <script src=\"js/ajax.requester.js\"></script>\n    <script src=\"js/upload.handler.js\"></script>\n    <script src=\"js/upload.handler.controller.js\"></script>\n    <script src=\"js/form.upload.handler.js\"></script>\n    <script src=\"js/xhr.upload.handler.js\"></script>\n    <script src=\"js/window.receive.message.js\"></script>\n    <script src=\"js/uploader.api.js\"></script>\n    <script src=\"js/uploader.js\"></script>\n    <script src=\"js/templating.js\"></script>\n    <script src=\"js/s3/util.js\"></script>\n    <script src=\"js/non-traditional-common/uploader.basic.api.js\"></script>\n    <script src=\"js/s3/uploader.basic.js\"></script>\n    <script src=\"js/s3/request-signer.js\"></script>\n    <script src=\"js/uploadsuccess.ajax.requester.js\"></script>\n    <script src=\"js/s3/multipart.initiate.ajax.requester.js\"></script>\n    <script src=\"js/s3/multipart.complete.ajax.requester.js\"></script>\n    <script src=\"js/s3/multipart.abort.ajax.requester.js\"></script>\n    <script type=\"text/javascript\" src=\"js/s3/s3.xhr.upload.handler.js\"></script>\n    <script type=\"text/javascript\" src=\"js/s3/s3.form.upload.handler.js\"></script>\n    <script type=\"text/javascript\" src=\"js/s3/uploader.js\"></script>\n    <script type=\"text/javascript\" src=\"js/paste.js\"></script>\n    <script type=\"text/javascript\" src=\"js/dnd.js\"></script>\n    <script type=\"text/javascript\" src=\"js/deletefile.ajax.requester.js\"></script>\n    <script type=\"text/javascript\" src=\"js/image-support/megapix-image.js\"></script>\n    <script type=\"text/javascript\" src=\"js/image-support/image.js\"></script>\n    <script type=\"text/javascript\" src=\"js/image-support/exif.js\"></script>\n    <script type=\"text/javascript\" src=\"js/identify.js\"></script>\n    <script type=\"text/javascript\" src=\"js/image-support/validation.image.js\"></script>\n    <script type=\"text/javascript\" src=\"js/session.js\"></script>\n    <script type=\"text/javascript\" src=\"js/session.ajax.requester.js\"></script>\n    <script type=\"text/javascript\" src=\"js/form-support.js\"></script>\n    <script type=\"text/javascript\" src=\"js/image-support/scaler.js\"></script>\n    <script type=\"text/javascript\" src=\"js/third-party/ExifRestorer.js\"></script>\n    <script type=\"text/javascript\" src=\"js/total-progress.js\"></script>\n    <script type=\"text/javascript\" src=\"js/ui.handler.events.js\"></script>\n    <script type=\"text/javascript\" src=\"js/ui.handler.click.filebuttons.js\"></script>\n    <script type=\"text/javascript\" src=\"js/ui.handler.click.filename.js\"></script>\n    <script type=\"text/javascript\" src=\"js/ui.handler.focusin.filenameinput.js\"></script>\n    <script type=\"text/javascript\" src=\"js/ui.handler.focus.filenameinput.js\"></script>\n    <script type=\"text/javascript\" src=\"js/ui.handler.edit.filename.js\"></script>\n    <script type=\"text/javascript\" src=\"js/third-party/crypto-js/core.js\"></script>\n    <script type=\"text/javascript\" src=\"js/third-party/crypto-js/enc-base64.js\"></script>\n    <script type=\"text/javascript\" src=\"js/third-party/crypto-js/hmac.js\"></script>\n    <script type=\"text/javascript\" src=\"js/third-party/crypto-js/sha1.js\"></script>\n    <script type=\"text/javascript\" src=\"js/third-party/crypto-js/sha256.js\"></script>\n. i had issues installing grunt on my machine. I'm trying now\n. As you  imagined, using the compiled file everything works.\nSo i can confirm that v4 support works perfectly. Good work !\n. i\u2019m following this thread for future updates and i\u2019ll make tests if you need. Thanks for your great work \n. Thanks, i'm updating it and i'll let you know. Is it possible to contact you directly to ask for a issue i'm facing with signature and custom file key ? \n. Hi, \nas previously said i'm facing some issues if i use a custom key on a chunked upload \nthis is the function i'm using to generate key\njavascript\nkey : function(fileId){\n                    var filename = \"test/\"+_self._fineUploader.getFile(fileId).name;\n                    return filename;\n                }\nif the upload is not chunked everything is ok, but if there's a chunked upload i got signature mismatch error \nif i change test/ with test_ it works everything\nabout the php signer, i've took it from the repo and used as is \n[EDIT] after further investigations i can see that aws javascript library doesn't escape / instead your library does \nthis is the path used by aws library\nhttp://bucketname-eu-upload.s3-eu-central-1.amazonaws.com/test/Archivio.zip?uploads \nand this is the path used by fineuploader \nhttp://bucketname-eu-upload.s3-eu-central-1.amazonaws.com/test%2FArchivio.zip?uploads\n[EDIT2]\ni've modified the \njavascript\n                urlSafe: function(id) {\n                    //return encodeURIComponent(handler.getThirdPartyFileId(id));\n                    return handler.getThirdPartyFileId(id);\n                }\nand in this way it works. \n. @rnicholus obviously my knowledge of the library is not deep enough to evaluate every consequence my changes caused ( and i'm not crazy enough to think i've not broke anything else :P ) by the way i'm working on a project that needs to be completed as soon as possible and chunked uploads on s3 are one of the key features, so i'm going to use it until you fix this. Thank you very much\n. @rnicholus me again... sorry for bothering you but i've found another little issues in v4 signature calculation if i use ( or ) in the filename they doesn't get escaped.\nfor example if the name of the file is \"promo company (2015).mkv\"\nhttp://mybucket.s3-eu-central-1.amazonaws.com/0_06-11-2015-13_31_02/promo%20company%20(2015).mkv?uploads\nand in this case i get SignatureDoesNotMatch error.\nusing aws client library the url for upload should be\nhttps://mybucket.s3.eu-central-1.amazonaws.com/0_06-11-2015-13_31_02/promo%20company%20%282015%29.mkv?uploads\n[EDIT] seems that even spaces creates problem. i've renamed the file in \"promo company 2015\" and i get the same issue. i'm considering to use the uuid instead of the filename and rename the file to it's original filename when i download it from s3, but someone else can not be so lucky\n. @rnicholus just to add some difficulties to my project, i've tested it with v4 signature and cloudfront in front of my bucket. As i've seen in previous comments it's supported and in fact i get the upload to work, but i think that there's an issue ( obiously due to amazon's engineers that have overcomplicated the signature process ) with this setup if the file is chunked. As previously said if the upload is not chunked it works , if the upload is chunked i get signature error.\nit' seems that for calculating the canonical string request s3 uses his host instead of the cloudfront host so it calculates a wrong signature.\nmy cf host is xxxxxxxxxx.cloudfront.net but in the s3 error message i see that canonical request contains \n``` javascript\nPOST\n/0_11-11-2015-11_48_10/840544-12.jpg\nuploads=\nhost:xxxxxxxxxxx-us-1-upload.s3.amazonaws.com\nx-amz-acl:public-read\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20151111T135754Z\nx-amz-meta-qqfilename:840544-12.jpg\nhost;x-amz-acl;x-amz-content-sha256;x-amz-date;x-amz-meta-qqfilename\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n```\nand looking at it you can clearly see the s3.amazonaws host \n. @rnicholus sorry for posted it here but i thought it was the correct place because changing \n``` javascript\nif (version === 4) {\n            v4.getEncodedHashedPayload(requestInfo.content).then(function(hashedContent) {\n                requestInfo.headers[\"x-amz-content-sha256\"] = hashedContent;\n                requestInfo.headers.Host = /(?:http|https):\\/\\/(.+)(?:\\/.+)?/.exec(options.endpointStore.get(id))[1];\n                requestInfo.headers[\"x-amz-date\"] = qq.s3.util.getV4PolicyDate(now);\n                requestInfo.hashedContent = hashedContent;\n            promise.success(generateStringToSign(requestInfo));\n        });\n    }\n\n```\nto this \n``` javascript\nif (version === 4) {\n            v4.getEncodedHashedPayload(requestInfo.content).then(function(hashedContent) {\n                requestInfo.headers[\"x-amz-content-sha256\"] = hashedContent;\n                //requestInfo.headers.Host = /(?:http|https):\\/\\/(.+)(?:\\/.+)?/.exec(options.endpointStore.get(id))[1];\n                requestInfo.headers.Host = \"xxxxxxxxxxx-us-1-upload.s3.amazonaws.com\";\n                requestInfo.headers[\"x-amz-date\"] = qq.s3.util.getV4PolicyDate(now);\n                requestInfo.hashedContent = hashedContent;\n            promise.success(generateStringToSign(requestInfo));\n        });\n    }\n\n```\nmake uploader work again... but i agree with you that this have no sense \n. well wait... don't know what i've changed but now it works... \n. You are right\n1) my url of s3 bucket is studio-us-1-upload.s3.amazonaws.com\n2) The url of my cf distro is d1wvkk8w7itn1i.cloudfront.net\ndo you mean the host header in the request of the signer or the header of upload to cf request ?\n. I confirm that fineuploader works perfectly with s3 accelerate by just changing the endpoint \n. i'll setup a demo as soon as possible\n. Here it's http://labs.e-tip.net/\nit's just the demo code. the only modification i've done is \nat line 10697 of s3.fine-uploader.js \njavascript\n_getLocalStorageId: function(id) {\n                var baseStorageId = super_._getLocalStorageId(id),\n                    bucketName = upload.bucket.getName(id);\n                    qq.log(baseStorageId + \"-\" + bucketName);\n                return baseStorageId + \"-\" + bucketName;\n            }\nand at line 5526 \njavascript\n_getLocalStorageId: function(id) {\n            var formatVersion = \"5.0\",\n                name = getName(id),\n                size = getSize(id),\n                chunkSize = chunking.partSize,\n                endpoint = getEndpoint(id);\n            qq.log(qq.format(\"qq{}resume{}-{}-{}-{}-{}\", namespace, formatVersion, name, size, chunkSize, endpoint));\n            return qq.format(\"qq{}resume{}-{}-{}-{}-{}\", namespace, formatVersion, name, size, chunkSize, endpoint);\n        },\nAs soon i add a file i can see in the console that localStorageId is always returned by function at line 5526 because i can see no -nucketName appended as you can see here \n[Fine Uploader 5.10.1] Grabbed 1 dropped files.\ns3.fine-uploader.js:252 qqs3resume5.0-12556.jpg-11738982-5242880-http://fineuploader-test.s3.amazonaws.com \ninstead of the expected \nqqs3resume5.0-12556.jpg-11738982-5242880-http://fineuploader-test.s3.amazonaws.com-fineuploader-test \n. Hi, i've modified my test suite.\ni've added a second uploader and modified the uploader code\nfor first uploader i've added to objectProperties object the following key function\njavascript\nkey : function(fileID){\n    return \"folder1/\"+uploader.getUuid(fileID)+\".\"+qq.getExtension(uploader.getName(fileID));\n}\nand for second uploader \njavascript\nkey : function(fileID){\n    return \"folder2/\"+uploader2.getUuid(fileID)+\".\"+qq.getExtension(uploader2.getName(fileID));\n}\nSteps to reproduce the issue\n- Start uploading a file larger than 6 MB to uploader1 so chunk upload is enabled\n- upload endpoint is this http://fineuploader-test.s3.eu-central-1.amazonaws.com/folder1/59950077-0b84-4ca6-9f5a-d242fda00f2e.mov\n- After upload is started refresh the page so upload is interrupted\n- Drop the same file in the second uploader and you'll see that the file is uploaded in folder1 even if key function points to folder2. \n  This happens because the localStorageID is calculated not considering that the key can be different for the same filename-filesize keys ( that is the actual localStorageId calculating method ) \n. I'll try to write a fix and open up a pull request. By the way the main issue is that the add function is called in qq.XhrUploadHandler contest so handler. is kind of qq.XhrUploadHandler instead of qq.s3.XhrUploadHandler. as soon as i fix this issue my solution would be to check if objectProperties.key is a function and if yes check if returns a kind of string that contains /. if yes strip out the filename and use also that part as localStorage key. Does that sound good for you ? \n. yep, actually the main issue i'm having is due to inheritance between s3 and non s3 version, i came out with too many methods to override\n. I agree with you that invalidating all actual storageIds is not acceptable. \ni've played today with sources to try appending some custom code to the localStorageId that is generated in 3.xhr.upload.handler.js but that function is never called. I have to play some more. Thanks for checking into this for me :)\n. i had checked into the utf-8 meta tag before posting and it's present\n\n ( i've tried both uppercase and lowercase versions )\n. Have you used my example or you used another one ? \n. I've asked because this issue started when i moved my destination bucket to frankfurt from dublin. \n. for my other projects i've used uuid as filename, but in this case i cannot use anything but filename ( to prevent collisions there's a folder that is generated on a per user basis ) that is appended to the filename. in my environment the key is a funciton\njavascript\nkey : function(fileId){\n    var filename = _self.options.folder+\"/\"+_self._fineUploader.getFile(fileId).name;\n    return filename;\n}\n. because changing to the uuid would require to rewrite too much things to use it instead of filename :( All projects i've started from scratch i've used the uuid with a db to associate the uuid to the original filename\n. Hi,\ni took the added code from here \nhttps://github.com/aws/aws-sdk-js/blob/master/lib/util.js#L46 and line #56\nI came up with this solution because in aws documentation ( http://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-header-based-auth.html ) there's a section that suggests to use a custom function to URIEncode because \nThe standard UriEncode functions provided by your development platform may not work because of differences in implementation and related ambiguity in the underlying RFCs. We recommend that you write your own custom UriEncode function to ensure that your encoding will work.\n. Regarding the Manual testing:\nI've tried to upload in 2 different regions ( ireland and frankfurt ) this files and all succeded\n- button_border copia.pdf\n- e & o.pdf\n- orderform & provae\u0300+a\u0300o\u0300u\u0300++a\u0300a\u0300.zip\n- clean_s3.zip\n- logo.png\n- no prof.jpg\n  in order to cover as much cases that i can. I ve tried with both \njavascript\nkey : 'filename'\njavascript\nkey : function(id) {\n    return uploader.getName(id);\n}\nRegarding the license... do you think that's better to rewrite the code not using the aws code ?\n. Now i'm on vacation for two weeks. is it a problem if i write the tests as soon as i return to work? \n. Here i'm, back from vacation.\nAs this is the first time i write tests, i have some difficulties to understand what needs to be tested. Can you please do an theorical example ( for example i would test if function returns right results if passing an empty string or something like that. ) \nThanks and sorry for bothering you\n. Sorry for the late feedback. I've wrote tests for the modified function and pushed to my fork \n. Well... as the function is just a string replace with some extras i can rewrite it in many ways to get the same result\n. @rnicholus , sure i can. \n. Comment added\n. unfortunately.... :( by the way i've found that even safari 7 has the same issue :( as usual it's the problem that i use the user provided filename because i can't change it :(. ",
    "soulchild": "Hmmm, I find this somewhat inconsistent because when using amazon AWS, getBucket() returns just the first part of the domain. So in the given example it would return \"mybucket\" instead of \"mybucket.s3.amazonaws.com\", wouldn't it? \n. I just went ahead and tried this out by debugging getBucket():\nFor \"test.s3.amazonaws.com\" it returns \"test\" as the bucket name.\nFor \"test.mydomain.com\" it returns \"test.mydomain.com\" as the bucket name.\nWe're not using AWS in the backend but ceph's S3-compatible API and when using our custom domain with fine-uploader the backend fails with \"policy check failed, variable not met condition: bucket\", which to me makes perfect sense because the S3 API expects the bucket name to be \"test\" and not \"test.mydomain.com\". For AWS, another regular expression in getBucket matches, which correctly extracts just the bucket name, so it's not an issue when using an amazonaws.com domain.\nOr am I completely on the wrong track? :)\n. Nice! I'll check out the current development branch. Cheers!\n. objectProperties.bucket did the job. Thanks again!\n. ",
    "ahorner": "Already done.\n. Thanks for looking into it.\n. ",
    "foolip": "OK, the \"does not expose the DataTransfer interface\" made me think exposing the DataTransfer interface would fix the problem. Can browsers that don't have webkitGetAsEntry just never drop folders, then?\n. Ah, so the problem is that the DataTransferItem interface isn't exposed. If it were, you could check for DataTransferItem.prototype.webkitGetAsEntry, right?\nI'm going to fix this in Blink now: http://code.google.com/p/chromium/issues/detail?id=448696\n. The fix has landed, if you try Chrome Canary in a few days you should be able to check if my suggested replacement would work or not. You'd have to keep the sniffing as a fallback for a year or so, of course.\n. How about the \"only way to test for complete Clipboard API support at this time\" case, do you need something to detect support for that as well?\n. Yeah, this does sound like something that's hard to do feature detection for. Would you happen to have a simple demo to illustrate the difference? I just want to make sure we're talking about the same thing, so that I can investigate what's correct per spec and maybe file bugs on the other browsers, if it hasn't already been reported of course.\n. ",
    "woozyking": "@rnicholus that makes perfect sense.\n. ",
    "hn1": "It would be nice to have just 2 versions - The Core and UI. On applications that serve international markets, in some localities, 60k can be a big deal.\nThanks\n. That would be great. We will wait for that to update our version. Thanks\n. ",
    "aramk": "I've put together an example here https://github.com/aramk/fine-uploader-meteor-demo. ",
    "nskarl": "5.1.3\ncode: $('#UploadImages').fineUploader('setItemLimit', 10);\nif do that:\nsetItemLimit: function(newItemLimit) {\n            this._currentItemLimit = newItemLimit;\n            this.log(this._currentItemLimit);\n        },\nin log it will return 10\nbut its not working, global this._currentItemLimit not set to 10\nsorry for my English (\n. all my code i show - $('#UploadImages').fineUploader('setItemLimit', 10);\nno changes in Fine Uploader\nbut it works correctly through Reset, why?\n. ",
    "nyala1": "Cheers, have done so now. \n. ",
    "burakbostancioglu": "@rnicholus Can you halp with this pull request please ? \n. @rnicholus Thank you so much, it was uploadSuccess POST request. It seems like this is going to be adjusted in 5.2.0 . Thanks!\n. ",
    "thanosp": "Forgot to mention but possibly related to #1191. Maybe a public interface solves both. \n. ",
    "courtchatter": "Thankyou at least for making a response.\nPlease update the 2 issues that I created in https://github.com/FineUploader/fine-uploader-php-docs/issues and also reply to http://stackoverflow.com/questions/28347173/fine-uploader-php-installation-directory to save anyone else from wasting their time. I see that you have now removed the invitation to try the PHP version from your home page. \n. ",
    "jasonm": "Thanks @rnicholus - relevant JS is https://gist.github.com/jasonm/06371654d172f84f87aa and full page source https://gist.github.com/jasonm/c33596d685c05efcdfeb\nURL is https://minerva.kgi.edu/application/application-center/ but that's behind a signup flow.\n. Hi @rnicholus, the request.endpoint value is https://s3.amazonaws.com/minervaschools-application-upload declared on https://s3.amazonaws.com/minervaschools-application-upload\n. ",
    "ajorias": "So maybe start simple and allow a field of types to exclude from scale.\n. ",
    "arvind-agarwal": "Is there any progress on this feature? We also need to exclude Animated Gif from scaling.\n. ",
    "shiningdracon": "Workaround:\nExclude all gifs from scale.\nFor fine-uploader.js,\nreplace\nif (identifier.isPreviewableSync()) {\nto\nif (originalBlob.type !== \"image/gif\" && identifier.isPreviewableSync()) {\nFor fine-uploader.min.js,\nreplace\nreturn p.isPreviewableSync()?\nto\nreturn (o.type!==\"image/gif\"&&p.isPreviewableSync())?\n. ",
    "sido420": "I was thinking of a workaround for this issue. Is it possible to use custom resizer for scaling and on seeing image/gif let the file upload as is and for other files use the default/custom behaviour as normal?\nIf that makes sense, can you suggest code for this please?\n. @rnicholus makes sense to you as well? . ",
    "Dayjo": "@rnicholus This would be suuper helpful :). I know this is a really old issue, and I hate bumping, but I'm just wondering if anyone has actually come up with a solution for this. It's really a breaking feature as it means you cannot upload an animated GIF at all. . ",
    "andreas-venturini": "I noticed this error today after a user reported that uploads didn't work for them\nUser agent Mozilla/5.0 (Linux; Android 5.1; LG-H815 Build/LMY47D) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/38.0.2125.102 Mobile Safari/537.36\nFineUploader Version 5.5.0\nTypeError: Cannot read property 'upload' of undefined\n1\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 345 col 4327 in qq.extend._registerProgressHandler\n2\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 346 col 27382 in v.initHeaders.then.s.failure.error\n3\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12351 in [anonymous]\n4\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 8057 in Function.qq.each\n5\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12328 in qq.extend.success\n6\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 346 col 27172 in [anonymous]\n7\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12351 in [anonymous]\n8\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 8057 in Function.qq.each\n9\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 343 col 12328 in qq.extend.success\n10\nFile https://XXX.cloudfront.net/assets/application-74cc883326e236859bdeb28fac648581.js line 346 col 14732 in Object.t\n. I suspect the upload stalled on their mobile device due to mobile network quality issues and was then manually aborted. We didn't receive a final upload failure notice. \nShortly before and after the above error message (all within one minute) we observed XHR returned response code 0 warnings which would indicate network quality issues.\nI just wanted to add this here for reference in case someone looks for context of this warning in future.\n. Here is the relevant section that I extracted from the compiled production js\njavascript\n...\n  function() {\n    this.FileUploader = function() {\n      function e(e, t) {\n        null == t && (t = {}), this.el = e, this.options = t, this.setupUploader()\n      }\n      return e.prototype.setupUploader = function() {\n        var e, t;\n        return t = this, e = null, this.el.fineUploaderS3({\n          uploaderType: \"basic\",\n          button: this.el,\n          multiple: this.options.multiple,\n          maxConnections: this.options.maxConnections || 3,\n          validation: {\n            acceptFiles: this.options.acceptFiles || null,\n            sizeLimit: this.options.sizeLimit || 0,\n            minSizeLimit: this.options.minSizeLimit || 0,\n            allowedExtensions: this.options.allowedExtensions || []\n          },\n          request: {\n            endpoint: \"https://xxx.s3-eu-west-1.amazonaws.com\",\n            accessKey: \"XXX\"\n          },\n          objectProperties: {\n            acl: this.options.acl || \"public-read\",\n            key: function(e) {\n              var n, i, r;\n              return r = \"production/\" + qq.getUniqueId(), i = this.getName(e), n = t.options.extension || qq.getExtension(i), void 0 !== n && (r += \".\" + n), r\n            }\n          },\n          signature: {\n            endpoint: \"/upload_signatures\",\n            customHeaders: {\n              \"X-CSRF-Token\": $(\"meta[name=csrf-token]\").attr(\"content\")\n            }\n          },\n          uploadSuccess: {\n            customHeaders: {\n              \"X-CSRF-Token\": $(\"meta[name=csrf-token]\").attr(\"content\")\n            },\n            endpoint: this.options.endpoint,\n            params: this.options.params || {}\n          },\n          chunking: {\n            enabled: !0,\n            concurrent: {\n              enabled: !0\n            }\n          },\n          resume: {\n            enabled: !0\n          },\n          iframeSupport: {\n            localBlankPagePath: \"/upload_success.html\"\n          },\n          retry: {\n            autoAttemptsDelay: this.options.autoAttemptsDelay || 5,\n            maxAutoAttempts: this.options.maxAutoAttempts || 20,\n            enableAuto: !0\n          }\n        }\n....\n. I have tested with both, an actual Android 4.4.4 device and Android 4.4.4 virtual device, and both worked.  So I assumed that the 4.4.2 virtual device behavior would also be reproducible on an actual 4.4.2 device as the 4.4.2 virtual device was obtained from the same source (http://www.android-x86.org/download). \nI currently do not have access to an actual Android device with 4.4.2 running on it.\nAlso https://code.google.com/p/android/issues/detail?id=62220 suggests this might be only an issue in 4.4.(1) and 4.4.2 Android devices\n. ",
    "eyaleee": "hey there @rnicholus - I have this issue you mentioned - I have a multi-chunked upload I'm cancelling and get this error... although it's benign like you said, and it doesn't bother FU to continue to the next file, it's still not a cool thing to have this error thrown. WDYT?\nUncaught TypeError: Cannot read property 'chunking' of undefined\n    at qq.s3.XhrUploadHandler._getPersistableData (xhr.upload.handler.js:275)\n    at s3.xhr.upload.handler.js:175\n    at promise.js:55\n    at Function.qq.each (util.js:654)\n    at qq.Promise.success (promise.js:54)\n    at Object.n [as onComplete] (multipart.initiate.ajax.requester.js:140)\n    at s (ajax.requester.js:145)\n    at XMLHttpRequest. (ajax.requester.js:253). ",
    "rainbowdash28": "Hey, thanks for the quick reply :)\nThe problem is - I forgot to mention this before - my endpoints are set by requesting them from the server via Ajax, while starting the upload.\n. ",
    "SinghSukhdeep": "@rnicholus I believe this can be closed since it hasn't been reported by anyone else since. @rnicholus this can be closed I think. Yes, it's related to #1652 \nIn addition to having typescript definitions, also needed is class declarations and named exports from common index.d.ts file.\nA good example to that is angular2-highcharts library, which is just a handful of typescript wrappers for the original commonJS Highcharts library and works perfectly with Angular 2. If you look at their dist directory, all it contains is just handful or file which have class declarations and named exports for all the different components.\nI know this probably is a low priority task for you. I can help to get this done, but I have very little knowledge about fine-uploader library\n. Sure I'll definitely give it a shot as me and my team definitely want to use this library instead of any other.\nI looked over the options and methods in the API and I'll start preparing a TS definition file.\nHow do I contact you for advice, questions and overall progress?\n. This repo contains the first draft that I've prepared today which includes declarations for CORE and UI methods.\nI'll keep adding more to it.\nYou can have a look if you want.\n. Ok I can do that. I'm not sure how to create a pull request and push my changes\n. Closing this issue since we have PR #1719 . If you check the fine-uploader.spec.ts fle, If I use the 'new' keyword to instantiate FineUploader, TypeScript is complaining.\nIf I don't use the 'new' keyword, things seem to be okay. I'll do more testing once I'm done writing everything\n. If you check the fine-uploader.spec.ts fle, If I use the 'new' keyword to instantiate FineUploader, TypeScript is complaining.\nIf I don't use the 'new' keyword, things seem to be okay. I'll do more testing once I'm done writing everything\n. http://docs.fineuploader.com/branch/master/api/options-ui.html#thumbnails.placeholders\nthe notAvailablePath option is listed twice\n. http://docs.fineuploader.com/branch/master/api/options-ui.html#thumbnails.placeholders\nthe notAvailablePath option is listed twice\n. http://docs.fineuploader.com/branch/master/api/options-azure.html#signature.endpoint\nIn description here where it says \"The endpoint that Fine Uploader can use to send GET for a SAS before sending requests off to S3\"\nI think instead of S3 it should be Azure.\n. http://docs.fineuploader.com/branch/master/api/options-azure.html#signature.endpoint\nIn description here where it says \"The endpoint that Fine Uploader can use to send GET for a SAS before sending requests off to S3\"\nI think instead of S3 it should be Azure.\n. I see that you have changed the base branch from master to develop.\nI should have forked from develop.\nIs there anything else I need to do to base off of develop branch?\nIn this thread I'm seeing this message\nAdd more commits by pushing to the master branch on SinghSukhdeep/fine-uploader.\nWhich branch should I push my changes now?\n. I see that you have changed the base branch from master to develop.\nI should have forked from develop.\nIs there anything else I need to do to base off of develop branch?\nIn this thread I'm seeing this message\nAdd more commits by pushing to the master branch on SinghSukhdeep/fine-uploader.\nWhich branch should I push my changes now?\n. http://docs.fineuploader.com/branch/master/api/qq.html#qq.each\nthe description for parameter iterable is incorrect.\n. Okay, well so far I've written about 80% of util functions already. I'll take them out then.\nIf there is anything else you have in mind which is to be removed in future releases, please let me know before I write it all.\n. I've written down everything that is there in the API's.\nPlease do a code review when you get a chance.\nI'm gonna do some testing meanwhile and will push if I find any issues.\nThanks \ud83d\ude03 \n. Creating a definition file enables the use of FineUploader in any TypeScript project.\nAngular 2 is itself written in TypeScript, so this facilitates the use of FineUploader in Angular 2 project as well.\nBut still, something like import qq from 'fine-uploader' won't be possible, because that requires class declarations and named exports. (To do that, I'll need to do some more research).\nSo now with TS def file, If someone wants to use FineUploader, they can just have the FineUploader JS globally scoped and just start writing TypeScript.\nHere is how we can publish our TS def file.\nLet me know and we'll proceed further.\nTS def files are picked up automatically by TypeScript aware editor such as Visual Studio Code (which I've used to write declarations), we just have to publish it properly.\n. TS does support CommonJS modules. \nI can do let qq = require('fine-uploader') and it will work fine.\nBut to use the import syntax, A library needs to have an index file at the root which would do named export of ES6 modules.\nI can get an Angular 2 project working using the require syntax, but I won't be able to generate a production bundle using Rollup, which needs the importsyntax rather than require to effectively apply tree-shaking.\nHaving said that, I wouldn't call myself a GURU on those things, but that's what I've figured since I've been working with TS and Angular 2\n. I'm currently trying to follow the TS module resolution\nFollowing that, if I place my TS def file index.d.ts in the node_module/fine-uploader/ directory \nand place a default export in index.d.ts like this \n```\ndeclare var qq: FineUploader.qq;\nexport default qq;\n```\nthen the import qq from 'fine-uploader' seems to be okay.\nI need to do some more work/research/testing on it to make sure things go well all the way up to generating a production bundle using Rollup.\nI'll keep you posted \n. Ok so, I've done some basic testing in a dummy Angular 2 app and everything seems to be working fine.\nNot doing any named imports/exports as of now (need to do more research on it to make it work), just including fine-uploader.js globally.\n. The changed file list shows two files changed (which is all what I've added), I'm not sure what is missing?. The typescript/fine-uploader.spec.ts is just a test file showing the use of proper syntax in TS.\nAbout how will TS pickup the def file please read this\nEither we put the def file in a directory and point \"types\" property in package.json to that path or we just put the file at the root and name it index.d.ts or we publish it separately from the project under Github's DefinitelyTyped and then users can install the def file as npm install @types/fine-uploader.\nI'm currently using it as if installed using third option.\nThe def file will be then located at node_modules/@types/fine-uploader/index.d.ts.\nThey do recommend the first approach though.. As of TS v2.1, the first approach seems to be working properly (Wasn't working before, that's why I was using @types approach).\nI'll review the def file once more and will let you know when I think everything is okay.\nAnd yes I have no issues with becoming a contributor. What do I have to do in order to be so?. My bad, I can get it working only by using @types approach.\nTS compiler is complaining with other two ways, It has something to do with the way fine-uploader file structure is.\nWorks only if I put the def file at node_modules/@types/fine-uploader/index.d.ts.\nI have to do some more digging on this. @rnicholus sorry didn't get any time during the holidays and had some tight deadlines before that, will have some time this week to look at it.. I looked at it, they are also preparing a similar definitions file as we are.\nMaybe somehow we can merge their progress with ours and get someone to review our code.\nAbout removing a package, once we publish fine-uploader with the definitions included, then they can deprecate that package, we don't have to do it.\nIn this pull I need to set the types property to point to our bundled declaration file in order to locate the definition file, which I haven't done yet as I'm unable to get it to work that way.\nI've looked at some of the TS docs but haven't found a resolution to the problem yet. I'll keep looking. @andy-ms okay got it, I also came to this resolution because I'm not using the library as a module and I was missing that triple slash directive.\nIncluding the dependency like that does the job.\nThanks for your help.\nAny chance someone can review our code before we publish the package?\nI would really appreciate that.. Everything done. New PR #1719 . I can confirm that with the changes from this PR, build seems to be working nicely in windows under cygwin. Works in MS Edge as well, tested on following version\n\n. PR #1689 Continued here. I'll add that method's definition.\nI don't have anything more left to write, I just wanted if someone could review the definitions.\nOther than that everything is ok from my side.\nAbout the new method:\nDocs don't really specify the type for id parameter, whose id is it and what the parameter is supposed to do. So I just wrote whatever is there right now. Yes the definitely typed defs should be eliminated after this . Ok, I'll take a look at qq.Promise and make changes to functions that are returning a promise. Later after 6.0 release, we'll update the def to return native Promise. Little typo in the docs here.\nIt should say Call this on a promise to indicate failure. instead of Call this on a promise to indicate success.. I'll work on including the Typescript folder in the build process whenever I get some time. @rnicholus I've updated Makefile to include typescript directory and has followed the steps you stated earlier to test changes. New project can see the defs no problem. Please review . Thanks for your prompt support.\nMy Twitter handle is Sukh9212.\nThanks for the tweet as well . @don-bluelinegrid see PR #1840 \nCurrent TS definitions do not support ES6 style import.\nYou will have to include the fine uploader js file in your html page and follow this file for syntax guidance . As I said earlier, we are providing the typescript definitions. Current way of consumption is as I wrote in my previous comment.\nWe are going to provide import support soon.\nJust be patient.. #1840 has been merged and released as 5.15.0\nHappy Importing !!. FYI - Modern browsers already allow this via <input type=\"file\" /> which is what fine-uploader is using. While selecting files, Chrome on Android does asks for camera or documents. Choose camera and take the photo. Works on iOS Safari as well. @artursvonda anything else you want to push before I merge this?. I'm aware of all this, but currently we haven't done any named exports for TS, currently we've just provided a compatibility for TS projects,\nNamed exports is something that I want to look at going further.\nIn the documentation we should provide more information specific to TS and how the library should be used.\nCurrently if you want to follow correctly, there is a file called fine-uploader.test.ts right next to fine-uploader.d.ts which demonstrates proper syntax.\nHope this helps.. Yes that page should work for TS instructions.\nLittle explanation to why things are the way they are right now:\nI can easily add named exports to the def file, so something like this at the end\nexport { qq, FineUploader }; would do the job and then can be imported as such\nimport { qq, FineUploader } from 'fine-uploader';\nand then you may do \nlet uploader = new qq.FineUploader(uiOptions);\nBut even then the type of variable uploader here will be any since the constructor doesn't return anything and cannot return anything as long as we're using a new keyword.\nThis is a TypeScript rule that only a void function can be called with the new keyword.\nAll of these things came into my attention while I was writing the definitions and since the original syntax is with the use of new keyword, I had to keep the def that way and return void from constructors.\nSo in order to get proper tooling and all the TS goodies, you'll have to do\nlet uploader: FineUploader.qq = new qq.FineUploader(uiOptions);\nAnother problem with named exports that I have right now is with Rollup. (I can explain that later)\nWhich is what most of the Angular 2/ Typescript based projects use to generate production builds\nI'll have to make sure that named exports work properly with Rollup before I can add it.. @rainstormza can you show me your entire component code. Here is a sample syntax for TypeScript.\nMore importantly you need /// <reference types=\"fine-uploader\" /> at the top of your component file.\nand try to use variable declaration like this \nuploader: FineUploader.qq;\nuiOptions: FineUploader.UIOptions;\ncoreEvents: FineUploader.CoreEvents;\nadd some UI options like this\nthis.uiOptions = {\n    element: document.getElementById('fine-uploader-manual-trigger'),\n    template: \"qq-template-manual-trigger\"\n}\nthen initialize FineUploader like this\nthis.uploader = new qq.FineUploader(this.uiOptions);\ndon't do this\ndeclare var qq:any;. @rainstormza you can't use the <script> tag in a component's html. Angular considers it unsafe.\nChange that to a div and try. @rainstormza you're doing the following\nelement: document.getElementById('fine-uploader-gallery'),\nbut in your code I don't see an element with this id.\nadd an element in your html file as\n<div id=\"fine-uploader-gallery\"></div>\nand see if it works. No that's the only way to consume FineUploader in Angular 2 project right now.\nWe'll look into proper Angular 2 module style consumption in future. Fixed in #1840  and released as 5.15.0. @rakeshmotghare please see https://docs.fineuploader.com/branch/master/features/modules.html\nscroll down to TypeScript + Angular version 2 and higher\nEverything is explained there.\n. @erensogut543 just seems like some of your own css is overriding Fineuploader styles.\nCheck your DOM and see what that block is and what styles are being applied on it. \nNot Fineuploader issue at all\n. @rnicholus Any idea why Travis build is failing on this one?\nDoesn't seem like anything in this PR would break the build.. @rnicholus Just wanted to know out of 3 merging options, what is your preferred way of merging PR's?\nI'll do the same for any future merges.. @jleider thanks for your contribution.. I'll be happy to help as much as I can.\nI've never done something like this before, so please let me know the exact steps to follow.. @jclangst Yes the current declaration file is structured using global declaration template and it is required that the fine-uploader JS file be included in project's index.html.\nI see that you are using webpack for your angular 2 project, I've been using SystemJS and Rollup to generate bundles for my projects.\nRollup was one of the reasons I didn't modularized the TS def file, because it leads to problems in the prod bundle.\nI see your point and I already wanted to look at this for a while now.\nI'll take a look at your PR soon, thanks for your contribution.. Fixed in #1840 and released in version 5.15.0. @chaitanyya yes this is the correct way of doing it as of now.\nHave a look at here for more info on syntax.\nSorry about the documentation, whole TS integration details aren't documented properly.. This is fixed in #1840 and released in 5.15.0. I see that the def file has changed considerably. It will take me some time to get through this.. Current structure is set in a way that you have to obviously include fine-uploader JS file globally in your index.html and provide support to be able to use the same syntax for TS projects.\nAnd hence we wouldn't need Rollup or any other module bundler/loader to load the library, that's how it is working right now.\nI totally understand what you are saying or trying to implement here. But I'm afraid it's not going to work with Rollup as of yet.\nI haven't tried your changes with Rollup yet, I will soon.\nAlso just a note that Rollup isn't my obsession, it's what is recommended by Angular team itself and in all their documentation. Meaning that there are lots of people out there using exactly that myself included.\n. I haven't forgotten about this. Haven't had any time to work on this.\nI'm hoping to dedicate some time this weekend.. Did some testing and I've put together a repo here where all the changes are seems to be working with SystemJS and Rollup (Thanks to improvements rollup's commonJS plugin).\nI need to do some more testing on a real Angular 4 & TypeScript project and then we can go further from there.\nI am optimistic that this will be a great benefit to Angular & TypeScript based projects, but is also a major syntax change for the existing users who are using globally scoped FineUploader JS with current TS definitions. \nAlso we need to document this change properly and maybe have a dedicated page or section for Angular 2+ and TypeScript integration.. I think it'll be better now if we divide the modules into individual files for each and have one index.ts exporting everything since we're now using proper import export syntax.\nIt'll be easier to maintain and also code reviewing future changes as I'm really having hard time finding out issues such as above. I think splitting by current module level should be okay for now, we can always split it further if needed.\nI'll take a further look at all the declarations to make sure they are all as they were.\nCan you also make sure all the interface declarations are as they were and they're extending other interfaces properly.\nThanks for all your contribution so far. In addition to \n'fine-uploader/lib/core'\n'fine-uploader'\n'fine-uploader/lib/s3'\n'fine-uploader/lib/azure'\nalso need to declare the 'fine-uploader/lib/all' module which would essentially have all the flavours. @irbian as you can see in this PR we're in the middle of transforming our TypeScript support.\nIf you want to use FineUploader in your project at the moment, look at this file for syntax.\nHowever it will change for better after we merge this PR.. @jclangst  Are you still pursuing this PR?\nIf not, the things that I mentioned in my last review, I'll have to revert those back to what it was before and then merge this. I'm hoping to have this released very soon as many users are requesting this. @rnicholus Can you please review the documentation changes from this PR and also qq and its related functions are no longer available for TS users, so slight syntax change is required for all TS users.\nI have updated the documentation to reflect how library should be imported in TS, is there anything else we need to do before we merge this?. Yes this only affects TypeScript users, no one else.\nlet is mostly used in TS instead of using var directly, but it actually compiles down to var, so don't worry about it.\nI've read the maintainers guide before, \nIf I understand correctly, following are the steps:\n\nUpdate the version number in package.json and version.js\nThen do squash and merge this PR into develop branch\nThen merge develop into master\nRun publish Makefile recipe from master branch, which would publish to npm.\nCreate a new Release in the Releases section following the instructions\n\nStep 6 in the Releasing steps about customize.js is bit unclear to me.\nAnd what should be the next version number 5.14.6 or 5.15.0 since this is major change for TS users. I see you already have few other PR's on 5.15.0 so I'm guessing it'll probably be 5.14.6.. It's as described in the PR description. Changes to the import statement as outlined in the doc update and all of the utility functions being used like qq.functionName won't be available.\nYou told me once that you are planning to remove those in future releases, so I guess that's fine. Besides TS users really don't need those functions.\nimport qq from 'fine-uploader/lib/all' also isn't available because the global namespace qq isn't there.\nSo essentially in order to use all flavour together, separate import is required for each flavor.\nOther than those changes, there isn't any change in the syntax other than what's described in the PR description.\nSo in order to release this as v5.15.0, need to move the PR's currently under this tag to another milestone. I'm not sure I understand your question exactly.\nWhat exactly isn't working and where is it in your code?\nThe initialization this.uploader = new qq.FineUploader(this.uiOptions); is working or not?\n. Hmm, I see what you're doing.\nThis seems like an issue with the value of this at different points in your code. You are using this.inputCategories inside an callback function where this might belong to something else other than what you expect (the component).\nTry console.log(this) at that point to see what you have in this.\nIf such is the case then you'll have to declare another variable like let __this = this; before entering the callback function and use the new __this in there.\nLittle TS tip, Don't declare the new variable as _this with single underscore, because that is reserved by TS compiler and you shouldn't declare a variable with that name anywhere in your code.. This method should help to determine items that are currently uploading or queued.. sorry I forgot about it.\nyou need to declare let __this = this; inside ngOnInit just like you've done in your uploadFiles() function if you want to use it.\nAnyway, where is your variable inputCategories declared?\nIf it is declared inside your class then it should be accessible by doing this.inputCategories anywhere in your component.\nIt's might just be the case that this refers to something else other than your component inside the callback function.\ntry console.log(this)  at different stages in your functions and see what comes up.\n. Closing as no further information is provided.. @maivantan1992  thanks for your contribution . There is already an issue for this #1649 . Closing as the issue already exists. @rnicholus sorry I missed out to change the version number in the original PR. My bad.\nCan you review this?. @rnicholus I can work on updating the TS def now? as your planned development is complete.. Would need the docs updated before I can start with TS update.\nLot seems to have changed and I can't seem to figure everything out by looking at all the changes.\nDoc update would point me in straight direction.. TypeScript Updated. @rnicholus do this needs to be reviewed by someone other than you in order to merge?. @bradleyayers I haven't used any tools for generating type definitions (I don't know if any such tools exist that can auto generate).. @rnicholus Sure I'll take a look. We should also update the azure module similarly as that is also missing the core module declaration.\nSomething I missed out previously. @bradleyayers Just wanted to check your thoughts on possibility of 'fine-uploader/lib/all' in TS. This is missing and I can't think of a way to have this since we don't have the qq namespace here. Hey sorry I was away for couple days. I think it all looks great except for one line I mentioned above. Just to weigh in, we only need to specify file extensions for module loaders like SystemJS (not sure about Webpack) and module bundlers like Rollup (again not sure about Webpack).\nAs far as normal import export is concerned, having or specifying index.js in the docs doesn't matter.\nSo only a slight modification is required in the bundler/loader configs.\nAnd in our package.json\n\"main\": \"lib/traditional.js\" would also needs to be changed to \"main\": \"lib/traditional/index.js\". Hi @bradleyayers are you still pursuing this PR. We did a lot of work on this and it would be great if we could merge this.. Awesome!\nI will look into this again and see what is missing and hopefully we can get this through. Is this working for you?\ncustomHeaders?: \n  | { [headerName: string]: string }\n  | (fileId: number) => { [headerName: string]: string };\nIsn't there an extra | at the beginning or I'm not reading it right. And I'm seeing some issues here\n\n. Hi @Fensterbank , I will need to test the PR just to make sure nothing breaks.\nI have bunch of PRs to review and I'm hoping to do it all together. I'm not finding time to do so at the moment but I'm hoping to have some time next weekend. Will try to do my best.. I tested this on Firefox android and the changes are working well.\nThanks for the PR. Will be released once I review few other pending PRs. Any further updates?\nIf not, this will be closed soon.... @rnicholus this seems like something we can easily merge. Seems handy to have those two callbacks. I hear you, I will look at this closely soon and will try my best. Hoping to get some time soon to look at all the pending PRs. Everything looks good.\nThis also requires docs update for drag and drop page\nCan you please add that as well and I'll merge this. I don't know whether this is even doable.\nMaybe @rnicholus can chime in on this.\nBut I don't see this happening anytime soon unless someone want to give it a shot.\nPR's are welcome... Its unclear as to what the issue is and I haven't seen this issue before.\nAnd again, please show your code as we can't do much without looking..\nIssues will be closed soon if no further update arrives... ES6, CommonJS, TypeScript and Angular support documentation is listed here https://docs.fineuploader.com/branch/master/features/modules.html\n. Well, there isn't anything special about using FU inside an Angular component, but still if you need more reference I recommend looking at this file.\nMy repo is pretty old and probably outdated as I was using it just for testing purposes.\nHope this helps. Would you be willing to open a PR with changes?. Although I don't actually see how would this be beneficial.\nOrdering the images in the UI doesn't really matter as this order wouldn't sustain once images go to your server.\nI don't quite understand what exactly you are trying to do, can you maybe clarify a bit.\nOtherwise I don't see this being implemented ever. . Can you please show your code?\nCan't help you without looking at your code.\nPlease read the issue template...... In the issue template there is this section..\n\nAll relevant Fine Uploader-related code that you have written\n{simply copy and paste the JS used to control Fine Uploader browsers-ide}\n{also include your template HTML if related to a UI issue}\n\nI need to see you browser side JS and HTML, not your server side code.. Can't help you without looking at your code, this is your server side issue anyway. Fine Uploader is expecting JSON response but your server isn't sending valid JSON. Check your server side script.. This is an issue with your server config, its not returning valid css files with correct MIME type, not a Fine Uploader issue and without looking at your code can't help.. Please look at the issue template and ask relevant questions. We cannot help you with your database issues. If there is an issue with Fine Uploader library itself, please provide detailed explanation of the actual issue. Hi @Javarome \nWhen does the Uncaught TypeError: target.onload is not a function error actually comes?\nIf you could let me know the reproduction steps, I would like to see the error.. Okay sounds good. Will merge this and release with few other pending PRs. How are we supposed to help you without looking at your code?\nPlease read the issue template bud.. Please read the issue template and present real problems.. @gwilson2151 can you try using the latest version and see if the issue persists. @jleider this interface must also extend S3CoreOptions. @jleider this interface must also extend AzureUIOptions. @jclangst is there any reason to change this interface's declaration?\nBefore it was (id: number): void; and now it is constructor(id: number);. @jclangst I guess since you did replace all for all occurrences of word declare, it has led to sentences like those. \nsee declare missing between If you and the rest of the sentence . @jclangst check this sentence as well, due to replacement of declare. @jclangst same problem caused by replacing declare here as well. @jclangst this function and 3 above it has declaration like this (id: number): PromiseOptions | string; before.\nAny reason for the change?. @jclangst this function declaration has been changed as well?. @jclangst this function declaration has been changed as well. @jclangst I see lot of function declarations have been changed to use constructors.\nIs there a specific problem with previous declarations?. @rnicholus We are still talking about returning Fine-uploader's own implementation of Promise and not native Promise?\nAlso in this line, should it be In asynchronous or If asynchronous?. I'll keep the ability to return both ATM then.\nIs the In supposed to be If there?. Ok that's fine. I'll make changes accordingly then.. This is a good catch. I don't think we need to do this here as the interface AzureUIOptions is already extending UIOptions and AzureCoreOptions. Here we only need to specify the properties that we are overriding from the parent interfaces. Yes I have encountered that before. Then here we would only need to specify UIRetryOptions and not both as UIRetryOptions already extends the RetryOptions. @rnicholus are these module export changes okay with you?\nIt's fine as long as TS concerns.\nWe would also need to update the modules doc page to reflect these changes appropriately. It should be fine according to my understanding too.\nBut if we are referencing fine-uploader/lib/traditional.js directly, as it is needed for Rollup config, that would need to be changed to fine-uploader/lib/traditional/index.js, which seems like a reasonable small change that only affects people who utilize Rollup, primarily Angular users.. @bradleyayers I think this should be export * from 'fine-uploader' instead of core. azure and s3 is fine here, It's just that we are exporting the core fine-uploader from here, it should be the UI module which is fine-uploader and not fine-uploader/lib/core. azure and s3 should be exported from the fine-uploader/lib/all module but not from the fine-uploader module.\nAnd FineUploaderBasic isn't exported from fine-uploader.\nThat must be imported from fine-uploader/lib/core. I think since we are not exporting FineUploaderBasic from fine-uploader module, we shouldn't export the same from fine-uploader/lib/azure and fine-uploader/lib/s3 as well.\nThe core modules should only be exported from the fine-uploader/lib/core, fine-uploader/lib/core/azure and fine-uploader/lib/core/s3\nThat's what makes more sense to me.. Great, I think we're good to go. @seltix5 this is incorrect as getParams method doesn't need this parameter. Can you please correct this?.\nI'll be happy to write tests for this. @seltix5 this object should also be removed from here and return statement needs to return an object\nCurrently you have null there, it should be like:\n```\n[\n    {\n        \"type\": \"Object\",\n        \"description\": \"Object containing parameters for the upload request\"\n    }\n]\n```. ",
    "Mds92": "So, how can I build it, Could you please post a link to describe it?\n. Thanks anyway. ",
    "studiorepublic": "It could ask the user to report the error at a certain email address, try again later and just generally be more user-friendly. \n. Implementing both would be great. How would I detect the error?\n. ",
    "mcorrigan": "I second correcting this. We have thousands of users trying to upload everyday, some of which have had incorrect system times. While that I agree that their system times should be accurate, it seems unreasonable for us to expect it to always be so. I don't know of any professional web services that fail due to an incorrect system time on the client. As the policy is being processed by our own servers first (validation and signing), it would make sense to use the time on the server for these requests. As a paid customer, we hope you will strongly consider making this change. \nThanks for all your hard work on this.\n. ",
    "schmuhl": "We are seeing a lot of failed uploads because of this. While I am stupefied by the apparent number of people with bad system times, this should not be a prerequisite for them using our site. Otherwise we love the functionality of FineUploader as it solves a number of problems for us. \nIs there any way - or incentive - that can expedite the inclusion of the configurable expiration time?\n. ",
    "mikesherov": "@rnicholus, thanks for responding. I'm afraid the proposed solution will not work for the issue I outlined in https://github.com/FineUploader/fine-uploader/issues/1387#issuecomment-127343461\nCorrect me if I'm wrong, but a more robust solution involves passing server time as a drift parameter to account for users clocks being wrong.\nI really love Fineuploader, and dislike having to maintain a hacked fork. Would you be willing to accept a patch that introduces a drift parameter?\n. Yeah, I'll write a test as well. Are we in agreement on the interface? I'll add a drift parameter? I no longer think it belongs as a key on the signature object but rather a key on the main options object since it effects more than just signature signing.\nThoughts?\n. OK, I'll put it on the request object, but how about the date being handed in being the unix timestamp in milliseconds, so the code would still be able to determine drift easily by doing serverDate - Date.now()?\n. I'll see if I can get this done today. If not, I'll defer to you. Thanks for your patience and support!\n. OK, thats fine. Just let me know if you want me to work on this after 5.4 is out. Thanks again for all your hard work!\n. Looks good to me.\n. ",
    "orlandovald": "Understand the IEEE standard but from a user perspective (in my case 98% Windows users) it is confusing and inconsistent. An option to decide which one to use (defaulting to the the IEEE standard) would be helpful in this scenario.\n. Agree with your statements, my scenario here is that I don't want to produce any client-side preview (or maybe a small number) to avoid any stress on the browser and I can control this with the current thumbnails.maxCount option. So far so good, now I want to return a thumbnailUrl for every single file that gets uploaded, in this case the thumbnailUrl does not get rendered if the maxCount limit has been reached, so restricting client-side previews via the maxCount option also restricts the rendering of server-side thumbnails.\n. Ok, then the documentation is a little misleading as it doesn't mention restricting the server-side generated thumbnails,\n\nmaxCount\nMaximum number of client-side generated previews to render per Fine Uploader instance. A call to the reset method resets this value as well.\n. Any suggestion for my issue, i.e. restricting client-side previews but not server-side ones?\n. Sounds good, thanks\n. \n",
    "kocholes": "In the Validation Demo the code for restrict the file size is:\nsizeLimit: 51200 // 50 kB = 50 * 1024 bytes\ni think it should be:\nsizeLimit: 50000 // 50 kB = 50 * 1000 bytes. ",
    "jardakotesovec": "Thanks for response.\nIn first case uploader.addFiles([event.target]); target is not array: \nconsole.log(event.target)\n<input type=\u200b\"file\" data-reactid=\u200b\".e.1.0.0.2.0.2.1.0.0.1.1\">\u200b\nIn second case uploader.addFiles([event.target.files]); files is also not array, but FileList object:\nconsole.log(event.target.files)\nFileList {0: File, length: 1, item: function}\nAnd according to docs input should be array of inputs or fileLists or ... .\n. Ok, makes sense. Thanks!\n. Impressed with such support :+1: .\n. ",
    "maxmatthews": "It's definitely not a Chrome only issue because I experienced a similar problem in Safari. A sparse bundle/image is exactly what you said it is, a folder disguised as a file. It's basically a DMG that can expand as you put files in it.\n. I think what is happening is FineUploader is detecting that it's a folder and needs to be zipped, then starts to zip it and floods the cache because it happens to be so big.\nIt's weird. Firefox detected it as a folder but Chrome and Safari let me upload it as one file\n. Sure. Let me create one for you. Give me a sec\n. The file is going to take a little while to upload so I'll post the link tomorrow morning\n. ",
    "dscherbel": "I have tested this on iOS Safari on an iPhone 5, iPhone 6, and iPhone 6 Plus. Safari works just fine. Chrome on all of these devices produces the faulty behavior. Chrome, Firefox, and IE on desktop work flawlessly also.\nAs far as code goes, I'm working in a private repo. If you would like, I can share a few code snippets, but since I am reproducing the same problem on your website under your s3 demo, I think they are unnecessary.\n. ",
    "chrylis": "I'm still on 5.1.3; I hadn't seen the new release. I'll move us over as soon as practical. Thanks!\n. ",
    "rohanc": "I need this feature too. Here's my use case:\nI have a dynamic form where fields appear in a table. When the user presses \"Add row\", a new set of fields is created and one of these is a file upload input. I use the FineUploaderBasic API.\nI think it would be best if we could construct the FineUploaderBasic object without specifying any buttons at all and then associate the buttons afterwards. Perhaps the \"button\" and \"extraButtons\" distinction is an unnecessary complication.\nIn the absence of this feature, the workaround for my project was to construct a new uploader object for each new row of my table. This is not ideal though, because it means I can't take advantage of your queuing feature and a lot of other management code became more complicated than it ought to be.\n. ",
    "eugenebond": "@rnicholus I don't entirely understand how the workflow can work in case of a temporary credentials and if I want to use my own signature server. In this case there is no way to supply sessionToken and JS will never add x-amz-security-token header which will lead to AWS rejecting the request.\n. @rnicholus I don't want to do client-signing, my ultimate goal is to have server-side signing workflow. The problem I am facing is that there is no way to have server-side signing workflow function with temporary credentials because there is no way for me to provide sessionToken.\n(also thanks for very quick replies!)\n. @rnicholus \nThat's a good question, that's more of a company workflow thing. Devops provide us with a place where we can request temporary credentials when necessary and then we can play around with those. Once we have a working prototyple, devops creates a permanent key+secret, we store those safely and deploy (and at this point findeuploader will work perfectly fine).\nSo for production purposes the server-side signing workflow with temp credentials doesn't make any sense but for dev purposes this use case can have its applications in the development cycle (perhaps for large corporations only; I would imagine for smaller ones, it's easier to keep track of credentials without this complicated system).\n. @trauts2 \nI haven't worked on this since spring 2015 and my memories are a bit hazy so apologies if something in my reply is inaccurate. From what I remember, the \"4th bit\" comment was about supplying all 4 of these http://docs.fineuploader.com/api/options-s3.html#credentials\nMy understanding is that Fineuploader's original intention is to have this flow used in cases when you want frontend to handle signing. You might not want to use this because of security implications.\nIn my case I wanted to use tmp credentials and backend signing approach. I don't remember finding a good fix for this and since, in my case, I had to work with tmp credentials in dev only, I think I ended up hacking something in fineuploader internals (since I anyway had an approximate idea where things were located after trying to debug it). I haven't kept the files and don't remember the codebase anymore so unfortunately I can't advise you what to change, but even then, you probably don't want to do that for prod anyway, because it was some quick and ugly hack.\n. ",
    "Jud": "@rnicholus if you are provisioning server keys via IAM instance profiles (AWS best practices), you must supply the sessionToken, which is currently not possible with fine-uploader (while using backend signing)\n. @rnicholus If there was a way to pass through the x-amz-security-token header from the signature response, and have fine-uploader use it when communicating with S3, that would work.\n. ",
    "trauts2": "I'm hitting this issue now as well.  And it's biggie.  Basically fineuploader has worked like a dream during development, running on local and dev boxes with non-temporary credentials.  But now that we're migrating to boxes with credentials provided by IAM roles, which are temporary and require the header and sessionToken, posts are no longer accepted by S3.\nHas someone identified a workaround for this?  Hoping I just haven't tried everything yet.  Adding the token value via sessionToken doesn't work, the required header isn't sent as part of the request.\nAWS docs discuss using temporary credentials at https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_use-resources.html#RequestWithSTS\nOpen to any and all suggestions\n. I'm not sure I follow the workaround.  @eugenebond would you mind sharing the configuration that ended up working?  What is the 4th bit you added to the credentials block?  \nPersonally my workaround is to not use the IAM Instance Profile until I have a good workaround.  I can get away with that for a while, but it would be great to get the plumbing working with temporary credentials since this is arguably weakening the security to put static credentials on boxes.\n. Thanks for the details @eugenebond.\nAnd @rnicholus no worries!  Fineuploader's feature set and quality make it seem like a small army has been working on it, hard to believe it's just mostly you.  Impressive, and I'm grateful.  I can get pretty far using on-instance credentials, and when support for temporary credentials makes it's way in (I'm using serverside signing) we'll use it then. \n. Count me in if you think I'd be helpful. I just did a bit of a deep dive\ninto IAM instance profiles and at the very least can provide a working\ntestbed\nOn Wednesday, June 29, 2016, Ray Nicholus notifications@github.com wrote:\n\nCool, thanks Mike. I'm mostly interested in being sure that I understand\nhow to use STS properly in a real-world scenario, using AWS best practices.\nLet's talk next week. If anyone else in this thread is interested in\ncontributing information about their intended use of STS/temp credentials,\nplease let me know ASAP. Perhaps we can all chat at once.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1406#issuecomment-229258369,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AD0TaMH5JsGSFtjze9Qac_Jyz53A8Dzwks5qQf9OgaJpZM4EQYP9\n.\n. \n",
    "mgoodness": "@rnicholus I'd be thrilled to help with implementation. My current knowledge of STS is exclusively on the ops/provisioning side of things, but I'll devote some cycles to learning the API when I'm back in the office next week.\n. ",
    "MetricMike": "Hey @rnicholus - this issue doesn't look like it's moved in the past few months. Is there any more information you need or help the community can provide to push this forward? Thanks!. ",
    "xistext": "@rnicholus What is the status of this feature?  We are using federated identity pools and auth0.  We get an AWS credentials with the auth0 token.  Then pass the credential's access id to to fine-uploader, using zappa lambda signing endpoint.  All to upload to S3 buckets ... but get \"access id doesn't exist\".  It sounds like the signature is missing required sessionToken data required?  Thanks!  . I tried #1939 but couldn't figure out how to make signing work.  I can sign with zappa as the signature endpoint.  My issue is AWS federated identities give temporary credentials that don't make a valid signature without the corresponding security token sent via x-amz-security-token header.  You already have x-amz-security-token in your code so maybe I just need to set or enable it?  I really appreciate your efforts and hope to use fine-uploader as it seems the finest:)\n  . When do you think this branch might be merged?  I was hoping to be able to use fine-uploader to access s3 with federated identities but have been stuck for a couple weeks.  It seems like the AWS signed urls might be the ticket.  Do you take donations to help with motivation?  Thanks!. I have installed 5.16.0-RC1.  How do I tell it not to use the signature endpoint but instead to use the signed url?  I am trying to use the url generated by s3.getSignedUrl as the request endpoint.  Thanks!.  I tried setting the signature endpoint as the docs specify '/s3/signature' but get an error 'Failed to load resource: the server responded with a status of 405 (Method Not Allowed)' on that url when I upload my image.  I have tried setting version:4 or not but saw no difference.  Thanks for your replies.. ",
    "albertpr9": "Even with the multiple attribute present on the file input element, if a video is selected, the browser will render a blank page. \n. @rnicholus here's the guide to report a bug on facebook https://www.facebook.com/help/326603310765065/\n. @feltnerm here are the different scenarios and results I've gotten with iPhone 5 - iOS 8.3\nScenario 1 - Form WIHOUT the multiple attribute present \nI get the options to Take a Picture/Video or to open the file chooser.\nResult: Selecting any option will crash the browser and render the browser unusable until facebook app is restarted.(Can't open any more links on facebook)\nScenario 2 - Form WITH the multiple attribute present\nI can only open the file chooser. If pictures are selected then it will work. But if a video is selected the browser will render a blank page, but will not crash.\n. @feltnerm that's unfortunate. So for now I'm just going to hide the upload input field for mobile users. Hope they fix is soon.\n. ",
    "khejing": "Sorry for posting here, but I still don't understand why I can't convert a non-ui instance into one that contains the extendable ui. OK, I will post it on stack overflow, thank you!\n. ",
    "xlkit456852": "Oh, I fixed it .Thanks guys.\n. ",
    "devang-rathod": "You are right, but currently we are stuck in this issues and we need solution for this. so please if you can help us.\n. ",
    "smacode": "Yes\n. Sorry, there was no opportunity to answer immediately.\nI can reproduce described behaviour only with \nfine-uploader.js (5.1.3)\nfine-uploader-gallery.css (5.2.1)\ngallery template (5.2.1)\nDo you need any sources now?\n. Such ood configuration came out after some experements.\nAnd I noticed that only when creted new clear test project\nto reproduce described behaviour.\n. Yes, it fixes. No obvious issues in other browsers.\n. The situations are different.\nIn https://github.com/FineUploader/fine-uploader/issues/1416 you exclude \nitem that has not been uploaded.\nIn this issue you delete item that has been already uploaded.\n. At \nhttp://fineuploader.com/customize.html\nI see \"Download 5.2.1\" button.\n. Ok, I'm waiting for pre-release.\n. Custom endpoint\n. Looking into it now.\n. There are additional issues. Please, wait  a little\n. All issues (#1416, #1417, #1418, and #1419) - \u043e\u043a.\nWhen I begun to test, I faced the problem, \nthat later was hard to reproduce.\nProblem: \nthumbnail generation stops at some item (more often closer to the end of list).\nHow to reproduce:\n- Firefox 38.0.5\n- a lot of open tabs (~30)\n- number of images: 36\n- image size: 1-2 Mb\n- Fine Uploader element outside of form\n- a little of free system memory\n- CPU: high loaded (not necessarily)\nBut if thumbnail was not generated for even one item,\nafter deleting all items and uploading them again, \nno thumbnail is generated. \n. I've edited the post: \"a little of FREE system memory\"\n~350 Mb on Windows 7 Ultimate\n. Ok, thank you.\n. ",
    "kkirsche": "Because it's not used and has never been used. It's completely pointless to include.\n. To each their own. I strongly disagree with that view, but whatever\n. This is literally going to every single person who has this in their bower.json. I'm not bothering with reading each contrib doc. I do apologize for not following it, but too many to do.\n. Also their maintainer says they probably won't ever use it: http://stackoverflow.com/questions/24844901/bowers-bower-json-file-version-property\n. ",
    "mohitjee15": "We are on the latest version 5.2.2.\nIn the totalProgress callback http://docs.fineuploader.com/api/events.html#totalProgress,\nWe are getting two things totalUploadedBytes and totalBytes.\nSo in the following scenario we are getting correct values for totalUploadedBytes and totalBytes:-\n- When new files are added\n- When a file is deleted\n- When a file fails\nBut we get incorrect value for totalBytes in the following scenario:-\nPreconditions:-\n- We are using fine uploader core\n- We are trigger the uploads manually\n- We are doing manual retry (autoRetry is disabled)\nScenario:-\n1) We queued 4 files for upload, foo.pdf(50MB), bar.pdf(50MB), foobar.pdf(50MB), barfoo.pdf(50MB).\n2) We triggered the upload using uploader.uploadStoredFiles().\n3) Say foo.pdf, bar.pdf failed and foobar.pdf and barfoo.pdf passed.\n4) Now if we retry foo.pdf and bar.pdf simultaneously, in the callback for totalBytes we should receive  100MB (50MB for foo.pdf and 50 MB for bar.pdf) but it shows 50MB only. \n. What i meant with \"simultaneously\" is while the first retried file is in\nprogress, if you retry the second one also.\nOn Fri, Jun 19, 2015 at 1:42 AM, Ray Nicholus notifications@github.com\nwrote:\n\nCan you elaborate on how you are retrying two files \"simultaneously\"? I'm\nnot seeing how this is even possible with the current API. Brief testing\nshows the total bytes being updated correctly when the second file is\nretried.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1424#issuecomment-113276074\n.\n\n\nMohit Suman\nWeb Developer(JS Ninja)\n. \"As you can see from my post, I am still unable to reproduce this. If you\nare confident an issue exists, please share the exact line or lines that\nare causing the issue, along with a proposed fix.\"\nSorry for not replying early.\nBut in my first post itself I have mentioned the line that has the problem\nand the fix that is required.\nI'll be happy to share create a pull request if you want.\nOn Tue, Jun 23, 2015 at 8:09 PM, Ray Nicholus notifications@github.com\nwrote:\n\nClosing as I am unable to reproduce. I'd be happy to consider re-opening\nif this changes.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1424#issuecomment-114529321\n.\n\n\nMohit Suman\nWeb Developer(JS Ninja)\n. Chrome browser. Version 42 i think.\nWhich browsers are you using to reproduce this? If I'm able to reproduce\nmyself, I'll look into a fix for 5.3.0.\nOn Thu, Jul 23, 2015 at 5:42 AM Mohit Suman notifications@github.com\nwrote:\n\nIn the demo page :- http://fineuploader.com/demos\nI tried to upload near about 1800 files all pretty small less than 1 MB.\nOnce I click on Upload button it started uploading, but after 840 files\nthe progress bar disappears and for the rest of the 760 files I have to\nclick \"Upload\" button again.\nWe are also facing similar problem in our end.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1439.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1439#issuecomment-124084105\n.\n. When are you guys releasing 5.3.0 as it is in dev branch? Because till then it is a production bug for us.\nOne more thing what problems are you facing in uploading 1800 files?\nWe just copy pasted a bunch of files and were able to test it 5 mins.\n. ok i'll verify today and let you know.\n. ",
    "TimDaub": "Ok, yeah totally missed the fileLimit option. Now multiple uploads are working fine.\nI think the main problem is essentially that getResumableFilesData() is not retriving results from the browsers local storage.\nTherefore - of course - nothing can be autoRetired as for the library, there is nothing.\nIf I can help you with more, then please reach out to me here and I'll try to answer all your questions.\n. Good morning,\n@rnicholus Any updates on the issue yet?\n. Yeah, that sounds good, though it would be even cooler if fineUploader\nwould either use es6-promises (as a polyfill) or q(Promises A+).\nBecause right now, this adds more payload to our application, as we don't\nuse fineUploader's promises anywhere except for in fineuploader specific\ncode.\nOn Wed, Jun 17, 2015, 14:43 Ray Nicholus notifications@github.com wrote:\n\nWe can look into explicitly returning a status value from this method,\nspecifically a promise, in some future release.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1426#issuecomment-112784526\n.\n. Ok, fair enough but without looking into it, is it compliant with:\nhttps://gist.github.com/domenic/3889970 or the Promise A+ spec?\n\nOn Wed, Jun 17, 2015, 21:47 Ray Nicholus notifications@github.com wrote:\n\nThe internal promise impl probably accounts for about 500 bytes gzipped.\nHardly noticeable.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1426#issuecomment-112926094\n.\n. > The messages sent to these callbacks are meant to be generic.\n\nWhy? A developer could still make them generic if he doesn't want to see the individual ones.\n. Nope, \nI emptied my onComplete function and I'm still able to reproduce the error.\nIt happens in:\ns3.fine-uploader.js:5237 Uncaught TypeError: Cannot read property 'temp' of undefined\nwhich is:\n```\nclearXhr: function(id, chunkIdx) {\n            var tempState = handler._getFileState(id).temp; // here handler._getFileState(id) is undefined\n        if (tempState.xhrs) {\n            delete tempState.xhrs[chunkIdx];\n        }\n        if (tempState.ajaxRequesters) {\n            delete tempState.ajaxRequesters[chunkIdx];\n        }\n    },\n\n```\n. ",
    "josefloreschura": "Hi @rnicholus. just tested this and worked!\nError in dev console is no longer displayed and the scaled image was cancelled properly.\nThanks!\n. I want to enforce to only upload pictures with great quality and one of the ways to do it is limiting the min size. Pictures with less than 3Mb are considered low quality which I want to avoid.\n. > The size of an image does not necessarily describe its quality\nI agree and that's why I said it's only one way to filter the images, there are other filters.\nAnother reason is that the user has a max quota to upload images, let's say is 100MB. We would want to avoid the user reducing the filesize image (sacrificing quality) just to upload more images. I know images can be reduced or compressed trying to keep quality, but in fotography there is a limit you can reduce the filesize without losing quality\n. ",
    "stof": "Well, AngularJS relies on such attributes in their templates\n. ",
    "MikeSmith01": "Thank you so much!:))\n. Well, I think that your answer made sense where an id named \"qqparentuuid\" would be stamped on resized versions of images if the original was uploaded, since the resized versions originated from a parent. I can see the thought behind that:) In this case probably the easiest thing is to just include \"qqparentuuid\" on resized images as well if the original is not sent, since technically speaking, it would serve the same purpose. Or, maybe, you could name it something along the lines of a qqresizeuuid, since the parent is not there, just the kids;) It's entirely up to you.\nI made it work with name as a unique identifier for now. But I have to strip out the \"name\" from file names, the extra brackets \"()\", and I also remove spaces from the file name just for cleanliness. And it works...just not exactly that dependable or pretty. We are still developing things...so no rush on a release version.\np.s. I will provide feedback about the demo page in another post with a few ideas. Just wanted to let you know that I have not forgotten:)\nThanks again,\nMike\n. Did a little more testing today, and found out that name won't work as a unique link for resized images because if I upload the same image twice, the name is the same for both uploaded images and code breaks. Will have to wait for the enhancement:)\n. Thanks Ray, I'll give it a try:)\n. Hi Ray, thanks for making the adjustment. I will certainly take a look at it either this weekend if I find time or early next week (I'm out of town due to holiday). Happy 4th of July!\n. Hi Ray, I'm sorry, but how do I get to that branch? I would need azure.fine-uploader.min.js for testing.\nThanks,\nMike\n. Ok, I just tested, everything works as expected, now there's a qqparentuuid present without the original image being sent:) Thank you!\nMike\n. Thanks Ray, I will use this version meanwhile:)\n. Hi Ray, thank you for your reply. \nI absolutely agree with you that the code quality, documentation quality, and support quality is very crisp with FineUploader. I am very proud of having to work with it:)\nI was not aware that the demos were old, they very well might be, you would know better:) I just wanted to provide an example of the demos that I would personally expect to see, as these types of demos with code/functionality side by side tend to be the best. I did see the code link at the demos page. At the time I wrote this there was no demo for basic..so I guess that's why I wanted to see more demos. (p.s. that demo of that flashy image gallery might have primed me also;)\nIt's really weird that some users would ask for less demos, I as a developer, would never ask for less demos or complain that they are too complex. Why would anybody ever do that? Demos are on take what you need basis, it's not like one tries to cram demos in the developer's head. The more examples the better, saves time on reading documentation right? When I develop I might copy/paste code snippets from this and that demo and put things together pretty fast, I find this pretty convenient to work like that. With all honesty, I am having a thought now that those users might have been bogus and tried to intentionally undermine FineUploader's sales/reputation. While a flashy demo is subjective, a plain vanilla is going to look plain vanilla to everyone.\nIt's nice to hear that you have something in the works, I'm looking forward to it:) Honestly, putting up good demos and polishing them up can be quite exhausting and tiring work, it would probably feel like that last 10% of the way, which are the hardest. But they have to be there. As I already suggested, maybe trying to put FineUploader in context with image gallery, video gallery, and file gallery would be good. More updated code demos like the ones composed by a friend would be super nice. I am having a picture come up in my head now of a chest of jewels that's being unfortunately closed with only a few jewels shown on the top. I want to see it all so I can look no further from the start.\nThank you,\nMike\n. Hi Ray, I am glad I could provide valuable input. I am sure you will think up of something good for the demos:)\nRegards,\nMike\n. Hi Ray,\nThank you for your comment. It certainly can be tracked server side and I did play with both events, onComplete() and onAllComplete(). The onComplete() event fires for each file, for example, in case of a resized images it would fire once for large, medium, and thumbnail version of the image. But when images get uploaded to the server I already know which image it is by looking at its name prefix. So onComplete() event doesn't tell me anything new. I also could make it work server side and check the database to see if all resized instances of an image have been uploaded when images get saved. But I would have to do it upon each individual image arrival because images get saved to database out of order just to the way the threads are scheduled. So this could certainly work, just won't be as polished. That's why I wanted to suggest an event something along the lines of onAllComplete() but for each batch of resized instances of an image. That way when this event fires, I know that all resized instances of an image have been uploaded and it's safe to schedule processing for that batch with just one simple call. The code would just look more professional that way.\nMike\n. Hi Ray, thanks for the update. It definitely would help in my case, but it's not critical, so I understand where you are coming from. Thanks for being open minded towards future feedback.\nThanks,\nMike\n. ",
    "andr3s2": "Thank you for the quick response ,\nAccording to your respose, I don't think is a signature issue because it is done in your server (you have the credentials).\nAccording to browser plugin I have tested the example in Safari, Chrome, FF and the same problem.\nAlso I have done as 'incognito' in chrome without any extension and still the same problem.\nI'll appreciate any help.\nThank you in advance\n. ",
    "subinvarghesein": "\nvalidate event returns filename (which contains extension) and size. You can use that\nCurrently you would need to keep a model on your side to track how many docs and jpgs where submitted and on the same validate event, based on your model, can return false to reject the file\n. \n",
    "cariquitanmac": "@rnicholus do we have any workaround for this?. ",
    "antonsarov": "I am commenting under this issue cause the problem seems to be related but not exactly as described above.\nThe problem comes actually from the fact, that the original image is deleted (my onDeleteComplete is executed) but the scaled image is not deleted (from a Fine Uploader's point of view). This happens because I have defined hideScaled: true - and this is documented. However I am missing a functionality where I can delete the scaled image as well.\nI thought about making a separate deleteFile(...) call when my onDeleteComplete callback is executed but how do I get the ID of the scaled image? And even if I get it, this seems to be a bit overcomplicated.\nIt would be really cool to have something like:\nscaling: {\n        sizes: [\n            {name: \"small\", maxSize: 100, deleteWithOriginal: true},\n            {name: \"medium\", maxSize: 300, deleteWithOriginal: false}\n        ]\n    }\nwhere you can specify which scaled versions should be deleted along with the original image.\n. Having a global scaling option to delete scaled images along with the reference image would be super cool! Should I open a separate issue with the request?\nMeanwhile, is there any way to force the deletion of the hidden scaled images? Getting the ID would help here.\n. ",
    "pafro": "+1 for this.\n@colevoss Any chance of seeing your calculation code and how it's implemented - this feature is on my UI list and I really like not 'reinventing the wheel!'\nIs your code looking at a each uploading file and also the 'overall' upload speed (all files combined?)\n. ",
    "JHGitty": "I additionally need to know the remaining time of the upload(s). Any idea?\n@rnicholus The UI code / documentation should contain an example for this.\n. @rnicholus Great idea and thanks! I think this is helpful: http://stackoverflow.com/questions/21162749/how-do-i-calcuate-the-time-remaining-for-my-upload\n. I use JQuery. Here is my code. This code only works out-of-the-box if you have only 1 uploader box on your page. Otherwise you need to change the hardcoded div #progress-text and #uploader-speed.\n- Add remaining time\n- Add total progress %\n- Add upload speed\n``` js\n        var uploadSpeeds = [];\n\n        function updateSpeedText(totalUploadedBytes, totalBytes) {\n            var progressPercent = (totalUploadedBytes / totalBytes).toFixed(2);\n            if (isNaN(progressPercent) || progressPercent >= 1) {\n                $('#progress-text').text('');\n            } else {\n                var progress = (progressPercent * 100).toFixed() + '% total';\n                $('#progress-text').text(progress);\n            }\n\n            // upload speed\n            uploadSpeeds.push({\n                totalUploadedBytes: totalUploadedBytes,\n                currentTime: new Date().getTime()\n            });\n            var minSamples = 6;\n            var maxSamples = 20;\n            if (uploadSpeeds.length > maxSamples) {\n                // remove first element\n                uploadSpeeds.shift();\n            }\n            if (uploadSpeeds.length >= minSamples) {\n                try {\n                    var firstSample = uploadSpeeds[0];\n                    var lastSample = uploadSpeeds[uploadSpeeds.length - 1];\n                    var progressBytes = lastSample.totalUploadedBytes - firstSample.totalUploadedBytes;\n                    var progressTimeMS = lastSample.currentTime - firstSample.currentTime;\n                    // megabytes per second\n                    //var MBps = (progressBytes / (progressTimeMS / 1000) / (1024 * 1024)).toFixed(2);\n                    // megabits per second\n                    var Mbps = ((progressBytes * 8) / (progressTimeMS / 1000) / (1000 * 1000)).toFixed(2);\n                    //console.log(progressBytes, progressTimeMS, Mbps, uploadSpeeds.length);\n                    if (Mbps > 0) {\n                        $('#uploader-speed').text(Mbps + ' Mbps / remaining: ' + ((totalBytes - totalUploadedBytes) / progressBytes).toFixed(1) + ' seconds');\n                    } else {\n                        $('#uploader-speed').text('');\n                    }\n                } catch (err) {\n\n                }\n            }\n        }\n    });\n\n```\nDon't forget to add a callback to FineUploader:\ncallbacks: {\n                    onProgress: function (id,name,totalUploadedBytes, totalBytes) {\n                        updateSpeedText(totalUploadedBytes, totalBytes);\n                    }\n                }\nAnd don't forget to add the 2 divs to your template:\nhtml\n                <div id=\"uploader-speed\"></div>\n                <div id=\"progress-text\"></div>\n(I have added them inner div qq-total-progress-bar-container)\n. I use JQuery. Here is my code. This code only works out-of-the-box if you have only 1 uploader box on your page. Otherwise you need to change the hardcoded div #progress-text and #uploader-speed.\n- Add remaining time\n- Add total progress %\n- Add upload speed\n``` js\n        var uploadSpeeds = [];\n\n        function updateSpeedText(totalUploadedBytes, totalBytes) {\n            var progressPercent = (totalUploadedBytes / totalBytes).toFixed(2);\n            if (isNaN(progressPercent) || progressPercent >= 1) {\n                $('#progress-text').text('');\n            } else {\n                var progress = (progressPercent * 100).toFixed() + '% total';\n                $('#progress-text').text(progress);\n            }\n\n            // upload speed\n            uploadSpeeds.push({\n                totalUploadedBytes: totalUploadedBytes,\n                currentTime: new Date().getTime()\n            });\n            var minSamples = 6;\n            var maxSamples = 20;\n            if (uploadSpeeds.length > maxSamples) {\n                // remove first element\n                uploadSpeeds.shift();\n            }\n            if (uploadSpeeds.length >= minSamples) {\n                try {\n                    var firstSample = uploadSpeeds[0];\n                    var lastSample = uploadSpeeds[uploadSpeeds.length - 1];\n                    var progressBytes = lastSample.totalUploadedBytes - firstSample.totalUploadedBytes;\n                    var progressTimeMS = lastSample.currentTime - firstSample.currentTime;\n                    // megabytes per second\n                    //var MBps = (progressBytes / (progressTimeMS / 1000) / (1024 * 1024)).toFixed(2);\n                    // megabits per second\n                    var Mbps = ((progressBytes * 8) / (progressTimeMS / 1000) / (1000 * 1000)).toFixed(2);\n                    //console.log(progressBytes, progressTimeMS, Mbps, uploadSpeeds.length);\n                    if (Mbps > 0) {\n                        $('#uploader-speed').text(Mbps + ' Mbps / remaining: ' + ((totalBytes - totalUploadedBytes) / progressBytes).toFixed(1) + ' seconds');\n                    } else {\n                        $('#uploader-speed').text('');\n                    }\n                } catch (err) {\n\n                }\n            }\n        }\n    });\n\n```\nDon't forget to add a callback to FineUploader:\ncallbacks: {\n                    onProgress: function (id,name,totalUploadedBytes, totalBytes) {\n                        updateSpeedText(totalUploadedBytes, totalBytes);\n                    }\n                }\nAnd don't forget to add the 2 divs to your template:\nhtml\n                <div id=\"uploader-speed\"></div>\n                <div id=\"progress-text\"></div>\n(I have added them inner div qq-total-progress-bar-container)\n. ",
    "elevenpast": "Hello,\nI just had another incident reported and was able to jump on their system.   OSX 10.10.5 and Safari 8.0.8 again.\nThe upload went from 99% to Processing, and stayed there for several hours.   The console log showed nothing, even though debug is true.  This user has good upload speed, 30 mbps via speedtest.\n\nThen something strange happened when I navigated away from the upload page.  The file apparently went through, and our backend processing picked it up. So \"onAllComplete\" must have fired at that point.\nI don't have a 10.10.5 system to test this out, but several clients can reproduce it every time.\nJO\n. I'll create a 10.10.5 environment and see if I can replicate.\n. I cannot reproduce, which isn't very helpful.\nJO\n. ",
    "nisargrthakkar": "I am getting same issue \nfine-uploader.core.js:960 Uncaught (in promise) TypeError: Cannot read property 'status' of undefined\n    at webpackJsonp../node_modules/fine-uploader/fine-uploader/fine-uploader.core.js.qq.UploadData.setStatus (fine-uploader.core.js:960)\n    at webpackJsonp../node_modules/fine-uploader/fine-uploader/fine-uploader.core.js.qq.FineUploaderBasic._onDelete (fine-uploader.core.js:2112)\n    at Object.onDelete [as onSend] (fine-uploader.core.js:1399)\n    at sendRequest (fine-uploader.core.js:2786)\n    at prepareToSend (fine-uploader.core.js:2887)\n    at Object.send (fine-uploader.core.js:2923)\n    at webpackJsonp../node_modules/fine-uploader/fine-uploader/fine-uploader.core.js.qq.FineUploaderBasic.sendDelete (fine-uploader.core.js:4052)\n    at Object.onSuccess (fine-uploader.core.js:460)\n    at fine-uploader.core.js:1806\n. ",
    "applibs": "Yes sure, but why error message in log?\n. I have another problem.\nWith this setting: \"scaling\": { \"sendOriginal\": \"false\", \"sizes\": [ {\"name\": \"sized\", \"maxSize\": \"1900\"} ]}\n, but in uploader UI a see 2 preview images: 1x sized + 1 original. 1 is in files folder and second in chunks folder.\n. And next trouble:\n{ \"validation\": {  \"itemLimit\": \"1\", \"allowedExtensions\": [\"jpeg\", \"jpg\",\"avi\",\"png\"] }, \"scaling\": { \"sendOriginal\": \"false\", \"sizes\": [ {\"name\": \"sized\", \"maxSize\": \"1900\"} ]} }\nand with sessions setting:\nsession : { params: { files: uploaded }, endpoint: '/libs/scripts/uploaded.php', refreshOnRequest:true  }\nAfter reload page I have one already uploaded file which I see in UI of FU. But after try to upload next image I got error: Too many items (3) would be uploaded.  Item limit is 1. But I have only one. OK, I deleted that one image, soo in UI is no image, I try upload newone, but with message: Too many items (2) would be uploaded.  Item limit is 1. Seems that it count scaling image, but in scaling setting I have sendOriginal: false, soo in this setting example is only 1 image request.\nWhen I have no scaling setting then count is correct and FU works.\nAnd why FU send 2 requests for same thumb for session images only? I see it in Chrome network console.\n\n. But why its takeing twise from cache?\n. For other people I found that it is broken by ckeditor plugin named 'eqneditor'. By disabling it all works well.. ",
    "am05mhz": "hi @rnicholus, sorry I forgot to mention that I don't use validation.sizeLimit as it is client side protection, what I use id PHP's class sizeLimit property in order to do server side validation.\nThanks\n. umm, I use FineUploader PHP class, so it is involved to FineUploader, or may be its a different project? sorry if I did not know this as what I understood, that is a part of the same project.\n. ah, okay, sorry for the mix up, i'll post that in that section\n. ",
    "hemlata09": "\"1000 concurrent uploads\" means 1000 users are going to upload media files per second.\nCan FineUploader handle 1000 concurrent users per second?\n. ",
    "bionik": "Thanks for responding. I'm not totally convinced that it's the Google Fonts' fault, instead I think it's the templating engine not working correctly in Firefox. If I edit the generated dom and add umlauts by hand, everything works. Seems to me that it's the templating engine's internal character encoding that does not work correctly. Here is a screenshot of your demo, I added some umlauts to the second filename by hand, the part of the DOM is visible in Firefox inspector. \n\n. Well okay then, strange. Anyway, I got no problem pasting paragraphs containing umlauts to the test tool you linked. This is a confusing problem :) \nThe reason why I was suspecting the templating engine is that there seems to be two types of different umlauts there; in the screenshots I provided, the broken umlauts are different than the ones I added directly to the DOM. \nMaybe I have to try something else then. Thanks.\n. Ok. Thanks for responding and keep up the great work!\nLauri Hakkarainen\n+358 40 5432188\n\nOn 24 Sep 2015, at 18:42, Ray Nicholus notifications@github.com wrote:\nI've attached pictures of a word with an umlaut entered into the google fonts typecast demo page on FF and Chrome - no Fine Uploader involved. You can see there is a clear rendering issue in FF. You'll need to contact either the Fonts or the Firefox team for further support.\nFirefox:\nChrome: \n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "michaeljmx": "We use the S3 uploader on one domain and it calls the uploadSuccess callback on another domain, so it has to do a cross-domain request. All the required CORS settings are configured correctly, and we have no problems with Chrome, Firefox or IE10+. However, in IE9 the requests get stuck.\nGenerally if 3 files are uploaded (with 3 maximum connections enabled), so they are uploaded at the same time, the first callback works but the next two got stuck. If I check IE11 in IE9 emulation mode, I see in F12 developer tools that these requests are \"pending\". However, when I check it in real IE9, I see that the requests are aborted.\nThe changes I mentioned above seem to have fixed the issue, while more tests may be required.\n. Unfortunately no, for the moment I changed it in the bundled script. The change I made is the following: I replaced the following code:\n``` javascript\n    function getCorsAjaxTransport() {\n        var xhrOrXdr;\n    if (window.XMLHttpRequest || window.ActiveXObject) {\n        xhrOrXdr = qq.createXhrInstance();\n\n        if (xhrOrXdr.withCredentials === undefined) {\n            xhrOrXdr = new XDomainRequest();\n        }\n    }\n\n    return xhrOrXdr;\n}\n\n```\nwith this one:\n``` javascript\n    function getCorsAjaxTransport() {\n        var xhrOrXdr;\n    if (window.XMLHttpRequest || window.ActiveXObject) {\n        xhrOrXdr = qq.createXhrInstance();\n\n        if (xhrOrXdr.withCredentials === undefined) {\n            xhrOrXdr = new XDomainRequest();\n\n            // Fixes bug with IE9 - https://social.msdn.microsoft.com/Forums/ie/en-US/30ef3add-767c-4436-b8a9-f1ca19b4812e/ie9-rtm-xdomainrequest-issued-requests-may-abort-if-all-event-handlers-not-specified?forum=iewebdevelopment\n            xhrOrXdr.onload = function () { };\n            xhrOrXdr.onerror = function () { };\n            xhrOrXdr.ontimeout = function () { };\n            xhrOrXdr.onprogress = function () { };\n        }\n    }\n\n    return xhrOrXdr;\n}\n\n```\n. I understand that one file can be uploaded using multiple connections, and in this case there won't be connections left for other files. However, the problem is that after processing such large file, the uploader sometimes becomes stuck in the single-connection mode.\nI'll explain below the test I performed. Sorry for the long post.\nWe use the following setting:\nmaxConnections - 3 (default)\nchunking - enabled\nconcurrent - enabled\nFirst test I performed was to upload 5 small files (less than 5MB each). As I understand the size of 5MB is important here as it is the minimal size of chunk in S3, and we use the S3 uploader.\nThe upload process I saw was the following:\nStep 1:\nFile 1 - uploading\nFile 2 - uploading \nFile 3 - uploading\nFile 4 - queued\nFile 5 - queued\nStep 2:\nFile 1 - uploaded\nFile 2 - uploading \nFile 3 - uploading\nFile 4 - uploading\nFile 5 - queued\nStep 3:\nFile 1 - uploaded\nFile 2 - uploaded \nFile 3 - uploading\nFile 4 - uploading\nFile 5 - uploading\nStep 4:\nFile 1 - uploaded\nFile 2 - uploaded \nFile 3 - uploaded\nFile 4 - uploading\nFile 5 - uploading\nStep 2:\nFile 1 - uploaded\nFile 2 - uploaded \nFile 3 - uploaded\nFile 4 - uploaded\nFile 5 - uploading\nStep 5:\nFile 1 - uploaded\nFile 2 - uploaded \nFile 3 - uploaded\nFile 4 - uploaded\nFile 5 - uploaded\nSo everything worked as expected.\n. Next test was to upload one large file (about 15MB and 5 small files). \nAnd I saw the following (\"File 0\" is the large file):\nStep 1:\nFile 0 - uploading (using several threads)\nFile 1 - queued\nFile 2 - queued \nFile 3 - queued\nFile 4 - queued\nFile 5 - queued\nStep 2:\nFile 0 - uploaded\nFile 1 - uploading\nFile 2 - queued \nFile 3 - queued\nFile 4 - queued\nFile 5 - queued\nStep 3:\nFile 0 - uploaded\nFile 1 - uploaded\nFile 2 - uploading\nFile 3 - queued\nFile 4 - queued\nFile 5 - queued\nStep 4:\nFile 0 - uploaded\nFile 1 - uploaded\nFile 2 - uploaded\nFile 3 - uploading\nFile 4 - queued\nFile 5 - queued\nStep 5:\nFile 0 - uploaded\nFile 1 - uploaded\nFile 2 - uploaded\nFile 3 - uploaded\nFile 4 - uploading\nFile 5 - queued\nStep 6:\nFile 0 - uploaded\nFile 1 - uploaded\nFile 2 - uploaded\nFile 3 - uploaded\nFile 4 - uploaded\nFile 5 - uploading\nStep 7:\nFile 0 - uploaded\nFile 1 - uploaded\nFile 2 - uploaded\nFile 3 - uploaded\nFile 4 - uploaded\nFile 5 - uploaded\n. As you can see in the second test the uploader uploaded small files one by one. My interpretation is that because of some problem with connection management after processing the first file the uploader adds one connection at a time.\n. The version we use is 5.2.2. Unfortunately I don't know how it is possible to reproduce the issue - we received the errors using an ajax callback in onerror handler and could not reproduce it in our own environment. Unfortunately I cannot share our code at the moment.\nSorry, I know that it's not very helpful. I thought that maybe other users encountered the same error and/or you may suggest a general idea of what could cause the issue that can help with finding the source of the problem.\n. About half of people that get this exception cannot finish the upload process and the upload seem to be stuck (onAllComplete isn't called for them and onComplete with error response is neither called), while some of them upload few files before getting this error. Other half finishes upload successfully. \nWe'll try to get more information on the issue and I'll post here if we find something that could help with fixing the issue.\n. Unfortunately we didn't have a chance yet. Probably we'll wait for the next version and then try it in production - we could not reproduce the problem in our own tests.\n. ",
    "Marak": "@rnicholus -\nThank you for the question answer.\nCan you specify or comments on the trade-off between specifying a high or low chunk size. Let's say, what is the performance difference 5meg chunks and 50meg chunks.\nIn my current solution I have a few users with unreliable internet getting too many ERR_CONNECTION_RESET from s3. In some cases they can't get past a whole chunk.\n. ",
    "barchard": "Sounds like a good approach. Thanks. \n. ",
    "aknosis": ":+1:\nNeed this same functionality to prevent polluting source with more images and allowing to share elements with the parent site.\n. ",
    "100ent": "https://dev.twitter.com/rest/reference/post/media/upload-chunked\n. If you post a concurrent upload. The initial post is max connections in my case 3. When the actual upload (jxhr) event is fired off, it occurs with the endpoint I set on chunkdata index 1. So even though the initial endpoint is example.com/init fineuploader uses the example.com/append ....\n. CODE EXAMPLE\nrequest: { endpoint: example.com/api/init }\nchunking: {enabled: true} \n.....\nonuploadchunk {\n        if(chunkData.partIndex){ //if greater than 0\n            $(\"#fine-uploader-gallery\").fineUploader('setEndpoint', 'http://example.com/api/append');\n    }\n. Not true, try it\n. All of the code examples first upload's go to the append endpoint and the init endpoint never get's hit on firefox\n. My point is the change should only occur at the second part index or greater. But it's affecting partIndex 0\n. Sorry maybe so, I've never used github\n. I didn't think it was a bug because being that it's concurrent I figured it somewhat made sense that all of the chunks went out to an individual endpoint, and as of now you can change endpoint per set of chunks, just not per individual chunks\n. So if it's intended that endpoint can be set on each individual chunk than yes this is a bug\n. Well there are many ways I could fix this. One would be the ability to toggle concurrent uploads via API\n. And a correction I don't want to change the endpoint per each individual chunk personally. My first chunk needs to go to init, just like twitter's api\n. All middle chunks can go to append, and last (finalize) endpoint is already implemented\n. So if after my first upload I could turn on concurrent uploads so all the following get sent to a new endpoint that would be fine\nEXAMPLE\nonchunkupleoad success\n     setendpoint : example.com/append\n    setconcurrent: true\n. TWITTER |\nINIT    Initialize an upload    command, total_bytes, media_type    JSON\nAPPEND  Upload(s) of chunked data   command, media_id, segment_index, either media or media_data    HTTP 2XX\nFINALIZE    Complete the upload command, media_id   JSON\nSTATUS  Check the processing status of the upload (for async video uploads only)    command, media_id   JSON\n. I don't understand why my questions are all over the place. I am usually considered a great communicator what don't you understand? It's straight forward, setendpoint gets obliterated in concurrent uploads. The only used endpoint is whatever endpoint is set on the last chunk of each concurrent upload. IE upload 3 chunks\nchunk1 set endpoint x\nchunk2 set endpoint y\nchunk3 set endpoint z\nAll 3 chunks get posted to chunk endpoint z.\nThis is obviously flawed functionality, or at least should be documented in the docs with a note that set endpoint doesn't work as expected with concurrent uploads.\nMy issue at this point is being that the twitter api, (twitter's team works tirelessly on making API's that are up to standard) can't even work with fine uploader. That alone seems justification to at least consider adjusting this.\nBut moreover, it's many logical implementations that would involve at the very least an initial endpoint feature, similar to the success. endpoint feature. I will code it myself if you don't see value in what I'm saying, I just didn't want my adjustment to be incompatible with future updates.\nAlso, another pointer is this success true thing is kinda not a good idea. For me and probably any developer with their own API. I want my api to be able to work with any choice of jQuery file uploader, so I won't conform it to your choices of wording, etc instead I have had to make many tweaks. And the success true is an easy on to eliminate because success can be based on header response just as easily. Point being a more barebones option may be a good idea in the future so that it can be compatible with updates and still allow developers free rein.\n. Clarification to barebones option being in addition to the s3, azure, basic options etc.\nAnd I do see value in the success true response for anyone just wishing to slap in a file uploader with ease.\n. If screenshots are need please let me know I can show a complete walk through of this problem.\n. ",
    "jfpaulin": "Sorry, I forgot to include that. I'm using version 5.3.0\n. Yes you're right. And the fix included in the linked issue is working.\nThanks for the headsup.\n. @rnicholus sorry for the delay, I was out of the office last week. I will try to get those logs for you this week.\n. @rnicholus I attached two files. The first one is 'all.logs.txt', this contains all the console log for my failed uploads. I attached all the log to be sure that you have all you need since this is hard to reproduce. You can see the first chunk error around the line number 9430.\nThe second file, 'complete.post.txt' contains the request headers for the complete multipart post and the body for this post.\nWhat was weird, is that that time, I had to force a resume on the file. Because after uploading the last chunk, everything stopped ... No more progress, no more post/put and no more logs in the console. So I force a resume of the file by refreshing the page and selecting the same file then I was able to get the error for the complete post..\nI'll try to reproduce it again without interfering, but I'm not sure if that change anything. \nall logs.txt\ncomplete post.txt\n. @rnicholus I also noticed that when resuming the file, FineUploader uploaded the chunk number that failed.. Then do the complete multipart post which failed.\nLet me know if you need more details.\n. @rnicholus Do you think that the fact the file upload stopped after uploading the last chunk is also related to that problem ?\n. Ok. Because I'm still making tests on this, and everytime I get that problem, the upload stop and I have to force a resume on it. I can try to do it again and send you the post/put logs for the last chunks ?\n. I can put the code in here but the code is working with every other browsers we tested.\nWhich part do you need? Do you want all the HTML, JS and PHP code?. I did some digging into that and I found that the problem is with the 'chunking' feature. If I disable this feature, the upload is working fine on Safari 9.1. But when I do enable it here is the error I get from AWS S3 :\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nSignatureDoesNotMatchThe request signature we calculated does not match the signature you provided. Check your key and signing method.**PUT\n,\nx-amz-date:Thu, 03 Aug 2017 13:23:46 GMT\n/webcargo-usstd-trial-dev/1501766626-a501aab81a61d41afd192f39db69e169.zip?partNumber=1&uploadId=WMEx5fYwfnvkG4oiF8ooh5ohG0UjZfitJ6QzpTdAhT3qe_AoakW2fbra3OaiMa4qVB5IFKH7yg6vyslbFGJvtqCM7JBT4Ui7pErjNbpJnvNY9op8PhtMv.EHQH1xkAe7vRTTJ0znaCCl8WiyzbTlm/F2Yn8=50 55 54 0a 0a 2c 0a 0a 78 2d 61 6d 7a 2d 64 61 74 65 3a 54 68 75 2c 20 30 33 20 41 75 67 20 32 30 31 37 20 31 33 3a 32 33 3a 34 36 20 47 4d 54 0a 2f 77 65 62 63 61 72 67 6f 2d 75 73 73 74 64 2d 74 72 69 61 6c 2d 64 65 76 2f 31 35 30 31 37 36 36 36 32 36 2d 61 35 30 31 61 61 62 38 31 61 36 31 64 34 31 61 66 64 31 39 32 66 33 39 64 62 36 39 65 31 36 39 2e 7a 69 70 3f 70 61 72 74 4e 75 6d 62 65 72 3d 31 26 75 70 6c 6f 61 64 49 64 3d 57 4d 45 78 35 66 59 77 66 6e 76 6b 47 34 6f 69 46 38 6f 6f 68 35 6f 68 47 30 55 6a 5a 66 69 74 4a 36 51 7a 70 54 64 41 68 54 33 71 65 5f 41 6f 61 6b 57 32 66 62 72 61 33 4f 61 69 4d 61 34 71 56 42 35 49 46 4b 48 37 79 67 36 76 79 73 6c 62 46 47 4a 76 74 71 43 4d 37 4a 42 54 34 55 69 37 70 45 72 6a 4e 62 70 4a 6e 76 4e 59 39 6f 70 38 50 68 74 4d 76 2e 45 48 51 48 31 78 6b 41 65 37E65298EF59E59EEEusbzx1aNF3rOWnqT3bstf1V26dYF981hFzZYs9c+XDPydlMPXS30ax7Kwl0LPzoXDIAOydnSbIw=\n```\nDo you think you can take a look? Or do you need more information? I can also send you a link to our implementation if you want to test it.. ",
    "dbeg": "A Fine Uploader S3 signing server can be implemented in almost any language you wish. However only PHP, Java, and Node.js example servers are actively maintained by the FU team (though a few other examples are included). To leverage this functionality within VB6 or VBScript you will need to write you own server, which is a fairly simple endeavor and is heavily documented.\nIf you have any further questions that are not actual issues or feature requests, please ask within StackOverflow.\n. Everything you will need to know in order to create your own server can be found in our documentation as well as an in-depth, step-by-step blog post.\n. This issue tracker is not for general troubleshooting. Please leverage StackOverflow.\n. This issue tracker is not for general troubleshooting. Please leverage StackOverflow.\n. Please be patient. Your question has been answered.\n. You only need to purchase a license if you plan on using Fine Uploader within a commercial application. You can simply download a copy at any time.\n. > Signing policy documents server-side is the one mandatory task your server must perform, regardless of features enabled and browsers supported.\nFortunately this process is heavily documented with numerous server-side examples available.\nIf you have any further questions that are not actual issues or feature requests, please ask within StackOverflow.\n. I receive an HTTP 200 response when attempting to access both of those docs pages. Can you further explain what responses you're receiving?\nAlso, all the documentation is included within the fine-uploader repository, should you care to build it locally.\n. I'm fairly certain this feature is not available within FU, as the request.endpoint is not something that is configurable beyond one value for all requests.\nYour second option of moving the thumbnails upon upload completion is perhaps the best, and easiest option. There are a number of ways to accomplish this, and as always you will have a handle on complete files within the onComplete callback.\n. FU supports an itemLimit within its core options. Can you leverage this functionality instead?\n. Alright, knowing that requirement, I suppose the first thing I would do it actually leverage the onSubmit callback instead of onComplete, as it seems much more appropriate to validate before any actual uploading has started (I suspect the error you're referencing might be occurring due to the upload actually succeeding and then some unexpected workflow being triggered thereafter, though that's just a hunch).\nIn any event, from the onSubmit validation callback: \n\nReturn false to prevent submission to the uploader.\n. Potentially a dupe of  #1519?\n. \n",
    "webproofmt": "Is it possible you will send me the response formats that we use in fine uploader so that I can write my own code for it?\n. I am using below Policy format and creating a application/json format with policy base 64 and signature sha base 64 but getting \"Error attempting to parse signature response: SyntaxError: Unexpected token s\" error. Can you suggest where I am wrong:\nstrToPolicy =  \"{\"\"expiration\"\": \"\"2015-01-01T12:00:00.000Z\"\", \"\"conditions\"\": [ {\"\"bucket\"\": manishtests3.s3-website-ap-southeast-1.amazonaws.com }, {\"\"acl\"\": \"\"public-read\"\" },{\"\"key\"\": my access key id},{\"\"x-amz-meta-qqfilename\"\": Search.png}, ]}\"\n. Dbeg are you going to help me out???????????\n. ",
    "GFoley83": "@rnicholus I'm looking to avoid using the node sdk as we may be switching to S3 in the near future; which is where I was hoping Fineuploader would come in and be that layer of abstraction.\nJust need to know if it what I'm thinking is possible or not.\n. That's what I thought but wanted to be sure. Thanks for your help.\n. Thanks for the fast response Ray. So when you say:\n\nIn the case of a finalization error, it will only attempt to re-finalize\n\nSo you mean that Fine Uploader will retry the finalize call one time and if that fails I'll just have to manually retry the upload?\nMy worry is that is that we'll hit the max the auto retries when chunking before Azure stops throwing 503s and it's in this scenario that I'm unsure of what to do next with Fine Uploader; start the whole upload again or manually call retry(id). \n. Ok great. In the case above I can probably store the file uploader instance and retry the upload after a few minutes have passed (i.e. given Azure time to recover).\n. Something like below. Essentially I want to avoid abandoning the upload at all cost but also give Azure time to recover from the 503. \nE.g. All 5 auto retry attempts have failed, wait 2 minutes and retry manually. \n``` javascript\n// Init fine uploader object\nvar fineUploader = new qq.azure.FineUploaderBasic(fineUploaderConfig);\nfineUploader.addFiles(file);\n// Start the upload\nfineUploader.uploadStoredFiles();\n.....\n// Below methods gets called only after some period of time (e.g. 2 minutes) if we've reached the max amount of auto retry attempts.\nfineUploader.retry(someId);\n```\n. Thanks a lot Ray, really appreciate your help and the work you've done with Fine Uploader. The guys in customer support have been getting a lot of great feedback since we made the switch.\n. ",
    "skvale": "Sorry, I didn't base it off of the development branch.  Will open again off of that.\n. #1508 \n. ",
    "HarshadewaHR": "Fair enough. You have already done an amazing job. So thanks a lot.\n. ",
    "mrtomtom": "Just a bump to this, I see it's added as a low priority but it would be really great to specify max width and max height separately.. ",
    "andypryor": "@rnicholus   \n\nCan you link to the exact comment where this was mentioned in #937?\n\nYes,  edited the link to the comment.\n\nHave you turned off concurrent chunking and attempted to reproduce?\n\nWe've been unable to reproduce this in house actually.  I would be down to try disabling concurrent chunking for a portion of our users if we think it will help.\n\nFine Uploader, by default, will auto-retry. By \"the second upload attempt\" do you mean the next auto-retry? If not, please explain further.\n\nSorry should have been more clear,  I do not mean the automatic retries.  The upload succeeds when the user re-initiates the upload workflow.\n. The automatic retries produce the same result.  I've seen it retry a few hundred times before the users just cancel the upload.  On cancel we call,\n\nfineUploaderS3('cancelAll');\n      fineUploaderS3('clearStoredFiles');\n      fineUploaderS3('reset');\n\nAfter this another attempt will work.   We've been trying really hard to reproduce this,  and haven't been able to so far.\n. @rnicholus   We just reproduced this.  When uploading files from a flash drive,  if you pull out the flash drive mid upload it will produce these logs.  It works the same for network shares or other non local files.  Deleting the files mid upload from a local drive doesn't seem to cause any problems though.\nThe automatic retries do succeed once the access to the files comes back,  but the error messaging around this probably could be improved?\n. @rnicholus   The client probably shouldn't send a request if it can't read the bytes from the file?  The only improvements I can think of would be better messaging,  and possibly including the path to the file that can't be accessed.  I'm not sure if this falls within FineUploader scope though?\nThanks for your help on this!\n. ",
    "NamespaceValentine": "A workaround for anyone experiencing this issue is to set ACL to authenticated-read and give the user you want (in our case the canonical id of another cloudfront distro) full permissions on the bucket. However, I would still think that allowing this feature is a Good Idea for object level permissions.\n. Deleted my last two comments, please disregard as our testing suite was bugged. Sending the header as a meta param is working correctly, thank you.\n. Syntax:\nparams: {\n                        'x-amz-grant-read':'id=canonical id here'\n                    }\n. A for instance is:\nReceived an empty or invalid response from the server!\nPropagated from  https://github.com/FineUploader/fine-uploader/blob/master/client/js/s3/request-signer.js line 302. Some errors like this are string literals embedded in the code with no option override.\n. My options\n{\nelement: document.getElementById('sr-fine-uploader'),\n                template: 'qq-template-s3',\n                request: {\n                    endpoint: CLOUNDFRONT DISTRO HERE, \n                    accessKey: \"REDACTED\"\n                },\n                cors: {\n                    expected:true,\n                    allowXdr:true,\n                    allowCors: true\n                },\n                chunking: {\n                    enabled:true,\n                    partSize: 31457280,\n                    concurrent: {\n                        enabled:true\n                    }\n                },\n                objectProperties: {\n                    acl: 'bucket-owner-full-control',\n                    bucket: BUCKET NAME HERE,\n                    host: BUCKET NAME FORMATTED AS HOST HERE,\n                    region: \"us-west-2\",\n                    serverSideEncryption: true,\n                    key: function(id){\n                        return keyPrefix() + s3Uploader.getName(id);\n                    }\n                },\n                signature: {\n                    endpoint: '/signature', //Correctly signs in all cases\n                    version: 4\n                },\n                retry: {\n                    enableAuto: true,\n                    autoRetryNote: document.getElementById('retry-text').name+\" {retryNum}/{maxAuto} ...\"\n                },\n                text: {\n                    waitingForResponse: document.getElementById('waiting-for-response').name\n                },\n                validation: {\n                    sizeLimit: 1073741824\n                },\n                messages: {\n                    sizeError: \"You can upload a file or multiple files. Individual file size cannot exceed 1GB.\"\n                },\n                iframeSupport: {\n                    localBlankPagePath: \"/fineUploaderBlank.html\"\n                }\n            }\n. I think I have traced the issue. The file is getting correctly uploaded, but we disallow people to get at the file without a signed url. Fineuploader seems to be checking to see if the file was uploaded, but it cannot see the file, therefore it considers it a failure. Is there a way to turn off the test, or to add some business tier logic that tests the upload by requesting the signed url?\n. This may be an inaccurate understanding of what the tests are that you are running, but that is my best guess based on this documentation.\n\"To be absolutely sure, Fine Uploader S3 examines some parameters in the iframe\u2019s URL (such as the bucket and key) to ensure that the response refers to the correct file.\"\n. The redirect is happening, that is the GET that is failing. The form submits correctly because the file makes it to S3, but the UI claims that the file upload fails, and so the user sees an error. Here are the headers for the blank page GET:\nRequest headers:\nRequest: GET /fineUploaderBlank.html?bucket=[correct bucket here]&key=[expected key here, url encoded]&etag=[urlencoded etag]\nAccept: text/html, application/xhtml+xml, /\nReferer: [referring uri here]\nAccept-Language: en-us\nUser-Agent: Mozilla/5.0 (compatible; MSIE 9/0; Windows NT 6.0; Trident/5.0)\nAccept-Encoding: gzip, deflate\nHost: [our url, same dns as the blank html page]\nConnection: Keep-Alive\nCache-Control: no-cache\nCookie: [several cookies that we normally pass around our site on requests here]\nResponse headers:\nResponse: HTTP/1.1 200 OK\nCache-Control: max-age=0, no-cache\nContent-Type: text/html;charset=UTF-8\nDate: Wed, 24 Feb 2016 18:05:42 GMT\nStrict-Transport-Security: max-age=15552000\nConnection: keep-alive\nI see no request body in this request. In case you need it, here are the headers for the request that causes the redirect (the POST to cloudfront):\nRequest headers:\nRequest: POST /HTTP/1.1\nAccept: text/html, application/xhtml+xml, **\nReferer: [referring uri here]\nAccept-Language: en-us\nUser-Agent: Mozilla/5.0 (compatible; MSIE 9/0; Windows NT 6.0; Trident/5.0)\nContent-Type: multipart/form-data; boundary=-----------------------------7e02bb1e10172\nAccept-Encoding: gzip, deflate\nHost: [cloudfront dns]\nContent-Length: 1348053\nConnection: Keep-Alive\nCache-Control: no-cache\nRequest Body:\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"key\"\nid-2775747901/1MBzipFile.zip\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"success_action_redirect\"\n[URI for blank page here]\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"x-amz-server-side-encryption\"\nAES256\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"acl\"\nbucket-owner-full-control\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"x-amz-meta-qqfilename\"\n1MBzipFile.zip\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"x-amz-algorithm\"\nAWS4-HMAC-SHA256\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"x-amz-credential\"\n[AWS Access Key Id here]/20160224/us-west-2/s3/aws4_request\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"x-amz-date\"\n20160224T181030Z\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"policy\"\n[Policy here]\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"x-amz-signature\"\n[Signature here]\n-----------------------------7e02bb1e10172\nContent-Disposition: form-data; name=\"file\"; filename=\"1MBzipFile.zip\"\nContent-Type: application/x-zip-compressed\n[Binary File Data Not Shown]\n---------------------------7e02bb1e10172--\nResponse headers:\nResponse: HTTP/1.1 303 See Other\nContent-Length 0\nConnection keep-alive\nDate: Wed, 24 Feb 2016 18:05:43 GMT\nx-amz-server-side-encryption: AES256\nETag: \"[etag here]\"\nLocation: [the https endpoint for the empty html page along with the same query params as the GET request]\nServer: AmazonS3\nX-Cache: Miss from cloudfront\nVia: 1.1 ea961b1c94972f8feffbb14a32ffee07.cloudfront.net (CloudFront)\nX-Amz-Cf-Id: L37o25JSoD1PO_C-OwH5daTaCw8EcUODgJl7yPCiyFIOuPwTxQ==\n. I am more than willing to make myself available. Just let me know what you need.\n. Thank you, in the meantime I'll just fork it locally and ignore the check, when the fix is available I'll swap back.\n. The fix worked for our use case. Thank you very much.\n. I dont think so, in this one concurrency is a non-factor, it is off, so it is not a race condition issue. This is on a chunk by chunk basis taking a hugely excessive amount of time to process the cryptojs function in IE exclusively. They look like two separate issues.\n. Thank you for the explanation.\n. Without the concurrent chunking the issue did not occur, the uploads went smoothly with no spike in CPU. As our temporary workaround for a more long term solution that was the way we went. Our next steps will be to test against 5mb chunks, if that does not fix it, we will determine if v2 signing is a valid method.\n. Our signature is proxied to another server, without the cors section the headers for the proxy do not get set appropriately in the case of IE9.\n. Our current routing pattern is a bit weird due to current constraints, our apache server is too old currently to correctly route https requests to AWS which require the SNI protocols that older Apache does not support. Due to this we hit a route on the server that proxies to a NodeJS proxy which proxies using https to our signing method which is fronted by AWS ApiGateway. In the NodeJS proxy, we set the host properly, and add the content-type in the cases where it was not set by the fineuploader request (ie9). However, there were still cors issue with the flow when we tried it that allowing the cors components in fineuploader to solve. Its possible our proxy could manipulate the headers as needed, but we were not able to devote the time to discovering the issue during this setup.\n. As a clarification to your earlier point about concurrent chunking, you are correct, it was the disabling of chunking altogether that fixed the issue, the reason concurrent was disabled was that we tried that as a first step (chunking enabled, but only one chunk at a time). That the ie ternary is still in the concurrency is simply because it was not removed when we also added the ternary for allowing chunking at all.\n. Ah ok, I see it now, it is in the callbacks options rather than the validation options, for anyone who comes across this issue:\nhttp://docs.fineuploader.com/branch/master/api/events.html#validate\n. ",
    "psusmars": "Oh duh, thanks! It didn't even occur to me that the documentation that was referring to this exact scenario in the S3 documentation required V4 signatures: http://docs.aws.amazon.com/AmazonS3/latest/API/mpUploadUploadPart.html. Also thank you again for the phenomenal effort you put into this project. It's greatly appreciated.\n. In the off chance someone stumbles here, or if you have a better place to put this, I've put up a gist of how to create the V4 signature in Ruby: https://gist.github.com/psusmars/7b0966711752bee28c12\n. This may actually be a bug, since if I specify \"filename\" as the key property (leaving it to Fine Uploader to specify), I still don't receive the properly escaped path for signature generation in the canonical request:\nPOST\\n/66ft+High+Overlap+8-14.zip\\\n. ",
    "ericmackrodt": "Oh, didn't know that. Sorry.\n. What you suggested would be ideal, the problem is that it wouldn't support asynchronous code within onUploadChunk. That's what I need to support since each of the chunks I'm sending to the server are being encrypted using a WebWorker and there's no way to wait for the async work to be done within onUploadChunk unless I add a callback to it the same way I did with the other event. But I wanted to keep the event that already existed the same.\nDo you have another suggestions that would work with async code?\nAnother thing is, the only chunk that's allowed to have its size changed is the last one, the other ones can't have the size changed and there's a validation in the code to avoid it from happening.\n. Hello, do you have a suggestion for this case?\n. Do you prefer that I open a feature request instead of writing the feature?\n. Okay, if it's possible to leave it open, I'll try to get around to implement it, If I can't, if you could implement it for a post 6.0 release, it'd be awesome.\nThanks for the quick response.\n. ",
    "rupert1073": "Hi Ray, thanks for all your work, our clients were having daily issue\nconcurrent chunks was on, the bigger the files the more often the issue\nhappen, i can reproduce it most of the time with file larger than 15G but\nonce in awhile the file goes thru. we'll be happy to help you with the\ntests.\nOn Fri, Feb 5, 2016 at 3:47 AM, Ray Nicholus notifications@github.com\nwrote:\n\nThis is looking to be caused by a very unusual race condition. I'm not\nentirely certain about the chain of events, and reproducing looks to be\ndifficult. I have not had any luck yet. The concurrent chunking feature is\ncomplex, as is the code. I'm hesitant to make any changes to the logic in\nthis code unless I am 100% certain of the outcome and am certain that the\nchange needs to be made. I also thought about simply checking the internal\narray that maintains the part numbers yet to be uploaded for a match before\nadding a new part number, but this check would occur often, and for very\nlarge files, this array could be quite large and examining it for a\nduplicate could be costly. Unless someone has some thoughts or insight\nregarding reliable reproduction, I may just opt for an easy \"fix\" that\ninvolves removing a duplicate entry in the \"complete multipart\" manifest.\nI really don't think this has any relation to the size of the file (6GB vs\n500 MB), but I can see how the issue would be frustrating when a very large\nfile fails to upload at the last step and is not retryable. Just out of\ncuriosity, how often are your customers seeing this issue?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1519#issuecomment-180254455\n.\n. Absolutely, it will be our pleasure to help you on this,\n\nLe vendredi 5 f\u00e9vrier 2016, Ray Nicholus notifications@github.com a \u00e9crit\n:\n\nIf this truly does take that large of a file to reproduce, then I will\nhave difficulty reproducing myself due to limited bandwidth at my current\nlocation. I'm still not convinced that file size is really a factor. A\nrequest error is required to reproduce, and this is more likely to occur\nwith much larger files somewhere along the way. That is probably why you\nare seeing this with larger files. Did you say you are able to reproduce\nyourself very easily? If so I'd like to be able to send you updates for\ntesting/verification in order to get to the bottom of this as quickly as\npossible. Will that work for you?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1519#issuecomment-180666305\n.\n. Hi @rnicholus  , did you received my email?\n. \n",
    "dofinium": "\nProbably some problem with my connection. It works through translate.google.com. Thank you.\n. ",
    "bebraw": "@ericmackrodt Did you have any luck with this?\n. ",
    "keyeh": "I was the person on Stack Overflow, wasn't sure if you saw it so I posted here.\n. If this is implemented it's also a good idea to show a \"Resizing...\" status text to the user as creating many different sizes of very large images can take 30+ seconds. The status text should be visible on both the scaled and the original to account for the hideScaled and sendOriginal options.\nPerhaps adding onResize and onResizeComplete callbacks would be more appropriate\n. @classofoutcasts Yeah, Pica is way faster. Do you have some good unsharp settings? I'm using this:\nelse {\n            var tmpCanvas = document.createElement(\"canvas\");\n            tmpCanvas.width = iw;\n            tmpCanvas.height = ih;\n            var tmpCtx = tmpCanvas.getContext(\"2d\");\n            tmpCtx.drawImage(img, 0, 0);\n            window.pica.resizeCanvas(tmpCanvas, canvas, {\n                quality: 3,\n                alpha: false,\n                unsharpAmount: 30,\n                unsharpRadius: 0.6,\n                unsharpThreshold: 0,\n                transferable: true\n                },\n                function () {\n                    tmpCanvas = tmpCtx = null;\n                    canvas.qqImageRendered && canvas.qqImageRendered();\n            });\n        }\n. Modules are definitely a better solution. In addition to the scaling I have a lot of very ugly hacks to customize Fine uploader for my needs (particularly S3 uploads and scaling).\nHowever if modern-uploader is still far away it may be reasonable to put a note in the Fine uploader documentation about scaling quality & alternative scaling libraries.\n. In addition to the scaling library:\n- Send image dimensions in header to S3 metadata/create endpoint\n- Events/Callbacks for scaling images for UI\n- Send Base64 encoded scaled image\n- Edge case where scaled images sometimes hit create endpoint after the parent if the parent filesize is very small. (not really an issue, accounting for it on server side)\nWish list\n- Scale images when added to upload queue, not when the upload starts.\n- Different jpg quality per scaled image (smaller images handle more compression before degrading)\nMy platform is for content creators so they all have powerful computers. We get to save some costs by scaling on their machines.\n. Scaling all the images at the same was just a thought to compensate for limby-resize being slow. Sometimes a file would finish uploading before the next is done scaling. When you're scaling and uploading hundreds of 20 megapixel images the delay adds up. But it's not an issue with unmodified fine uploader.\nWe embed base64 images in HTML to use as a placeholder while the actual, larger image loads.\n- Embed a small 20px image in HTML\n- Stretch the image to the actual image's dimensions\n- Apply Gaussian blur\n- Wait for the actual image to finish loading (standard or 2x retina)\n- Fade out blurred image to actual image\nIt's similar to Facebook's cover page loads. It gives a nice effect while images load. (If you haven't guessed already I'm working on an extremely photo-heavy platform)\n. Sorry if I was unclear, the base64 images are not used for fine uploader; I'm not using the thumbnails feature at all. They are for public pages like photographer's portfolios, photo albums, etc.\nAs for the code for that I'm basically (trying) to call scaleImage() in onComplete(), converting the returned blob to b64 and POSTing it to another endpoint. \nI'll get back to you with the full code in a bit\n. My solution to this was to move the image in the create endpoint.\n. Great work. I'm ready to test if needed. I'm not targeting iOS, only desktop browsers though.\n. ",
    "classofoutcasts": "Pica seems to be a considerably faster implementation than limby for high quality down scaling.\nAny progress on hq scaling?\nhttp://nodeca.github.io/pica/demo/\n. Appreciate your efforts, no other file uploader has this yet, afaik!\nHopefully it will become part of the future html5 canvas features...\n. ",
    "davidtgq": "Would it be possible to use this mechanism (of delegating image processing to an external library) to not scale the photo, but to (for example) optimize it? A usage of this may be using a jpeg encoding library to optimize the rescaled and thumbnailed images outputted by pica or limby. In other words, run multiple external processing libraries in series, where the first library's output is the input for the second library, and so on.\n(Admittedly this is something that can be done manually with the getFile and addFiles method, which may be a more suitable solution for such rare usage cases)\n. ",
    "deviprsd": "That is the best way so far, of course, I found it really odd in my design to have the popup with a message not desired. It was irritating. So, I had a quick workaround \njavascript\n$(\"#fine-uploader\").fineUploader({\n    uploaderType: 'basic',\n    // other options\n}).on('complete', function(e, id, name, response){\n    $(e.currentTarget).find('input[name=\"qqfile\"]').attr('title', '');\n}).find('input[name=\"qqfile\"]').attr('title', '');\nLike you said each time it was created and removed, so after each request completion I had to reset it again. And right after it returns the $(\"#fine-uploader\") jQuery object after initialization.\n. Yup, anyway it has been added to the milestone for 5.6.0, all we have to do is wait.\n. Oh well, great :+1: \n. @alphestdev that should be the normal behavior. You can set it as nothing and it won't appear I guess. Will try now. Have you updated the jQuery version also?\n. Works like charm :heart_eyes: \n. ",
    "bradleyayers": "@KevinGrandon why did you close this PR? Did you hit a blocker for this issue?. Thanks @KevinGrandon for the quick reply! I've raised https://github.com/FineUploader/fine-uploader/pull/1983 as a bit of an experiment to gauge project health. (I'm currently evaluating whether to use FineUploader). Is there anything holding this back?. I'm happy to take a stab at this one, I'll raise a PR and see what you think.. Sounds good. I'd suggest creating a 5.x branch off master for bug-fixes, and use master for 6.0. That may have less development overhead involved than maintaining a 6.0 branch and merging master, but it's not something I feel strongly about. I'll go with the release/6.0.0 branch for now.. It's indeed quite challenging, I suspect we'll probably to do it in a piece-meal fashion, rather than one large PR as I suspect there will be too many changes to comfortably review. But initially I'm just going to make all the changes at once to get a rough sense of the different patterns that need changing.. I've done some investigation and I think a viable path forward may be as follows:\n\n\nAdd a requirement on native Promise being available:\n\nthrow an error during load if typeof Promise === \"undefined\"\nUpdate docs and public API surface area to use native promises (i.e. only return and accept native promises, not qq.Promise, not Q.js)\n\nRefactor internal code case-by-case (separate PR each) to switch from qq.Promise to native Promise.\n\n\nDecide on whether all reject() calls use Error (and if specialised Error should be used, e.g. with .xhr property)\n\nDecide on new shape for single-value resolve() values.\nRepeat \u2934 until no remaining usage of qq.Promise\nFor any tests that check qq.Promise and Q.js, refactor to only test native Promise.\nDelete qq.Promise\n\n\n\nThis should be achievable in a piece-meal fashion, i.e. not one large pull request. Thoughts?. Have you looked into upstreaming this change into FineUploader?. Thanks for the quick reply! What do you recommend as a path forward here? Will master be used for the 6.0 major release, or is there a different branch strategy? Presumably also I should use a feat: + BREAKING CHANGE commit message if IE7 is still supported. I saw the 5.16.0 release and it looks like a lot of really nice improvements! Congratulations on getting that out!. I've updated the base branch to release/6.0.0, are you happy to merge this to there?. Sure sounds good, what\u2019s the best way to contact you?. @SinghSukhdeep are there any tools to automate generation of fine-uploader.d.ts?. @SinghSukhdeep I've pushed up a couple of commits attempting to add lib/all and lib/core/all. To be honest I'm not exactly sure what exists in those distributions, so if you can double check I got it right that would be great. It's times like these I hope having an ES module distribution would remove the need for these separate distributions. I'd really like to have the whole code base migrated to TS to make these things easier.. @SinghSukhdeep let me know if you're aware of any other issues, else I think this is good to go.. @rnicholus this should be good to go.. Fair call, this might be better suited for release/6.0.0?. The file extension references are only for the bundler configurations, which I don't have direct experience with (e.g. rollup). Nothing will change with respect to standard JavaScript imports.. > So, does this there are no breaking changes then?\n\"Breaking change\" is a subjective term, so I think this boils down to being a judgment call. I'm happy to call this not a breaking change, even though if people are relying on exact file locations for custom build configurations they'll need to make some changes when upgrading. If you'd rather err on the side of calling that a breaking change, then I can target this to release/6.0.0. \nWithout an unambiguous definition for breaking change this decision just needs to be a judgement call made by a maintainer.. @SinghSukhdeep does pkg.main support having the file extension omitted?. Reverting the documentation changes would also require reverting the code changes that move lib/traditional.js to lib/traditional/index.js, else the docs won't match up with the file structure.. > To ensure we don't break backwards compatibility, can't we just keep the traditional.js, s3.js, etc files?\nYeah I considered that, but I wasn't sure if the module resolution spec includes whether to try directory or file first when resolving. It seemed like a risky approach that could be broken in the future. It's probably worth checking though.. I'm assuming that for package.json to have effect the directory index needs to be used by TypeScript. I'll have a play with this and report back.. I've tested this and leaving the .js files in-place, and adding package.json in subdirectories seems to work. I'll update the PR to use this approach to minimise the changes.. @SinghSukhdeep I'm not actively working on it, but I am still using my FineUploader fork in production (it includes this change + using native promises), so I'm still invested in seeing this succeed.. > Isn't there an extra | at the beginning or I'm not reading it right\nTypeScript has supported leading | for a while, see https://github.com/Microsoft/TypeScript/issues/12071. It was purely a stylistic choice from me to try and visually separate the two items of the union.\nI'm going to wait for #1989 before raising a PR for this.\n\nAnd I'm seeing some issues here\n\nThanks I was missing some parenthesis around the function, I've updated the snippet.. I had the same thought, but actually this is required to be explicitly merged as TypeScript does not allow implicit merging of incompatible types via multiple inheritance (xxx extends Foo, Bar).. Ah I understand now! I've updated to be just UIRetryOptions \u2014 thanks. I didn't intend to make any changes to the way people import modules. They should still be able to import fine-uploader/lib/traditional. My understanding was that lib/traditional.js and lib/traditional/index.js can both be imported via lib/traditional.. Oh I see, I hadn't noticed those before. Yes I'll update those in this pull request. Good catch!. Ah interesting. So do you think azure and s3 should be exported from fine-uploader?. Makes sense, and do you think azure and s3 should also be exported from fine-uploader? I thought they were accessible via qq.s3.* etc. And is FineUploaderBasic not exported from fine-uploader?. Okay, I've removed the FineUploaderBasic export from the non-core lib modules, and switched to export * as suggested.. ",
    "KevinGrandon": "I can\u2019t remember, maybe it auto-closed since I deleted that branch. Feel free to take this if it\u2019s still relevant.. ",
    "clemorphy": "Thank you very much !\nThat's perfect !\nI also needed to remove camera: {  ios: true  }, because with this setting, if one extraButton was filled, the two others were disappearing.\n. ",
    "fundup": "OK thanks for that. I will post my solution when I will finish.\n. Here is an example of solution using Php and Aws/sdk, after having upload thumb : \nphp5\npublic function moveToAnotherBucket($objectKey) {\n        $s3Client = $this->getS3Client();\n        /** @var Aws\\Result $copy */\n        $copy = $s3Client->copyObject([\n            'Bucket' => self::thumb_bucket, //target\n            'Key' => self::thumb_prefix.\"{$objectKey}\", //new key\n            'CopySource' => \"{$this->expectedBucketName}/{$objectKey}\", //source :bucket/key\n        ]);\n        $this->deleteFileInBucketAfterCopy($s3Client, $copy, $objectKey);\n    }\ndeleteFileInBucketAfterCopy use $s3Client->deleteObject() function.\n. Posted code is wrong due to I deleted a comment and ' image: { '  line at the same time :( . So my option is structure properly I think.\nvalidation: {\n                    allowedExtensions: ['jpeg', 'jpg', 'png'],\n                    acceptFiles: \"image/gif, image/jpeg, image/png\",\n                    sizeLimit: 20000000, // 20MB : Attention limit must match with php\n                    image: {\n                        minHeight: 1000, //1000px\n                        minWidth: 1000\n                    },\n                    stopOnFirstInvalidFile: false\n                },\nI will try to find a solution and I'll post it.\n. Hy,\nI had same problem when photos were comming from a camera. I think the problem is comming from fineuploader and not Pica. Indeed for portrait when sourceHeight > sourceWidht I had targetHeight < targetWidth. So I did a quick fix before resizing with Pica.\nvar sourceWidth = resizeInfo.sourceCanvas.width;\n    var sourceHeight = resizeInfo.sourceCanvas.height;\n    //before resize target sizes\n    var targetWidth = resizeInfo.targetCanvas.width;\n    var targetHeight = resizeInfo.targetCanvas.height;\n    //switch if error\n    if(sourceHeight > sourceWidth &&  targetWidth > targetHeight) {\n        resizeInfo.targetCanvas.height = targetWidth;\n        resizeInfo.targetCanvas.width = targetHeight;\n    }\nHope it helps\n. ",
    "AzureCloudDev": "Hi there, no I cannot. Because the user can upload images, then delete images, then upload more images, all in a single session. itemLimit wouldn't work because if a user uploaded 8 images, then deleted, 6, they can upload 6 more again, as long as there are 8 images visible on the page. itemLimit would not allow that.\n. Good point! I am already doing that. If there are already 8 images uploaded then onSubmit() prevents that by returning false. However, if there are less than 8, then onSubmit doesn't catch it. In my case onComplete() awaits for server response because there is some processing that needs to be done on the image like adding it to database and scheduling it for processing, so onSubmit() fires and fails validation check before onComplete() returns, causing another upload when there has already been 8 images uploaded (just onComplete() hasn't returned yet.) so that's why I have to do this in both places. What's interesting about the error is that it only happens sometimes..seems like some internal states get out of sync or something.\n. Well the issue is basically the error that's happening. It doesn't break the functionality of the FineUploader...but I am not left with a comfortable feeling of seeing javascript errors on the page. It might be a bug...thought I'd let you know..\nOk things might have been a little confusing the way I explained it, so let me try to re-explain it.\nHere's how the page works: User can upload the image at which point it is shown on the page with a \"Delete\" button below it. So the user can upload and delete images after they have been uploaded. The requirement is to have no more than 8 images on the screen. So a user can upload 2 images, then delete them, then upload 8 images and not delete any and save everything. At this point the user would have uploaded 10 images in a current session. itemLimit would not allow for that. The reason why a user can upload and then delete images, is just for convenience purposes, just in case a user uploaded image(s) they didn't like or don't quite fit with the rest of the images, they could simply delete these image(s) and re-upload new ones, and then after everything looks good save everything on the page. Is this a little more clear now?\n. In my case the user uploads the images first, so the itemLimit is increased everytime an upload happens. Only after the image is uploaded, it is shown along with its correspinding \"Delete\" button. Now a user can delete the image, but deleting the image does not subtract from itemLimit, because that's internal to FineUploader. So if I upload 8 images from the start, itemLimit will be at 8, now the user deletes the images, the itemLimit is still 8. Because the user has just deleted 8 images they can upload 8 images again (requirement is to have 8 images displayed on page), but the itemLimit is already 8, effectively blocking them from doing any more uploads.\n. Well that's caveat, I am not using Fine Uploader's delete feature.\n. I was a little more concerned about the error that sometimes occurs, and as far as I can tell I don't think I am doing anything \"illegal\" in the code. I am just afraid that this error could somehow break the rest of JS on the page and that would be real bad..\n. Well, I guess I just don't, the Delete that I am using is just a html button on the page that triggers some server side functionality. It also has html logic as removing the table cell with image.\nI can take a look at Fine Uploader's delete, if that's the only way of doing it.\n. Ray, let me ask you this, just before you close this, with the itemLimit, what will happen if a user comes to a page from a fresh page load and has already 7 images uploaded. Now he selects 8 images (when he's only really allowed to upload 1) and tries to upload. I don't think itemLimit would catch it (because it's going to think that this is a new session that allows up to 8 images to upload, but it is not)and the images would start uploading way past the total of 8 allowed, this is the scenario that I am trying to prevent.\n. I could do that, but even then, the user can delete 4 images, and have allowance to upload 4 more, so I would have to adjust the itemLimit yet again?\n. yeah, but this would require a tighter coupling with Fine Uploader's functionality that I don't want to and don't really need to do. I just wish cancelAll() worked as expected without throwing intermittent errors. This discussion sounds like inability or inflexibility of support to investigate the issue at hand by simply providing other ways to solve the problem in arguably more complex ways.\n. I will try to investigate the suggestion you have provided. But let me tell you, from a customer's perspective, the level of courtesy that I have received in regards to this issue, is unsatisfactory. Support hasn't even attempted to reproduce the issue, but simply stated that \"they have not had any issue with the api call\", that's not how support should resolve possible bug issues reported by customers. Besides it almost makes a customer feel like a liar. \nHere's how I hear it coming from support \"We are not going to take a look at this even if this is a bug, try some other functionality that seems to work in most cases, oh and by the way you should have posted this on stackoverflow\" Is this a normal workflow for investigating errors originating from documented api functions calls?\nI think the approach I am describing here is the most simplistic of all, it requires no tight integration with Fine Uploader and requires no additional server calls to pull any data from the server. Doing it the suggested way almost feels like you have to use certain workflows to avoid running into other unfixed or new errors, which almost makes the customer wonder about the quality of the product.\n. ",
    "himanshuvora": "Hello,\nGood Day!\nFile upload is working fine with Chrome with all size of files.\nUpload fails only with IE11 and file size larger than 5 MB. \nConsole Log\n[FineUploader] Processing 1 files or inputs...\n[FineUploader] Sending upload request for 0\n[FineUploader] xhr - server response received for 0\n[FineUploader] responseText = \n[FineUploader] Error when attempting to parse xhr response text (SyntaxError: Syntax error)\nResponse Alert (XHR returned response code 500)\nI could not understand what's going wrong, please help me.\nThanks,\n. Thanks for your quick response, please do me a favor. If you can give me list of possible reasons for failed server response.\nThanks,\n. ",
    "Tailzip": "Hi,\nI'm trying to validate a file before upload, I followed the documentation, so I'm returning a promise in my onSubmit callback but my file isn't being uploaded (I'm using S3 wrapper) when the promise is fullfilled. Here a simple code, that I believe should work, but it doesn't...\n```js\nconst onSubmit = (id, name) => {\n  const p = new qq.Promise();\nsetTimeout(() => {\n    p.success();\n  }, 2000);\nreturn p;\n};\n```\nAny thoughts?\nThanks!. ",
    "madjarian": "REQUEST:\nRequest URL:http://open-demo.groupetransatlantic.com/app_groupe_prod.php/fr_FR/fineuploader/endpoint\nRequest Method:POST\nStatus Code:200 OK200 OK\nRequest Headersview source\nAccept:application/json\nCache-Control:no-cache\nContent-Type:multipart/form-data; boundary=----WebKitFormBoundaryOruK3bKL4xPyEvBA\nOrigin:file://\nUser-Agent:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.110 Safari/537.36\nX-Requested-With:XMLHttpRequest, XMLHttpRequest\nRequest Payload\n------WebKitFormBoundaryOruK3bKL4xPyEvBA\nContent-Disposition: form-data; name=\"qquuid\"\n69b91e78-fe45-4519-af52-4be134568fe0\n------WebKitFormBoundaryOruK3bKL4xPyEvBA\nContent-Disposition: form-data; name=\"qqfilename\"\nADAM_AA0437.mov\n------WebKitFormBoundaryOruK3bKL4xPyEvBA\nContent-Disposition: form-data; name=\"qqtotalfilesize\"\n52589829\n------WebKitFormBoundaryOruK3bKL4xPyEvBA\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"ADAM_AA0437.mov\"\nContent-Type: application/octet-stream\n------WebKitFormBoundaryOruK3bKL4xPyEvBA--\nResponse Headersview source\nCache-Control:no-cache\nConnection:Keep-Alive\nContent-Encoding:gzip\nContent-Length:65\nContent-Type:text/plain; charset=UTF-8\nDate:Mon, 07 Mar 2016 17:18:03 GMT\nKeep-Alive:timeout=5, max=100\nServer:Apache/2.4.6 (CentOS) OpenSSL/1.0.1e-fips PHP/5.5.30\nVary:Accept-Encoding\nX-Powered-By:PHP/5.5.30\nRESPONSE:\n{\"error\":\"File name empty.\",\"uploadName\":null} <- we checked the $_REQUEST['qqfilename'] or ($_FILES[$this->inputName]\n. I always got true on qq.supportedFeatures.chunking and qq.supportedFeatures.uploading\n. ok thx you\n. ",
    "uyson": "@rnicholus   chunk upload send wrong content-type, \nContent-Disposition: form-data; name=\"qqfile\"; filename=\"ADAM_AA0437.mov\"\nContent-Type: application/octet-stream\nwhy the component send wrong content-type,. @rnicholus  thanks, I got it. . ",
    "bengal75": "Apologies, it seems that this is due to my including CSS from Zurb Foundation 5, which by default sets the visibility property on the dialog element to 'hidden'. Fine Uploader evidently doesn't expect this, and does not change the element's visibility.\nChanging the string in getDialog() appears to force Chrome to use native dialogs instead, which are obviously visible. This seems related to why the whole thing is a non-issue in Firefox, where the HTML5 dialog element gets used in both cases.\nThanks for the prompt response in any case!\n. ",
    "jfwblog": "The Travis CI build failure is due to the whitespace issues I mentioned I believed were false positives.  If the --force parameter is used to ignore the whitespace issues then the rest of the tests succeed.\n. The whitespace issues have been resolved.  \nI can't guarantee that I will have the time to add any new unit tests, I would need to spend considerable time figuring out how to write these tests within the context of the existing test framework.  You or someone else can probably do this more quickly and easily, in more consistent style too.\n. I made a few more commits that address certain issues and add some additional capabilities.\nI added a fourth parameter to the onSigningRequestComplete callback which is to be used as a return parameter.  An empty credentials object is passed to the callback which temporary credentials can be assigned to in order to change the credentials used by fineuploader for the current request in progress.  This differs from setting the credentials globally to fineuploader via the setCredentials call in that concurrent uploads may all use distinct credentials without risking changing any of the credentials used by any other request (race condition).\nIn the process of testing this it was also discovered that to support multipart uploads the generateHeaders function would need to be updated to accept an additional parameter, credentials which influences what credentials are used for the request to Amazon.  This parameter is optional and if omitted then the function will use the credentialsProvider like usual.  Also, in the event that sessionToken is changed by the callback, generateHeaders also required the addition of a x-amz-security-token header in order to be accepted by Amazon.  (These details are internal and not necessary to be known by a developer implementing onSigningRequestComplete callbacks that change credentials.)\n. > Why not just check the return value from the callback handler?\nThat would be simple, but I already have the return value being used to return the singing request response.  The response gets fed further down the pipeline into code executed later so I figured it may be useful for the callback to give the user an opportunity to modify the response, in case it has fields which need to be stripped, or transformed, etc. .  So to preserve that functionality I thought passing the optional temporary credentials as an output parameter would be the cleanest way to move forward.  I figured it would be more useful more often to return a modified response than it would be to return credentials.\n. Sorry for the late response:\nEssentially, the features requested in #1406 are satisfied with this pull request.  As you have noted, it is not a good idea to use setCredentials, my pull request does not call setCredentials.  (The confusion is, my pull request accounts for the case where a user does call setCredentials from within the callback.  If a user does do this the new credentials should still be used.  If the user instead returns new credentials without calling setCredentials, then the current request will use the returned credentials without calling setCredentials.  The returned credentials will not persist beyond the current request.)\nThe scenario described by #1406 is essentially the same scenario which prompted this development.  We were in need of an S3 uploader which uses a different credential for each request.  We wanted the signing server to return new credentials each time it was queried.\nThe fourth return param for temporary credentials can be eliminated in the way you describe, by incorporating it as a new field on the return object.  That would work, I only went this route because I wanted to avoid conflicts/collisions with the signing request response object.  What if the signing request response object has a field called credentials but there is no signing request callback configured?  It should be up to the callback to dictate whether new credentials should be used, the signing server should work with the callback to make the proper arrangements to prevent false positives or other potential issues within fineuploader.\n. this and other areas have been updated to reflect making the code less dense, easier to follow.\nthis part here with the isError detection was a little convoluted, my apologies.  content of errorMessage was not being used to determine error state, rather it was !response which if true would ensure that errorMessage gets assigned properly (and after being cast to boolean errorMessage === !response === true).\nBut I have made this more clear and better now, nevermind what it was before.\n. I have changed this so now Object.assign is used if it is available, if not then object cloning is performed manually with hardcoded fields.\nI figured it is good to use Object.assign if available because in the future if the credentials object gets more fields added then Object.assign will pick them up as opposed to manually copying the object which will require us to add the additional fields in the copying code as well.\n. This was the ideal solution I was hoping existed, but in my cursory glance at the qq util functions I must not have seen this one.  Will update this later.\n. ",
    "iliaznk": "I modified the last line of v4.getCanonicalUri method as return (\"/\" + path) and it seems to be working fine.\n. My page has a <meta charset=\"utf-8\"> tag and I don't think it has something to do with the server side since this is the data generated by Fine Uploader and sent to the server for signature.\nWell, anyway, I got it working for me.\n. But it is data coming from Fine Uploader, how can it be server side? As I mentioned, I changed the return value of v4.getCanonicalUri from return escape(\"/\" + decodeURIComponent(path)); to return (\"/\" + path); to get it working. I also will try to upgrade to the latest version and see if it works there without any modifications.\nThanks for you help! \n. So, I've upgraded and everything is the same, and why wouldn't it when the v4.getCanonicalUri method is the same. Just to make it clear, for example, if I have a file named \u0444.jpg, Fine Uploader encodes it in the canonical request as /%u0444.jpg, does it look like a normal encoding to you? Those percent signs together with u? But everything works fine if I change encoding to %D1%84.jpg.\nOn my server side I just use standard Python 2.7 library to generate the signature.\nBy the way, in the canonical request I receive from Fine Uploader there's another line with an encoded filename x-amz-meta-qqfilename:%D1%84.jpg and as you see here the filename is encoded differently and correctly.\nI guess, there's only one way we can check what the problem is: if you could check the canonical request you get from Fine Uploader in your environment and if a unicode filename is also different in those two lines of the canonical request but it's working fine, then.... what does it mean then? :)\n. I see. Well, at least I made it work and AWS is happy with my signature. Thanks again!\n. Yes, it did. I don't personally see it as a major problem. I'll just modify it again, when I have to. I've made some small modifications to the Fine Uploader code to suite my needs before that anyway.\nBy the way, this is what Wikipedia says:\n\nThere exists a non-standard encoding for Unicode characters: %uxxxx, where xxxx is a UTF-16 code unit represented as four hexadecimal digits. This behavior is not specified by any RFC and has been rejected by the W3C. The third edition of ECMA-262 still includes an escape function that uses this syntax, along with encodeURI and encodeURIComponent functions, which apply UTF-8 encoding to a string, then percent-escape the resulting bytes.\n. Sounds great, thanks!\n. \n",
    "sohkai": "They've added more docs here.\nIt sounds like they're just leveraging Cloudfront with the accelerated endpoint, but from what I can tell in https://github.com/FineUploader/fine-uploader/issues/1016, Amazon's fixed the issues with Cloudfront that prevented FineUploader from working with it before?\n. Totally forgot about this thread, but we've been using this feature for 3 months (it's already been that long?!) without fail.\n. @rnicholus Nope, we did exactly what @DaveDeCaprio did a few months ago and it seems to be holding up. Just a change to the endpoint for FineUploader.\n. I've updated with the suggestions above, will squash after everything checks out.\n. Wasn't sure how to link to the previous heading with jmd syntax so I linked it to the AWS page for now. If possible, I think it'd be nicer if this link pointed to the section above.\n. Didn't check if When uploading to S3 via a CDN, you must specify the name of the bucket applies to the accelerated endpoint since it's using a different subdomain. Maybe @rnicholus you could quickly double check how this logic is applied right now and if it'll work for the s3-accelerate.amazonaws.com subdomain?\n. We specify the objectProperties.bucket out of habit, but can confirm that it still works when not specified. I'll add a bit here to clarify that you also don't need to specify the bucket if using Accelerate.\n. The Uploading to S3 With Transfer Acceleration section, but this point will be moot with the changes below.\n. ",
    "DaveDeCaprio": "I have been successfully using S3 Transfer Acceleration for a couple days with Fine Uploader and so far it's been working as advertised.  However, I don't think I've actually seen a transfer that has really leveraged the edge network yet (so far all uploads have been originating in the US and going to US-East).  I should have European and Australian uploads coming in this week though.\n. I can't easily share a full example, but I can say all I had to do was hit the \"enable S3 Transfer Acceleration\" option in the AWS Console and then set my endpoint to the s3-accelerate one.  The only code change was setting the endpoint below:\nrequest:\n    accessKey: \"XXXXXXXXX\"\n    endpoint: \"https://my-bucket-name.s3-accelerate.amazonaws.com\"\n. Hi Ray, now that I can see the error, I posted this StackOverflow question on how to resolve: http://stackoverflow.com/questions/36868969/how-to-work-around-requesttimetooskewed-in-fine-uploader\nAny help you could supply would be appreciated.  If you just give some basics I can update the answer with more detail.\nDave\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Monday, April 25, 2016 5:34 PM\nTo: FineUploader/fine-uploader fine-uploader@noreply.github.com\nCc: David DeCaprio daved@alum.mit.edu; Author author@noreply.github.com\nSubject: Re: [FineUploader/fine-uploader] Pass xhr object through error handlers (#1559)\nNice catch and thanks for the PR! I'll look at this a bit closer tomorrow, and if everything checks out, I'll release Fine Uploader 5.7.1 with the fix.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub https://github.com/FineUploader/fine-uploader/pull/1559#issuecomment-214551301   https://github.com/notifications/beacon/AAzVuvQNd0FygZSQdFNeQLkVMzv1n_P6ks5p7UFPgaJpZM4IPbP3.gif \n. Yes, it's not directly related to the Pull Request.\nDave\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Tuesday, April 26, 2016 10:26 AM\nTo: FineUploader/fine-uploader fine-uploader@noreply.github.com\nCc: David DeCaprio daved@alum.mit.edu; Author author@noreply.github.com\nSubject: Re: [FineUploader/fine-uploader] Pass xhr object through error handlers (#1559)\nThis seems unrelated to your pull request, am I correct?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub https://github.com/FineUploader/fine-uploader/pull/1559#issuecomment-214782288   https://github.com/notifications/beacon/AAzVulesKXfDxaHeWTWFdCbgNCLmuDM1ks5p7i59gaJpZM4IPbP3.gif \n. That worked perfectly. Thanks.\nDave\nFrom: Ray Nicholus [mailto:notifications@github.com] \nSent: Tuesday, April 26, 2016 10:29 AM\nTo: FineUploader/fine-uploader fine-uploader@noreply.github.com\nCc: David DeCaprio daved@alum.mit.edu; Author author@noreply.github.com\nSubject: Re: [FineUploader/fine-uploader] Pass xhr object through error handlers (#1559)\nThat specific issue can be solved with Fine Uploader's clockDrift feature, introduced in 5.5 https://blog.fineuploader.com/2016/01/19/fine-uploader-5-5-heavily-requested-s3-updates/ . I'll post more details as an answer to your question on SO shortly.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub https://github.com/FineUploader/fine-uploader/pull/1559#issuecomment-214783239   https://github.com/notifications/beacon/AAzVuv9w9iBCjK8E3TXnQerR4ZYoukwcks5p7i8sgaJpZM4IPbP3.gif \n. ",
    "bradwestness": "Cool! I am now at a private company that operates out of Beloit, but I was at UW-Madison until November of last year. :) (Just realized that I had not updated my GitHub profile to reflect that).\nWe were definitely not having this issue until a few weeks ago either, and nothing has changed with our implementation, so my thought is it might only occur on the most recent version(s) of Chrome/Firefox. It also doesn't occur on Internet Explorer or Edge. My first instinct was to verify that the JSON we were returning was valid, but every response from our incremental file handler is identical to the one in the screenshot above, so I don't know why it would occur only on the .finalizeChunks call (and there's no \"status\" parameter in the response JSON to begin with). \n. Some contact info to receive a link would be good. I'll have to talk to my team in the morning about getting some credentials for you since all of our usages are behind authentication.\n. Here's a sample ASP.NET project that should enable you to re-create the issue: https://onedrive.live.com/redir?resid=33C6ADC7636F5E0A!1039811&authkey=!AD_cqZ4FGdYBWOs&ithint=file%2czip\n. Alright, here's a PHP version! :)\nfineuploader-test.zip\n. The upload does complete successfully, but I still get the error in my console when using that sample PHP app on a completely fresh XAMPP install with nothing except bootstrap and jQuery on the page, and the \"xhr\" parameter is undefined in the onComplete callback method. \nConsidering the handler is literally just returning success: true and doing no processing, and there's no other scripts running on that page, I don't know what other variables would be due to my environment, it seems pretty clear to me that it's an issue with FineUploader.\nMaybe it only occurs on Windows? I haven't tried on other OS's.\n. I just had a co-worker try the sample app on his Mac (on Chrome) and it got the same error, so that also rules out it being a Windows-only issue.\n. ",
    "ssineriz": "I had exactly the same issue, and managed to fix it adding a check on the xhr variable passed in the finalizeChunk method (jquery.fine-uploader.js@3835)\njavascript\nfinalizeChunks: function(id, responseParser) {\n    var lastChunkIdx = handler._getTotalChunks(id) - 1, xhr = handler._getXhr(id, lastChunkIdx);\n    if (responseParser) {\n        if (xhr == null) xhr = handler._getXhrs(id)[0]; // <- Added this row\n        return new qq.Promise().success(responseParser(xhr), xhr);\n    }\n    return new qq.Promise().success({}, xhr);\n}\nI didn't go any further on the matter, but I guess that, for the last chunk, some still unfulfilled promise didn't populate the xhr when the finalize is called. All other previous chunks returned a non null xhr.. ",
    "GusBeare": "oh no!  what a numpty..  sorry to have wasted your time.\nHow many times have I stared at that code and not noticed?\nI need a holiday..\n. ",
    "CLAassistant": " All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA..  All committers have signed the CLA.\n.  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.\n.  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.\n.  All committers have signed the CLA..  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 2 committers have signed the CLA.:white_check_mark: rnicholus:x: greenkeeper[bot].  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 2 committers have signed the CLA.:white_check_mark: adrianchung:x: Adrian ChungAdrian Chung seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 2 committers have signed the CLA.:white_check_mark: rnicholus:x: greenkeeper[bot].  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.Alexandru Bucur seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it.. ",
    "pborreli": "Done\n. ",
    "lifo101": "It's not just an issue in IE10 though. I've been using Firefox for my development and it still serializes the arrays improperly.\nIs there a work-around to allow me to manually serialize the array when a file is POSTed? I've tried using onSubmitted with setParams() but that doesn't work since setParams() is limited too. Is there a way to hook into the AJAX request that I'm missing?\n. I modified my server logic when handling the uploads so I can support the array params in the POST request. This will do until a proper fix is in place in fineuploader. Thanks!\n. Essentially, yes. I created an onUpload event  handler to alter any array parameter so setParams will process it:\nonUpload: function(id, name) {\n    // work-around bug in fineuploader. It doesn't handle serializing arrays properly\n    var form = $('form[name=\"document\"]').serializeArray();\n    if (form.length) {\n        var params = {};\n        for (var i = 0; i < form.length; i++) {\n            var key = form[i].name, value = form[i].value;\n            // don't use negative index since IE doesn't support it\n            if (key.substr(key.length - 2, 2) == '[]') {\n                key = key.substr(0, key.length - 2);\n            }\n            if (typeof params[key] != 'undefined') {\n                if (params[key].push !== undefined) {\n                    params[key].push(value);\n                } else {\n                    params[key] = [params[key], value];\n                }\n            } else {\n                params[key] = value;\n            }\n        }\n        this.setParams(params, id);\n    }\n},\nThat causes fineuploader to POST the arrays as comma separated lists.\nThen on the server side, I intercept the parameters and simply split them on a comma before my form routines run (symfony framework).\nedit: just realized I had a glitch in my routine.\n. Not arrays? We're talking about form values being posted to a server. Technically, There's no such thing as a real 'array' in html forms, right?. The only way to fake it is to send the same input name multiple times and have the server side script combine them into an array. Which is the defacto way of how this works with any (most?) scripting languages on the web. PHP, happens to require any 'array' inputs to have the suffix \"[]\" so it knows to build an array when it sees the same form name more than once. \nFineuploader needs to not assume all form inputs have unique names.\n. I looked at the code briefly and figured it wouldn't be trivial. I don't know if I'd be able to do a proper PR for this, depending on how in-depth it is. If you can easily outline the changes, I might be able to take a look. But I can't promise anything.\nI appreciate your efforts. \n. ",
    "ducktype": "Run through this bug today,\nplease use the same formatfrom jQuery,\nthe order of the fields is important!\nBAD:\nargs = {\n   'phone[]': ['444-444-4444', '555-555-5555'],\n   address: '1313 Mockingbird Ln'\n}\nGOOD:\nargs = [\n   {name: 'phone[]', value: '444-444-4444'},\n   {name: 'phone[]', value: '555-555-5555'},\n   {name: 'address', value: '1313 Mockingbird Ln'}\n]\nfu.addFiles([file_input_el],$('form').serializeArray())\ni think should be simple to fix, in iframe mode simply cycle and add  hidden in the same orde with the same name and value, in FormData mode the api is already this way .append(name,value)\nwhat do you think?\nthx in advice. I know FineUploader does not depend on jQuery, i'm simply saying that, this format is the defacto standard, and permit to handle the order, that matter a lot.\nAll browser preserve the post orders from forever, and many applications depend on it including our own, java/asp.net people does not know that because their frameworks handle request data structures as hashes. \nBut is wrong because are losing information from the browser, for example think of a form with drag drop to reaorder things, because the dom input order is preserved in the request data you can avoid to keep hiddens with indexes and to handle this index update via js.\nThe majority PHP, ruby python and others framework for web use this features!!\nthx in advice. https://www.w3.org/TR/html401/interact/forms.html#h-17.13.4.1\nThe control names/values are listed in the order they appear in the document. The name is separated from the value by =' and name/value pairs are separated from each other by&'.\nThe parts are sent to the processing agent in the same order the corresponding controls appear in the document stream. Part boundaries should not occur in any of the data; how this is done lies outside the scope of this specification.\nHTML5 it's not explicit, but they often reference the \"tree order\"\nI assure you that in many years i've see no browser to not preserve the dom order in the request, \nwith any enctype,\nlynx included :)\n. Hi @rnicholus do you think this patch will be enough to support this use case and retain backward compatibility?\nqq.obj2Inputs() uses qq.obj2FormData() so the patch seems needed only here!\n```js\nqq.obj2FormData = function(obj, formData, arrayKeyName) {\n    if (!formData) {\n        formData = new FormData();\n    }\n    //support ordered formdata: https://github.com/FineUploader/fine-uploader/issues/1577 \n    if(qq.isArray(obj)) {\n      qq.each(obj, function(key, val) {\n        if(!qq.isObject(val))\n          return;\n        var pk = val.name;\n        var pv = val.value;\n        if(!qq.isString(pk) || !qq.isString(pv))\n          return;\n        if(!pk)\n          return;\n        if(arrayKeyName)\n          pk = arrayKeyName + \"[\" + pk + \"]\";\n        formData.append(pk,pv);\n      });\n    } else {\n      qq.each(obj, function(key, val) {\n          key = arrayKeyName ? arrayKeyName + \"[\" + key + \"]\" : key;\n          if (qq.isObject(val)) {\n              qq.obj2FormData(val, formData, key);\n          } else if (qq.isFunction(val)) {\n              formData.append(key, val());\n          } else {\n              formData.append(key, val);\n          }\n      });\n    }\n    return formData;\n};. ",
    "neotropic2023": "Sorry, I should have been more clear. Was rushing things. I downloaded from here on GitHub. I attempted to test it, but it kept failing as it was trying to load a file that did not exists.\nWill try that link.\n. ",
    "nsmaminebelhassine": "If fixed that by changing the getCanonicalUri method ( applicable only for v4 and chunked uploads if I understand the code ) : \nif added the bucket name before the file uri\nnow the request goes clean to the sign process\n```\n          getCanonicalUri: function(endOfUri) {\n                var path = endOfUri,\n                    queryParamIdx = endOfUri.indexOf(\"?\");\n            if (queryParamIdx > 0) {\n                path = endOfUri.substr(0, queryParamIdx);\n            }\n            return escape(\"/\"+ \"my-bucket-name\" +\"/\"+ decodeURIComponent(path));\n        },\n\n```\nNow i'm searching how to make it dynamically read the actual bucket name.\nBut the question is :  Is this coherent and correct ? As a workaround it works perfectly but i don't like to ship with changed code on 3rd party librairies.\nI encountred another similar problem with the host and corrected it with just providing the \"host\" in the objectProperties.\n. I removed the key function and changed it to the \"uuid\" value \nobjectProperties: {\n            key: \"uuid\",\n            region: $(\"#region\").val(),\n            host: \"s3-eu-central-1.amazonaws.com\"\n        },\nSame problem : \nFineuploader -> backend sign url : \n{\"headers\":\"AWS4-HMAC-SHA256\\n20160607T135713Z\\n20160607/eu-central-1/s3/aws4_request\\nPOST\\n/c4d88dd0-8102-4a53-b161-5b203f263d62.pdf\\nuploads....\"\nFineuploader -> AWS S3\nAWS Canonical Request  :  \n<CanonicalRequest>POST\n/my-bucket-name/c4d88dd0-8102-4a53-b161-5b203f263d62.pdf\nuploads=\n....\n</CanonicalRequest>\nSame if i change the key value to \"filename\"\nI had the same reasoning at the beginning but seems to be unrelated.\nAnd yes v4 signatures are not broken for everyone : i didn't found the same problem elsewhere.\n. ",
    "genestd": "I'm having this EXACT problem, and can't figure out where to look for the solution.  Is it possible for you to point me to code where the S3 object key to be uploaded is defined?  FineUploader is using a different value for the request to the signing endpoint vs. the POST request to the S3 endpoint - specifically it is adding the bucket name to the object key when POSTing to S3.. ",
    "chris-denning": "Hi,\nI'm hitting the same problem, and have done some debugging.  Hopefully this will point you in the right direction for a fix.\nThe problem seems to affect the \"bucket in path\" style endpoints, which are then only option when your bucket name contains dots, for example \nhttps://s3.eu-west-1.amazonaws.com/my.bucket.name\nIt doesn't appear to make a difference whether I use a custom \"key\" function.\nIn this case, for chunked uploads, the \"string to sign\" sent by Fine Uploader to my signing endpoint has the correct hostname (s3.eu-west-1.amazonaws.com), but the path is just the key, whereas the path in this case should include the bucket name, e.g.\nmy.bucket.name/key\ngetCanonicalRequest() in this case includes \"method\" followed by \"end of URL\" followed by \"querystring\".\nThe endOfUrl is constrcuted as follows:\nendOfUrl = requestInfo.key + \"?\" + endOfUrl;\nbut if \"end of URL\" is meant to be \"path\", this should start with the bucketname, only if the AWS endpoint style doesn't include the bucketname in the hostname.\nDoes this help?. I see this issue has been closed, but there are 2 other open issues tracking the same problem\nhttps://github.com/FineUploader/fine-uploader/issues/1914\nhttps://github.com/FineUploader/fine-uploader/issues/2010. ",
    "batmany13": "I ran into this problem as well, and its because we're using https://s3.eu-central-1.amazonaws.com/<frankfurt-bucket> and in the AWS response, it specifically expects that the \"path\" include the bucket ie /<frankfurt-bucket>/fine_temp/0256a7b2-bd9e-4b99-9093-9d7ece85efff.mp4 and the \"host\" should be s3.eu-central-1.amazonaws.com.  However, fineuploader sends something different in the \"headers\" params, with the path as /fine_temp/0256a7b2-bd9e-4b99-9093-9d7ece85efff.mp4 and host as s3.eu-central-1.amazonaws.com/<frankfurt-bucket>.  When we changed our signature logic to put the bucket in the path, and removed the bucket from host, it started working.\nFrom AWS\n```\nPOST\n//fine_temp/0256a7b2-bd9e-4b99-9093-9d7ece85efff.mp4\nuploads=\nhost:s3.eu-central-1.amazonaws.com\nx-amz-acl:private\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20180605T210731Z\nx-amz-meta-qqfilename:.mp4\nhost;x-amz-acl;x-amz-content-sha256;x-amz-date;x-amz-meta-qqfilename\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n```\nSent by fineuploader\n```\nPOST\n/fine_temp/0256a7b2-bd9e-4b99-9093-9d7ece85efff.mp4\nuploads=\nhost:s3.eu-central-1.amazonaws.com/\nx-amz-acl:private\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20180605T210731Z\nx-amz-meta-qqfilename:.mp4\nhost;x-amz-acl;x-amz-content-sha256;x-amz-date;x-amz-meta-qqfilename\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n```. ",
    "truthSeekr": "And what with that approach \n```\nPOST\n/fine_temp/0256a7b2-bd9e-4b99-9093-9d7ece85efff.mp4\nuploads=\nhost:frankfurt-bucket.s3.eu-central-1.amazonaws.com\nx-amz-acl:private\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20180605T210731Z\nx-amz-meta-qqfilename:.mp4\nhost;x-amz-acl;x-amz-content-sha256;x-amz-date;x-amz-meta-qqfilename\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n``\nShould it work with host like thatfrankfurt-bucket.s3.eu-central-1.amazonaws.com**????????**. @cretueusebiu Did you find any solutution since that time ?. I can't even make it to add this custom header. It just ain't adding and no error. I just added it with            customHeaders: {\n                'Access-Control-Allow-Origin': \"http://localhost:3000\",\n                'Access-Control-Allow-Credentials': \"true\",\n                'x-amz-decoded-content-length': \"10\"\n            }`\nI used chunked. @cretueusebiu is your notification set to notify your server when file uploaded or chunk uploaded ? . Ok I can see that AWS S3 doesn't charge for uploading transfer. So there is no need to check chunk size since I doesnt pay for it. Does it mean that if I set somehow this 'x-amz-decoded-content-length` and file will be larger, it won't save it ? therefore I won't be charged for storing file. You wrote before that this header doesn't work properly for you. Do you mean only that u can upload file with more size than specified and aws saves it ignorign this header ? or you can upload file that is larger and it doesn't save at finish of completing chunks. Thanks for reposting me.. Sorry, i just found it but my tries to fix end on dirty bucket name pasted\nin complete multiupload function. I tries coupe of variation but with no\nsuccess. Im not that experienced\npt., 29 cze 2018, 04:27 u\u017cytkownik Ray Nicholus notifications@github.com\nnapisa\u0142:\n\nIf you see an issue in the codebase, please open up a PR with your\nproposed fix. Thanks.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/2017#issuecomment-401228664,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJmP6ZDurTkvWgbeQVZrwWPN0Q_s9Kpuks5uBZCJgaJpZM4U0IZT\n.\n. \n",
    "fbg13": "I want to use the core mode, but i can't figure out how to display the image name and thumbnail after the images have been selected.\nMore precisely how to use the drawThumbnail method. Seeing an example would help me understand.\n. I deleted the template because my \"issue\" was no bug and no feature request, nor would it be allowed on stack overflow.\nI only suggested for a core mode demo to be added amongst the UI demos and gave you an example as to why i needed one.\nI'm sorry if it's something i should know if i want to use core mode, but i felt a core mode would be helpful.\nAnd sorry if this kind of request is not allowed here, but i don't know were else i could do it.\n. It was merely a suggestion, if you feel it's not worth, no problem.\nThe way I phrased it might have come as demanding, i'm sorry, i didn't mean to be rude.\n. onTotalProgress: function(tub, tb) {\n    console.log(tub);\n    console.log(tb);\n    var percentage =  Math.round((parseInt(tub) * 100)/parseInt(tb));\n    document.getElementById('upload-progress-'+i).innerHTML\n        = '<div class=\"progress-bar\" style=\"width:'+percentage+'%;\"><div id=\"progress-label-'+i+'\" class=\"progress-label\">'+percentage+'%</div></div>';\n}\n[Fine Uploader 5.10.0] Received 1 files.\n0\n273708\n0\n0\nhttp://i.imgur.com/bPNcmmQ.png\n. ",
    "gavboulton": "@Erazihel @rnicholus This feature looks like something I need. I'd like to pause an queued uploads when I receive a 500 response from one upload. I would then like to resume the queue when triggered by the user.\nDo you have any plans to further investigate the remaining problem? I could take a look if not. Do you know what the test would be so that I can make it pass?. ",
    "krraghavan": "I will submit a pull request for this in a few days.  The way I got this working for us is to:\n1. Create a chunkParamsStore and corresponding API method (set and get) on that store to set the parameters to set per chunk.  Since my use case was only targeting sending requests using Ajax requests I only changed the xhr method of uploading.\n2. Implement the onUploadChunk method in our application that sets these parameters in the store\n3. Added these additional parameters in the setParamsAndGetEntityToSend method from the chunkParamsStore\nOur server signature (Spring MVC) looks like this.  We post the \"chunk-info\" param with content-type = application/json.  ChunkInfoInput is a POJO that contains information about the chunk itself (again our goal is to create a REST API that works with any client - our UI client uses Fineuploader so we don't want to tie our server signature to any specific client). The Blob itself is sent in the \"chunk-data\" parameter (using the normal Fineuploader capability).\nSo this change will allow you to send arbitrary JSON (or any mime-type for that matter) with each chunk.\n@RequestMapping(method = RequestMethod.POST,\n                                path = \"/{oid}/chunk\",\n                                consumes = MediaType.MULTIPART_FORM_DATA_VALUE,\n                                produces = {MediaType.APPLICATION_JSON_UTF8_VALUE})\n    public ResponseEntity saveChunk(@PathVariable String oid,\n                                                          @RequestPart(\"chunk-info\") ChunkInfoInput chunkInfoInput,\n                                                          @RequestPart(\"chunk-data\") MultipartFile imageFile,\n                                                          UriComponentsBuilder uriComponentsBuilder)  {\n// upload handling code here\n}\nLet me know if you see problems with this approach or if something else needs to be done.  I can paste the diff or you can take a look at the diff on my fork (krraghavan/fine-uploader)\n. No it does not.  If the chunkParamsStore does not have any data for the chunk nothing happens.  Since the only way for this store to have something is through custom client code (via the onUpLoad method) nothing else should be impacted.\n. Sorry sent that last comment as a different user.  Please let me know if I should generate a PR.  I'm kind of hoping it can get into 5.10 so I can use the official version of fineuploader in our code.\n. Thanks for the response.  I respectfully disagree that this is an uncommon workflow - REST API signatures should not be dictated by client capabilities.  Unfortunately most JavaScript client implementations have chosen to go with a simple approach.  Google in fact defines the API in terms of multipart payloads that can take JSON but their client implementation does not.  Fineuploader was one library I thought had the right architecture to allow this capability without any complications (my PR is only changing 4 files and < 100 lines of code to provide this functionality which will allow server implementations to be decoupled from client implementations).  \nI do agree with your comment on support/maintenance and am happy to help out as needed but I don't really know/understand the burden adding a new capability like this puts on you.\n. Thx - also just checked my commit and it's 31 lines of code to provide this new functionality.  Will look into the testing and documentation comment you mention above.  Sending a PR as well for your comments.\n. I have fixed the unit tests so the build is now passing.  Please review my\nPull request and let me know if you need me to do anything else.\nRaghavan\nOn Tue, Sep 6, 2016 at 1:30 PM, Ray Nicholus notifications@github.com\nwrote:\n\n@LusciousPear https://github.com/LusciousPear Check out #1597\nhttps://github.com/FineUploader/fine-uploader/pull/1597. It needs unit\ntest work, and I have yet to review the changes.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1591#issuecomment-245080610,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGe9nqAFW3gM-aGxl4Zza1o9VRgDEudUks5qnc1ngaJpZM4I5Rie\n.\n. Hi Ray, Tests were passing and it's been a while so pinging you again.  I need this feature now for another project as well and would prefer to use the released version rather than my fork.  Pls let me know if I need to do anything more to move the ball forward.. No I am using my fork in our project. Works great. Have to fix unit tests. Will do that in the next week or so and get back to you. My changes broke the unit tests and I'll also look to add more for my changes\nThx for following up\nRaghavan. \n\nPlease pardon my brevity and any typos as this mail is sent from my mobile device\n\nOn Jul 13, 2016, at 3:34 PM, Ray Nicholus notifications@github.com wrote:\nIt looks like you ran into some issues while implementing this. Do you have plans to continue your work?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Hi Ray - is there anything more you need from me before you merge this in?\n. \n",
    "ddileep": "Pls let me know if you're ok with this - I can generate a Pull request to merge it.\n. ",
    "manvesh": "Do you have any updates on this? I would like to use this feature in our project.. chunkId !== null (this fails for chunkId == 0). ",
    "mgurnani": "Your blog is down again !!\nSecure Connection Failed\nAn error occurred during a connection to blog.fineuploader.com. Cannot communicate securely with peer: no common encryption algorithm(s). Error code: SSL_ERROR_NO_CYPHER_OVERLAP_\n. Great !! Thanks !. ",
    "bgilbert": "I'd love to work on this, but it seems I'm not going to have the time.  Thanks for asking, though!\nIt turns out that IE11 not only prefixes the API, but implements an older draft of the spec that uses event callbacks instead of Promises.\n. ",
    "daviesgeek": "Okay cool! I just signed it! No prob and thank you!\n. No problem.\nAwesome! That would be great!\n. ",
    "TekLord1": "Thanks for the quick response.\nI believe I understand how the total progress bar is supposed to work.\nIn the \u201cManually Trigger Uploads\u201d example you can select multiple files to upload. Once selected, you click on \u201cUpload\u201d to start the upload process.\nWhen I use this example on my traditional server I see one \u201ctotal progress\u201d bargraph at the top of the page and one bargraph associated with each file being uploaded.\nBefore the code change, the total progress bar would duplicate the value as shown for each bar. \nAfter the change, the total progress appears to work correctly.\nIn other words, if you are uploading 3 files, the total progress bar would replicate the same completion value as each file would be uploaded. After the change, the total progress bar would show 33% complete after the first file was uploaded, 66% after the second file, and finally 100% after the third file.\nI removed qq-progress-bar  from the following line and it appeared to fix the issue \u2026\n\nOn another note\u2026\nThe demo shows an \u201cUpload\u201d button with an embedded graphic arrow. But, the 5.10 download does not include this feature\u2026\nI would like to have this if possible.\nThanks again for your efforts.\n. Here are the two buttons. The on-line demo has a button that incorporates a graphic upload icon. But when I use the exact same code the graphic does not appear. There must be something different in the CSS that is included with 5.10 vs the CSS that the on-line demo is using.\n\n\n. Thanks. I have created some button graphics.\nThis is a very nice application. It is really great that users can resize the images and view thumbnails prior to uploading. Keep up the great work.\n. ",
    "birarda": "Hey @rnicholus, thank you for the prompt reply. It is much appreciated. You've got a great library here and I hope you don't feel like I was suggesting this would be a trivial amount of work.\nI believe it is possible to generate a single SAS that allows all blob operations on the container with read, write, create, list, and delete permissions. I've just tested that now and confirmed that I was able to put an empty block in my Azure container. \nOn our end, we're creating that SAS using a stored access policy and then revoking said policy once the user is no longer allowed to upload to their container.\nI'm going to attempt to hack this in to a fork of FineUploader today by simply returning a set SAS where it would normally hit the middleman server to request a SAS for the blob.\n. I set the stored access policy that the SAS uses only on the container I want my user to be able to enact operations on. This works for our purposes since we have a container associated with each user. This prevents the SAS for one container from having any permissions on other containers in the storage account.\nI understand that this may not be seen as a general purpose improvement to Fine Uploader.\nOnce I get through my tests today, if it works as I need I'll reference my fork here so any with the same desires can see how I've made it work. Happy to then close the issue if this isn't a workflow you envision supporting.\n. Put up #1604 to continue the discussion. It's lacking tests currently but hopefully that shows you how I'm using it so you can provide appropriate feedback.\n. I'm sorry about my delay in responding here. I'll try to cover how I build the SAS URI and what we use it for.\nIn our backend, I generate a SAS URI\u00a0for a given container. Here are the important params we add to the URI.\nsp (signedpermissions): racwdl - grants all actions (read, write, add, create, delete, and list) on the container and its contained blobs\nsr (signedresource): c - specifies that the shared resource is a container\nsv (signedversion): 2015-04-05 - specifies the desired Azure API version\nsi (signedidentifier): $stored_access_policy_name - specifies the access policy to be granted (already stored with the container ACL)\nsig (signature): $signature - the HMAC-SHA256 signature constructed following https://msdn.microsoft.com/en-us/library/azure/dn140255.aspx\nWe generate a stored access policy for each container that is valid for one month from creation. This stored access policy is left on the container for as long as we want the SAS URI to be usable. This allows us to revoke access whenever (by removing the stored access policy) even if the client has saved the SAS URI we pass down to their browser.\n. For our purposes, we want the user that has the SAS URI to be able to delete whatever items they want in the container. Each container is associated with a particular user, so until we revoke their access (by removing the stored access policy) we want them to have that access.\nOne could opt not to provide that access by removing d from the abbreviated permission list.\n. ",
    "drsect0r": "@rnicholus Our backend infrastructure is using the Accept header for API versioning. \n. @rnicholus I don't agree, according to this RFC the Accept header can be used for API versioning, vendor schema, and application type. \n. @rnicholus Thank you for your time. We will solve this on our end. \n. ",
    "glen-84": "@rnicholus The accept type is compatible with JSON (+json) ... it's similar to GitHub's accept type.\nI'm not sure what the exact rules are here.\n. ",
    "timot7782": "so I tried to set $headersStr = \"\" and this occurs\n`\n\n( ! ) Fatal error: Uncaught exception 'InvalidArgumentException' with message ' in C:\\wamp\\www\\internasional\\assets\\aws\\Aws\\ClientResolver.php on line 350\n( ! ) InvalidArgumentException: Missing required client configuration options: \nregion: (string)\nA \"region\" configuration value is required for the \"s3\" service\n  (e.g., \"us-west-2\"). A list of available public regions and endpoints can be\n  found at http://docs.aws.amazon.com/general/latest/gr/rande.html.\nversion: (string)\nA \"version\" configuration value is required. Specifying a version constraint\n  ensures that your code will not be affected by a breaking change made to the\n  service. For example, when using Amazon S3, you can lock your API version to\n  \"2006-03-01\".\nYour build of the SDK has the following version(s) of \"s3\": * \"2006-03-01\"\nYou may provide \"latest\" to the \"version\" configuration value to utilize the\n  most recent available API version that your client's API provider can find.\n  Note: Using 'latest' in a production application is not recommended.\nA list of available API versions can be found on each client's API documentation\n  page: http://docs.aws.amazon.com/aws-sdk-php/v3/api/index.html. If you are\n  unable to load a specific API version, then you may need to update your copy of\n  the SDK. in C:\\wamp\\www\\internasional\\assets\\aws\\Aws\\ClientResolver.php on line 350\nCall Stack\n#TimeMemoryFunctionLocation\n10.0009170536{main}(  )...\\endpoint.php:0\n20.0077546696verifyFileInS3(  )...\\endpoint.php:68\n30.0077546720getObjectSize(  )...\\endpoint.php:266\n40.0077546736getS3Client(  )...\\endpoint.php:294\n50.0118772392Aws\\AwsClient::factory(  )...\\endpoint.php:98\n60.0118772992Aws\\S3\\S3Client->__construct(  )...\\AwsClient.php:315\n70.0118773136Aws\\AwsClient->__construct(  )...\\S3Client.php:199\n80.0149994144Aws\\ClientResolver->resolve(  )...\\AwsClient.php:151\n90.0149994768Aws\\ClientResolver->throwRequired(  )...\\ClientResolver.php:246\n\n`\nI m using the latest aws sdk 3.x and ::factory is depreciated I think, I tried using the new method and it still doesnt work. \n. Hi.\nSo I changed the line to $headersStr = (isset($contentAsObject[\"headers\"])?$contentAsObject[\"headers\"]:\"\");\nand still amazon still requires the version and region. And when I passed in the region, it still requires the version (as per AWS SDK 3.x). Are you still using ver 2.x? What can I do to solve this?\n. ",
    "Eneuman": "The problem was on my end.\nWhen using thumbnails from Azure, you also need to add CorsHttpMethods.Get to CORS or it will not work.\nIt might be a good idea to add this to docs at http://docs.fineuploader.com/branch/master/endpoint_handlers/azure.html\nThanks for a great component!\n. ",
    "neko": "I wouldn't say it's needed. It's just useful in that it's a protocol specifically made for the purpose of resumable uploads and I feel it is more efficient because of that.\n\nIf such a change were to be made, it would have to be non-breaking so exiting users would not have to change any server code.\n\nI think if it were an option to use the tus protocol (default being false), it'd be non-breaking.\n. ",
    "openscript": "It's a pity that FineUploader defined it's own specific protocol for chunking and resuming, instead of using  TUS. For TUS many end-points are already implemented and ready to go, whereas for the library-specific FineUploader protocol it's not.\n. Okay, I understand, if there was nothing like that back then. I'm sorry.\nI didn't find any libraries. All I found is some examples in here: https://github.com/FineUploader/server-examples\nWhere can I find the libraries?\n. ..but back to the topic. Where would you start implementing TUS in FineUploader? It would be great to have some bullet points to start with. :-)\n. Thank you for the detailed answer.\nThe project I need that for is running on Rails. \nI've been scrolling through some code of FineUploader and also the TUS JS client implementation. I'm still estimating, which solution provides the desired functionality (chunking, resuming and client side image resize) and is realisable within an acceptable time, but it's hard to get an overview over FineUploader in that short time.\nRight now it feels like taking the TUS JS client and a library to manipulate images (maybe cropper, but this adds jQuery as a dependency, which I don't like that much), is the best option. So I don't have one big thing, more a two or three quite tight libraries. It feels like this is easier to manage and handle. \n. I've started working on the integration of TUS into FineUploader. I've decided for the following approach:\n1. Getting FineUpload build and tests up and running\n2. Hacking something quick and dirty together, which works against the official TUS server implementation. I replaced stuff in the traditional handler.\n3. Starting over from the traditional handler with a documented, tested and sophisticated implementation of TUS into FineUploader. \n4. Add a new module for TUS and alter the MakeFile. That's where I'm now.\nThe next step is going to be to use the code from the quick and dirty hack and more from the TUS JS client to make it working in the clean implementation.\nI've started a document about the integration in here. My fork of the clean implementation can be found here.\nDiscoveries so far are:\n- The support for old browser (especially the ones without the File API), blow up the FineUploader. The first implementation is going to be without taking care of support for old browsers.\n- FineUploader seems to be built very well. It's modular, which makes it easy to integrate TUS, (almost) without touching the other code.\n- Tests are working well too. There are no integration tests. The first implementation of the TUS module in FineUploader is not going to be throughout tested, whereas all the changes which are made to the FineUploader outside of the TUS module must be tested.\n- Concurrent chunk uploading is not going to be supported by the TUS implementation, because as far as I see the TUS protocol has no concurrent support.\nI'll working again on the integration this Friday.\n. > I'm not sure what you mean here. Fine Uploader support for older browsers works as expected, and I'm not aware of any issues. What issues are you seeing?\nThis is not an issue! I just don't guarantee that it's going to work for all browser from the beginning.\n\nI suppose it depends how you define integration tests. In one sense, there are a lot of integration tests, but there are no webdriver tests, that is true. I never got around to writing these, and that would take an immense amount of time to even test the most trivial features.\n\nYes, 'click'-tests consuming a lot of time.\n\nThat's unfortunate. Concurrent chunking was a highly requests Fine Uploader feature, and it has the potential to speed up single large file uploads significantly. I wonder if the TUS spec can be updated to account for this.\n\nI absolutely support this, but one step after another. \n\nOne other thing - in your fork, it looks like you've reformatted almost all of the files in the repository. I'd ask that you not do this and focus specifically on the feature at hand. I suspect this will already be a very time consuming feature to write, test, and document, and I don't want the scope to get out of control.\n\nThis is already undone. I didn't want to do that. This was part of my quick and dirty implementation.\n. ",
    "janko": "\nConcurrent chunk uploading is not going to be supported by the TUS implementation, because as far as I see the TUS protocol has no concurrent support.\n\nAfter some digging, I found out about the Concatenation extension to the TUS protocol, which enables parallel chunk uploads!\nRubytus unfortunately doesn't support it yet, but hopefully it shouldn't be too difficult to add it. In any case it would be great if the FineUploader implementation can somehow autodetect whether the server supports Concatenation (since it's an optional extension), and it if it does use parallel chunk uploads, otherwise use sequential chunk uploads.\n. ",
    "suhaotian": "@rnicholus \n. Soga\n. I use it in react, so I don't need the template \ud83d\ude22 \n. Sorry\n. ",
    "lsegal": "Ownership for the code falls directly to AWS, so my response may not be authoritative in any way (since I'm not an Amazon lawyer, or any kind of lawyer frankly).\nThat said, this code looks fine to me personally. I would recommend that if you borrowed a function simply call that out in the code comments for the functions. A simple AWS escape function pulled from aws-sdk-js licensed under Apache 2.0 - http://github.com/aws/aws-sdk-js notice would probably make their end happy enough. \n. @rnicholus I think that's great. I would only add that those functions were basically taken wholesale  in their entirety (having touched those util functions quite a few times I immediately recognized the code when I saw the PR diff), so it's not quite \"a line here and there\". They were modified slightly (removed comments and added some callouts to qq), but simply attributing the full functions would be the right thing to do IMO.\n. ",
    "sergei-maertens": "Thanks for the quick reply - I wasn't sure if it was intentional or not, but at least we have CI's that cover our asses :-) It's not really affecting me other than that my build unexpectedly broke.\nI know that the jQuery wrapper versions are things that shouldn't be used anymore, and I'm excited to upgrade to 5.8+ to be able to use ES6 imports. As with many things, there is legacy code that should be tackled some day.\n. ",
    "chriswestw": "I did edit the issue description as requested Ray.\n. ok Ray I  will put the Get Started data on some Designer focused community\nwebsites and ask them to give their opinions and suggestions.\nFor info..I have already sent the get started guide to a handful of\nco-designers (asking for their help before I posted on stackoverflow).\nSome understand how to develop css/html and content pages. And a handful\nare into mysql databases and a little php. Pretty much the same\nresponse....fabulous  looking demos and specification ....but how do you\nget it working without an understanding of JS\nOn Sun, Aug 14, 2016 at 4:05 AM, Ray Nicholus notifications@github.com\nwrote:\n\nHowever as designers we would welcome a step by step guide\nSince I'm not a designer, I'm not quite sure how to comply. Can you\noutline the exact elements of the guide that were confusing?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1640#issuecomment-239653298,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AM8naFIuLsHFQCsLi5UdK6BG_X-wWJb8ks5qfoYAgaJpZM4Jjkjb\n.\n. Is not so hard I don't think. We do use blueimp. Its easy to take the demo versions which work first time out of the box. Then if you know where to look its pretty easy to change multiple parameters - all in one php file. And some js/php developers have done a great job of creating xml / json parameter driven configs to facilitate this (eg PHPFormbuilder). So what all that means is guys like us can (and do) use it a lot. That said your Fine loader spec and demos seem to suggest its a much more flexible product. And the easiest of all to use. All that's really needed here is a bit of hand-hold documentation and (possibly) an out of the box starting point (which may actually exist now but we dont know) - load the page and it runs.  So that really is all there is too this request.  Designers are all pretty good at html, usually a bit of JS but nearly never any HTTP.  Personally I think there is a big gap out there for a configurable dead easy to use uploader...that just runs. Id be happy to work with you on that as your \"test dummy\". But I would equally understand if our types isn't really where you are targeting this product. \n. I will look at this link properly in the next couple of hours Ray.\n\nBefore I do let me give you a very first impression of the clicks on the links  that you just sent over. Please take these as comment from a guy that truly respects the genius that has gone into your plug ins and just wants to benefit from that genius. Here goes....\na) first your link says go to 'GitHub repo'. Look at the 'stack JS Uploader'. Trust me I am scared of the terminology already (I am not really-but you get my point). Most designers wouldn't click on a link like that. They actually would be too scared. You could have said instead...\"here is a link to get you going. it will enable you too....upload mages, manipulate images, easily post images to your database etc\" Most designers don't even know what angular js etc is. Heard of it yes..but certainly don't want to risk learning it. \nb) The GitHub repo...is the home of geniuses. Its not home to us creative types. If you are a budding google employee - great. If you just want something really nice to use as an uploader (upload-post-configure) you wont be looking on GitHub repo. its an alien world to our types. \nc) The terms used on the link pages and the underlying method for getting started.....could be written with people like us in mind.  It will say what you say now, But in a language that doesnt scare us off. Its just a version that actually says the same stuff but in a manner that is procedural and simple to grasp for our kinda types. Simple procedural instructions with links as required. I am an engineer by grad - so have spent an awful lot of time building bridges between experts designers and 'not-so-expert users and adopters\nd) Just a further point on c) ,,, our types tend to source out of the box scripts and fiddle with them!! Codecanyon and its like tends to be where we go rather than GitHub which terrifies us.\nI will take a good look at your angular stack js uploader .... and see if I can figure it out Ray. \nThanks\n. ok thanks Ray. I am trying to be a friendly fool here. No intentions of annoying you. Obviously if we are not your market just say so. But I honestly believe you have an opportunity to make something special here. \nI did try to get into the link you sent over. It opened up with....\"This example assumes you are already comfortable with AngularJS, node.js, HTML, JavaScript, and CSS\". That really is a big ask for our types. We are too busy deciding on what images to use, how to configure the database schema or writing a forms management procedure for users etc,...But I am convinced you have the tools here to make your uploader universal, used and talked about - its just the presentation\nIf you are able to get us past our inadequacies we would be happy people!\n. Ray - this is brilliant if you can really do it!\nIf you want I will work with you to implement and test your procedure.  And as we go I will add requests for help which you (with my input if you want it) could turn into designer-friendly  extensions of the procedure. For example you would be amazed at how difficult our types find it doing really simple things (for you) like finding out how to upload the file.names  and post them to databases. Its not because its hard...but because its explained in language that is just alien to us. Imaging the benefits to us of being able to follow dead simple instructions to take advantage of S3 etc. Imagine being able to download a gallery of uploaded images onto a page (say) using json (but not even knowing we were using json). Imagine being able to resize images on load- following a few simple instructions. All this is so so hard right now. I have looked at Uploadify, Blueimp, DropZone and others. They all claim to be easy. And sure - they are to developers. But to us lot the language is so hard to understand. But it really doesn't need to be that way. \nOne other thing I would suggest. You could market this new (for designers) solution via Codecanyon etc the same way as things like PHPFormbuilder that I mentioned earlier. They will typically take 50% but there is a big designer community out there. Offer them a free trial. That will lower the barriers to it being tried. Make its a doddle to get up and running. Be the first to genuinely transform the world of uploads. I will assist you with suggestions about how to get the message over if you wish - it really is needed by your market in my opinion.\nJust for your info I am on a boat (on the sea) for a couple of weeks (from tomorrow morning) but will log into my emails whilst onshore and provide you with input - if you want it. [Email on a boat is another one of those problems to be solved - at an affordable cost]. \n. OK- I will keep an eye on the progress whilst I am away. And will happily assist with the test and feedback when I get back. The functions I mentioned in my prior post were just off-the-cuff examples of areas where we struggle. There are a others. But from my experience nearly any complex problem can be turned into a series of simple steps (wizards)-that pretty much anyone can follow. But I do appreciate it can be a thankless (even monotonous) task especially for  the genius types---to  write those procedures etc. Good luck Ray. I'm excited to see the outcome. \n. ps An extremely easy to use and customize full-stack version of Fine Uploader, aimed at non-developers.....\nsugestion: ''full stack'' wont mean much to a lot of designers. I know its common language amongst developers. But putting a designer hat on - it adds to the trepidation. Maybe intro like...\nLogo\nstrap line: the world easiest to use Image and File Uploader solution\nsub strap:  ....designed for designers ...\nNo programming needed. Just simple to follow steps. \n..........................then a small handful of bullet points extolling virtues and benefits ...............................\ncall to action:  -------3 min youtube->download ->and click GO to GO\npps Codecanyon suggestion wasn't meant to suggest a profit making opportunity. You will find a lot of our types lurking there hoping for something nice and easy to use... and not expensive.\n. Hi Ray\nI hope you are well. How is Fine Loaded for Designers progressing? \nRegards\nChris\nSent from my iPhone\n\nOn 17 Aug 2016, at 07:44, Ray Nicholus notifications@github.com wrote:\nClosed #1640.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. OK will keep an eye on progress. I have informed a few other guys in the\ndesign community about what you are doing as well Ray. The industry needs\nthis\n\nOn Sun, Aug 28, 2016 at 5:28 AM, Ray Nicholus notifications@github.com\nwrote:\n\nYou can follow progress at https://github.com/FineUploader/fine-uploader-\nfor-designers. For the next week or so (possibly even longer) I'll be\ncompletely tied up preparing my book https://amzn.com/1484222342 for\npublishing. I'll get back to this and other non-mandatory Fine Uploader\nduties once things have calmed down.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1640#issuecomment-242955621,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AM8naCTfeE5ZtaoAVxhh7hhP0IvfYKoBks5qkQ5ggaJpZM4Jjkjb\n.\n. \n",
    "strohhut": "What I find a bit confusing about the \"Getting Started\" guide is:\nStep 1 says to download the bundled files. \nStep 2 is already instantiating the FineUploader JS object. \nHow about explaining what (and how) needs to be referenced before using it? I know that this is explained elsewhere but a consistent \"Getting Started\" guide that takes you from the beginning to a working default would be nice.\n. I'm just a beginner at fine-uploader so I don't think I can write real documentation. But it be great if the current step 2 would become step 4. \nFor step 2 I'd make a light version of \"Decide which Fine Uploader to use\" without any code samples yet. Just explain the differences in functionality. \nFor step 3 I would use the \"Importing Fine Uploader\" section. I'd adjust the \"Globally Scoped\" section though. I would remove the new qq.FineUploader code and instead mention here that templates have to be included for the UI mode. So step 3 should mention everything that should be referenced for the different modes (core/UI/Azure/S3) and how to do it (and not leave out something like the html templates).\nThen for step 4 I'd finally show the instantiations of the different modes and the options with JS samples.\nAnother thing is that the downloaded fine-uploader bundle doesn't have a client folder but the templates are using it\n<link href=\"client/fineuploader-gallery.css\" rel=\"stylesheet\">\n<script src=\"client/fine-uploader.js\"></script>\nI know that installing fine-uploader via bower gives you a Client folder but the readme there says to use the bundle. Also via bower I don't get  the fine-uploader.js. It's only in the bundle. I don't think people are really putting all fine-uploader files in a top-level folder called client. The usual path would be something like /lib/fine-uploader/dist/ but I guess that becomes off-topic now.\n. Nice. Another thing I just noticed is that the documentation for \"API\" -> \"Options\" doesn't have an entry for the callbacks option and the \"API\" -> \"Events\" documentation doesn't mention that 'the callbacks object belongs to the callbacks property of the option object.\n. Leaving out code samples from step 1 and step 2 and the more in-depth explanations are great. Looks like the new guide will be very helpful and easier to understand. I'll comment here if I notice something.\n. A couple of things I noticed about the new step 3:\n- At the beginning the word \"properly\" is a bit overused.\n- I think for a getting started guide it's not really necessary to say that the minified\n  versions are needed for production enviornment. Adding this information every time adds much noise and saying that they are \"needed for production\" sounds like there is a functional difference. Maybe it's enough to mention at the end of step 3 that minified versions of the above files exist for production if desired. Maybe add that those files follow the usual naming scheme in having the same names as the unminified versions but end with min.js or min.css.\n- I think this line has a mistake regarding the optional and debugging info:\n\"fine-uploader/fine-uploader-gallery.min.css (optional, but useful for live-debugging)\"\n- For the image files I'd not only mention that they are needed but that they have to be in the same directory\n  as the fine uploader css files so that the image file paths used in the css files will work.\n. I see. It's just that a programmer who is advanced enough to care about performance and minified files will automatically look for minified versions.  Including the information about the minified files as it is now in step 3 seems like it's trying to make too big of a deal about the fact that minified versions exist. I'd simply focus on the files that make a functional or visual difference in the Getting started Guide. I don't think it should teach people to use minified files there.\nEdit: Or you could go the other way and only mention the minified files and assume that a programmer who is  advanced enough for debugging knows to use the unminified versions for debugging. :)\n. I noticed that there is something missing in this sentence: \"The sections below will show you how to necessary Fine Uploader files in a globally scoped environment\" in step 4.\nThe heading in step 5 \"Initial Options\" seems a bit strange to me because it suggests that only later there are other/additional options. Maybe you can rename it to something like \"Basic Options\".\n. Yes, it's mainly a psychologial thing (missing the satisfaction that the initial look is restored after realizing that selecting any files was a mistake and canceling them.) When I acted as test user the problem wasn't (as you already said) that I feared that I can't drop files any longer.\nUnfortunately I'm a beginner at fine uploader and I'm no JavaScript programmer but I guess reverting uploaderEl.removeAttribute(DROPZPONE_TEXT_ATTR); in the cancel event handler when the number of files is zero should be a start.\n. I fully understand. I regard this issue as having very low priority too. :)\nI'm mainly a C# dev. Sometimes I'm hacking some TypeScript though. At first I tried Dropzone.js because there are TypeScript type definitions for it on DefinitelyTyped but now I'm using fine-uploader because I think its programming model is easier to use.\n. If I ever gonna need more than the basic fine-uploader options and if I find the time I'll definitely consider making a definition file. :)\n. Sorry, I didn't test it in the browser, I only saw it in code.. ",
    "andresespinosapc": "Defining an options object and passing it into each uploaded is not the same, it's still very uncomfortable to add new settings apart of the default ones.\n Sadly, I don't know how to implement this without jQuery, I'm more a jQuery user. i've only seen it on another library that requires jQuery and I've found it a great idea.\n. ",
    "emilecantin": "Generating a signed URL: http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#getSignedUrl-property\nSigning a policy: https://github.com/FineUploader/server-examples/blob/master/nodejs/s3/s3handler.js#L132\nTo me, it seems more like the \"supported\" case with S3 is with signed URLs, but I might be wrong. I don't really understand the rationale with signing the policy, but you seem to be pointing towards chunked uploads, is that the reason? It's not really explained in the documentation.\n. \"It's for chunking\" is an acceptable explanation for me. I believe it should be mentioned in the documentation, but for now it solves my issue. Thanks!\n. ",
    "raresserban": "Hello.Sorry for commenting on such an old request, but how exactly can I use a presigned url generated from the backend into FineUploader?\nI have looked through the docs and I can not seem to find anything.... ",
    "fromkeith": "Created pull request to fix cygwin.\n1698 . wow... yea...\nthats not supposed to be in there... Fixed hopefully.... I know if the file is pulled before signing, it will have a size of 0 and I think the signing will complete succesfully. It just signs what it thinks an empty file. Then it uploads to s3, and of course s3 complains about an empty file. The root of that problem is that the file size went to zero when it wasn't zero to begin with. I couldn't figure out where to add code to solve that, so instead thought relying on S3s errors would be fine.\nThe error that I encountered, was the FileReader getting an error when creating the signature. It would properly reject its promise. However, the calls to getEncodedHashedPayload did not listen for the rejection. So I just went in and propagated up the rejection call.\n. I saw the file just 'hang'... It never actually starts uploading or reports an error. No XHR requests get made and the state of the file doesn't change.\n. If you put a break point on the 'failure' below, do you ever hit it?\njavascript\ngetEncodedHashedPayload: function(body) {\n    ...\n        reader = new FileReader();\n        reader.onloadend = function(e) {\n            if (e.target.readyState === FileReader.DONE) {\n                if (e.target.error) {\n                    promise.failure(e.target.error); // here\n                }\n                else {\n                    var wordArray = qq.CryptoJS.lib.WordArray.create(e.target.result);\n                    promise.success(qq.CryptoJS.SHA256(wordArray).toString());\n                }\n            }\n        };\n   ...\nI was able to hit the failure if I pulled the sd card while it was trying to read the file.\nFrom what you saw:\n1. is something that is especially problematic for really bad internet connections. I would love to see a timeout setting somewhere.\n2. Definitely ran into this. Less useless xhr requests would be awesome\n. I can change it to uname if you like. Found the function 'findstring' which will let us see if CYGWIN is in the uname... Then we just use that as the condition for the switch.\neg.\nMake\nplatform = $(shell uname -s)\nifeq ($(findstring CYGWIN,$(platform)),CYGWIN)\n    npm-bin = $(shell cygpath -u $(shell npm bin))\nelse\n    npm-bin = $(shell npm bin)\nendif\n. What I get is CYGWIN_NT-10.0\n. Looks like lint failures... fixing that. I never actually looked at the file size differences...\ns3-core.min: 142KB\ns3-core-worker.min: 150KB\nI'll take a look at unit tests and incorporating your code comments a bit later.. From your feedback:\n\n'useWorker' changed to 'workerUrl'\n'qq.s3.worker()' changed to 'qq.s3.createS3InlineWorkerUrl()'\nMoved the new code from request-signer into a new file 'request-signer.worker-manager.js'\nAdded in unit tests. I had to fix Date so that it was constant, so I can verify the signatures not changing.\nRemoved the error from being thrown. Instead it is logged.. I also want to do a bit more testing on multiple browsers with these changes. I've just done a quick one on Firefox, IE, Edge and Chrome.. not as indepth as I want yet. But I thought you would want to look at the reformatting sooner rather than later.\n\nOne thing that I could use guidance on... is that because RequestSigner gets created multiple times, my worker-manager gets created multiple times.. Is there a better place to create the manager, but still get the options from the signer?. Sorry. Got distracted by other things.\nI think I have a working copy that I've restructured mostly. I think the last main task I had left was moving the worker creation to a different module per your suggestion.. Anything I need to do to progress?. No worries. Just wanted to make sure I wasn't blocking anything.. It shouldn't be. I explicitly return null if there is no valid worker. Otherwise a promise is returned. No other return path is available.. Old habits?\nI can remove the _s. Left over from when s3 core didn't include the inline worker. It should be safe to remove it.. if we remove the check, that line goes away.. I do find short-circuit returning to be easier to read. However, its your code base, so I can modify it to an else-if if you prefer.. Off. No worker used.\nI've set it as the default so that its by default backwards compatible.. That's run by node in the build process. Not by a browser.. ",
    "JugerHiTech": "It is great to see this^^ waitring so long\n. ",
    "azmeuk": "@rnicholus How can we get the downloadUrl variable from the template, to render the full download link in the anchor link?\n. ",
    "Igmat": "@rnicholus but elements inside dropzone can use stopPropagation function for avoiding user confusion and keep whole drop area clickable, because second is pretty common use case and a lot of users expects such behavior.. ",
    "lscholten": "As an additional comment; we have used the tool on http://www.easyexifdelete.com/ to strip all EXIF from our photo set. This reduces the total file size from 865 to 861.3 MB, but suddenly the uploads works without problems, both on our implementation and the demos in the demo page.\n. Thanks for your reply.\nWe are also quite confused by the fact that removing EXIF fixes the problem. We've tried another real user data set which failed, and removing EXIF there also seems to fix the problem.\nAdditionally, we have tried using Pica as a replacement, just like in the example code in the documentation. But the browser still crashes. \n. ",
    "hummerz5": "Thanks for your advice; the issue was indeed server side. The server sends a very infrequent 502 error for an unknown reason, with little explanation. For the time, I have enabled the overlooked autoRetry option.\nThanks again.\n. ",
    "1dot44mb": "I have custom labels applied to items in upload queue list (like order number for example). I have to wait for qq.FineUploader to complete (applying its template, getting previously uploaded files, etc) and then run my custom javascript method to apply labels to items based on their order, name, etc.\n. Thanks, onSessionRequestComplete callback solves \"getting previously uploaded files\" problem. \nHowever it would be good if qq.FineUploader method has an \"initialization complete callback\" imho. So that we know when FineUploader form (dropzone) is ready for user interaction and we can make post processing of template, file list, visual stuff, etc.\n. Thanks,\nIn two separate scenarios i mentioned above; the delete requests are different. One of them contains UUID in URL and other does not. My question is; why are they not consistent? They are both delete file requests.\nBecause they are different, we have to handle two separate request scenarios on the server side (routing, custom logic, etc.)\n. Thanks\n. ",
    "DavidPIsaac": "I see the alias as the origin in the OPTIONS request, and I see\nAccess-Control-Allow-Origin: *\nIn the OPTIONS response.\nI see Status 200 response to both the OPTIONS and POST.\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Friday, September 02, 2016 2:44 PM\nTo: FineUploader/fine-uploader fine-uploader@noreply.github.com\nCc: David Isaac David.Isaac@bpsconsulting.com; Author author@noreply.github.com\nSubject: Re: [FineUploader/fine-uploader] Upload does not work with CNAME DNS alias with https session (#1660)\nsounds like a CORS issue with your server. what do you see in the dev tools console?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/FineUploader/fine-uploader/issues/1660#issuecomment-244456624, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AU8SQoy8p_gtgfLzi93VP6zfEsqfEOOVks5qmG5agaJpZM4Jz-jo.\n. Good call, there it is:\nCross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at https://assets.actualdomain.com/s3/aws.json?data%5BGroup%5D%5Bid%5D=70757&data%5BFormField%5D%5Bid%5D=1453481&data%5BAsset%5D%5Bfile%5D=DSCF3334.JPG. (Reason: CORS header 'Access-Control-Allow-Origin' missing).\nEven though the response to the immediate prior OPTIONS request contains this in the header:\nAccess-Control-Allow-Origin: *\nCache-Control: no-cache, must-revalidate\n\u2026\nAnd the response to the POST itself is status code\n200 OK.\nI haven\u2019t tried with debugging on.\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Friday, September 02, 2016 4:04 PM\nTo: FineUploader/fine-uploader fine-uploader@noreply.github.com\nCc: David Isaac David.Isaac@bpsconsulting.com; Author author@noreply.github.com\nSubject: Re: [FineUploader/fine-uploader] Upload does not work with CNAME DNS alias with https session (#1660)\nI mean, what errors, log messages do you see, especially when debug is set to true?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/FineUploader/fine-uploader/issues/1660#issuecomment-244474581, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AU8SQq9YqaulJK49V0uCMvgUjvZ4i6XNks5qmIEtgaJpZM4Jz-jo.\n. Thanks\u2026we should consider this issue closed as it looks like an environment issue not a FineUploader issue.  You\u2019ve been very helpful.\nFrom: Ray Nicholus [mailto:notifications@github.com]\nSent: Sunday, September 04, 2016 8:50 AM\nTo: FineUploader/fine-uploader fine-uploader@noreply.github.com\nCc: David Isaac David.Isaac@bpsconsulting.com; Author author@noreply.github.com\nSubject: Re: [FineUploader/fine-uploader] Upload does not work with CNAME DNS alias with https session (#1660)\nThis does sound like an issue with your server's handling of CORS. Note that you must return proper CORS headers not only in response to the preflight request, but also the proper ACAO header in response to the POST. A 200 status does not indicate that CORS headers are correct. If you have further CORS questions, stack overflow is a more appropriate place to ask, since I'd like to keep this issue tracker for issues with the library and feature requests.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/FineUploader/fine-uploader/issues/1660#issuecomment-244601822, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AU8SQk-j7Z8QI1DuukYuwMR7SMZyLNMsks5qmr6IgaJpZM4Jz-jo.\n. ",
    "danielebriggi": "Great! Thank you!\n. ",
    "pyaesone17": "I am not talking about chunking upload. What I mean is progress bar inside \nul list is always hiding. You may also inspect this on documentation demo page.\n. Sorry I edited my comment\n. \n\n\nWhat i mean is this individual progress bar is always hiding.  It is not multi upload . I upload one by one.\n. Thank you for your reply .btw  Is there a way to set event handler in runtime for event handling.\n. Sorry. Adding qq-server-scale on img solved the issues.. ",
    "bpvarsity": "Was a writeup/guide ever made? . No problem nateweiss. Holidays have a way of doing that :) \nHopefully the fix is simple like you said. \n. ",
    "RayCLin": "I can't, it is quickstart sample code on the web page, not in the repository.\nlocation: http://docs.fineuploader.com/quickstart/01-getting-started.html\nTraditional endpoint, UI feature set\n<script src=\"fine-uploader/fine-uploader.min.js\"\"></script>\n. ",
    "zelding": "I see; thank you!\n. ",
    "rdptz": "Hi, \nyou are right, lowering the pause the performance issue seems to disappear.\nI still wonder if it would not be better to let the browser render the image, when the thumbnailUrl is explicitly given from the session endpoint JSON. This way there would be no issues with chrome too, I guess.\nThanks!\n. ",
    "agamemnus": "I can't use the template if I don't know if it is a bug or a feature. What am I supposed to do? (should I treat this as a bug or a feature?)\n. Oh right. Yes, it is the input name that needed to be modified not the\nfilename. This was what this modification does.\n. Please re-Open!\nOn Nov 1, 2016 9:07 PM, \"Michael Romanovsky\" agamemnus@gmail.com wrote:\n\nOh right. Yes, it is the input name that needed to be modified not the\nfilename. This was what this modification does.\n. Well, the back-end gets data from that variable and, then uses it to generate the file name. I would do it differently, but I am not the backend developer so can't change it... maybe it could still be a useful variable to other people for random uses.\n\nBut, I was just thinking that maybe this behavior could extend to every setting variable that is not immediately run/evaluated.\nOne idea -- maybe if a variable is static, make it a function, and then always run it as a function, or something like that. Or, just individually modify it with for example the method I suggested above.\n. Oh ok. I thought I tried it but it didn't seem to work. I will try again.\n. ",
    "andy-ms": "Hi @SinghSukhdeep, I'd be willing to help, but could you explain to me the way this library is used? On the DefinitelyTyped tests, everything uses a qq global variable. But the NPM package appears to have module.exports. Can this library be used as a module?\nIf it is not used as a module, you will need /// <reference types=\"fine-uploader\" /> to include the file in the compilation. (Use the --listFiles compile option to see which files get included.) Modules in node_modules/@types get included automatically, but not all of those in node_modules.. ",
    "bradfordwagner": "@SinghSukhdeep I think you did some really nice thorough work here. \n@rnicholus I think we need to set up CI for this TypeScript component. Treating the TypeScript definitions as first class is much better than having it maintained in the DefinitelyTyped repository, and I'd be happy to contribute. Would it be possible to have a feature branch that both @SinghSukhdeep and I could work out of?. Sounds great to me. ",
    "lior800900": "Hi why you close it???\n. ",
    "guzart": "Apologize for not following guidelines, I just saw that duplicate line while I was reading the code and went to submit a pull request using Github's UI. Will submit changes from develop next time \ud83d\ude38 \n. ",
    "anik786": "In which case, can we please add this feature to the Core UI as I believe this would be a common feature for many apps.. I'm a bit confused how to do it using the existing API anyhow. I have looked at your answer in SO, and unsure as to how do this.\nI added a \"Open\" button in the fine-uploader-row-template file. \nI also know how to hook on the onStatusChange event to check when the status becomes UPLOAD_SUCCESS. \nHowever I cannot seem to find a way to fetch the original response from the server using just the ID, as this is where we would get the URL from.. ",
    "kawaljeetb": "This is happening with every image I upload in firefox [version - 50.1.0]. Yes.. Tried using the latest version of Fineuploader(5.11.10). But still throws the same error in Firefox.\nBut both the versions are working in chrome. Images gets scaled in chrome.. there is one more issue that occurs in Firefox before scaling is 'Error: No createObjectURL function found to create blob url'. Following are the lines of code that is throwing error only in firefox:\n Original Code \n        var URL = window.URL && window.URL.createObjectURL ? window.URL :\n                window.webkitURL && window.webkitURL.createObjectURL ? window.webkitURL :\n                null;\n      if (!URL) { throw Error(\"No createObjectURL function found to create blob url\"); }\n img.src = URL.createObjectURL(srcImage); \nOriginal Code \nSo I m replacing these lines of code with the following ones:\n Replaced Code \nfunction createObjectURL ( file ) {\n        if ( window.webkitURL ) {\n            return window.webkitURL.createObjectURL( file );\n        } else if ( window.URL && window.URL.createObjectURL ) {\n            return window.URL.createObjectURL( file );\n        } else {\n            return null;\n        }\n        }\n img.src = URL.createObjectURL(srcImage);\nReplaced Code \nSo the createobjecturl issue gets resolved but then image scaling gets failed.\nIs Is it because the above code.\nAgain, this is happening for me in both the versions of Fineuploader.\nThanks.\n. ",
    "temirfe": "I have similar issue in Firefox. When I select large image the scaled version is only some part of image. In chrome it works ok. \nWhen I checked console of firefox it says \"Image corrupt or truncated\". This seems to be common bug in firefox because it \"requests image too fast\". \nIs there any work around for this? Maybe set some delay time before scaling so that firefox finishes loading image?\n(Fine Uploader 5.13.0)\n(Firefox 59.0.2). ",
    "sgarcialaguna-mms": "I filed https://bugzilla.mozilla.org/show_bug.cgi?id=1319053 for Firefox. Other than that, dropping folders works fine for us in Firefox.. I played around with the example a bit more. After the upload is complete, I can call uploader.getFile(0) (or any other valid index) and that's where I see the blob still being held.. Sounds good to me. Like I said, I'm already using a similar workaround anyway with this._handler.expunge(id), so a documented way of doing that or something like that is all I was looking for.. ",
    "sschuerz": "Sorry for my late response. I created executable test cases now.\nGeneral remarks to my test cases\nI implemented the needed adaptions directly in the built file jquery.fine-uploader.js (included in the FineUploader release file fine-uploader.zip) to be able to provide an example that is very similar to our real use case. The original source files that need to be adapted are mentioned in my initial issue (client/js/jquery-plugin.js and client/js/uploader.basic.api.js). I can provide a pull request that for the original source files if needed.\nI implemented my suggested solutions for \"First problem\" and \"Second problem\" (see my initial issue), however I used my \"alternative solution\" involving the qq object in both cases.\nContents of the ZIP files\n\nfine-uploader folder: Unzipped version of the FineUploader release file fine-uploader.zip from the latest release 5.12.0. The modified version of jquery.fine-uploader.js is additionally included as jquery.fine-uploader.adapted.js.\nrico.js: The version of Rico we use (1.1.2). I know this is an older version, but extending the Object prototype is also done in other (newer) JS libraries.\nindex_*.html: I used your example at http://docs.fineuploader.com/quickstart/01-getting-started.html (\"Traditional endpoint, UI feature set\") as a starting point and adapted it as far as needed to show the problems. All my modifications are accompanied by comments.\nindex_error.html: File that includes the unmodified version of jquery.fine-uploader.js to show the error at initialization. The problem is explained in detail in my initial issue.\nindex_working.html: File that includes the modified version of jquery.fine-uploader.js (jquery.fine-uploader.adapted.js) and therefore produces no error at initialization.\n\nWhy two ZIP files?\nexample_jquery_2.2.3 uses jQuery 2.2.3 and represents our current use case with the problems I described in my initial issue.\nexample_jquery_3.1.1 uses the latest jQuery version 3.1.1 and shows another problem similar to the two problems I described in my initial issue. See the section below for a description of this prolbem.\nAdditional problem with jQuery >= 3.0.0\nSince the implementation of $.isPlainObject has changed in jQuery 3.0.0 (see https://blog.jquery.com/2016/06/09/jquery-3-0-final-released/), a small additional modification is needed in the function transformVariables in the source file client/js/jquery-plugin.js:\nIn the iteration over the source variable, the callbacks options object now counts as \"plain object\", so the else if condition $.isPlainObject(val) evaluates to true (in jQuery < 3.0.0 the else path is entered here). Therefore, the transformVariables function is called recursively for the callbacks object and all of its properties (including \"not own\" properties, e.g. the Rico extend method) are added to the xformed object (as \"own\" properties), which is used for further options processing. So you end up with the problem at the regex execution in the addCallbacks function (name = /^on(\\w+)/.exec(prop)[1] where prop is e.g. \"extend\") again.\nI've solved this problem by using qq.each instead of $.each for object iteration in the transformVariables function (qq.each does not iterate over \"not own\" properties whereas $.each does).\nI think in general it is usually seen as a good practice in JS not to iterate over \"not own\" properties (unless there is a special need to do so of course) to avoid unexpected results in varying usage environments.\nThe ZIP files\nexample_jquery_2.2.3.zip\nexample_jquery_3.1.1.zip\n. ",
    "ensean": "I think I have not describe the issue clearly...\nMy code goes as follows\nvar uploader = new qq.FineUploaderBasic({\n            button: $(\"#addAttLocal\").get(0),\n            maxConnections: 1,\n            request: {\n                endpoint: ctx + \"/web/mail/attachment/fupload?\" + urlUtil.serialize({\n                    target: that.newMailId,\n                    attachmentTypeId: 'MAIL_ATTACHMENT'\n                })\n            },\n            multiple: true,\n            validation: {\n                sizeLimit: 50000000\n            },\n            callbacks: {\n            //codes omited...\n            }\n        });\nThe issue maybe that the user could click the addAttLocal button several times, and the integer file ids may be duplicated across these clicks which resulting calling the cancel method will always affect the file processed by the latest uploader ... . By the way, I am using fineuploader in core/basic mode, it seems that the getId methods is for the UI mode .... Thanks for your update.. ",
    "DonGiulio": "Got this same problem, +1 on the issue. . ",
    "tomservaux": "Sorry, I tried responding to this yesterday from my phone but it didn't send for some reason. \nThe File Upload Dialog is the bootstrap modal dialog I referenced in the initial description. It contains the FineUploader template as well as a \"Done\" button that allows closing the dialog. The problem is that in most browsers the File Selection Dialog is itself Modal so you can't click in the browser when it is open. For some reason in Chrome this is not the case. I can click on the Done button to close my dialog even when the File Selection Dialog is open. This deletes the file input element from the DOM and crashes chrome.. hmmm, I just tried reproducing the bug so I could send screen shots and I could not. I wonder if there was something messed up  with Chrome. \nI will close this. It appears to be a bug in Chrome if anything.. ",
    "kb-ptti": "It's a bug because the purpose of the example is to teach me about Fine-Uploader and its template system, so if I see something declared to have \"no dependencies\" then I have to assume that all the classes are something to do with Fine-Uploader templates because, by definition, I know nothing about them and am learning from this example.  So, yes, you're right, use of the boostrap.css \"btn\" and \"btn-primary\" button styling classes is also a bug, because I thought they were something to do with Fine-Uploaders template system too.. ",
    "Darmody": "@rnicholus Hi.\nhttps://github.com/Darmody/fine-uploader/blob/master/client/js/traditional/traditional.xhr.upload.handler.js#L77-L81\nI think isErrorUploadResponse treat 204 as a success response. So that parseResponse will try to parse an empty responseText.\nhttps://github.com/FineUploader/fine-uploader/blob/c1b4954f21381dbd664e379abf571c988e2265c0/client/js/traditional/traditional.xhr.upload.handler.js#L103. @rnicholus Oh, sorry. I caught your point now.. @rnicholus Is it sufficient now?. @rnicholus I see, then I will close this one.. ",
    "vincent-guesnard": "Ok, i see that the owner just did an update of files on the 5.12.0 release. That's OK for me :)\nThank you !. ",
    "matchon-on": "The message says in the post request, 'IncorrectNumberOf FilesInPOSTRequest', and 'POST requires exactly one file upload per request.' . I selected only one file for upload. Is it possible that when the upload is submitted, somehow multiples files are put in the muliti part post data? \n. Tried plupload. It worked.\nCompared the multipart data. I found out your name field for file is : 'qqfile', while plupload is more standard 'file'. Is this why? Maybe my object service only knows 'file'.\nIs there a way to set the field name for file in your API? I still prefer yours even plupload works. \nYours:\n------WebKitFormBoundary3nRlhLkzBAvp1aCi\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"qrcode_for_gh_4ccf93996023_1280 (1).jpg\"\nContent-Type: image/jpeg\nPlupload:\n------WebKitFormBoundaryRASn1DYJKS7swdIA\nContent-Disposition: form-data; name=\"file\"; filename=\"qrcode_for_gh_4ccf93996023_430.jpg\"\nContent-Type: image/jpeg\n. Thanks.\nt works now. But a new problem comes. Your lib attempts to parse the response body as Json automatically. But my object store service provider responds with xml.\nIs it possible to override this? I tried onComplete callback by response parsing as json still happens before it is called.\nOr should I use onError? . Oh. Thanks for the response. Maybe I will have to hack your code now. :). ",
    "don-bluelinegrid": "There is still an index.d.ts missing, and as a result the d.ts files inside the /typescript directory are not being automatically found by TypeScript.. Also, there is no export statement in the typing file, so nothing is being picked up as a default export.\nThere needs to be a default export of qq.. I am not going to do that.\nI'm using TypeScript and webpack, and every module that's provided as an npm package can be imported using an import statement.  I don't include any JS files in my index.html, and I don't plan to start doing that.\nI read various PRs talking about TypeScript compatibility, and I see typescript d.ts files in the package.  Why do these exist, if there is no TypeScript compatibility?. ",
    "rgfoley": "Sorry for the long delay, haven't had occasion to work with files in some time, so it totally slipped my mind. The issue occurs regardless of timing, since the steps were executed via some UI elements.. ",
    "mrdziuban": "Not sure why tests failed on Travis, but they passed when I ran them locally.. @rnicholus thanks, I updated the documentation. I would be happy to add a unit test, but I looked into the existing S3 tests and wasn't able to find a way to tap into the S3 request signer from the test. Let me know if there's an example of this, or what you think the best way to proceed is.. Thanks again @rnicholus. I was able to add some tests by specifying the onError callback to the uploader.. Thanks!. ",
    "dan-0": "All valid points. I was not aware of number 2, and that negates much of the potential seriousness of this.\nWith that considered, in addition to this being a breaking change, I would consider it to be something to be left to the developer implementing FileUploader to be concerned with. I agree with killing the issue.\n. ",
    "369857519": "I did something like this\nvar uploader = new FineUploaderTraditional({\n           options: {\n              request: {\n                 endpoint: 'http://xiaomiup.up9.v1.wcsapi.com/file/upload',\n                 token:this.props.token,\n                 customHeaders:{\n                    'Access-Control-Request-Headers':'x-requested-with'\n                 }\n              }\n           }\n        })\nbut it's not working. ",
    "xllily": "@rnicholus  I just be able to adding a captureoption in fine-uploader.js. I mean I only be able to add a capture option in the packaged source code. ",
    "greenkeeper[bot]": "Version 4.0.2 just got published.\nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits .\n\ne7821b4 Version 4.0.2.\n0b34e25 Fixes #874 - regression in at-rule tokenization.\n\nSee the full diff.\n\n. ## Version 4.0.2 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits .\n\nb3d5454 Version 4.0.2.\n76496f4 Bumps clean-css dependency to 4.0.2.\n\nSee the full diff.\n\n. ## Version 4.0.3 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits .\n\n51fda1a Version 4.0.3.\n83adb94 Bumps clean-css dependency to 4.0.3.\n\nSee the full diff.\n\n. ## Version 4.0.4 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 3 commits .\n\n4600371 Version 4.0.4.\n63b44d6 Bumps clean-css dependency to 4.0.4.\n2ebee6e Corrects release comparison links in changelog.\n\nSee the full diff.\n\n. ## Version 4.0.5 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits .\n\n325cd6b Version 4.0.5.\n40443cc Bumps clean-css dependency to 4.0.5.\n\nSee the full diff.\n\n. ## Version 0.0.28 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 3 commits .\n\n47e3b53 chore(branch): bump for patch\ncd462d3 Merge pull request #59 from edi9999/patch-1\nae895f6 Update package.json\n\nSee the full diff.\n\n. ## Version 2.8.4 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits .\n\n40ceddb v2.8.4\n7aa6911 fix corner cases in reduce_vars (#1524)\n\nSee the full diff.\n\n. ## Version 2.8.6 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 12 commits .\n\n33b5f31 v2.8.6\n35a849d collapse assignment with adjacent subsequent usage (#1553)\nb70591b handle variable declaration within catch blocks (#1546)\nb33e7f8 improve unsafe on undefined (#1548)\n1f0333e stay safe with constants in IE8- (#1547)\neb98a7f fix handling of shebang and preamble (#1545)\n78d1bb9 fix a corner case in #1530 (#1552)\nea9ab9f resolve issue with outdated version of async (#1549)\nce54c9c disallow collapse_vars constant replacement in for-in statements (#1543)\n07accd2 process code with implicit return statement (#1522)\n18059cc compress numerical expressions (#1513)\nb5e0e8c facilitate fix for #1531 (#1542)\n\nSee the full diff.\n\n. ## Version 2.8.7 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits .\n\na5d62a3 v2.8.7\n067e5a5 fixup for #1553 (#1555)\n\nSee the full diff.\n\n. ## Version 2.8.8 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 7 commits .\n\n144052c v2.8.8\n65c848c include benchmark.js in test suite (#1564)\n8a8a94a fix deep cloning of labels (#1565)\n8153b7b transform function calls to IIFEs (#1560)\nd787d70 avoid substitution of global variables (#1557)\n3ac2421 collapse_vars: do not replace a constant in loop condition or init (#1562)\na9fc9dd suppress semicolons after do/while (#1556)\n\nSee the full diff.\n\n. ## Version 2.8.9 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 5 commits .\n\n344d11d v2.8.9\nc7cdcf0 fix function name eliminiation (#1576)\n3ee5574 only run benchmark & jetstream on CI (#1571)\ndedbeef plan B for IE8 do-while semi-colon fix (#1572)\nbd6dee5 fix return from recursive IIFE (#1570)\n\nSee the full diff.\n\n. ## Version 2.8.10 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 5 commits .\n\ne9920f7 v2.8.10\n7e465d4 scan RHS of dropped assignments (#1581)\naa80ee3 remove checkboxes from Issues template\n80e8176 explain how to make a proper bug report (#1579)\n711f88d scan assignment value in drop_unused() (#1578)\n\nSee the full diff.\n\n. ## Version 2.8.11 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.11\n\u00a0\n\n\nCommits\nThe new version differs by 5 commits .\n\ncf45e2f fixup for #1585 (#1589)\n8354758 v2.8.11\n9e6b128 fix catch variable reference in IE8 (#1587)\n93cdb19 Correctly raise a parse exception with a missing loop body (#1585)\nb633706 fix & improve function argument compression (#1584)\n\nSee the full diff.\n\n. ## Version 2.8.12 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.12\n\u00a0\n\n\nCommits\nThe new version differs by 4 commits .\n\n919d5e3 v2.8.12\ne3a3db7 temporary fix for boolean bug (#1597)\nd9344f3 disallow parameter substitution for named IIFEs (#1596)\nbe80f7e support multi-line string in tests (#1590)\n\nSee the full diff.\n\n. ## Version 2.8.13 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.13\n\u00a0\n\n\nCommits\nThe new version differs by 8 commits .\n\nb2b8a0d v2.8.13\nac40301 fix chained evaluation (#1610)\n3563d8c extend test/run-tests.js to optionally execute uglified output (#1604)\n5ae04b3 make collapse_vars consistent with toplevel (#1608)\na80b228 fix hoist_vars on reduce_vars (#1607)\ncf4bf4c fix stack issues with AST_Node.evaluate() (#1603)\n8223b2e fix AST_Node.optimize() (#1602)\n381bd38 minor clean-ups (#1600)\n\nSee the full diff.\n\n. ## Version 2.8.14 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.14\n\u00a0\n\n\nCommits\nThe new version differs by 8 commits .\n\n30a7504 v2.8.14\na3cc3a9 make expect_stdout work on Node.js 0.12 (#1623)\n96f8bef fix commit 88fb83a (#1622)\ncd58635 fix AST_Binary.lift_sequences() (#1621)\n274331d transform String.charAt() to index access (#1620)\n0489d6d handle runtime errors in expect_stdout (#1618)\nfb09283 fix top-level directives in compress tests (#1615)\nb7c112e Add --in-source-map inline documentation (#1611)\n\nSee the full diff.\n\n. ## Version 2.8.15 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.15\n\u00a0\n\n\nCommits\nThe new version differs by 6 commits .\n\n6b2f347 v2.8.15\n48ffbef account for cross-scope modifications in collapse_vars (#1634)\nc0f3fea introduce compressor.info() (#1633)\na00040d fix a bug in simple_glob (#1632)\nee95c1b metadata cleanup (#1630)\n4bceb85 throw parse error on invalid assignments (#1627)\n\nSee the full diff.\n\n. ## Version 2.8.16 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.16\n\u00a0\n\n\nCommits\nThe new version differs by 12 commits .\n\n491f16c v2.8.16\na30092e fix invalid AST_For.init (#1657)\nb1abe92 introduce ufuzz.js (#1655)\nb454ce6 Update ISSUE_TEMPLATE.md\n32283a0 fix cascade of evaluate optimisation (#1654)\nac51d4c fix corner case in AST_For.init (#1652)\n0432a7a fix assignment extraction from conditional (#1651)\nf3a1694 fix assignment substitution in sequences (#1643)\n2e0dc97 improve error marker placement (#1644)\n7010356 fix expect_stdout (#1642)\n79334dd fix regression: CLI options with hyphens like -b ascii-only (#1640)\ne918748 improve collapsible value detection (#1638)\n\nSee the full diff.\n\n. ## Version 2.8.17 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.17\n\u00a0\n\n\nCommits\nThe new version differs by 26 commits .\n\n6ab3224 v2.8.17\nc909ffb fix unused on var of the same name within catch (#1716)\nf71f490 fix is_number() on += (#1714)\nfb177a6 drop anonymous function name when overshadowed by other declarations (#1712)\n65da9ac handle var within catch of the same name (#1711)\n67d0237 fix tail trimming of switch blocks (#1707)\n984a217 fix mangle for variable declared within catch block (#1706)\naa3f647 ufuzz: workaround for Function.toString() v2 (#1700)\nc526da5 has_side_effects() should take AST_Switch.expression into account (#1699)\n581630e fix typeof side effects (#1696)\nf595293 preserve side effects in switch expression (#1694)\nf001e4c fix cascade on anonymous function reference (#1693)\n57ce5bd handle overlapped variable definitions (#1691)\n861a79a fix delete related issues in collapse_vars and reduce_vars (#1689)\n00996af ufuzz: workaround function name and toString() (#1688)\n\nThere are 26 commits in total. See the full diff.\n\n. ## Version 2.8.18 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.18\n\u00a0\n\n\nCommits\nThe new version differs by 3 commits .\n\nae740b9 v2.8.18\nec7f37f remove UGLIFY_DEBUG (#1720)\neb48a03 fix corner case in unused (#1718)\n\nSee the full diff.\n\n. ## Version 2.8.19 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.19\n\u00a0\n\n\nCommits\nThe new version differs by 10 commits .\n\na84564d v2.8.19\nc595b84 fix catch symbol mangling (#1734)\n7cb1adf remove paranthesis for -(x*y) (#1732)\n7bea38a optimize try-catch-finally (#1731)\n0f910ee improve tests from #1726 (#1729)\nbeb9659 speed up IIFE elimination (#1728)\nf1a833a speed up equivalent_to() and AST_Switch (#1727)\n2e41cd6 fix missing parentheses around NaN/Infinity shorthands (#1726)\n09f77c7 output optimal representations of NaN & Infinity (#1723)\nfef0bf9 improve beautified output of switch blocks (#1721)\n\nSee the full diff.\n\n. ## Version 2.8.20 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.20\n\u00a0\n\n\nCommits\nThe new version differs by 2 commits .\n\nf8a71b5 v2.8.20\n11e9bdc fix missing preamble when shebang is absent (#1742)\n\nSee the full diff.\n\n. ## Version 2.8.21 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.21\n\u00a0\n\n\nCommits\nThe new version differs by 15 commits .\n\nb7f6b73 v2.8.21\n9469c03 fix corner case in switch (#1765)\nd575276 avoid confusion of NaN & Infinity with catch symbol of the same name (#1763)\nf7ca4f2 fix corner cases in switch and undefined (#1762)\nc076e7b speed up fuzzer code generation (#1757)\n4a55bb0 minor tweaks to test/ufuzz.js (#1756)\n28ecea5 upgrade fuzzer (#1754)\n9a31170 fuzz regexp literals, more constant numbers, typeof expression (#1755)\nee3fe0f fix switch branch elimination (#1752)\n87f6e1b minor tweaks to fuzzer (#1751)\nc934fc8 implement test/sandbox.js (#1749)\n257ddc3 improve compression of undefined, NaN & Infinitiy (#1748)\n1ddc057 combine rules for binary boolean operations (#1744)\ne6b76a4 Massive extension of the fuzzer (#1697)\na0c3836 sort options in alphabetical order (#1743)\n\nSee the full diff.\n\n. ## Version 2.8.22 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv2.8.22\n\u00a0\n\n\nCommits\nThe new version differs by 21 commits .\n\n04b8964 v2.8.22\nd6fbc36 fix LHS cases for NaN & friends (#1804)\n9a97884 enhance test/ufuzz.js (#1803)\n0479ff0 fix a couple of bugs in global_defs (#1802)\ncf72fe5 fix delete corner cases (#1799)\na1532eb extend ufuzz generator (#1783)\nc2a1bce fix pure_getters for chained property access (#1798)\ne3c9c22 fix corner cases with delete (#1796)\n0f4cd73 introduce \"strict\" to pure_getters (#1795)\n281e882 fix reduce_vars on catch variable (#1794)\ncc6aa3e fix incorrect context in variable substitution (#1791)\ne869779 enable inline_script by default (#1793)\n06cdb74 improve pure_getters (#1786)\nff289b9 implement delayed resolution for reduce_vars (#1788)\n9b6bc67 optimise do{...}while(false) (#1785)\n\nThere are 21 commits in total. See the full diff.\n\n. ## Version 3.0.0 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.0\n\u00a0\n\n\nCommits\nThe new version differs by 34 commits0.\n\n7313465 v3.0.0\n2c7ee95 fix unsafe on evaluate of reduce_vars (#1870)\necf3563 kill opera (#1869)\ndee5a27 enhance collapse_vars (#1862)\n5a25d24 rename variables for better readability (#1863)\nbffdc8d update test/benchmark.js resources (#1864)\n69b5663 restore report of supported options (#1861)\nea92897 improve literal return optimization (#1860)\n2cb55b2 enforce toplevel on other compress options (#1855)\nbbb5f2a Update ISSUE_TEMPLATE.md (#1846)\n76d19b6 fix fuzzer on this (#1842)\n9e62628 fix unused on for-in statements (#1843)\n9bf72cf improve parser under \"use strict\" (#1836)\n64d7443 update README for 3.x (#1840)\n45ce369 fix AST_For.init patch-up in drop_unused() (#1839)\n\nThere are 34 commits in total.\nSee the full diff\n\n. ## Version 3.0.1 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.1\n\u00a0\n\n\nCommits\nThe new version differs by 7 commits0.\n\n014f428 v3.0.1\na3b2eb7 return Error from minify() (#1880)\nda295de support dumping AST (#1879)\n4f8ca46 deprecate low level API (#1877)\ne547483 support minify() output as AST (#1878)\n2d99d06 update documentation\n98cf95e fix test for #1865 (#1873)\n\nfalse\nSee the full diff\n\n. ## Version 3.0.3 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.3\n\u00a0\n\n\nCommits\nThe new version differs by 11 commits0.\n\naae7d49 v3.0.3\n0459af2 Update issue template: change harmony to uglify-es (#1900)\n04f2344 Remove unnecessary git clone instructions in README (#1897)\nbad9d5c Change harmony to uglify-es in master README (#1895)\na0f5f86 gracefully handle non-Error being thrown (#1893)\n41996be extend test timeout\n5fd8244 v3.0.2\nc14e280 print error stack in CLI (#1890)\nbc3fa78 mention minify().error\n8c7c107 update minify() usage in test/ufuzz.js (#1888)\n3dd328d [3.x] fix documentation for beautify options (#1882)\n\nfalse\nSee the full diff\n\n. ## Version 3.0.4 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.4\n\u00a0\n\n\nCommits\nThe new version differs by 5 commits0.\n\ndaaefc1 v3.0.4\n1d407e7 fix invalid transform on const (#1919)\n2b44f4a update README (#1918)\ne51c354 fix typo (#1913)\n3bf1946 update documentation (#1909)\n\nfalse\nSee the full diff\n\n. ## Version 3.0.5 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.5\n\u00a0\n\n\nCommits\nThe new version differs by 9 commits0.\n\nff526be v3.0.5\ne005099 fix & improve coverage of estree (#1935)\n504a436 Tweak README Notes (#1934)\n3ca9022 fix bugs with getter/setter (#1926)\nfd09512 document 3 max passes (#1928)\n9e29b6d clarify wording (#1931)\nc391576 remove support for const (#1910)\nac73c5d avoid arguments and eval in reduce_vars (#1924)\n547f41b add documentation for side_effects & [#@]__PURE__ (#1925)\n\nfalse\nSee the full diff\n\n. ## Version 3.0.6 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.6\n\u00a0\n\n\nCommits\nThe new version differs by 6 commits0.\n\n050474a v3.0.6\nf6c805a print package name alongside version in CLI (#1946)\n9464d3c fix parsing of property access after new line (#1944)\nf18abd1 minor fixes to README.md\n3be06ad reorg README for 3.x (#1942)\n265008c improve keyword-related parser errors (#1941)\n\nfalse\nSee the full diff\n\n. ## Version 3.0.7 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.7\n\u00a0\n\n\nCommits\nThe new version differs by 2 commits.\n\nc881394 v3.0.7\ncb45886 export TreeTransformer (#1950)\n\nSee the full diff\n\n. ## Version 3.0.8 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.8\n\u00a0\n\n\nCommits\nThe new version differs by 7 commits.\n\n43add94 v3.0.8\nefcf167 make expect_stdout node version specific (#1963)\n6ed9091 fix docs for side_effects flag to reflect current behavior (#1966)\n569c21e improve RegExp handling (#1959)\n87c3a2c remove space_colon (#1960)\nbaef8bf update output options in readme (#1958)\n0813c53 remove Travis CI badge\n\nSee the full diff\n\n. ## Version 3.0.9 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.9\n\u00a0\n\n\nCommits\nThe new version differs by 2 commits.\n\n3408fc9 v3.0.9\neae2675 introduce unsafe_regexp (#1970)\n\nSee the full diff\n\n. ## Version 3.0.10 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.10\n\u00a0\n\n\nCommits\nThe new version differs by 6 commits.\n\nd3c4a8e v3.0.10\n7e164ab add \"es5\" to package.json keywords (#1980)\n22aedef document minify() option toplevel (#1979)\n58fae7d enhance if_return to handle return void... (#1977)\n5bf8d7e document 3.x minify() does not throw errors (#1975)\n1df9d06 document minify warnings and add an error example (#1973)\n\nSee the full diff\n\n. ## Version 3.0.11 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv3.0.11\n\u00a0\n\n\nCommits\nThe new version differs by 5 commits.\n\ne95052a v3.0.11\ne667f0a fix source map offset (#1993)\n69ac794 add another minify() options example (#1988)\nefdb659 improve usability of global_defs in minify() (#1987)\na1dedeb more refinement of minify() documentation (#1983)\n\nSee the full diff\n\n. ## Version 4.0.10 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 20 commits (ahead by 20, behind by 18).\n\n9d26ac4 Version 4.0.10 release notes.\n9be432a Bumps clean-css dependency to 4.0.10.\n9b4e745 Version 4.0.9 release notes.\n634861a Bumps clean-css dependency to 4.0.9.\n0ca9845 Version 4.0.8 release notes.\n2b12089 Bumps clean-css dependency to 4.0.8.\n6be8e47 Version 4.0.7 release notes.\n2c9b6f2 Bumps clean-css dependency to 4.0.7.\nee3f37b Version 4.0.6 release notes.\n540d8ff Bumps clean-css dependency to 4.0.6.\na7a880d Version 4.0.5 release notes.\n770aba7 Bumps clean-css dependency to 4.0.5.\nef2f413 Version 4.0.4 release notes.\n3acc576 Bumps clean-css dependency to 4.0.4.\n2f67b66 Corrects release comparison links in changelog.\n\nThere are 20 commits in total. See the full diff.\n\n. ## Version 4.0.11 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 22 commits (ahead by 22, behind by 20).\n\ndb54d25 Version 4.0.11.\n3f59a5f Bumps clean-css dependency to 4.0.11.\n121cd90 Version 4.0.10.\nb7c06a0 Bumps clean-css dependency to 4.0.10.\n23d67eb Version 4.0.9.\n95cd0d5 Bumps clean-css dependency to 4.0.9.\n7af2a8f Version 4.0.8.\n3830ae1 Bumps clean-css dependency to 4.0.8.\n30f03f1 Version 4.0.7.\n6d28bf5 Bumps clean-css dependency to 4.0.7.\nb79a554 Version 4.0.6.\n1b9fa20 Bumps clean-css dependency to 4.0.6.\n325cd6b Version 4.0.5.\n40443cc Bumps clean-css dependency to 4.0.5.\n4600371 Version 4.0.4.\n\nThere are 22 commits in total. See the full diff.\n\n. ## Version 4.0.12 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits .\n\n97d2199 Version 4.0.12.\n31efa4a Bumps clean-css dependency to 4.0.12.\n\nSee the full diff.\n\n. ## Version 4.1.0-pre just got published. \nUpdate to this version instead \ud83d\ude80 \n. ## Version 4.1.0 just got published. \nUpdate to this version instead \ud83d\ude80 \n. ## Version 4.1.1 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits0.\n\nf7c229a Version 4.1.1.\nf64cbf9 Bumps clean-css dependency to 4.1.1.\n\nfalse\nSee the full diff\n\n. ## Version 4.1.2 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits0.\n\nf57ac2a Version 4.1.2.\ndefdaf9 Bumps clean-css dependency to 4.1.2.\n\nfalse\nSee the full diff\n\n. ## Version 4.1.3 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 2 commits.\n\ne4f28f2 Version 4.1.3.\n6b5feda Bumps clean-css dependency to 4.1.3.\n\nSee the full diff\n\n. ## Version 1.7.0 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nv1.7.0\nBug Fixes\n\nmiddleware: change to use vanilla for loop (ac62cc0), closes #2671\nreporters: Revert the backwards-incompatible log priority order changes (316b944), closes #2582\n\nFeatures\n\nrunner: Buffer stdout and stderr for output when errors occur (460d423)\n\n\n\nCommits\nThe new version differs by 11 commits0.\n\n2a847c2 chore: release v1.7.0\n47e52e4 chore: update contributors\na99dc52 chore: fix lint task\n51b4f64 Merge pull request #2682 from wesleycho/fix/for-in\nac62cc0 fix(middleware): change to use vanilla for loop\n14b6dfd Merge pull request #2664 from LoveIsGrief/feature-karma-2663\n722bbbb docs: add notice about casing in exports\ne93d1e3 Merge pull request #2676 from mgol/log-order-fixes\n316b944 fix(reporters): Revert the backwards-incompatible log priority order changes\nef62da9 test(reporters): Fix the log suppressing tests\n460d423 feat(runner): Buffer stdout and stderr for output when errors occur\n\nfalse\nSee the full diff\n\n. ## Version 3.0.2 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 5 commits .\n\n0dbccf3 3.0.2 released\nf0b443d Browser files rebuild\n3497540 Make node_canvas use more local\n5326383 Fix wasm crash on upscale, close #87\n562b0e7 Fix macros\n\nSee the full diff.\n\n. ## Version 3.0.3 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 5 commits .\n\n9f87533 3.0.3 released\n32ec98f Browser files rebuild\n2752bc7 Readme update\nc35575a Block cib resize by default - bad quality\n28bc091 Add debug messages + fix cib detection\n\nSee the full diff.\n\n. ## Version 3.0.4 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nCommits\nThe new version differs by 4 commits .\n\n99eb078 3.0.4 released\necbfb46 Browser files rebuild\n38b1f1e IE fixes\n10c017d Update readme example/docs\n\nSee the full diff.\n\n. ## Version 3.4.0 just got published. \nUpdate to this version instead \ud83d\ude80 \n. ## Version 3.4.1 just got published. \nUpdate to this version instead \ud83d\ude80 \n\nRelease Notes\nOhai CRLF...\nFixed a publishing mishap with git's autocrlf settings.\n\n\nCommits\nThe new version differs by 3 commits0.\n\nac0c1c8 v3.4.1\n64d96d3 :ship: Release v3.4.0\n4e3252e Force rebuild of mocha.js on npm version\n\nfalse\nSee the full diff\n\n. ",
    "farskid": "Yeah sure. My upload process has two phases. In the first phase, users submit their file to fine uploader and it uploads it to a temp folder inside my upload server. Then in phase two Nodejs streams these temp files to the permanent server.\nThe problem\nFine uploader changes files status to success as soon as the file is uploaded to the temp server, but what I actually need is that I want to hold the file's status until Nodejs streams the file to the primary server successfully. It could be done (I guess), once onComplete listener accept a promise object and change the status to success when the promise resolves, or change it to failed when promises rejects.. Don't know how to defer it to uploader from my server.\nWhat I'm doing now is something like this:\ncallbacks: {\n  onSubmit: (id, name) => {\n    return new Promise((resolve, reject) => {\n      checkForUploadPermission(name, size).then((response) => {\n        if (response.success) resolve(response)\n        else reject('Not Permitted!')\n      })\n    }),\n    onComplete: (id, name) => {\n      // Since onComplete does not accept a promise, It doesn't wait for server resonse and evaluates the status to success immidiately\n      return new Promise((resolve, reject) => {\n        uploadToPermanentServer(name, size).then((response) => {\n          if (response.success) resolve(response)\n          else reject('Upload to permanent server failed!')\n        })\n      })\n  }\n}. I managed to solve the issue eventually by not using the Gallery higher order component. I used the stateless components such as Thumbnail manually and Did not listen to the status that uploader sends to the file after onStatusChange. What solved this was to connect the uploader component to my reducer which updates file's status when my NodeJS server has finished it's async upload back there. By the way, I'm using React Fine Uploader.. About the Thumbnail, My bad.\nI added some useful components to my package of React fine uploader, I could send a PR if you wish. Thanks for the great support and fabiolous library.. ",
    "OndrejIT": "@rnicholus \n<!-- Fine Uploader JS file\n    ====================================================================== -->\n    <script src=\"/static/fine-uploader/fine-uploader.js\"></script>\n    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js\"></script>\n...\n    \n<!-- Your code to create an instance of Fine Uploader and bind to the DOM/template\n====================================================================== -->\n<script>\n    var manualUploader = new qq.FineUploader({\n        element: document.getElementById('fine-uploader-manual-trigger'),\n        template: 'qq-template-manual-trigger',\n        request: {\n            endpoint: \"/upload-server/upload\"\n        },\n        chunking: {\n            enabled: true,\n            success: {\n                endpoint: \"/upload-server/chunksdone\"\n            }\n        },\n        thumbnails: {\n            placeholders: {\n                waitingPath: '/static/fine-uploader/placeholders/waiting-generic.png',\n                notAvailablePath: '/static/fine-uploader/placeholders/not_available-generic.png'\n            }\n        },\n        maxConnections: 3,\n        autoUpload: false,\n        debug: true\n    })\n\n    qq(document.getElementById(\"trigger-upload\")).attach(\"click\", function() {\n        manualUploader.uploadStoredFiles();\n    });\n</script>\n\n`. > And also let me know when this last worked (version)\nI don't know, I tested 5.13.0, 5.10.0 - Not working.... In docs:\nProviding your own UUID for files\n\nIf you would like to track files with your own generated UUID, you can return the new UUID for the file at any time in your server's response. If chunking is enabled, it generally would be most prudent to return this new UUID in the response to the first or last chunk. Once you return the new UUID in your response, Fine Uploader will update its client-side records and begin to use that UUID from that point forward. New UUIDs must be returned as the value of a newUuid property. See the values section above for an example.\nhttp://docs.fineuploader.com/endpoint_handlers/traditional.html\n. ok thx.. \n",
    "AlexC": "@rnicholus I too would like the behaviour that is documented. Is there a workaround to change the UUID based on a response callback?. Thanks for the quick response, that's just what I was after. Here's what I'm doing for other peoples reference:\nonUploadChunkSuccess: (id, chunkData, response) => { uploader.methods.setUuid(id, response.uuid) }. ",
    "sellou": "I experience the same problem with chunked upload. \nMy need is to free chunks on the server when the upload is canceled. The problem is that when we submit the file through addFile, we don't get an id or uuid in return to trace the upload.\nWhen we add our own id through params to addFile, we don't get it back when we call getUploads. \nThis leaves us with no means to trace uploads when canceled. We tried to use newUuid but it is not working. Do you have any suggestion ?\nThanks.. ",
    "andreiucm": "I have the same problem as @sellou. Would be highly useful if addFile will return id/UUID or both. I use S3 and can't use the newUUID because even if I set the param object I am not able to get these params within FineUploader.getUploads(id)method. After uploading the file I use the returned URL to submit this URL to my backend and register the file to be used(play video) by the logged USER on my Web APP. So if addFile will return the ID or UUID everything will be much easier.\nNote: just add that I noted the UUID can change in case we already uploaded some % of a file and the resume feature is used. In that case inside onSubmit callback we have one UUID and inside onUpload callback we have another UUID, So will be nice if addFile will return consistent UUID.. Ok I will try to simplify because my project is more complicated and I use coffeescript. Hope this is not a problem.\nFirst file\n```\nimport qq from \"fine-uploader/lib/s3\"\n   @fineUploader = new qq.s3.FineUploaderBasic(\n   {\n        debug: true\n        autoUpload: true\n        multiple: false\n        objectProperties:\n            bucket: \"----------------------------------------------\"\n        request:\n            accessKey: \"-------------------------------------------\"\n            endpoint: \"------------------------------------------\"\n        signature:\n            endpoint: \"------------------------------------------\"\n        deleteFile:\n            enabled: true\n            endpoint: \"------------------------------------------\"\n        validation:\n            sizeLimit: 2147483648\n            allowEmpty: false\n            itemLimit: 20\n        chunking:\n            enabled: true\n            mandatory: true\n        resume:\n            enabled: true\n            recordsExpireIn: 7\n        callbacks: {\n            onSubmit: (id, name) =>\n                # Called when the item has been selected and is a candidate for uploading\n                @createUploadProcess id\n\n            onUpload: (id, name) -> _.noop()\n                # Called just before an item begins uploading to the server.\n\n            onResume: (id, name, chunkData) -> _.noop()\n                #Called just before an upload is resumed\n\n            onComplete: (id, name, responseJSON, xhr ) =>\n                # Why responsJSON doesn't contain the url???\n\n\n            onAllComplete: (succeeded, failed) -> _.noop()\n                # succeeded - ids of succesfuly uploaded files / failed ...\n\n            onProgress: (id, name, uploadedBytes, totalBytes) =>\n                progress = Math.floor((uploadedBytes*100)/totalBytes)\n                @updateUploadProcess id, progress: progress\n\n            onTotalProgress: (totalUploadedBytes, totalBytes) =>\n                @totalProgress = Math.floor((totalUploadedBytes*100)/totalBytes)\n\n            onCancel: (id, name) =>\n                # Called when the item has been canceled.\n                @removeUploadProcess id\n\n            onDelete: (id) =>\n                # Called just before a delete request is sent for the associated item\n                @updateUploadProcess id, progress: 0\n\n            onDeleteComplete: (id, xhr, isError) =>\n                # Called just after receiving a response from the server for a delete file request.\n                @removeUploadProcess id\n\n            onStatusChange: (id, oldStatus, newStatus) =>\n                if newStatus in [ @status.REJECTED, @status.UPLOAD_FAILED ]\n                then @removeUploadProcess id\n                else @updateUploadProcess id, status: newStatus\n        }\n    }\n\n)\nSecond file \nimport qq from \"fine-uploader/lib/s3\"\nprofile come from global @profilesList\n@profile.dropZone = new qq.DragAndDrop(\n    {\n            dropZoneElements: [@profile.zoneElement]\n            classes:\n                dropActive: @profile.dropActiveClass\n            allowMultipleItems: false\n            callbacks: (\n                processingDroppedFiles: ()  ->\n                    # TODO: display some sort of a \"processing\" or spinner graphic\n            processingDroppedFilesComplete: (files, dropTarget) =>\n                # TODO: hide spinner/processing graphic                              \n                # @fineUploader is global\n\n                @fineUploader.addFiles [files]\n\n                 uploads = @fineUploader.getUploads()  this return a lot of uploads\n\n                 profile.uuid = upload.uuid ???? how t get the upload corresponding to the dropped file\n\n```\n                MY ISSUE!\n                how t be sure what is the upload corresponding to the dropped file because I am sure I \n                drop only one file\n                because the multiple is false**\n\n                I like to associate the profile with the upload recently started\n\n                If addFiles will return a list of uploads or at least a list of uuids but maybe I missing  \n                something and i can realize what I need with the existing stuff\n\n```                 \n            dropError: (errorCode, errorRelatedData) ->\n                @onDropError?(errorRelatedData)\n        }  \n}\n\n)                  \n```. ",
    "CoolGoose": "Hi @rnicholus \nI'm using the below code to do some vuejs integration work (among other things, let me know if you want the full js code for the section.\nIf you mean why would I 'delete' a file without the ajax request, mostly since there's a message queue in the back that handles the removal of files.\n``js\nonSubmitDelete(id) {\n    swal({\n        title: 'Are you sure?',\n        text: \"Remember to save your changes!\",\n        type: 'warning',\n        showCancelButton: true,\n        confirmButtonColor: '#3085d6',\n        cancelButtonColor: '#d33',\n        confirmButtonText: 'Yes, delete it!'\n    }).then(() => {\n        vm.$store.dispatch(addons/deleteFile`,\n            { filename: this.getName(id), uploadRef: vm.uploadRef }\n        ).then(() => {\n            $(this.getItemByFileId(id)).remove();\n        });\n    });\nreturn false;\n\n},\n```. I'm actually not even doing an ajax request on delete, i'm updating the list of available items in vue, and on the page's update method i'm saving it to persistance with the updated object containing the various aspects of the product (text, description, current image list and a flag that says it should trigger a delete process).\nThe point that you bring up is valid however, it's a way of controlling the delete process by itself outside of fineUploader, and the closest and fastest thing i could think of is allowing control of the various states of the files by hand.. @rnicholus didn't see that yet, thank you for the heads up.\nMy vue integration is way more crude, and it's based around the default fineUploader templates and methods, without a major sort of rewrite (hooking into events and api's)\nThe alternative for setStatus, would be a way of changing the status from within onSubmitDelete event, or allow it to 'pass' without doing any type of ajax request.\n. @rnicholus that's true ;) I agree for a better long term solution that would help maintainability .\nWould you want me to do an initial rough pull request with:\n\nsetStatus with DELETE and DELETE_FAILED\nextract onDeleteComplete if/else into _handleDeleteSuccess / _handleDeleteFailed ?\nupdate the docs with the info ?\n. @rnicholus I've written an initial pull requests so we can discuss the changes. https://github.com/FineUploader/fine-uploader/pull/1739. @rnicholus I've added documentation, getNetUploads options, modified the condition and added a qq.error throw in addition to the console.log . Hopefully i didn't miss anything. @rnicholus should be moved now into then, and added done as a param to it and called it by hand after the asserts. I hope it's good :) my mocha testing is somewhere around 0\n. \n",
    "jedie": "Then you should create a blog entry with a link to https://github.com/FineUploader/fine-uploader/releases\nAnd also add a link into README ;). ",
    "ajaysingh13500": "hay why you closed it..... ",
    "sourabhnighot": "Hi Nicholas,\nI have attached the html page in which we use fine uploader to upload file.\nYou can just open the html page and see the console error in the console\nwindow of Google Chrome Browser.\nOn Mon, Feb 6, 2017 at 8:46 PM, Ray Nicholus notifications@github.com\nwrote:\n\nSorry, I'm unable to reproduce without seeing your code. This sounds like\nan issue specific to your setup/code, but I'll be happy to consider\nre-opening once you update the issue with all of the code needed to\nreproduce.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1742#issuecomment-277712826,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AYZoxgInXRm0RQMMJzbGwfFXisJNNRzrks5rZzlMgaJpZM4L4LUo\n.\n. Strange because I had attached and I can see. No problem I will attach the\nhtml file again.\n\nOn Thu, Feb 9, 2017 at 7:43 PM, Ray Nicholus notifications@github.com\nwrote:\n\nNothing is attached\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1742#issuecomment-278652109,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AYZoxo2x_wN1BgB6x7BBh3gPCrw-3sdSks5rax8jgaJpZM4L4LUo\n.\n. \n",
    "rainstormza": "@rnicholus Is it not possible to use with angular 2 ?\n. @sgwatgit Do you use fine-uploader with angular-cli ?. @sgwatgit I try it with angular-cli but it seem doesn't work for me\nCould you please show me the instruction ?\nmy code \n```\nimport { Component, OnInit } from '@angular/core';\ndeclare var qq:any;\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.css']\n})\nexport class AppComponent implements OnInit {\n  title = 'app works!';\nconstructor() { }\nngOnInit() {\n    let uploader = new qq.FineUploader({\n});\n\n}\n}\n```\nError \nEXCEPTION: Error in :0:0 caused by: Cannot find template script at ID 'qq-template'!\nthanks. @rnicholus I try to chnage \n<script type=\"text/template\" id=\"qq-template-gallery\">\nto\n<div id=\"qq-template-gallery\">\nbut upload page not appear. @rnicholus  @SinghSukhdeep \nso this my step and my code\nng new new-project // for create project using angular-cli\nnpm install fine-uploader --save // install fine-uploader to my angular-cli project\nimport css and js file into project like this\n.angular-cli.json file\n\"styles\": [\n        \"styles.css\",\n        \"../node_modules/fine-uploader/fine-uploader/fine-uploader-gallery.min.css\"\n      ],\n      \"scripts\": [\n        \"../node_modules/fine-uploader/fine-uploader/fine-uploader.min.js\"\napp.component.ts file\n/// <reference types=\"fine-uploader\" />\nimport { Component, OnInit } from '@angular/core';\n// declare var qq:any;\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.css']\n})\nexport class AppComponent implements OnInit {\n  // title = 'app works!';\nuploader: FineUploader.qq;\nuiOptions: FineUploader.UIOptions;\ncoreEvents: FineUploader.CoreEvents;\n\nconstructor() { }\nngOnInit() {\n    /*\n     * Prepare/set options for the core + UI FineUploader\n     /\n    this.uiOptions = {\n        element: document.getElementById('fine-uploader-gallery'),\n        template: \"qq-template-gallery\"\n    }\n/**\n * Instantiate the FineUploader and pass in the uiOptions\n */\nlet uploader: FineUploader.qq = new qq.FineUploader(this.uiOptions);\n  }\n}\n\napp.componet.html file\n Fine Uploader Gallery template\n    ====================================================================== \n<script type=\"text/template\" id=\"qq-template-gallery\">\n    <div class=\"qq-uploader-selector qq-uploader qq-gallery\" qq-drop-area-text=\"Drop files here\">\n        <div class=\"qq-total-progress-bar-container-selector qq-total-progress-bar-container\">\n            <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-total-progress-bar-selector qq-progress-bar qq-total-progress-bar\"></div>\n        </div>\n        <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n            <span class=\"qq-upload-drop-area-text-selector\"></span>\n        </div>\n        <div class=\"qq-upload-button-selector qq-upload-button\">\n            <div>Upload a file</div>\n        </div>\n        <span class=\"qq-drop-processing-selector qq-drop-processing\">\n            <span>Processing dropped files...</span>\n            <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n        </span>\n        <ul class=\"qq-upload-list-selector qq-upload-list\" role=\"region\" aria-live=\"polite\" aria-relevant=\"additions removals\">\n            <li>\n                <span role=\"status\" class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n                <div class=\"qq-progress-bar-container-selector qq-progress-bar-container\">\n                    <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n                </div>\n                <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n                <div class=\"qq-thumbnail-wrapper\">\n                    <img class=\"qq-thumbnail-selector\" qq-max-size=\"120\" qq-server-scale>\n                </div>\n                <button type=\"button\" class=\"qq-upload-cancel-selector qq-upload-cancel\">X</button>\n                <button type=\"button\" class=\"qq-upload-retry-selector qq-upload-retry\">\n                    <span class=\"qq-btn qq-retry-icon\" aria-label=\"Retry\"></span>\n                    Retry\n                </button>\n\n                <div class=\"qq-file-info\">\n                    <div class=\"qq-file-name\">\n                        <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n                        <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\" aria-label=\"Edit filename\"></span>\n                    </div>\n                    <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n                    <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n                    <button type=\"button\" class=\"qq-btn qq-upload-delete-selector qq-upload-delete\">\n                        <span class=\"qq-btn qq-delete-icon\" aria-label=\"Delete\"></span>\n                    </button>\n                    <button type=\"button\" class=\"qq-btn qq-upload-pause-selector qq-upload-pause\">\n                        <span class=\"qq-btn qq-pause-icon\" aria-label=\"Pause\"></span>\n                    </button>\n                    <button type=\"button\" class=\"qq-btn qq-upload-continue-selector qq-upload-continue\">\n                        <span class=\"qq-btn qq-continue-icon\" aria-label=\"Continue\"></span>\n                    </button>\n                </div>\n            </li>\n        </ul>\n\n        <dialog class=\"qq-alert-dialog-selector\">\n            <div class=\"qq-dialog-message-selector\"></div>\n            <div class=\"qq-dialog-buttons\">\n                <button type=\"button\" class=\"qq-cancel-button-selector\">Close</button>\n            </div>\n        </dialog>\n\n        <dialog class=\"qq-confirm-dialog-selector\">\n            <div class=\"qq-dialog-message-selector\"></div>\n            <div class=\"qq-dialog-buttons\">\n                <button type=\"button\" class=\"qq-cancel-button-selector\">No</button>\n                <button type=\"button\" class=\"qq-ok-button-selector\">Yes</button>\n            </div>\n        </dialog>\n\n        <dialog class=\"qq-prompt-dialog-selector\">\n            <div class=\"qq-dialog-message-selector\"></div>\n            <input type=\"text\">\n            <div class=\"qq-dialog-buttons\">\n                <button type=\"button\" class=\"qq-cancel-button-selector\">Cancel</button>\n                <button type=\"button\" class=\"qq-ok-button-selector\">Ok</button>\n            </div>\n        </dialog>\n    </div>\n</script>\n\nmy error console\nEXCEPTION: Error in :0:0 caused by: Cannot find template script at ID 'qq-template-gallery'!\nErrorHandler.handleError @ vendor.bundle.js:53400\nvendor.bundle.js:53402 ORIGINAL EXCEPTION: Cannot find template script at ID 'qq-template-gallery'!\nErrorHandler.handleError @ vendor.bundle.js:53402\nvendor.bundle.js:53405 ORIGINAL STACKTRACE:\nErrorHandler.handleError @ vendor.bundle.js:53405\nvendor.bundle.js:53406 Error: Cannot find template script at ID 'qq-template-gallery'!\n    at J (eval at webpackJsonp.526.module.exports (http://localhost:4201/scripts.bundle.js:28:8), :6:1240) [angular]\n    at new qq.Templating (eval at webpackJsonp.526.module.exports (http://localhost:4201/scripts.bundle.js:28:8), :6:4293) [angular]\n    at new qq.FineUploader (eval at webpackJsonp.526.module.exports (http://localhost:4201/scripts.bundle.js:28:8), :5:27169) [angular]\n    at AppComponent.webpackJsonp.436.AppComponent.ngOnInit (http://localhost:4201/main.bundle.js:69:24) [angular]\n    at Wrapper_AppComponent.ngDoCheck (/AppModule/AppComponent/wrapper.ngfactory.js:22:53) [angular]\n    at CompiledTemplate.proxyViewClass.View_AppComponent_Host0.detectChangesInternal (/AppModule/AppComponent/host.ngfactory.js:28:26) [angular]\n    at CompiledTemplate.proxyViewClass.AppView.detectChanges (http://localhost:4201/vendor.bundle.js:72629:14) [angular]\n    at CompiledTemplate.proxyViewClass.DebugAppView.detectChanges (http://localhost:4201/vendor.bundle.js:72824:44) [angular]\n    at ViewRef_.detectChanges (http://localhost:4201/vendor.bundle.js:54710:20) [angular]\n    at http://localhost:4201/vendor.bundle.js:36624:67 [angular]\n    at Array.forEach (native) [angular]\n    at ApplicationRef_.tick (http://localhost:4201/vendor.bundle.js:36624:25) [angular]\n    at ApplicationRef_.loadComponent (http://localhost:4201/vendor.bundle.js:36599:14) [angular]\n    at ApplicationRef.bootstrap (http://localhost:4201/vendor.bundle.js:36587:14) [angular]\nErrorHandler.handleError @ vendor.bundle.js:53406\nvendor.bundle.js:53409 ERROR CONTEXT:\nErrorHandler.handleError @ vendor.bundle.js:53409\nvendor.bundle.js:53410 DebugContext\nErrorHandler.handleError @ vendor.bundle.js:53410\npolyfills.bundle.js:2794 Unhandled Promise rejection: Error in :0:0 caused by: Cannot find template script at ID 'qq-template-gallery'! ; Zone:  ; Task: Promise.then ; Value: ViewWrappedError Error: Error in :0:0 caused by: Cannot find template script at ID 'qq-template-gallery'!\n    at ViewWrappedError.ZoneAwareError (http://localhost:4201/polyfills.bundle.js:3236:33)\n    at ViewWrappedError.BaseError [as constructor] (http://localhost:4201/vendor.bundle.js:25017:16)\n    at ViewWrappedError.WrappedError [as constructor] (http://localhost:4201/vendor.bundle.js:25082:16)\n    at new ViewWrappedError (http://localhost:4201/vendor.bundle.js:53783:16)\n    at CompiledTemplate.proxyViewClass.DebugAppView.rethrowWithContext (http://localhost:4201/vendor.bundle.js:72854:23)\n    at CompiledTemplate.proxyViewClass.DebugAppView.detectChanges (http://localhost:4201/vendor.bundle.js:72827:18)\n    at ViewRef.detectChanges (http://localhost:4201/vendor.bundle.js:54710:20)\n    at http://localhost:4201/vendor.bundle.js:36624:67\n    at Array.forEach (native)\n    at ApplicationRef_.tick (http://localhost:4201/vendor.bundle.js:36624:25)\n    at ApplicationRef_.loadComponent (http://localhost:4201/vendor.bundle.js:36599:14)\n    at ApplicationRef.bootstrap (http://localhost:4201/vendor.bundle.js:36587:14)\n    at http://localhost:4201/vendor.bundle.js:36399:89\n    at Array.forEach (native)\n    at PlatformRef_._moduleDoBootstrap (http://localhost:4201/vendor.bundle.js:36399:42)\nconsoleError @ polyfills.bundle.js:2794\npolyfills.bundle.js:2796 ZoneAwareError\n.  <div id=\"qq-template-gallery\">\ntry div but error still appear\nEXCEPTION: Error in :0:0 caused by: Cannot set property 'innerHTML' of null\nErrorHandler.handleError @ error_handler.js:54\n(anonymous) @ application_ref.js:261\nwebpackJsonp.599.ZoneDelegate.invoke @ zone.js:330\nonInvoke @ ng_zone.js:273\nwebpackJsonp.599.ZoneDelegate.invoke @ zone.js:329\nwebpackJsonp.599.Zone.run @ zone.js:126\n(anonymous) @ zone.js:679\nwebpackJsonp.599.ZoneDelegate.invokeTask @ zone.js:363\nonInvokeTask @ ng_zone.js:264\nwebpackJsonp.599.ZoneDelegate.invokeTask @ zone.js:362\nwebpackJsonp.599.Zone.runTask @ zone.js:166\ndrainMicroTaskQueue @ zone.js:529\nerror_handler.js:56 ORIGINAL EXCEPTION: Cannot set property 'innerHTML' of null\nnot sure this line of code might be a probelem ?\ntemplate: \"qq-template-gallery\". \nit works :)\n Fine Uploader DOM Element\n    ====================================================================== \n<div id=\"fine-uploader-gallery\"></div>\n\nI forgot this line of code , my bad \nnow I can use any function of fine-uploader library right ?\nanyway , do we have another way for include this library to project ?\nsuch as create this library as a module and then we can add module in app.module.ts and use it by\nangular selector like this\n\nthanks for your helping @SinghSukhdeep  @rnicholus . ",
    "modulbuero": "Uhm, why did you just close this? Is this feature already available and i just didn't see it? . ",
    "stevenAric": "ok, take your time and i am waiting for a response.. Mr rnicholus , i solved this issue on my side and worked perfectly, please review the code.\nthe change will be only in _onValidateBatchCallbackSuccess Event and I will remark the changes by two starting and end comments.\n```\n_onValidateBatchCallbackSuccess: function(validationDescriptors, items, params, endpoint, button) {\n//The Beginning of the updates ################################\nvar getAllSpecsOfCurrentButton=this._extraButtonSpecs[this._getButtonId(button)];//get Specifications of each button to get Validation Rules\nif(getAllSpecsOfCurrentButton&&getAllSpecsOfCurrentButton.validation&&getAllSpecsOfCurrentButton.validation.itemLimit&&getAllSpecsOfCurrentButton.validation.itemLimit>0){ //if it is an extra button and containing validation rules and itemLimit , then make the global _currentItemLimit property = the itemLimit Specified in the validation Rules\n                    this._currentItemLimit=getAllSpecsOfCurrentButton.validation.itemLimit;\n                }\n                else if(!getAllSpecsOfCurrentButton){ //if it isn't an extra button , that means that it is the default uploader button ,so restore the itemLimit Global validation rules to the global _currentItemLimit variable\n                    this._currentItemLimit=this._options.validation.itemLimit;\n                }\n                else{ //in all failure cases, return the global limit variable to itemLimit original value\n                      this._currentItemLimit=this._options.validation.itemLimit;\n                }\n//The end of the Updates   #############################              \n            var errorMessage, itemLimit = this._currentItemLimit, proposedNetFilesUploadedOrQueued = this._netUploadedOrQueued;\n            if (itemLimit === 0 || proposedNetFilesUploadedOrQueued <= itemLimit) {\n                if (items.length > 0) {\n                    this._handleCheckedCallback({\n                        name: \"onValidate\",\n                        callback: qq.bind(this._options.callbacks.onValidate, this, validationDescriptors[0], button),\n                        onSuccess: qq.bind(this._onValidateCallbackSuccess, this, items, 0, params, endpoint),\n                        onFailure: qq.bind(this._onValidateCallbackFailure, this, items, 0, params, endpoint),\n                        identifier: \"Item '\" + items[0].file.name + \"', size: \" + items[0].file.size\n                    });\n                } else {\n                    this._itemError(\"noFilesError\");\n                }\n            } else {\n                this._onValidateBatchCallbackFailure(items);\n                errorMessage = this._options.messages.tooManyItemsError.replace(/\\{netItems\\}/g, proposedNetFilesUploadedOrQueued).replace(/\\{itemLimit\\}/g, itemLimit);\n                this._batchError(errorMessage);\n            }\n        },\n\n```. I am sorry, but honestly,  I can't perfectly deal with repositories specifically on the point of where I should upload the new modified file, but honestly too, I want to be able to help so,  can I upload the file here or in StackOverflow as an issue? . By Mistake , i create this , https://github.com/FineUploader/fine-uploader/pull/1765 , you can delete it and the new one here https://github.com/FineUploader/fine-uploader/pull/1766 and i am sorry for that.. @rnicholus  : i closed the first and here is the second , and after this pull request ended , i will start create a new function called deattachForm() , that release the attached form either by element option or by setForm function, i am waiting for your response.. Never Mind , Take Your Time.. ",
    "varby1984": "fineuploader.txt\n. I apologize, I realized now that the code has undergone a coding and not vinene displayed correctly. I 'the first time I write here. Something wrong?. thanks. Hi  rnicholus. Do you have any news about my problem? Thanks!. ",
    "strokirk": "@rnicholus I see, thanks for the quick response.\nIn my case, I get the error response from a Nginx server which only returns the status code. Would it be possible to handle this case?. ",
    "artursvonda": "@SinghSukhdeep Nope, ok to merge.. Currently because of this I can't upgrade to a new current stable as it breaks my build. I'd be happier if this was merged sooner rather than later. :). ",
    "zaryk": "Edit: cleaning up the code with pre, and adding additional information:\n+1 - In my case, I would need to prompt the user if the file exists, and each file could have a prompt.  Also, with the work around that I provided below, users may complain about additional clicks.  Since the file already exists, there are 4 scenarios that could occur.  \n\nUser can overwrite the file\nUser can rename the file automatically, server would append _1 to the name\nUser can resume the file, maybe because the cache has been removed already and the file on the server is smaller than the uploaded file (clearing history seems to remove it, even if it has not been expired).  Also, it is possible that for whatever reason, one person sees that the file has not been uploaded completely, it has expired, and wants to continue the upload.\nUser can cancel and rename the file manually.  Event would have to be cancellable.\n\nEDIT:\n\nUser drags and drops file\nOnUpload, Prompt the user for Overwrite, Rename, Resume, Cancel\nOnUploader Server Side - Check to see if file already exists and if it does, return the file size on server and a new file name, which may or may not used, but is generated server side.\nIf there is an error or user cancels from prompt, it will not cancel through fineuploader, it will just have a status that isn't used by anything else.  If the status is, ALREADYEXISTS, the deleteFile or cancel cannot remove it from the list.  The continue/pause cannot continue or pause it.  It just sits there until it has been taken care of by the user.\n\n\nI have been able to work around this by checking if the file already exists onsubmit through ajax call (because I still want the file to show) and get the server filesize, and display a link for each file that already exists.  I modified the fineuploader with another status of AlreadyExists, and set the status to this so the other events do not trigger on it. \nNOTE: javascript is not my area of strength:\nRetreives the onsubmitting information:\n\nonSubmitted: function (id, name) {\n                    //Triggered on drag and drop\n                    var file = manualUploader.getFile(id);\n                var result = $.ajax({\n                    type: \"GET\",\n                    url: '/server/upload/exists?foldername=' + (file.qqPath === undefined ? \"\" : file.qqPath) + '&filename=' + file.name + \"&size=\" + manualUploader.getSize(id),\n                    async: false,\n                    cache: false\n                }).responseText;\n\n                var result = jQuery.parseJSON(result);\n                var file = $(\".qq-file-id-\" + id);\n                var selector = file.find(\"#duplicate-selector\");\n                if (result.success === false) {\n\n\n                    file.find(\"#newSizeSelectorValue\").val(result.newSize);\n                    file.find(\"#oldSizeSelectorValue\").val(result.oldSize);\n\n                    var duplicate = file.find(\"#duplicate-options\");\n                    duplicate.click(function () {\n                        $(\"input[name=fileoperations][value=4]\").prop('checked', true);\n                        $(\"#fileNamePlaceholder\").text(name);\n\n                        var file = $(\".qq-file-id-\" + id);\n                        var oldSize = file.find(\"#oldSizeSelectorValue\").val();\n                        var newSize = file.find(\"#newSizeSelectorValue\").val();\n                        if (oldSize != \"0B (0KB)\" && oldSize !== newSize && Number(oldSize.substring(0, oldSize.indexOf(\"B\"))) < Number(newSize.substring(0, newSize.indexOf(\"B\")))) {\n                            $(\"#resumePlaceholder\").show();\n                            $(\"#oldSizePlaceholder\").text(oldSize);\n                            $(\"#newSizePlaceholder\").text(newSize);\n                        }\n                        else {\n                            $(\"#resumePlaceholder\").hide();\n                        }\n\n\n                        $(\"#duplicateId\").val(id);\n                        $(\"#duplicateModal\").modal({                    // wire up the actual modal functionality and show the dialog\n                            \"backdrop\": \"static\",\n                            \"keyboard\": true,\n                            \"show\": true                     // ensure the modal is shown immediately\n                        });\n                    });\n\n\n                    selector.show();\n\n                    manualUploader.setStatus(id, qq.status.ALREADYEXISTS);\n                }\n                else {\n                    selector.hide();\n                }\n            },\n\n\nUsed to rename the file, even though ideally it would not be on every chunk, but just the upload event:\n\n                onUploadChunkSuccess: function(id, chunkData, responseJSON, xhr)\n                    {\n                    if(responseJSON.fileName !== manualUploader.getName(id))\n                    {\n                        manualUploader.setName(id, responseJSON.fileName);\n                }\n                }\n\n\nUsed in the prompt to get the information that was retreived onsubmitting:\n\n        function SelectFileOperations() {\n            var id = $(\"#duplicateId\").val();\n            var selectorValue = $(\"input[name=fileoperations]:checked\").val();\n            if (selectorValue !== \"cancel\") {\n                var file = $(\".qq-file-id-\" + id);\n            file.find(\"#duplicateSelectorValue\").val(selectorValue);\n            var selector = file.find(\"#duplicate-selector\");\n            selector.hide();\n            manualUploader.setStatus(id, qq.status.SUBMITTED);\n\n        }\n\n    }\n\n\nUsed to set progress, which I have not completely figured out how to modify fineuploader with:\n\nonUpload: function (id, name) {\n                    var file = $(\".qq-file-id-\" + id);\n                var selectorValue = file.find(\"#duplicateSelectorValue\").val();\n                if (selectorValue !== \"\") {\n                    manualUploader.setParams({ operation: selectorValue }, id);\n                }\n                else\n                {\n                    manualUploader.setParams({ guid: \"\", operation: \"\" }, id);\n                }\n\n                if(selectorValue === \"append\")\n                {\n                    var file = $(\".qq-file-id-\" + id);\n                    var oldSize = file.find(\"#oldSizeSelectorValue\").val();\n                    var newSize = file.find(\"#newSizeSelectorValue\").val();\n                    manualUploader.updateProgress(id, name, oldSize.substring(0, oldSize.indexOf(\"B\")), newSize.substring(0, newSize.indexOf(\"B\")));\n                }\n            },\n\n. I want the file to still show in the uploader.  If I am not mistaken, rejecting on the onSubmit removes the file from FineUpload files so it no longer shows.  If it no longer shows, then there is no longer a prompt for the user to be able to handle it within fineuploader.  If there is no prompt, then there is no business logic that can be shown to the user.\nEdit:\nAlso, the user would have to redrag and drop the file, which is not likely will be accepted.. Would you add/modify events/methods so that server side fileSize can be used to resume the upload even after the file has expired from cache, or browser history has been cleared?\nThe onProgress you have setup currently, I believe, only is there for creating a custom progressbar.  In my case, since the user should have the ability to resume an upload after expiration/cleared browser history, then I need to be able to update the progress of fineuploader based on server side file size.  I am not just saying that the UI should be updated, but be able to resume from the correct chunk part.\nIf you look at the sendNext method I provided above, I have set a value that is only used during the server side resume process (CustomLoaded).  \nThe below condition makes sure this value is set, which indicates the resume is in process, and checks to see if the the remaining length of chunkParts doesn't equal the new loaded chunkPart size.  This is because, if the file is still in the cache, then the remaining amount of chunkParts has already been spliced to the correct number and the two values should be equal.  But, if the file is not in cache anymore, then the full amount of the remaining chunkParts are being loaded, and would have to be spliced to get the correct remaining chunkParts.\n\nif (state.CustomLoaded && (Math.ceil(state.file.size / options.chunking.partSize) - loaded + 1) !== state.chunking.remaining.length) {\n\n. \"There is a lot more information needed other than file size to resume a file.\"\nI disagree based on what I have as a work around, though it may be more complicated than what I am doing, or so far, I haven't ran into an issue, but there may be an issue.  Also, I am not using s3 or azure, at this time.\nEven though the events could be better suited for this type of thing, at least in this case, the only thing the developers would need is a better method exposed to indicate that this a special circumstance, and to compare the file size on the server with file being uploaded and move the chunkParts and UI appropriately.  Like I said, I already have this working and it is all that I have already posted codewise (minus passthru methods to get to the handler), so at least high level method does work.  \n\nFile is uploaded, but paused or user closes browser.  \n\nparts have already been saved to server at the location they are going to be at when it finishes uploading.  The codebehind is handling where the file is being saved to based on database configuration.  I use c#.\n\n\nFile in fineuploader has been removed from cache, either through expiration or clearing history.\n\n\nUser drags and drops the same file, and the developer  (me and us) codes the events to handle what may happen if the file exists, like I have with the prompt.\n\n\nNow if you want to handle actually getting the fileSize in the same progress or handle the prompt, it may be more complicated, but right now I have the fileSize returned onSubmitting and placed in file element, which is then used in the onUpload to change the progress of the chunks and UI.\n. Well, I am not sure about the \"only reasonable way\", but I am sure that would require more work.  Having more control over the FineUploader regardless of whether we export the data or not would be my preferable way to go, and I don't see why both methods could not be added.. \"But it sounds like you want to be able to supply resume records from the server, and not just rely on localStorage\"\nyes.\n\"In that case, I'm not sure why you are focusing on file progress/events.\"\nWith what is available and limited knowledge and time constraints, I had to use the above method to change both the UI progress bar percentage and chunkParts.  I am using the gallery template and not messing with much of the UI.  I had found out that calling your onProgress only changes the UI.  Then had to figure where to change the chunkParts.  I just need it to be called onUpload, so I made my own method to get there.  I am sure there were more builtin methods that I could have been used, but this is my process of understanding the library and workflows, and getting what I have been tasked to do done with limited knowledge.\n\"I think exporting the resume records and then re-importing them later would be, by far, the simplest route as well. This leaves a lot less margin of error as well.\"\nIf you think so, then I am all for it.\n. ",
    "mmezzawi": "Dear @rnicholus , \nIn my case , i need to send a request to a storage server that will execute the following : \n1- create path directory \n2- grant user access to the directory\n3- send a request to server 'B' using a paid service to log the upload and get a signature \n( in case 'B' return a false we need to run another part of business )\n4- send the signature back to the client side \n5- upload will start if all is ok\nI'm not using onSubmit because the process should start when user start the upload not just submit the file to the upload queue.\nThanks.. ",
    "jaredcassidy": "I think in endpoint.php the S3 Client library provides the url format, would you recommend I try modify that?\nendpoint.php line 270-277\n```\n// Provide a time-bombed public link to the file.\nfunction getTempLink($bucket, $key) {\n    $client = getS3Client();\n    $url = \"{$bucket}/{$key}\";\n    $request = $client->get($url);\nreturn $client->createPresignedUrl($request, '+15 minutes');\n\n}\n```. Thanks for the help\nFor testing I have decided to upload my files with public-read permissions so that I don't need to have a time-bombed/signed url for the file (changing the signing code to return the correct url scheme is out of my ability at the moment) \nin endpoint.php function verifyFileInS3 I have changed:\n$link = getTempLink($bucket, $key);\nto\n$link = \"http://\" . $bucket . \".s3.amazonaws.com\" . \"/\" . $key;\n. ",
    "abroekhuis": "Sure thing,\nI use a basic uploader, with no special headers or anything. If I try to upload a arbitrary blob the upload works fine. So the uploader itself is configured correctly.\njavascript\nvar uploader = new qq.FineUploaderBasic({...});\nI get the file using the File plugin api:\njavascript\nwindow.requestFileSystem(LocalFileSystem.PERSISTENT, 0,\n  function (fileSystem) {\n    fileSystem.root.getFile(filename, {create: false, exclusive: false},\n    function (fileEntry) {\n      // The fileEntry is not a File, so get the file from it\n      fileEntry.file(function(file) {\n        uploader.addFiles(file);\n        uploader.uploadStoredFiles();\n      });\n    }\n  }\n);. Done, see my previous comment.. I tried calling the uploadStoredFiles in the onSubmitted, but this didn't help.\nI also now noticed that the onSubmit is never called when adding a file like this, so likewise the onSubmitted is never called as well.\nAny other ideas?. The problem is from the call to check if the supplied argument is a File.\nreturn window.File && Object.prototype.toString.call(maybeFile) === \"[object File]\";\nThe result of the toString call is [object Object]. I'll need to see if the Cordova Plugin can fix this.\nIn the meantime, is there some easy workaround for this?. Thanks for the help, I understand it.\nI've filed a bug for the Cordova File plugin, so perhaps something can be improved from that side.\nFor now I've updated my project to use a Blob instead of a file, that works as expected.. Well, I totally skipped the File plugin for now. The mobile application is a data collection app, and instead of saving the data to a file, and then upload that file, I now store the data in memory, and create a blob out of it.\nvar recordedData = []\nrecordedData.push(..)\nvar blob = new Blob(recordedData)\nEventually, if the file is actually needed, I might just write the file, and when the upload is needed, read the file to memory again. So I can still use a Blob.\n. With the data as text, we have files with a size of about 10-15 MB. We'll have to see how this works for now. In binary this is smaller of course... ",
    "hamdibayhan": "@rnicholus Thanks for help.. ",
    "seangwright": "Here's the documentation that I think directly applies to this issue\nhttps://www.typescriptlang.org/docs/handbook/module-resolution.html\nBut I've not created js libraries with typings in an npm package before, I've only benefited from other people's work :( so I don't have a ton of insight into resolutions.. It looks like we want to add\nexport { qq }\nto the bottom of typescript/fine-uploader.d.ts which will provide a typed import.\nI see that the library exposes qq as a global but for those of us using Typescript and es2015 modules, the above addition would be helpful.. This is Typescript specific since it's all about the fine-uploader.d.ts which doesn't produce any actual code, it's only using to give typings support for the library.\nThe imports (depending on what you are using for module loading) will pull the library from the same place, which is defined in the library's package.json main property (\"main\": \"lib/traditional.js\",). Ah, good point.\nThe docs state this is how the azure version is imported\n```\n// use Fine Uploader Azure\nimport qq from 'fine-uploader/lib/azure'\n// You may replace \"rows\" w/ \"legacy\" or \"gallery\" depending on your needs\n// This assumes you have a loader to handle importing css files, such as Webpack css-loader\nimport 'fine-uploader/lib/rows.css'\nconst uploader = new qq.azure.FineUploader({...})\n```\nFirst changing the fine-uploader.d.ts export to export { qq, FineUploader };\nThen adding these interfaces to the FineUploader namespace in fine-uploader.d.ts\n```\ninterface qqAzure {\n        azure: Azure\n    }\ninterface qqS3 {\n    S3: S3\n}\n\n```\nFinally adding this file\n/lib/azure.d.ts\n```\nimport { FineUploader } from 'fine-uploader';\ndeclare var qq: FineUploader.qqAzure;\nexport { qq };\n```\nThen in the app that is importing fine-uploader can use the following\n```\nimport { qq } from 'fine-uploader/lib/azure';\nlet uploader = qq.azure.FineUploader({});\n```\nI'm sure there is a better way to structure all this stuff (possibly moving the FineUploader namespace to a separate file and creating .d.ts files for each export that should be available) but this should work.. I was attempting to, yes.. ",
    "rakeshmotghare": "Hi Sukhdeep, could you please fix the same issue for FineUploaderTranditional. Could you please add a type script definition file .d.ts for FineUploaderTranditional. Thanks in advance.. Here is the code I was using in a index.d.ts file I have created to make FineUploaderTraditional work in typescript.\nexport default class FineUploaderTraditional{\n    constructor(obj:any);\n    on(eventName:string, callBackFunction:Function):void;\n}. Thanks for the reply, . ",
    "erensogut543": "Hi @SinghSukhdeep , @rainstormza and everyone , I tried to integrate fineuploader to AngularJS 4 project . I integrated but I think something is missing because of  in my web page the FineUploader  takes up unnecessary space as shown below in the image . Can you help me to fix this ? \n\n/////////////////////////////////// My component.ts file /////////////////\nimport {FineUploader, UIOptions} from 'fine-uploader';\nimport {Component,  OnInit} from '@angular/core';\nexport class AddSalesComponent implements OnInit {\nuploader: FineUploader;\n  uiOptions: UIOptions;\nngOnInit() {\n    this.uiOptions = {\n      element: document.getElementById('fine-uploader-gallery'),\n      template: 'qq-template-gallery',\n      autoUpload: false,\n      debug: true\n    };\n/**\n * Instantiate the FineUploader and pass in the uiOptions\n */\nthis.uploader = new FineUploader(this.uiOptions);\n\n}\n/////////////component.html file ////////////////\n Fine Uploader Gallery template\n        ====================================================================== \n  <div id=\"fine-uploader-gallery\"></div>\n  <div id=\"qq-template-gallery\">\n    <div class=\"qq-uploader-selector qq-uploader qq-gallery\" qq-drop-area-text=\"Drop files here\">\n      <div class=\"qq-total-progress-bar-container-selector qq-total-progress-bar-container\">\n        <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-total-progress-bar-selector qq-progress-bar qq-total-progress-bar\"></div>\n      </div>\n      <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n        <span class=\"qq-upload-drop-area-text-selector\"></span>\n      </div>\n      <div class=\"qq-upload-button-selector qq-upload-button\">\n        <div>Upload a file</div>\n      </div>\n      <span class=\"qq-drop-processing-selector qq-drop-processing\">\n            <span>Processing dropped files...</span>\n            <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n        </span>\n\n      <ul class=\"qq-upload-list-selector qq-upload-list\" role=\"region\" aria-live=\"polite\" aria-relevant=\"additions removals\">\n        <li>\n\n          <span role=\"status\" class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n\n          <div class=\"qq-progress-bar-container-selector qq-progress-bar-container\">\n            <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n          </div>\n          <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n          <div class=\"qq-thumbnail-wrapper\">\n            <img class=\"qq-thumbnail-selector\" qq-max-size=\"120\" qq-server-scale>\n          </div>\n          <button type=\"button\" class=\"qq-upload-cancel-selector qq-upload-cancel\">X</button>\n          <button type=\"button\" class=\"qq-upload-retry-selector qq-upload-retry\">\n            <span class=\"qq-btn qq-retry-icon\" aria-label=\"Retry\"></span>\n            Retry\n          </button>\n\n          <div class=\"qq-file-info\">\n            <div class=\"qq-file-name\">\n              <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n              <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\" aria-label=\"Edit filename\"></span>\n            </div>\n            <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n            <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n            <button type=\"button\" class=\"qq-btn qq-upload-delete-selector qq-upload-delete\">\n              <span class=\"qq-btn qq-delete-icon\" aria-label=\"Delete\"></span>\n            </button>\n            <button type=\"button\" class=\"qq-btn qq-upload-pause-selector qq-upload-pause\">\n              <span class=\"qq-btn qq-pause-icon\" aria-label=\"Pause\"></span>\n            </button>\n            <button type=\"button\" class=\"qq-btn qq-upload-continue-selector qq-upload-continue\">\n              <span class=\"qq-btn qq-continue-icon\" aria-label=\"Continue\"></span>\n            </button>\n          </div>\n        </li>\n      </ul>\n\n      <dialog class=\"qq-alert-dialog-selector\">\n        <div class=\"qq-dialog-message-selector\"></div>\n        <div class=\"qq-dialog-buttons\">\n          <button type=\"button\" class=\"qq-cancel-button-selector\">Close</button>\n        </div>\n      </dialog>\n\n      <dialog class=\"qq-confirm-dialog-selector\">\n        <div class=\"qq-dialog-message-selector\"></div>\n        <div class=\"qq-dialog-buttons\">\n          <button type=\"button\" class=\"qq-cancel-button-selector\">No</button>\n          <button type=\"button\" class=\"qq-ok-button-selector\">Yes</button>\n        </div>\n      </dialog>\n\n      <dialog class=\"qq-prompt-dialog-selector\">\n        <div class=\"qq-dialog-message-selector\"></div>\n        <input type=\"text\">\n        <div class=\"qq-dialog-buttons\">\n          <button type=\"button\" class=\"qq-cancel-button-selector\">Cancel</button>\n          <button type=\"button\" class=\"qq-ok-button-selector\">Ok</button>\n        </div>\n      </dialog>\n    </div>\n  </div>\n\n. ",
    "emilyrodriguez": "Yes, rnicholus that's correct. It's the same gallery template used both times, I just tried using two different files to see if that would get the UI to show up.. I only want to load one template in two seperate instances of the Fine Uploader.. To the upload request and most likely to the delete request. I only want users that are logged in and have an auth token to be able to upload/delete photos. I have a countyId and propertyId that I want to add as headers as well so my db knows what photo belongs to what table and property.. The headers need to be set when the edit button is pressed, that's when the countyId and propertyId are retrieved/where the Fine Uploader UI is present. The token changes everytime the user logs in but will be the same when the photo uploads are conducted. The headers will vary on each request depending on what property is selected as it dictates the countyId associated with it and queries the db for the info.. You're talking about these functions? Do I write them in a json format or a xhr.setRequestHeader\nsetCustomHeaders: function(headers, id) {\n                this._customHeadersStore.set(headers, id);\n            },\n            setDeleteFileCustomHeaders: function(headers, id) {\n                this._deleteFileCustomHeadersStore.set(headers, id);\n            },\nAnd the callbacks for example would be these?\n_onSubmit: function(id, name) {},\n_onSubmitCallbackSuccess: function(id, name) {\n                this._onSubmit.apply(this, arguments);\n                this._uploadData.setStatus(id, qq.status.SUBMITTED);\n                this._onSubmitted.apply(this, arguments);\n                if (this._options.autoUpload) {\n                    this._options.callbacks.onSubmitted.apply(this, arguments);\n                    this._uploadFile(id);\n                } else {\n                    this._storeForLater(id);\n                    this._options.callbacks.onSubmitted.apply(this, arguments);\n                }\n            },\n            _onSubmitDelete: function(id, onSuccessCallback, additionalMandatedParams) {\n                var uuid = this.getUuid(id), adjustedOnSuccessCallback;\n                if (onSuccessCallback) {\n                    adjustedOnSuccessCallback = qq.bind(onSuccessCallback, this, id, uuid, additionalMandatedParams);\n                }\n                if (this._isDeletePossible()) {\n                    this._handleCheckedCallback({\n                        name: \"onSubmitDelete\",\n                        callback: qq.bind(this._options.callbacks.onSubmitDelete, this, id),\n                        onSuccess: adjustedOnSuccessCallback || qq.bind(this._deleteHandler.sendDelete, this, id, uuid, additionalMandatedParams),\n                        identifier: id\n                    });\n                    return true;\n                } else {\n                    this.log(\"Delete request ignored for ID \" + id + \", delete feature is disabled or request not possible \" + \"due to CORS on a user agent that does not support pre-flighting.\", \"warn\");\n                    return false;\n                }\n            },. Thanks. That helped. I appreciate your time.. ",
    "kiarashi": "Even when I use your code, I still get the Uncaught TypeError: $(...).fineUploader is not a function error.\nThe code of the plugin to initilize the FineUploader is slightly different than the examples given here in the docs and I'm new with jquery too.\nThe plugin's code (short version):\n```\njQuery(document).ready(function ($) {\n    'use strict';\nvar Woo_File_Uploader;\n\nWoo_File_Uploader = {\n    init : function () {\n        this.general();\n    },\n\n    general : function () {\n\n        $('.div-container-file-uploader').each(function () {\n            var extensions = $(this).data('extensions');\n            var item_id = $(this).data('item-id');\n\n            new qq.FineUploader({                    \n                ...\n                element: document.getElementById($(this).prop('id')),\n                callbacks: {\n                    onComplete: function (id, name, response, xhr) {\n                        ...\n                    },\n                    onDeleteComplete: function (id, xhr, iserror) {\n                        ...\n                    }\n                }\n            });\n        });\n\n    }\n};\nWoo_File_Uploader.init();\n\n});\n```. I'm ashamed to ask, but I still can't get it to work.\n[Fine Uploader 5.11.9] Caught exception in 'onSubmitted' callback - $(...).fineUploader is not a function\nMy code:\n```\njQuery(function ($) {\n    $(document).ready(function(){ \n        $('.div-container-file-uploader').each(function () {\n        var uploader = new qq.FineUploader({\n\n            element: document.getElementById($(this).prop('id')),       \n            callbacks: {\n                onSubmitted: function (id, name) {\n\n                    var submittedFileCount = $('.div-container-file-uploader').fineUploader( 'getUploads', {status: qq.status.SUBMITTED} ).length\n\n                    if (submittedFileCount > 0 ) {\n                        $( \".qq-gallery\" ).addClass( \"qq-files-submitted\" );\n                    }\n\n                }\n            }\n        });\n\n    });\n\n});\n\n});\n```\nWhen I add this code inside the plugin js file that initialize FU, it works just fine.\n```\nonSubmitted: function (id, name) {\n$( \".qq-gallery\" ).addClass( \"qq-files-submitted\" );\n},\n```\nWhen I use the code below in my theme instead, it overrides the plugin's FU options, which is not something I wish to happen for obvious reasons.\n```\njQuery(function ($) {\n    $(document).ready(function(){ \n        $('.div-container-file-uploader').each(function () {\n        var uploader = new qq.FineUploader({\n\n            element: document.getElementById($(this).prop('id')),       \n            callbacks: {\n                onSubmitted: function (id, name) {\n\n                    onSubmitted: function (id, name) {\n\n$( \".qq-gallery\" ).addClass( \"qq-files-submitted\" );\n},\n                }\n            }\n        });\n\n    });\n\n});\n\n});\n```. ",
    "OroborusCrowley": "I updated the issue, sorry for my bad explanation. Yes, the callback onComplete doesn't fire in Chrome, but in Firefox works fine. . Yes that's the problem. [Fine Uploader 5.11.10] Parsing template\nutil.js:236 [Fine Uploader 5.11.10] Template parsing complete\nutil.js:236 [Fine Uploader 5.11.10] Rendering template in DOM.\nutil.js:236 [Fine Uploader 5.11.10] Template rendering complete\nutil.js:236 [Fine Uploader 5.11.10] Received 1 files.\nutil.js:236 [Fine Uploader 5.11.10] Attempting to validate image.\nutil.js:236 [Fine Uploader 5.11.10] Generating new thumbnail for 0\nutil.js:236 [Fine Uploader 5.11.10] Attempting to draw client-side image preview.\nutil.js:236 [Fine Uploader 5.11.10] Attempting to determine if prueba.pdf can be rendered in this browser\nutil.js:236 [Fine Uploader 5.11.10] First pass: check type attribute of blob object.\nutil.js:236 [Fine Uploader 5.11.10] prueba.pdf is not previewable in this browser per the blob's type attr\nutil.js:236 [Fine Uploader 5.11.10] Not previewable\nutil.js:236 [Fine Uploader 5.11.10] Sending simple upload request for 0\nutil.js:236 [Fine Uploader 5.11.10] Resetting uploader...\nutil.js:236 [Fine Uploader 5.11.10] Resetting upload handler\nutil.js:236 [Fine Uploader 5.11.10] Cancelling 0\nutil.js:236 [Fine Uploader 5.11.10] Rendering template in DOM.\nutil.js:236 [Fine Uploader 5.11.10] Template rendering complete. But I get from the endpoint this response {\"success\":true,\"uuid\":\"documentos\",\"uploadName\":\"51950.pdf\"} , thats mean that the file was uploaded right? \n . Ok, thanks so much for the help. As you told me I reset the uploader before the upload completes, I managed to change my code to make it work.. I call it because I had the uploader in jquery ui-dialog modal, and every time the dialog is called I reset the uploader. . ",
    "mattredman": "Would it be possible to include a qq-specific tag on the img element? Maybe like so? I've stepped through and I can See it's the MegaPixImage plugin/component that's swapping out the url with the data tag.\nIs there SOME way to generate something long these lines? Sadly, I'm not a javascript expert..\n<img class=\"qq-thumbnail-selector\" qq-max-size=\"120\" qq-orig-src=\"/path/to/image.png\" qq-server-scale src=\"data:image/jpeg;base64....\">. Specifically the client has asked to be able to click on the thumbnail images on the upload screen as displayed in the image so they can see the full size image as soon as it's uploaded.\n\n. Yes I did. I added a \"callBacks\" element into my initialization of fineuploader, but it was only called when an image was uploaded. I supply a \"session\" endpoint and populate images already supplied for this job so couldn't see how to make something like this work for these pre-populated images.. Yep. I think I may have glossed over a few of the key points there. Thanks for your patience. . ",
    "rssluca": "Not sure about OP's solution but this is the way I did it: I wrapped the  with a lightbox link in both uploads and session complete callbacks.\nonComplete: function(id, filename, responseJSON) {\n        if (responseJSON.success) {\n            $('#fine-uploader-gallery').append(\n            $('.qq-file-id-'+id+' img').wrap('<a href=\"'+responseJSON.['url']+'\" data-lightbox=\"gallery\"></a>')\n        }\n    },\n    onSessionRequestComplete: function(responseJSON, success) {\n        if (success) {\n            $.each(responseJSON, function(index, value) {\n                $('.qq-file-id-'+index+' img').wrap('<a href=\"'+responseJSON[index]['originalUrl']+'\" data-lightbox=\"gallery\"></a>')\n            })\n        }\n    },\ni added originalUrl to the session response. ",
    "jcrombez": "I hope i'm not hijacking this issue but, i need to do something similar, i'm trying to add a link to the full size image.\nIt works well using the onComplete callback but for the initial files  i'm using addInitialFiles so i can't  use onSessionRequestComplete to add my links.\nI don't think i can use the alternate approach rnicholus mentioned since there is other buttons in the uploader, but maybe i just misunderstood the said approach.. ",
    "averichev": "@jcrombez Tell me, please, could you solve the problem?. ",
    "OpenESignForms": "That's too bad.  I mean, with a simple  control, the file uploads fine (and is also the same multipart/form-data).  This would seem to indicate that our web server has no real issue accepting the file, just when it's transmitted via fineuploader.\nIs there anything I can add to the javascript setup to help track down why it might suffer this when using xhr?  According to the progress meter, 100% of the file is transferred before it craps out.. Thanks.  I'll keep investigating.  . In case anybody sees this exchange:\nYou were right.  It was an out of memory error (damned tiny test server!) that somehow didn't appear in the tomcat logs.  I finally discovered this using the 'debug' option and looking at the javascript console where our \"status code 500\" error page included this helpful bit of information.  This also explains how it seemed to work, then failed, etc. and we couldn't figure out what the difference was.. ",
    "AnyaLavanya": "HI,\nHave gone through this link https://github.com/FineUploader/fine-uploader/pull/1796\nHowever the above is fix is once the debugger reaches onUpload, where as here in my case, once i ipload the file with large size neither ready method nor the call back methods like (upload etc) trigger. Page blocks for a certain time say 2 min then all the events trigger.. ",
    "andy-olson": "Ok...  that was a little odd..  I just added the console.log and loaded the page once, and the first one came back with a status of deleted.  But that seems odd given that it was just loaded from the session endpoint.  Then I closed everything and reloaded it, and now I can't get it to repro.. Does uploader use any local storage?  Is it possible it was hanging on to some state for the first item in the list?. ",
    "digitalmagnets": "Apologies for the code formatting, I am taking my first tentative steps here.\nThis is an example of a straight from camera image, containing orientation data:\nhttp://web.canon.jp/imaging/eosd/samples/eos70d/downloads/07.jpg\nIf it is uploaded and resized with Pica, the scaled dimensions are incorrect.. I have modified renderImageToCanvasWithCustomResizer(resizeInfo) with a hack:\nfunction renderImageToCanvasWithCustomResizer(resizeInfo) {\n            var blob = resizeInfo.blob, image = resizeInfo.image, imageHeight = resizeInfo.imageHeight, imageWidth = resizeInfo.imageWidth, orientation = resizeInfo.orientation, promise = new qq.Promise(), resize = resizeInfo.resize, sourceCanvas = document.createElement(\"canvas\"), sourceCanvasContext = sourceCanvas.getContext(\"2d\"), targetCanvas = resizeInfo.canvas, targetHeight = resizeInfo.targetHeight, targetWidth = resizeInfo.targetWidth;\n            transformCoordinate(sourceCanvas, imageWidth, imageHeight, orientation);\n            targetCanvas.height = targetHeight;\n            targetCanvas.width = targetWidth; \nAdded:\nif(resizeInfo.orientation == 8) {\n              targetCanvas.height = targetWidth;\n              targetCanvas.width = targetHeight;              \n            } \nsourceCanvasContext.drawImage(image, 0, 0);\n            resize({\n                blob: blob,\n                height: targetHeight,\n                image: image,\n                sourceCanvas: sourceCanvas,\n                targetCanvas: targetCanvas,\n                width: targetWidth\n            }).then(function success() {\n                targetCanvas.qqImageRendered && targetCanvas.qqImageRendered();\n                promise.success();\n            }, promise.failure);\n            return promise;\n        }\nI know this is a cludge but it does fix the problem for me it seems.. ",
    "Lysandros-SLR": "I am seeing the same behavior, resizeInfo.sourceCanvas has the correct dimensions given the exif data but the resized resizeInfo.targetCanvas has the dimensions wrong, They should be flipped around.. latest version 3.0.2. I have a fix for it in renderImageToCanvasWithCustomResizer add\ntransformCoordinate(targetCanvas targetWidth, targetHeight, orientation);\nand remove \ntargetCanvas.height = targetHeight;\ntargetCanvas.width = targetWidth;. ",
    "piernik": "So there could be new event - onContainerCreate to indicate when new item is placed into DOM.\nI have some custom  elements in item's template which need to be handled after inserting to DOM.. ",
    "horkenw": "Sorry, but I can't catch what you mention, which formatting?\nthe template formatting?? or something else?? :0. ok, is this what you needed??\nI just realized that I can use insert sign. :P. pull in source maps?\ncould you please show me a example??\nbtw, I'm actually use unminified js file to make my component, but all get the same.\nthe photo I showed you just use for a demo page. ok, now I give you a online sample,\nyou may see an empty page, but please open developer console, \nyou will see the error issue like that photo I mention before.\nfineupload. ",
    "vincenthure": "Thank you for your comment.\nBut the problem is that's I understand why my server don't return my a valid JSON.. ",
    "berlinone": "Same problem here:\nI am in a hosted server environment and trying to work around setting environment variables like $_ENV['S3_BUCKET_NAME']; but The php-s3-server needs AWS Keys as valid JSON string as i understand. But if i do this manually in JSON format, the php-s3-server still says {\"invalid\":true}. How do i get past this?. ",
    "FasettoAndrew": "Hi,\nNo i'm not seeing any progress bar's for any uploads on Firefox Android. This is due to the fact that in our project we are using the onTotalProgress callback to display progress bar details, which is why it doesn't get shown.\nThe onProgress callback does get called for Firefox Android, as do the onUpload, onComplete, onAllComplete etc call backs.\nThe only issue I can observe is with the onTotalProgress callback.. Hi,\nBelow is the JavaScript code we use for creating the fine uploader instance. I have added console logs to each call back function.\n```\nvar uploader = new qq.FineUploaderBasic({\n        request: {\n            endpoint: 'OurServerEndpoint'\n        },\n        chunking:\n        {\n            enabled: true,\n            concurrent:\n            {\n                enabled: true\n            },\n            success:\n            {\n                endpoint: 'OurServerEndpoint'\n            }\n        },\n        cors:\n        {\n            // all requests are expected to be cross-domain requests\n            expected: true,\n        // If you want cookies to be sent along with the request\n        // NOTE: If we enable this, we must change the CORS server must NOT include wildcard Access-Control-Allow-Origin headers, \n        //       and you must also include the Access-Control-Allow-Credentials header\n        //\n        // sendCredentials: true\n    },\n    retry:\n    {\n        enableAuto: true\n    },\n    callbacks:\n    {\n        onAutoRetry: function(id, name, attemptNumber) {\n            console.log(\"onAutoRetry called\")\n        },\n\n        onCancel: function(id, name) {\n            console.log(\"onCancel called\")\n        },\n\n        onComplete: function(id, name, responseJSON, xhr) {\n            console.log(\"onComplete called\")\n        },\n\n        onAllComplete: function(succeeded, failed) {\n            console.log(\"onAllComplete called\")\n        },\n\n        onDelete: function(id) {\n            console.log(\"onDelete called\")\n        },\n\n        onDeleteComplete: function(id, xhr, isError) {\n            console.log(\"onDeleteComplete called\")\n        },\n\n        onError: function(id, name, errorReason, xhr) {\n            console.log(\"onError called\")\n        },\n\n        onManualRetry: function(id, name) {\n            console.log(\"onManualRetry called\")\n        },\n\n        onPasteReceived: function(blob) {\n            console.log(\"onPasteReceived called\")\n        },\n\n        onProgress: function(id, name, uploadedBytes, totalBytes) {\n            console.log(\"onProgress called\")\n        },\n\n        onResume: function(id, name, chunkData) {\n            console.log(\"onResume called\")\n        },\n\n        onSessionRequestComplete: function(response, success, xhrOrXdr) {\n            console.log(\"onSessionRequestComplete called\")\n        },\n\n        onStatusChange: function(id, oldStatus, newStatus) {\n            console.log(\"onStatusChange called\")\n        },\n\n        onSubmit: function(id, name) {\n            console.log(\"onSubmit called\")\n        },\n\n        onSubmitDelete: function(id) {\n            console.log(\"onSubmitDelete called\")\n        },\n\n        onSubmitted: function(id, name) {\n            console.log(\"onSubmitted called\")\n        },\n\n        onTotalProgress: function(totalUploadedBytes, totalBytes) {\n            console.log(\"THIS OUTPUT IS FROM TOTAL PROGRESS\");\n        },\n\n        onUpload: function(id, name) {\n            console.log(\"onUpload called\")\n        },\n\n        onUploadChunk: function(id, name, chunkData) {\n            console.log(\"onUploadChunk called\")\n        },\n\n        onUploadChunkSuccess: function(id, chunkData, responseJSON, xhr) {\n            console.log(\"onUploadChunkSuccess called\")\n        },\n\n        onValidate: function(data, buttonContainer) {\n            console.log(\"onValidate called\")\n        },\n\n        onValidateBatch: function(fileOrBlobDataArray, buttonContainer) {\n            console.log(\"onValidateBatch called\")\n        },\n    }\n});\n\n```\nThe console.log output is shown in Firefox for desktop:\n\nThis is the console output from Firefox from Android:\n\n. The fine uploader instanse is declared as it is in this issue:\nhttps://github.com/FineUploader/fine-uploader/issues/1812\nWith the var being set as:\nvar uploader = new qq.FineUploaderBasic({...\nIn our upload method, we set files to the auto uploader using:\n```\n// Add them to the uploader \nuploader.addFiles(files, parameters);\n// Start uploading files\nuploader.uploadStoredFiles();\n```\nThen, in the onSubmit callback from the uploader, we call set params for the file with a new set of parameters\n// Pass it as a parameter for this file\nuploader.setParams(updatedParams, id);\nIn neither of the parameter sets do we modify or set the qquuid. But if we comment out the uploader.setParams method above in the onSubmit callback, the issue goes away.\nI can't show you any further code or server code, but the following shows the inspected request header keys on the server.\n\n. Sorry i've not had chance to reply to this, been to busy.\nAfter further use and testing, I believe the issue is related to using DateTime's as parameters because doing the following also causes the same issue:\n```\nvar params = new { uploadPath = \"Uploads\", lastModified = System.DateTime.Now };\n// Add them to the uploader \nuploader.addFiles(files, params);\n```\nHowever, called the ToString method on the DateTime appears to fix the issue.. ",
    "dawncold": "I have to modify qq.parseJson to adding some fields which Fineuploader needs. ",
    "ramusus": "I'm really interested to get this PR merged into any upcoming release. Is there any chance to get it there?. Great work @Novex! I investigate this issue myself and came to the same conclusions - the problem in isValidFileDrag. It's outdated and doesn't let Fineuploader to work together with drag-and-drop libraries, for example react-dnd.\nBTW, I see the Travis crashed because of just one trailing whitespace.. It shouldn't be difficult to fix.. @rnicholus For some reason v.5.15.2 doesn't contain fixes from this PR.\nCould you, please, check what version uploaded to npm with label 5.15.2?. @rnicholus thanks, it's working!. ",
    "Novex": "Hooray! Thank you for merging this \ud83c\udf89. ",
    "jdor300": "I will handle the 504, I just told you the whole story (don't mind the 504).\nThe problem is why after 1 minute the fine uploader is waiting for a response, he start to upload the file again.. Sorry that i didn't mentioned it but the retry of the upload is happening after 1 minute,\nthe 504 problem is happening after like 3-4 minutes (meantime the fine-uploader already did 1-2 retries).\nI also must mention that back in the server the file is fine, \nthe web get 504 after 3-4 minutes but we in the back end finish the manipulation after another 1 minute.. ",
    "NathanNZ": "The following snippet is an example of how you can bind all the fields from the file upload request, then use the file stream to write the uploaded file to a temporary file. \npublic async Task<IActionResult> Post(string qquuid, string qqfilename, int qqtotalfilesize, IFormFile qqfile)\n        {\n            // full path to file in temp location\n            var filePath = Path.GetTempFileName();\n\n            if (qqfile.Length > 0)\n            {\n                using (var stream = new FileStream(filePath, FileMode.Create))\n                {\n                    await qqfile.CopyToAsync(stream);\n                }\n            }\n        }\n\nFor more information about using .NET Core to upload files you can check out : https://docs.microsoft.com/en-us/aspnet/core/mvc/models/file-uploads?view=aspnetcore-2.1\n. ",
    "ellavs": "May be this helps - Fine Uploader ASP.NET Core 2 Example. ",
    "zenonp": "Could you please hint at what to look for and where, to fix this? . ",
    "cretueusebiu": "I found this workaround:\nAdd the header to the unprefixed names:\njavascript\nqq.s3.util.UNPREFIXED_PARAM_NAMES.push('x-amz-decoded-content-length')\nThen just pass the header via the params option:\njavascript\n// file is an instance of File\nuploader.addFiles([file], { 'x-amz-decoded-content-length': `${file.size}` }). Unfortunately this doesn't work as I expected. \nEven if I set this header with a certain size I can still upload a file with another size.\nI'm not sure if there's any other way to tell S3 what's the max file size.. @truthSeekr No. I just have bucket notifications enabled and once the upload is done, my server is notified and then I check the file size and delete it, if necessary. . @truthSeekr When new objects are created, so that's when the last chunk is uploaded.. I think it only checks it at the end. . ",
    "AndryHTC": "I have the same problem... I'm using the jQuery version in core mode, because with the core one doesn't work the dnd module. The on(\"progress\",...) fires only on chrome.. ",
    "thejanasatan": "Here's a JSFiddle I wrote to test this. \nhttps://jsfiddle.net/bLenv0w1/2/\nThe first chunk of code with if-else throws an error in IE 11. But the second chunk does not (without if-else.\nThe if-else here doesn't work. Check: https://github.com/alexgibson/tap.js/pull/26. @rnicholus bump. ",
    "jclangst": "So upon further digging into the codebase, it looks like fine-uploader uses UMD module design. Since Typescript users will in all likelihood use some sort of module mechanism other than the global namespace, this creates a problem with the way that the declaration file is currently structured.\nIt looks like the current declaration file is structured using this global declaration template. However, since the project can be modularized and Typescript users will almost definitely be using modules, it should use this template.\nWhy does it need to be this way? Because Typescript users won't have the qq variable exposed in the underlying javascript. So declare var qq at the end of the declaration file (which doesn't actually change the underlying code) will trick the Typescript compiler into thinking that qq exists (even though it doesn't) and then we will run into tricky runtime errors in the browser (my last several hours can attest ;) ). Since the typescript compiler doesn't complain, this is also probably why the code passed any build tests you had prior to deploying.\nI would be happy to refactor the Typescript as best I can if you want. I have already altered it appropriately for my usecase, but I can expand my fixes to the entire scope and submit a pull request. . As a note to aid in your review, I fortunately didn't change any of the\ndefinitions of any of the functions. I just exposed the js classes as\nTypescript classes, and encapsulated into them the appropriate functions\n(based on the online API).\nThis was done since Typescript users won't have access to the qq global\nvariable after they transpile their ts to js -- Typescript users will\nusually target a module system like AMD, CommonJS, or ES6 and the UMD\ndesign of the project will then not expose everything under a qq variable\nbut rather on an export object. That's why the Typescript docs recommend\nusing the module template (\nhttps://www.typescriptlang.org/docs/handbook/declaration-files/library-structures.html\n).\nI am not sure why having it the current way would have allowed rollup to\nwork with Typescript as it seems it should have still broken it. If you\nwant to use these new Typescript definitions with Rollup all you'd need to\ndo is change the module option of the tsconfig.json file to \"ES6.\" While I\nhaven't tested it, this will give you the import/export syntax that should\nallow rollup to work.\nWhat I do know, however, is that the current definitions will trick the\nTypescript compiler into allowing code that will lead to runtime errors.\nLet me know if I can help in any way.\nJack\nOn Thu, May 25, 2017 at 9:01 PM Sukhdeep Singh notifications@github.com\nwrote:\n\nI see that the def file has changed considerably. It will take me some\ntime to get through this.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/pull/1840#issuecomment-304163431,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AMr1ar6fywffvpVMnKvAy5Dj5Y1eu-BNks5r9iRVgaJpZM4Ng9kV\n.\n. Ah, I see what you are saying: there should be a both an import statement in the Typescript and a global include in the index.html file. That would certainly work, but it would be nice to just have to import the module once in our Typescript projects which is the functionality that the new .d.ts file provides and is recommended by the Typescript crew. Also, this would work much better with bundlers (including Rollup, I think).\n\nAlso, Rollup is certainly a wonderful utility (just haven't used it personally), and I did not mean to imply in any way that you should not love it and support it. What I am trying to say is that when transpiling Typescript, it will produce javascript that does not expose the global qq variable. Thus, you will get a runtime error regardless of whether you use Rollup or not -- unless, as you pointed out, you do a second include of the underlying javascript at a different point in your html code.\nIf you think I am wrong (and I certainly could be!), could you provide an example of how you are using Typescript with Rollup and not getting resulting runtime errors? I might be missing something.\nI think that this whole issue is probably a result of the import documentation page. It says that ES6 import syntax can be used with languages like Typescript and utilities like Webpack and gives several examples -- none of which would work in Typescript. That's what led me to develop the new Typescript definition file that now follows the Typescript's team's recommendations for UMD projects and will work out of the box with the instructions in the documentation.. No worries! Definitely hard to keep up with everything popping up every other month. Fortunately, the original instructions should be 100% fine -- we just need to have the .d.ts file treating the modules as modules rather than using the global namespace (which won't have anything on it since fine-uploader uses UMD).. Awesome!\nLet me know if I can help with anything.\nMy two cents would be just having an example import statement for TS on the\ndocumentation for importing would be enough. Everything else should\nfunction the same way.\nBest,\nJack\nOn Sun, Jun 11, 2017 at 4:42 PM, Sukhdeep Singh notifications@github.com\nwrote:\n\nDid some testing and I've put together a repo here\nhttps://github.com/SinghSukhdeep/fine-uploader-ts where all the changes\nare seems to be working with SystemJS and Rollup (Thanks to improvements\nrollup's commonJS plugin).\nI need to do some more testing on a real Angular 4 & TypeScript project\nand then we can go further from there.\nI am optimistic that this will be a great benefit to Angular & TypeScript\nbased projects, but is also a major syntax change for the existing users\nwho are using globally scoped FineUploader JS with current TS definitions.\nAlso we need to document this change properly and maybe have a dedicated\npage or section for Angular 2+ and TypeScript integration.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/pull/1840#issuecomment-307655433,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AMr1aj7QQzN6WXFp_ypM_xEFGYxcjDm0ks5sDFEegaJpZM4Ng9kV\n.\n. Yes. We can split the ambient module declarations into separate files (even splitting separate module elements into their own modules if we want to break it up even further); however, these new modules must have different names than those names in the final index.d.ts file (which need to remain as they are).\n\nAt what level do you want to split things into separate files? Current module level? Class/interface level? . Resolved:\nhttps://github.com/FineUploader/fine-uploader/pull/1840/commits/e95631cc61fd459756aebcbf6d05d33c1c2a91d2. Resolved:\nhttps://github.com/FineUploader/fine-uploader/pull/1840/commits/e95631cc61fd459756aebcbf6d05d33c1c2a91d2. ",
    "azampagl": "@jclangst What was your work-around to get the current version working for your use case? I'm running into the same issues due to qq not being exposed in the underlying JS.. ",
    "chaitanyya": "Okay, I finally figured it out. It'll be great if you add some similar process in your documentation. This is what I did to make it work:\nStep Zero:\nInclude the CSS and JS file in the angular-cli.json file.\n\"styles\": [\n        \"../node_modules/fine-uploader/fine-uploader/fine-uploader-gallery.min.css\"\n],\n\"scripts\": [\n        \"../node_modules/fine-uploader/fine-uploader/fine-uploader.min.js\"\n],\nStep One:\nAdd /// <reference types=\"fine-uploader\" /> on top of your component file.\nStep Two:\nDeclare following variables:\nuploader: FineUploader.qq;\nuiOptions: FineUploader.UIOptions;\ncoreEvents: FineUploader.CoreEvents;\nStep Three:\nAdd UI options and initialise FineUploader in ngOnInit\nthis.uiOptions = {\n    element: document.getElementById('qq-template'),\n    template: \"qq-template\"\n};\nthis.uploader = new qq.FineUploader(this.uiOptions);\nStep Four:\nAdd the template HTML in your component.html file. You may find the HTML in node_modules/fine-uploader/fine-uploader/templates/\nI can add more detailed process for TS integration in the Doc. But I want to confirm if it's the right way of doing it. @SinghSukhdeep . ",
    "irbian": "Hi!\nI have read some of your threads regarding the integration with angular 2. Is this one the most up to date? We are very interested on integrate this library with our project because we need the IE9 support. ",
    "quasi13": "@SinghSukhdeep I noticed 2 things regarding the TS canonical imports:\n\n'allowEmpty' seems to be absent from interface ValidationOptions\nI have not been able to successfully instantiate a new PromiseOptions as done here: https://github.com/FineUploader/fine-uploader/blob/5.15.3/client/typescript/fine-uploader.test.ts#L94\n\nPossibly, both of these are misunderstandings on my part.. I have also observed this in 'Traditional'.  This does not occur in v5.15.0, but it does occur in v5.15.3.  I didn't test the intermediate '.1' release.  In debugging, it seemed as though the .dispose() method wasn't doing what it implied.. ",
    "keiranmraine": "I have managed to isolate that this is only a problem for files that don't need to be chunked.\ne.g.\n1mb.rnd fails\n50md.rnd works\nJust the standard S3 example + php server with this as the in html config:\nvar uploader = new qq.s3.FineUploader({\n            debug: true,\n            element: document.getElementById('fine-uploader'),\n            cors: {\n              expected: true\n            },\n            objectProperties: {\n              bucket: 'test',\n              host: 'our.s3.url'\n            },\n            request: {\n                endpoint: 'https://test.our.s3.url',\n                accessKey: 'XXXXXXXX'\n            },\n            signature: {\n                endpoint: \"/vendor/fineuploader/php-s3-server/endpoint-cors.php\"\n            },\n            uploadSuccess: {\n                endpoint: \"/vendor/fineuploader/php-s3-server/endpoint-cors.php?success\"\n            },\n            iframeSupport: {\n                localBlankPagePath: \"success.html\"\n            },\n            chunking: {\n                enabled: true,\n                concurrent: {\n                    enabled: true\n                }\n            },\n            resume: {\n                enabled: true\n            },\n            retry: {\n                enableAuto: true,\n                showButton: true\n            },\n            deleteFile: {\n                enabled: true,\n                endpoint: \"/vendor/fineuploader/php-s3-server/endpoint-cors.php\"\n            }\n        });\nAnd minimal cors\n```\nCONFIGURE CORS ON BUCKET:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n\n\nPOST\nPUT\nDELETE\n3000\nETag\n\n\n\n```. @rnicholus is this a configurable option or some code to comment out?. As @davebiffuk has identified this to be a bug in ceph and tracking the problem in #1846 I'll close this. ",
    "davebiffuk": "https://github.com/FineUploader/fine-uploader/pull/1846 fixes this in my limited testing by setting a default content-type (\"application/octet-stream\") if the browser can't figure out a specific content-type. (I work with Keiran.). Thanks for the feedback. I've confirmed that this change isn't necessary with AWS S3. I'll pursue it with the Ceph/radosgw people. Would you be amenable to carrying this as a disabled-by-default feature, e.g. \"enable_sending_default_content_type\"?. ",
    "mlazze": "I understand.\nMoving the generation of the policy to the backend would require passing (or parsing from the policy) key, bucket, etc. to fineuploader, meaning that fineuploader has to implement the logic to change the request parameters according to the backend response: this means that the backend doesn't have to verify anything, but fineupload would have to keep its current behaviour and also allowing its request fields to be overridden. Not so many advantages for the required effort.\nThanks for the answer.. ",
    "Rux77": "I faced the same issue, Iam using s3 mode and Iam generating the signature and policy (endpoint) for V4 on backend using this package Directo and this package uses its own policy inputs when singing the policy:\nphp\n$policy = [\n            'expiration' => $this->expirationDate(),\n            'conditions' => [\n                ['bucket' => $this->bucket],\n                ['acl' => $this->options->acl],\n                ['starts-with', '$key', $this->options->valid_prefix],\n                [$contentTypePrefix, '$Content-Type', $this->options->content_type],\n                ['content-length-range', 0, $this->mbToBytes($this->options->max_file_size)],\n                ['success_action_redirect' => $this->options->success_action_redirect],\n                ['success_action_status' => $this->options->success_action_status],\n                ['x-amz-credential' => $this->credentials->AMZCredentials()],\n                ['x-amz-algorithm' => 'AWS4-HMAC-SHA256'],\n                ['x-amz-date' => gmdate('Ymd\\THis\\Z', $this->time)]\n            ]\n        ];\nWhich is different from Fineuploader request payload for the file Iam trying to upload: \n{\"expiration\":\"2018-03-16T09:10:45.082Z\",\n\"conditions\":\n\\[{\"acl\":\"private\"},\n{\"bucket\":\"bucket-name\"},\n{\"Content-Type\":\"image/jpeg\"},\n{\"success\\_action\\_status\":\"200\"},\n{\"x-amz-algorithm\":\"AWS4-HMAC-SHA256\"},\n{\"key\":\"37f86eae-46e9-4047-91c1-c8ee2cbf90b6.jpg\"},\n{\"x-amz-credential\":\"GWRQRFFXBA3C3S7GOVQQ/20180316/eu-central-1/s3/aws4\\_request\"},\n{\"x-amz-date\":\"20180316T090545Z\"},\n{\"x-amz-meta-qqfilename\":\"JPG-GG\\_400x400.jpg\"},\n\\[\"content-length-range\",\"0\",\"23424\"\\]\\]}\n\nso when I try to upload the file I will face many errors: \npolicy doesn't match ... etc ..\n. ",
    "popart-dev": "Because I wasn't aware the 2 shared anything in common. Apologies if I\nviolated protocol. I'll happily take one or the other down if one is\npreferred.\nDamion Moyer\nSenior Software Engineer\nPop Art, Inc.\nwww.popart.com\n(503) 548-9015 desk\n(503) 242-4292 main\n(503) 422-1402 mobile\nOn Mon, May 22, 2017 at 12:03 PM, Ray Nicholus notifications@github.com\nwrote:\n\nany reason you asked a question on SO and filed an issue here?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1843#issuecomment-303190907,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AD0nI4Fom3Jp5o0DShkQ4NkxyhsmJ3QXks5r8dv1gaJpZM4Nit_J\n.\n. \n",
    "sreerag-av": "this.uploader = new qq.FineUploader(this.uiOptions)\nthis works, i had to call it like this, in order for it to call access the uploader in the manual trigger event.\n```\nmanual trigger event\nuploadFiles() {\n    this.uploader.uploadStoredFiles();\n}\n```\nthe problem lies in the onUpload callback\ni want to send along some parameters along with the request (endpoint) that the uploader makes to the server. but \ndefaultParams['categories'] = this.inputCategories;\nthis.inputCategories is a user input inputed during upload, not during init\nso this.inputCategories is undefined and so at the server end it is passed as undefined\nhow can i get this value,\nalso is there any way to find out whether there is a file in the upload queue\n. ```\nngOnInit() {\nthis.uiOptions = {\n    debug: true,\n    autoUpload: false,\n    element: document.getElementById('fine-uploader-gallery'),\n    template: 'qq-template-gallery',\n    request: {\n        endpoint: 'http://localhost:3000/docapi/v1/documents/chunked'\n    },\n     chunking: {\n            enabled: true,\n            concurrent: {\n                enabled: true\n            },\n            success: {\n                endpoint: 'http://localhost:3000/docapi/v1/documents/chunked?done=true'\n            },\n            partSize: 4000000\n    },\n      resume: {\n        enabled: true\n    },\n     callbacks: {\n            onUpload: function (id, fileName) {\n              const defaultParams = {};\n              defaultParams['categories'] = __this.inputCategories;  #it will say cannot find name __this\n              this.setParams(defaultParams);\n        }}\n    };\n this.uploader = new qq.FineUploader(this.uiOptions);\n}\nuploadFiles() {\n    let __this = this;  ## its defined here in the trigger event.\n    console.log(\"value of this is \"+__this.inputCategories);\n    this.uploader.uploadStoredFiles();\n}\n```\ni tried your solution, but it says cannot find name __this.\nIs it that i can only access variables using 'this' inside ngInit , but then ngInit is called once and i can't pass any variables to it, after initialisation. is there a work around for this.\ncan i do something like this.uiOptions = new FineUploader.UIOptions{} and call this.uploader(this.uiOptions)\ncan i pass again the uiOptions to qq.Fineuploader without reinitialising it.\n. Ok wait i got it working, but can't get the values during auto upload which i need. this works for a manual trigger event, if there is no way to make this work with auto upload i will close this issue.\n```\ndefaultParams = {}; # set this\nngOnInit() {\nthis.uiOptions = {\n    debug: true,\n    autoUpload: false,\n    element: document.getElementById('fine-uploader-gallery'),\n    template: 'qq-template-gallery',\n    request: {\n        endpoint: 'http://localhost:3000/docapi/v1/documents/chunked'\n    },\n     chunking: {\n            enabled: true,\n            concurrent: {\n                enabled: true\n            },\n            success: {\n                endpoint: 'http://localhost:3000/docapi/v1/documents/chunked?done=true'\n            },\n            partSize: 4000000\n    },\n      resume: {\n        enabled: true\n    },\n     callbacks: {\n            onUpload: function (id, fileName) {}\n        }\n    };\nthis.uploader = new qq.FineUploader(this.uiOptions);\n}\nuploadFiles() { #manual trigger event\n    this.defaultParams['categories'] = this.inputCategories; #call it here\n    this.uploader.setParams(this.defaultParams);\n    this.uploader.uploadStoredFiles();\n}\n```. ",
    "drt0927": "I want to link to the click of the view button but can not hang it.. # onStatusChange\nconsole.log($('.qq-file-id-' + id + ' qq-upload-success')); //undefined\nWhen can I bind?\nviewBtn.setAttribute(\"onclick\", \"location.href='\" + serverPathToFile + \"';\");. ",
    "dpetker": "I'm not sure that this issue is a duplicate. That PR and associated issue is related to a non-standard MIME type, while this issue is related to standard MIME types (i.e. video files) and a change in behaviour from Edge 14 to Edge 15.\nLooking at the network requests in Edge 14/Chrome/FF you'll see the PUT to S3 doesn't include a content-type header (presumably because it's not required on PUT requests). Edge 15, however, decided to include it.. Actually, digging into the code a bit, I think the bug may lie in how you handle getFile calls on multipart uploads. XhrUploadHandler._getMimeType calls getFile using the passed in file ID which, in the case of multipart uploads, isn't an integer but a string of the format \"fileId.chunkIndex\" (I discovered this while developing my own workaround).\nBecause of that, the getFile call returns nothing so there's no way to get the MIME type. If you do something even as simple as:\njs\ngetFile(parseInt(fileId, 10))\nWill extract just the file ID portion and get you the file you want.. I'll see what I can do \ud83d\ude42 I need to spend some more time inside the code to make sure I don't introduce any regressions.. Just had a chance to verify, the fix works like a charm. Thank you!. ",
    "marcynek": "@micholus\nI'm sorry, I hope that now it is ok\nI do not know why \"Insert code\" doesn't work at all....\nI had to make \"8x nbsp's\" for TAB's ... and \"lt's and gt's\" for html brackets\nHope that it is better now.. @micholus\nAch ... lame me :)\nDone ... it's fixed now.\nBy \"insert code\" I meant a button in a function menu of WYSIWYG - it looks like this: \"<>\" .... and it makes ` .. but only one ;) - so that's why it didn't work.\n. Yes, I can confirm that workaround @nebaughman suggested works. rnicholus ... hmm maybe something as trivial as:\n(function(global) {\n    if (typeof(qq) === 'undefined') {\n        var qq = function(element) {\n            (...)\n         }\n     }\n(...)\nin every file: dnd.js and fine-uploader.js, and probably others...\nit should be enought\n--\nsincerely\nmarcyn. ",
    "nebaughman": "I am having this exact (mis)behavior with:\n\nFineUploader 5.14.3 (same as above)\nChrome 58.0.3029.110 (64-bit)\nmacOS Sierra 10.12.5\n\nFantastic library. Any help is most appreciated, thanks.\nEdit: BTW, This error is generated just by including the dnd.js after fine-uploader.core.js.. This seems to be the problem: Both dnd.js and fine-uploader.core.js start by defining var qq = function(element) { .... It seems to work for me by removing this block from dnd.js and including dnd.js after fine-uploader.core.js (so qq is defined only in one place).\nI'd fork & submit a pull request, but removing var qq = ... from dnd.js would make dnd.js NOT function stand-alone. Maybe the answer is to separate qq from each of these (ie, provide a qq.js separate from dnd.js, fine-uploader.core.js, etc).. ",
    "Meandmybadself": "I ran into the same issue using an NPM installation of fine-uploader and got around the issue with:\n```\nconst qq = require('fine-uploader/lib/core/all')\nconst dnd = require('fine-uploader/lib/dnd')\nthis._uploader = new qq.FineUploaderBasic({\n      autoUpload: false,\n      button: selectEl,\n      callbacks: {\n        onDelete: this._onDelete,\n        onSubmit: this._onSubmit\n      },\n      validation: {\n        allowedExtensions: ['jpeg', 'jpg', 'gif', 'png'],\n        acceptFiles: 'image/*'\n      }\n    })\n    this._dnd = new dnd.DragAndDrop({\n      dropZoneElements: [document.body],\n      classes: {\n        dropActive: 'drag-over'\n      },\n      callbacks: {\n        processingDroppedFilesComplete: (files, target) => {\n          this._uploader.addFiles(files)\n        }\n      }\n    })\n```\n. ",
    "Spongman": "i just ran into this with the latest release 5.15.6. including dnd.js kills it :(. i'm seeing the same errors. i'm loading the fu scripts using ",
    "cindreta": "Plus one here.\nI am using s3.fine-uploader.core.min.js and as soon as i add dnd.min.js to the mix i just start getting various JavaScript errors however i try to implement it. I get one of these two:\n- qq.s3 is undefined (calling dnd.min.js after s3.fine-uploader.core.min.js)\n- qq.DragAndDrop is not a constructor (calling dnd.min.js before s3.fine-uploader.core.min.js)\nUPDATE:\nJust as i wrote that i managed to get it working.\nSo the reason why it didn't work was: \nI went here: https://fineuploader.com/customize.html selected Amazon S3 and pressed download. Inside there were two files: dnd.js and dnd.min.js i tried using them and got the errors above.\nI then went to this repo directly and downloaded dnd.js directly from the repo (https://raw.githubusercontent.com/FineUploader/fine-uploader/master/client/js/dnd.js) and voila - works like a charm.\n. What i tried to say is that when i downloaded the files from https://fineuploader.com/customize.html  and tried to use dnd.js or dnd.min.js i was constantly getting these two errors:\n\nqq.s3 is undefined (calling dnd.min.js after s3.fine-uploader.core.min.js)\nqq.DragAndDrop is not a constructor (calling dnd.min.js before s3.fine-uploader.core.min.js)\n\nAfter that i went on to downlaod dnd.js directly from source (https://raw.githubusercontent.com/FineUploader/fine-uploader/master/client/js/dnd.js) and i used that version instead of the one that came with the downloaded ZIP file and it works just fine, out of the box, like magic.\n. ",
    "iryska": "I'm using version 5.16.0 and sill have the same error.\nBoth files starts with\n!function(global){var qq=function(e)...\nany solution for this? I need this work :(. ",
    "jimmalone": "@rnicholus,\nI can help test your fix for this issue. \nI have this exact issue others have reported.\n. ",
    "littleginsu": "Thank you for the quick reply! \nI looked at the angular version but could not figure out how to set custom templates? Along with the uploaders I am dynamically building, there is one main, static uploader on the same page which uses a different template. \nDo you, perhaps, have an example or documentation which explains how to set the template?\nThank you in advance for any assistance you can provide. . I am going to try to work with core and dnd. Thank you again.. ",
    "m3ldro": "I'm sorry my mistake.\nA stupid syntax error in my script messed up the json response.\nSorry.. ",
    "galvinhsiu": "@rnicholus - great idea. Updated PR - thanks!. @rnicholus any feedback on this PR?. @rnicholus i am interested, drop me a line.. Good feedback, ripped out the unused condition and slightly tweaked the unit test.. ",
    "cntrytwist": "I can confirm the same behavior when using Mac OS and Firefox 54.. ",
    "SpazzMarticus": "The problem is caused by leavingDocumentOut. Once you remove this part\njs\nif (qq.firefox()) {\n    return !e.relatedTarget;\n}\nit works in Firefox 54 as expected, but I guess in older Firefox versions there will be problems.\n. My fix does not work correctly any more in Firefox 56 (x64, Win) any more, because when leaving the browser window I get this error: Permission denied to access property \"x\"\nIt solves the anoying flickering problem, but does not hide the Drop-Zone when leaving the browser window.\nAlso in Firefox 56 (x64, Ubuntu 17) the x and y are not set to 0 or negative values when leaving the browser window.\nI hope you can fix this problem!. ",
    "cubiclesoft": "Ditto.  The flickering issue shows up in the demos in Firefox:\nhttps://fineuploader.com/demos.html\n. I ended up rolling my own solution using a different library:  https://github.com/cubiclesoft/jquery-fancyfileuploader\nThe flickering issue, which I can confirm is still happening in the demo (I'm running Windows 10 Pro 64-bit + Portable Firefox 56 32-bit + a couple of popular add-ons), along with the author's intentions to no longer support Fine Uploader caused me to move away from Fine Uploader for my integrations.  jQuery isn't a terrible dependency (usually) and I happen to like my solution better since there's very little that can go wrong and it works quite well on mobile devices.. A change in drag-and-drop support - one of the core features of a file uploader - needs to be tested widely across all browsers with as many versions as is reasonably possible.  This PR seems like a rather significant change to just accept into mainline with such minimal testing.  A less invasive approach would be to isolate just Firefox using the existing qq.firefox() check.. ",
    "maximilianschmid": "+1  flickering Firefox 55.0.3 (64-Bit) on MacOS 10.11.6. Tested patch successfully with Fine Uploader 5.15.0 on\n- IE11 Win732bit\n- FF 55 Mac\n- FF 55 32bit Win732bit\n- FF 30 Win732bit\n- Safari 10.1\n- Google Chrome 60  Mac & Win. ",
    "AyrtonRicardo": "+1 flickering Firefox 54.0 (64-bit) Linux. ",
    "priyankoctal": "Hi, I am not sure why this is closed ?. ",
    "seltix5": "to be able to style it with css, this is already done this way for each item =). hi,\ni already read that, thank you. yet i dont see any information about my question, i want to resize and crop to a specific size. using the default thumbnail creator it will only resize the picture.\nI supose i need to use a custom resizer for that?\nthank you.. hi, the example given does not work anymore :\nthumbnails: {\n    customResizer: !qq.ios() && function(resizeInfo) {\n        return new Promise(function(resolve, reject) {\n            pica.resizeCanvas(resizeInfo.sourceCanvas, resizeInfo.targetCanvas, {}, resolve)\n        })\n    },\n    ...\n}\ncan you update it? thanks!. I do can update the documentation, but about the tests I dont know how it works or what I need to do :/. Docs updated. Can you help me with the tests?. done ^^. thanks! its done.. ",
    "ICELI": "@rnicholus it\u2018s for security\uff1f. https://github.com/FineUploader/fine-uploader/blob/develop/client/js/upload-handler/form.upload.handler.js#L88\nuuid  is already statemented. Thank you for your reply.\nI have test this in IE8,9... and i can't find some docs for this. Could you show some for me?\n . ",
    "animatedcreativity": "This happens when I am using qq-max-size and qq-server-scale. Its working like a charm when I removed both these attributes from gallery.html template.\nBut, if qq-max-size and qq-server-scale attributes are set, then why it is converting image from png to black background jpg, is still an issue.\nBut, I am closing this for now.. ",
    "falsebyte": "Second bug is not actually bug but  my proxy server squid terminate connections without answers after 2 minutes 50 seconds and i see upload error when file is big. . ",
    "gohabsgo": "Hi Ray, I'm Steph, the CTO at MASV.io (LiveQoS Inc.) based in Ottawa, Canada.\nMASV.io is a new SaaS offering that caters to the Media & Entertainment, massive file transfer vertical.\nTiming is everything!  I'm in the midst of planning next 6-12 months which includes major features for our Rush web uploader, as well as MASV REST API, and was considering flipping over from our in-house uploader to FineUploader.\nI have a small team of developers, skin in the game, and an interest in monetizing usage of our cloud, but not the tools that promote such usage. \nWould you consider someone from or team to maintain it? I can offer you an assurance that we'll have the community's interest in mind and keep your baby alive.\nWould be great to speak to you actually, I'd like to know more about you and see if we have any common interests. I can also share with you my vision of MASV and how FU would benefit.  Regardless, I would really like to hear your vision for FineUploader and know what you wish you had time to do. Do you have time for a call next week Wed-Fri?\nThanks for your time,\nsteph@masv.io\n. ",
    "toabm": "Hi Ray,\nI am \u00c1ngel. \nI'm 32 years old and have been developing webs, apps, UI and so on since I was a kid. always supporting open source software.\nI'd love to participate and keep Fine Uploader alive. We can have a skype meeting if you like, I live in Madrid.\nThanks for your job during all this years,\n\u00c1ngel\n\nPS: Leave you my personal e-mail toabm@yahoo.es. ",
    "martinkouba": "Hi Ray,\nI am Martin. We are a small team based in Austria developing a Plattform where file upload is an essential part. So we have an interest in having a properly maintained library we can build upon. I can picture us becoming maintainer of the FineUploader project.\nLet me know about your plans. I dropped you a message in Skype.\nMartin. I did send you an invitation to your Skype account, though.\n\nAm 12.08.2017 um 08:01 schrieb Ray Nicholus notifications@github.com:\nUnfortunately nothing has panned out on this front. But it looks like I will have some time and motivation to address some of the bigger feature requests as part of my work on BrickFTP https://brickftp.com/.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/FineUploader/fine-uploader/issues/1881#issuecomment-321960156, or mute the thread https://github.com/notifications/unsubscribe-auth/ABNQ1lofwW5lKch4Krrh_zp2BcRqz3oWks5sXT_OgaJpZM4OQP-a.\n\n\n. I am happy to have a chat about that on Skype. I have resent my Skype invitation.. Hi,\nI think this is you ;-)\nI hardly use Twitter but I will dig out my account for you\n\nAm 04.11.2017 um 12:49 schrieb Ray Nicholus notifications@github.com:\nHi Martin: I\u2019m not even aware of a Skype account that I may or may not hold. Please contact me on Twitter and we can exchange contact information there. Thanks.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/FineUploader/fine-uploader/issues/1881#issuecomment-341890805, or mute the thread https://github.com/notifications/unsubscribe-auth/ABNQ1ol_5Ru0_sqS_iILdhonniy_WgVLks5szE9ngaJpZM4OQP-a.\n\n\n. I can see your pain.\nWould have loved to see it otherwise. Alas, we have postponed our switch to fineuploader. Other stuff got higher priority.\nMaybe next year.\nAm 31. Dez. 2017 05:26, um 05:26, Ray Nicholus notifications@github.com schrieb:\n\nWell, finding a suitable maintainer has been far more difficult than I\nanticipated.\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/FineUploader/fine-uploader/issues/1881#issuecomment-354584646\n\n. ",
    "ScotsScripts": "I wish I could help but it's not part of my skill set, however I'm curious about something you wrote- \"But I no longer rely on Fine Uploader myself,...\" What do you use instead of Fine Uploader?. ",
    "rcheung9": "Just curious as I read your Medium story on how this came to be.\nYou said you used to do this on your free time but it wasn't worth it until you started charging for licenses which made you good money then your company Widen took over the project and was providing you with a team or allowing you to work on this as part of your employment.\nIs that no longer the case seeing as you have a \"new employer\"? Since you continue to own it, does that mean Widen never officially sponsored it?\nSince that is the case, why don't you go back to your old licensing model.  Free for community use, license for commercial use.. ",
    "sizzlefinger": "Please DM me on Twitter @sizzlefinger with some details.  I would like to see if there is some way to work something out on maintaining and commercially sponsoring the project.  I use the project in my app and would love to help.  -sf. ",
    "ideablock": "Grew up in Eau Claire, went to Madison, would love to help you keep this maintained.   . ",
    "LukeM12": "Hey rnicholus. If you need some support ping me lukescotian@outlook.com\nInterested to know more. \nLuke. ",
    "Yulietta": "Hi,\ni am interested.\nGreetings, Yuli. ok i did. DM is disabled so tweeted at least. ",
    "munna": "I am interested, let me know where to start.\nNew Delhi, India.... ",
    "hirenalken": "I am using this with angular 2. insalled fineuploader via npm. \nTo import \nimport qq from 'fine-uploader/lib/core/s3';\n```\nngOnInit() {\n    this.setAlbumModal();\n    let browsedImages: BrowsedImage[] = [];\n    let instance = this;\nthis.uploader = new qq.s3.FineUploaderBasic({\n      button: document.getElementById('upload_image'),\n      debug: false,\n      autoUpload: false,\n      multiple: true,\n      validation: {\n        allowedExtensions: ['jpeg', 'jpg', 'png', 'gif'],\n        sizeLimit: 5120000 // 50 kB = 50 * 1024 bytes\n      },\n      region: 'us-west-2',\n      request: {\n        endpoint: 'https://xxxxx.s3.amazonaws.com/',\n        accessKey: 'XXXXXXXXXXXX'\n      },\n      signature: {\n        endpoint: 'http://xxxxxxxxxxxxxxx/s3_signature/',\n        // version: 4,\n      },\n      uploadSuccess: {\n           endpoint: 'http://localhost:3000?success=true'\n       },  \n      cors: {\n        expected: true,\n        sendCredentials: true\n      },\n      callbacks: {\n        onSubmit: function (id, fileName) {\n          console.log(\"ohh wow\");\n          instance.browsedImages.push({\n            id: id,\n            fileName: fileName\n          });\n      console.log(instance.browsedImages);\n      // passing data to child component for display. which is a modal component\n      // imageUploadModal referes to child modal component\n      instance.imageUploadModal.browsedImages = instance.browsedImages;\n      instance.imageUploadModal.open();\n       instance.imageUploadModal.drawImagePreview();          \n    },\n\n    },\n\n  }\n});\n\n}\n```\nbelow is the method which is used for preview in modal compoent. This method is part of imageUploadModal component. \n```\npublic drawImagePreview() {\n         this.ref.detectChanges();\n         for (let i = 0 ; i < this.browsedImages.length; i++) {\n                //  let imgElement = $('#preview-img-' + this.browsedImages[0].id);\n               let imgElement = this.elRef.nativeElement.querySelector('#preview-img-' + this.browsedImages[i].id);\n             console.log('preview-img-' + this.browsedImages[i].id);\n             console.log(imgElement);\n             this.fineUploader.drawThumbnail(this.browsedImages[i].id, imgElement, null, false);\n     }\n }\n\n```\nAbove code successfully previews images on modal. But in the console it generates target.onload() error. . ",
    "mottoregina": "That is not an answer because it's create by the format methode it self so the message that go's in create an undefined val. So how the hack can you ensure that it is not undefined? \nIt looks more that the reason is pore documentation and happy flow programming.. if the server gives a json response back it go's through the qq.format and it chockes on that.\nBecause it starts to remove the {} brackets from it and it ends in a undefined.\nSo pore documentation or only happly flow programming without unittesting.. It is quite easy reproduce this error use the java server code from the repository and you will see this error happing and open for example chrome develop . So it is not an old version (5.14.5). It is all from the githup repository (https://github.com/FineUploader/server-examples)\nthe method writeResponse from  UploadReceiver returns json and internally qq.format choke on it.\nAnd there is no documentation on the structuere of the json that should be return and what is except by the javascript code by fine uploader.\nI checked all other program languages from the examples to find a better json example but the other langauge don't return any json reponse. There are no examples in other language either. So Java example serverside code is the most completed in that sense.\n . ",
    "Michael-Overall": "How in depth would an appropriate pull request to fix this issue be?\nFor writing accompanying unit tests, test/unit/uploader.basic.api.js seems to use the Mocha unit test framework to ensure api functions set values correctly. It looks like tests have been implemented to either mock or use actual file uploads. What would be the preferred way to test limiting dropped files with these tools?. ",
    "mmartain": "Well, it was an issue afterall: On the azure api documentation page there is a mention about chunking, but not that u have to put the enabled flag also. So in the end the documentation was a bit confusion making me not realize you have to enable chunking explicitly... Maybe something to add in the documentation?. ",
    "msavvy": "Ok, Thanks.\nhttps://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail\nVirus-free.\nwww.avast.com\nhttps://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail\n<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>\nOn Thu, Jul 20, 2017 at 8:14 PM, Ray Nicholus notifications@github.com\nwrote:\n\nWe definitely do no support opera on iOS. Also, the issue, as you're\ndescribing it, is also definitely not an issue with this library\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/FineUploader/fine-uploader/issues/1887#issuecomment-316684803,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/Ac54mDrnIHjgaDNh-tgXu4g4CUqNbSAtks5sP0SUgaJpZM4Odnkk\n.\n. \n",
    "charlesswanson": "How do I configure fine-uploader to hit my local s3 endpoint? For example, my local s3 server might be running on localhost port 10001. \nrelated: https://github.com/jubos/fake-s3/wiki/Supported-Clients. ",
    "cartproduction": "`<!DOCTYPE html>\n\n\n\n\n<!-- Fine Uploader New/Modern CSS file\n====================================================================== -->\n<link href=\"azure.fine-uploader/azure.fine-uploader-new.css\" rel=\"stylesheet\">\n\n<!-- Fine Uploader JS file\n====================================================================== -->\n<script src=\"azure.fine-uploader/azure.fine-uploader.js\"></script>\n\n<!-- Fine Uploader Thumbnails template w/ customization\n====================================================================== -->\n<script type=\"text/template\" id=\"qq-template-manual-trigger\">\n    <div class=\"qq-uploader-selector qq-uploader\" qq-drop-area-text=\"Drop files here\">\n        <div class=\"qq-total-progress-bar-container-selector qq-total-progress-bar-container\">\n            <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-total-progress-bar-selector qq-progress-bar qq-total-progress-bar\"></div>\n        </div>\n        <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n            <span class=\"qq-upload-drop-area-text-selector\"></span>\n        </div>\n        <div class=\"buttons\">\n            <div class=\"qq-upload-button-selector qq-upload-button\">\n                <div>Select files</div>\n            </div>\n            <button type=\"button\" id=\"trigger-upload\" class=\"btn btn-primary\">\n                <i class=\"icon-upload icon-white\"></i> Upload\n            </button>\n        </div>\n        <span class=\"qq-drop-processing-selector qq-drop-processing\">\n            <span>Processing dropped files...</span>\n            <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n        </span>\n        <ul class=\"qq-upload-list-selector qq-upload-list\" aria-live=\"polite\" aria-relevant=\"additions removals\">\n            <li>\n                <div class=\"qq-progress-bar-container-selector\">\n                    <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n                </div>\n                <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n                <img class=\"qq-thumbnail-selector\" qq-max-size=\"100\" qq-server-scale>\n                <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n                <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\" aria-label=\"Edit filename\"></span>\n                <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n                <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n                <button type=\"button\" class=\"qq-btn qq-upload-cancel-selector qq-upload-cancel\">Cancel</button>\n                <button type=\"button\" class=\"qq-btn qq-upload-retry-selector qq-upload-retry\">Retry</button>\n                <button type=\"button\" class=\"qq-btn qq-upload-delete-selector qq-upload-delete\">Delete</button>\n                <span role=\"status\" class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n            </li>\n        </ul>\n\n        <dialog class=\"qq-alert-dialog-selector\">\n            <div class=\"qq-dialog-message-selector\"></div>\n            <div class=\"qq-dialog-buttons\">\n                <button type=\"button\" class=\"qq-cancel-button-selector\">Close</button>\n            </div>\n        </dialog>\n\n        <dialog class=\"qq-confirm-dialog-selector\">\n            <div class=\"qq-dialog-message-selector\"></div>\n            <div class=\"qq-dialog-buttons\">\n                <button type=\"button\" class=\"qq-cancel-button-selector\">No</button>\n                <button type=\"button\" class=\"qq-ok-button-selector\">Yes</button>\n            </div>\n        </dialog>\n\n        <dialog class=\"qq-prompt-dialog-selector\">\n            <div class=\"qq-dialog-message-selector\"></div>\n            <input type=\"text\">\n            <div class=\"qq-dialog-buttons\">\n                <button type=\"button\" class=\"qq-cancel-button-selector\">Cancel</button>\n                <button type=\"button\" class=\"qq-ok-button-selector\">Ok</button>\n            </div>\n        </dialog>\n    </div>\n</script>\n\n<style>\n    #trigger-upload {\n        color: white;\n        background-color: #00ABC7;\n        font-size: 14px;\n        padding: 7px 20px;\n        background-image: none;\n    }\n\n    #fine-uploader-manual-trigger .qq-upload-button {\n        margin-right: 15px;\n    }\n\n    #fine-uploader-manual-trigger .buttons {\n        width: 36%;\n    }\n\n    #fine-uploader-manual-trigger .qq-uploader .qq-total-progress-bar-container {\n        width: 60%;\n    }\n</style>\n\n<title>Fine Uploader Manual Upload Trigger Demo</title>\n\n\n\n The element where Fine Uploader will exist. \n\n\n Fine Uploader \n\n\n        <div class=\"qq-uploader-selector qq-uploader\" qq-drop-area-text=\"Drop files here\">\n            <div class=\"qq-total-progress-bar-container-selector qq-total-progress-bar-container\">\n                <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-total-progress-bar-selector qq-progress-bar qq-total-progress-bar\"></div>\n            </div>\n            <div class=\"qq-upload-drop-area-selector qq-upload-drop-area\" qq-hide-dropzone>\n                <span class=\"qq-upload-drop-area-text-selector\"></span>\n            </div>\n            <div class=\"qq-upload-button-selector qq-upload-button\">\n                <div>Upload a file</div>\n            </div>\n            <span class=\"qq-drop-processing-selector qq-drop-processing\">\n                <span>Processing dropped files...</span>\n                <span class=\"qq-drop-processing-spinner-selector qq-drop-processing-spinner\"></span>\n            </span>\n            <ul class=\"qq-upload-list-selector qq-upload-list\" aria-live=\"polite\" aria-relevant=\"additions removals\">\n                <li>\n                    <div class=\"qq-progress-bar-container-selector\">\n                        <div role=\"progressbar\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\" class=\"qq-progress-bar-selector qq-progress-bar\"></div>\n                    </div>\n                    <span class=\"qq-upload-spinner-selector qq-upload-spinner\"></span>\n                    <img class=\"qq-thumbnail-selector\" qq-max-size=\"100\" qq-server-scale>\n                    <span class=\"qq-upload-file-selector qq-upload-file\"></span>\n                    <span class=\"qq-edit-filename-icon-selector qq-edit-filename-icon\" aria-label=\"Edit filename\"></span>\n                    <input class=\"qq-edit-filename-selector qq-edit-filename\" tabindex=\"0\" type=\"text\">\n                    <span class=\"qq-upload-size-selector qq-upload-size\"></span>\n                    <button type=\"button\" class=\"qq-btn qq-upload-cancel-selector qq-upload-cancel\">Cancel</button>\n                    <button type=\"button\" class=\"qq-btn qq-upload-retry-selector qq-upload-retry\">Retry</button>\n                    <button type=\"button\" class=\"qq-btn qq-upload-delete-selector qq-upload-delete\">Delete</button>\n                    <span role=\"status\" class=\"qq-upload-status-text-selector qq-upload-status-text\"></span>\n                </li>\n            </ul>\n            <dialog class=\"qq-alert-dialog-selector\">\n                <div class=\"qq-dialog-message-selector\"></div>\n                <div class=\"qq-dialog-buttons\">\n                    <button type=\"button\" class=\"qq-cancel-button-selector\">Close</button>\n                </div>\n            </dialog>\n            <dialog class=\"qq-confirm-dialog-selector\">\n                <div class=\"qq-dialog-message-selector\"></div>\n                <div class=\"qq-dialog-buttons\">\n                    <button type=\"button\" class=\"qq-cancel-button-selector\">No</button>\n                    <button type=\"button\" class=\"qq-ok-button-selector\">Yes</button>\n                </div>\n            </dialog>\n            <dialog class=\"qq-prompt-dialog-selector\">\n                <div class=\"qq-dialog-message-selector\"></div>\n                <input type=\"text\">\n                <div class=\"qq-dialog-buttons\">\n                    <button type=\"button\" class=\"qq-cancel-button-selector\">Cancel</button>\n                    <button type=\"button\" class=\"qq-ok-button-selector\">Ok</button>\n                </div>\n            </dialog>\n        </div>\n    \n\n        var uploader = new qq.azure.FineUploader\n            element: document.getElementById('fine-uploader'),\n            request: {\n                endpoint: 'https://{ YOUR_STORAGE_ACCOUNT_NAME }.blob.core.windows.net/{ YOUR_CONTAINER_NAME }'\n            },\n            signature: {\n                endpoint: '/signature'\n            },\n            uploadSuccess: {\n                endpoint: '/success'\n            },\n            retry: {\n               enableAuto: true\n            },\n            deleteFile: {\n                enabled: true\n            }\n        });\n    \n\n`. ",
    "klausgao": "I solve it. here is the code.\nconst pica = require('pica/dist/pica')();\n.......\n          customResizer: function(resizeInfo) {\n            console.log(JSON.stringify(resizeInfo));\n           return pica.resize(resizeInfo.sourceCanvas, resizeInfo.targetCanvas, {});\n          },. ",
    "nillo": "i updated my initial post. ",
    "froamer": "OK, I've just found the qq-server-scale=\"false\" option for the q-thumbnail-selector img tag in the template. \nI think that covers my needs.\nThanks for an amazing library!!!!!. ",
    "guzial": "i have not  mapped my custom domain name to mine S3\ni'm hosting my site also on S3 without own domain . ",
    "frandevel": "Also to be checked that in the _formatSize method, the size in bytes is being devided by 1000 (1e3), but I guess it should actually be divided by 1024.. @rnicholus : If it's in bytes, for me, 1000 would be incorrect. If you convert from bytes to kb's you divide by 1024 and then to mb by 1024 again.. ok. Thanks for the info @rnicholus . ",
    "pruhstal": "@rnicholus thank you very much :). Thanks @rnicholus, that worked, however I'm running into the following response (400) from S3:\n<Error>\n  <Code>InvalidArgument</Code>\n  <Message>POST requires exactly one file upload per request.</Message>\n  <ArgumentName>file</ArgumentName>\n  <ArgumentValue>0</ArgumentValue>\n  <RequestId>[redacted]</RequestId>\n  <HostId>[redacted]</HostId>\n  </Error>\nI set up the bucket policy and created the user rules per: https://blog.fineuploader.com/fine-uploader-s3-upload-directly-to-amazon-s3-from-your-browser-3d9dcdcc0f33\nThis is the payload:\n```\n------WebKitFormBoundaryCJ3CGGH8JAY3B5aC\nContent-Disposition: form-data; name=\"qquuid\"\ne07c027b-0d47-43bf-8059-78d844bfa2c4\n------WebKitFormBoundaryCJ3CGGH8JAY3B5aC\nContent-Disposition: form-data; name=\"qqfilename\"\ntest\n------WebKitFormBoundaryCJ3CGGH8JAY3B5aC\nContent-Disposition: form-data; name=\"qqtotalfilesize\"\n918\n------WebKitFormBoundaryCJ3CGGH8JAY3B5aC\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"blob\"\nContent-Type: text/csv;charset=utf-8;\n------WebKitFormBoundaryCJ3CGGH8JAY3B5aC--\n```\nI found one other issue in this repo #1717 related to this error message, but they seem to be using the UI and not the core.. @rnicholus ok, so for some reason it still doesn't work:\n```\nimport qq from 'fine-uploader/lib/s3';\nconst uploader = new qq.s3.FineUploader({\n      debug: true,\n      request: {\n        endpoint: 'http://.s3.amazonaws.com',\n        accessKey: ,\n        secretKey: ,\n        sessionToken: null\n      },\n      chunking: {\n        enabled: true,\n      },\n      objectProperties: {\n        bucket: '',\n        host: 'http://.s3.amazonaws.com' // only needed for version 4 signatures\n      },\n      signature: {\n        // endpoint: '/s3/signature',\n        version: 2,\n      },\n      uploadSuccess: {\n        endpoint: null,\n        method: \"POST\",\n      }\n    });\nuploader.addFiles({name: 'test', blob: parsedFile});\n\n```\nI then get:\n\nSo why is the s3 lib requiring a template if I'm manually adding the files?\nThanks for helping me out.. I'm now uploading like:\nimport qq from 'fine-uploader/lib/core/s3';\nand calling it as such:\n```\nconst uploader = new qq.s3.FineUploader({\n      debug: true,\n      request: {\n        endpoint: 'http://.s3.amazonaws.com',\n        accessKey: ,\n        secretKey: ,\n        sessionToken: null\n      },\n      chunking: {\n        enabled: true,\n      },\n      objectProperties: {\n        bucket: '',\n        host: 'http://.s3.amazonaws.com' // only needed for version 4 signatures\n      },\n      signature: {\n        // endpoint: '/s3/signature',\n        version: 2,\n      },\n      uploadSuccess: {\n        endpoint: null,\n        method: \"POST\",\n      }\n    });\nuploader.addFiles({name: 'test', blob: parsedFile});\n\n```\nand I'm seeing:\nTypeError: Cannot read property 'XhrUploadHandler' of undefined\nbut I don't see anything in the docs about XhrUploadHandler.. ",
    "bibidon": "Are there any updates or workarounds?. ",
    "d-a-s": "I ended up manually altering the canonical header on my server, just before i did all the hashing and other stuff. As I recall, it was as simple as taking the bucket name from the \"host\" line and moving it to the beginning of the path, which i think is the next line.. ",
    "bagr001": "It is the same problem as here #2010 . I have conducted some research about this and found out folowing. The whole problem is when using S3 endpoint with bucket in URL - eg. https://s3.amazonaws.com/mybucket. Root problem is with function getCanonicalUri.\njs\ngetCanonicalUri: function(endOfUri) {\n    var path = endOfUri, queryParamIdx = endOfUri.indexOf(\"?\");\n    if (queryParamIdx > 0) {\n        path = endOfUri.substr(0, queryParamIdx);\n    }\n    return \"/\" + path;\n},\nThis function is returning only canonical path to the requested object but without the bucket name (/file.txt except /mybucket/file.txt). This is resulting in wrong signig request that differs from actual request to S3.\nIf you modify the code to this, it works.\njs\ngetCanonicalRequest: function(signatureSpec) {\n    return qq.format(\"{}\\n{}\\n{}\\n{}\\n{}\\n{}\", signatureSpec.method, v4.getCanonicalUri(signatureSpec.bucket, signatureSpec.endOfUrl), v4.getCanonicalQueryString(signatureSpec.endOfUrl), signatureSpec.headersStr || \"\\n\", v4.getSignedHeaders(signatureSpec.headerNames), signatureSpec.hashedContent);\n},\ngetCanonicalUri: function(bucket, endOfUri) {\n    var path = endOfUri, queryParamIdx = endOfUri.indexOf(\"?\");\n    if (queryParamIdx > 0) {\n        path = endOfUri.substr(0, queryParamIdx);\n    }\n    return \"/\" + bucket + \"/\" + path;\n},\nBut it's just a workaround. It definitely deserves a proper solution.. I have to make a closer look at the bloblem. But as far as i know, it will be much more complex because it affects the esential part of the library, particulary how host, bucket and canonical Uri is being determinated.. @JacobEvelyn can you provide more info about your configuration? \n- what is your setting\n- what is sent to the server as a request to sign\nI am using nodeJs handler.... ",
    "felipedeboni": "@bibidon replace the following functions:\njavascript\ngetCanonicalRequest: function(signatureSpec) {\n    return qq.format(\"{}\\n{}\\n{}\\n{}\\n{}\\n{}\", signatureSpec.method, v4.getCanonicalUri(signatureSpec.bucket,signatureSpec.endOfUrl), v4.getCanonicalQueryString(signatureSpec.endOfUrl), signatureSpec.headersStr || \"\\n\", v4.getSignedHeaders(signatureSpec.headerNames), signatureSpec.hashedContent);\n},\ngetCanonicalUri: function(bucket, endOfUri) {\n    var path = endOfUri, queryParamIdx = endOfUri.indexOf(\"?\");\n    if (queryParamIdx > 0) {\n        path = endOfUri.substr(0, queryParamIdx);\n    }\n    return \"/\" + bucket + \"/\" + path;\n},\nAlso, look for requestInfo.headers.Host = requestInfo.host and replace with:\njavascript\nrequestInfo.headers.Host = requestInfo.host.indexOf(requestInfo.bucket) > -1 ? requestInfo.host.replace(\"/\" + requestInfo.bucket, '') : requestInfo.host;. ",
    "nomadus": "@rnicholus \nThanks for the response, I shall add formatting, I missed that.\nIn the signature block I put\nsignature: {\n        endpoint:${config.environment.api_baseUrl}/s3/signature,\n        version: 4,\n        customHeaders: {\n          'Authorization': 'Basic ' + btoa(config.WS_USERNAME + ':' + config.WS_PASSWORD),\n        }\n      },\nAlso, the code works with no changes OK when I do not use CloudFront and instead directly upload to S3.. @rnicholus Is there some testing environment, where I could reproduce the issue?. This is strange, do you happen to know if there are any recommendations to setup cloudfront? All the settings seem to be default, except the ssl.\n\nOn Sep 10, 2017, at 9:01 AM, Ray Nicholus notifications@github.com wrote:\nSounds like a configuration issue with your CloudFront distribution. If you find a specific issue in the fine uploader codebase, let me know and I can reopen this.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I have created an S3 bucket in different region, which supports v2 signature and pointed CF to this, newly created S3. The upload works, so it seems to be not CF settings issue.. \n",
    "karms": "Updated.. The button is has no opacity and is positioned over the element that I add the fine uploader to such that I cannot click on it to start the upload. This is because the file input added by fine uploader always has a style that makes the input wider, taller, and invisible. I'll refer to the code again that's part of core, and I'll include the whole function so there's a better understanding of what is happening:\n```\nfunction createInput() {\n            var input = document.createElement(\"input\");\n            input.setAttribute(qq.UploadButton.BUTTON_ID_ATTR_NAME, buttonId);\n            input.setAttribute(\"title\", options.title);\n            self.setMultiple(options.multiple, input);\n            if (options.folders && qq.supportedFeatures.folderSelection) {\n                input.setAttribute(\"webkitdirectory\", \"\");\n            }\n            if (options.acceptFiles) {\n                input.setAttribute(\"accept\", options.acceptFiles);\n            }\n            input.setAttribute(\"type\", \"file\");\n            input.setAttribute(\"name\", options.name);\n            qq(input).css({\n                position: \"absolute\",\n                right: 0,\n                top: 0,\n                fontFamily: \"Arial\",\n                fontSize: qq.ie() && !qq.ie8() ? \"3500px\" : \"118px\",\n                margin: 0,\n                padding: 0,\n                cursor: \"pointer\",\n                opacity: 0\n            });\n            !qq.ie7() && qq(input).css({\n                height: \"100%\"\n            });\n            options.element.appendChild(input);\n            disposeSupport.attach(input, \"change\", function() {\n                options.onChange(input);\n            });\n            disposeSupport.attach(input, \"mouseover\", function() {\n                qq(options.element).addClass(options.hoverClass);\n            });\n            disposeSupport.attach(input, \"mouseout\", function() {\n                qq(options.element).removeClass(options.hoverClass);\n            });\n            disposeSupport.attach(input, \"focus\", function() {\n                qq(options.element).addClass(options.focusClass);\n            });\n            disposeSupport.attach(input, \"blur\", function() {\n                qq(options.element).removeClass(options.focusClass);\n            });\n            return input;\n        }\n```\nI posit that the css that is included, should be changed into simply qq(input).css({display: none'}); and the css added here to be moved into the version that has the UI included.\n. ",
    "vikyd": "Found a non-doc way:\nGet uploader instance: let uploader = $('.uploader').data('fineuploader').uploader\nGet uploader upload results: let uploadResults = uploader.getUploads(). How can I get uploader instance from element with current version ? \nWhere is the doc ?\n. Even not use the jquery wrapper, I need it, because I have more than one uploader in one page.\nI don't want to cache the loader variable.. ",
    "Saty7476": "I have tested  this with\n attached system info and the problem is same.\nIts not a network issue because I am able to upload video using chrome with same system and it is working flawless.\n. Sorry my mistake I'm using 5.15.0 version of library. I'm not getting any issue with chrome.. ",
    "beingak": "A screenshot will make much more sense.\nBefore uploading an image: There is an option to edit image name.\n\nAfter displaying custom error message edit option is no more.\n\nDoes this make sense now? I am using Fine Uploader 5.14.1\nThank you.\n. This was the case when on uploading server return success as false and custom error message was shown. I am not sure this case is under upload started. If yes then thanks for all your help and for this great plugin. I will look into another way so that user can rename image after error too. If there is something can be changed in core files, please let me know.. ",
    "Netherdrake": "Any tips for how to hook into FineUploader and perform the sha1checksum?\n(sorry for bugging you with requests). ",
    "JeffreyATW": "Ooh, that\u2019s great to hear. The bad news in my case is that I\u2019m trying to associate the file with the button that was clicked, and react-fine-uploader\u2019s <FileInput /> element doesn\u2019t assign a qqButtonId, so I\u2019m not sure what I\u2019d do in the success function. But I\u2019ll file a separate issue. Thanks!. ",
    "blacktoby": "I searched a way to avoid duplicate adding Thumbnails to the thumbGenerationQueue. \nI saw that the updateThumbnail is called two times:\nOne time in _addToList  and one time in _maybeUpdateThumbnail (part of qq.uiPrivateApi). \n_addToList is called when _onSubmit runs and _maybeUpdateThumbnail is called when _markFileAsSuccessful runs.\nAt this point I dont have a deeper look how fineuploader is working. So I just compared the parameters given when updateThumbnail is called. I saw that the first time showWaitingImg is true and the second time undefined.\nI also observed, that the second call of the update Function is not necessary to show the thumbnail image. So I just excluded the second push to the queue with:\nif(showWaitingImg !== true) { return; }\nMay be not the best way to handle this problem. For me it was the best way to get this problem solved, without deep dive into the code and change major procedures.. ",
    "Bhupadhy": "Hello @rnicholus,\nIm interested in using the per-file chunk sizes in my project with a stable version of fineuploader. I am thinking of forking the latest stable version and adding the commits which relate to that feature. Would something like this be possible? Which commits beyond 8eb98d7 and 53b397d relate to this feature? I have been using this feature in development and it seems to work well.\nThanks for your work on this project. @rnicholus ,\nI am currently using RC1 and I haven't ran into any issues yet.. ",
    "Quinlan96": "I think it initialized before the page was loaded, wrapping in a $(document).ready() fixes this.. ",
    "edwardsph": "I am seeing the same issue in 5.15.4 - I reverted to 5.15.2 and the problem disappeared.. ",
    "HiCoasterTao": "hello rnicholus, I removed dnd.js file. Thanks for noticing.. ",
    "dapug": "RESOLVED.\nThe issue isn't technically due to Fine Uploader, but Fine Uploader could be tweaked to handle this discrepancy.\nASP.NET MVC will treat string responses as JSON, and therefore will wrap \"quotes\" around output, and add the Content-Type \"application/json\" for you automagically.  By adding a \"Produces\" attribute to the controller, it forces the Content-Type you want:\n[HttpGet]\n[Produces(\"text/plain\")]\npublic string UploadSignature(string _method, string bloburi, string qqtimestamp)\n{\n}\nYay!  So yeah, File Uploader could be enhanced to trim junk like that, but it's really not the responsibility of the library IMO.\n@rnicholus Just FYI, the docs are out of sync with the latest code on that parameter I highlighted above.  it's _bloburi in the docs, but bloburi in the runtime code, and this can cause a brief head scratcher (null param) if you use the docs as you build your projects.\n. Honestly, I'm thinking about doing an entire .NET article.  It was waaaay too much pain to put a simple thing together due to gotchas you just don't think about every day, and I was shocked to see no real ASP.Net examples out there.  But yes, I will see what I can do about a PR for that at the very least.. ",
    "Martinsos": "Just in case somebody else is searching, I had the same problem. In my case it was mistake I made in SAS signer in my nodejs server: I was returning SAS token instead of SAS Uri. Also I can confirm that returning it as text/html works fine.. Awesome, thanks!\nQuestion for the future, if I change a piece of docs, is there any easy way to render it and check what it looks like?. ",
    "scumola": "Thanks, I read that and tried it but I don't need zappa or letsencrypt or anything like that and frankly I couldn't get it to work because it requires me to upload my AWS creds to an S3 bucket (a no-no), a whole new domain, ssl cert...  I just need a drop-in lambda function that'll do the signature without all of the extra crap.  I would think that this would be a pretty common request from users of your library.. ",
    "menangen": "Yes, I need too guide for using signed url from AWS Lambda on clients side. Which FU build is better to use? S3 or traditional uploader? In which event callback is better to use requesting to Lambda for signed url? And in which step to patch endpoint in FU instance? Advantages/disadvantages of chunked upload to S3, is it possible use chunked feature with one signed url to upload to S3 signed url endpoint? Thx for help :). ",
    "HemalR": "Would this be solved by having the signature be created via an arbitrary function? Then people can simply use whatever code they wish in order to generate that signature - whether that is a lambda function or something else (in my case, I'm trying to use a Meteor method to return the valid signature back to the client).. ",
    "DrewHoo": "Turns out this was a server error.. ",
    "sachin7254": "Workspace folder name should not be same. ",
    "BrianTolman": "ok - thanks.  I guess this issue is closed?. ",
    "o3LL": "Sure, that's what I was planning to do. Just wanted to know if this feature was suitable in this project ! . ",
    "rkbansal": "Fine Uploader version\n5.2.1\nBrowsers where the bug is reproducible\nGoogle chrome\nOperating systems where the bug is reproducible\nWindows 10\nExact steps required to reproduce the issue\n\nSelect any number of files only with invalid filename (invalid file name is any file which contains any of these ,/\\|'\";: characters in my case)\nAfter that, upload any valid filename.\nYou can see the fineuploader is trying to upload all the files including previous invalid files.\n\nYour Fine Uploader template markup\nWe are using our Own UI. And i think there is no need of UI in this case, if yes, then please let me know.\nDetailed explanation of the problem\nThis is my onValidate function\nonValidate: function(file){\n            if(file && file.name)\n            {\n                var pattern = /[,/\\|'\";:]/ ;\n                return !pattern.test(file.name);\n            }}\nI just want to remove the invalid files from the queue which is not happening by default when i am returning false from onValidate function. Any kind help will be fine.\n. Okay! I got it. It is maintaining the status of each file, so I can filter out files by status and show the files only with status equals \"submitting\" in the UI.. ",
    "awaistune": "If i retry it manually it will throw same error after each retry. I want to give this control to user so that user can check his/her connection in that time. Also on onError event why uploader calls total progress event. This happens when file exceeds total file size , Invalid extension/type. First status changed from submitting to rejected below is the debug log\n```\n\nuploader_left_fine.vue?2c3e:519 newStatus submitting\nfine-uploader.core.js?b73f:162 [Fine Uploader 5.15.6] Received 1 files.\nfine-uploader.core.js?b73f:162 [Fine Uploader 5.15.6] onValidateBatch - waiting for onValidateBatch promise to be fulfilled for batch validation\nfine-uploader.core.js?b73f:162 [Fine Uploader 5.15.6] onValidateBatch promise success for batch validation\nfine-uploader.core.js?b73f:162 [Fine Uploader 5.15.6] onValidate - waiting for onValidate promise to be fulfilled for Item 'linux-image-extra-4.8.0-59-generic_4.8.0-59.64_amd64.deb', size: 37408736\nfine-uploader.core.js?b73f:162 [Fine Uploader 5.15.6] onValidate promise success for Item 'linux-image-extra-4.8.0-59-generic_4.8.0-59.64_amd64.deb', size: 37408736\nuploader_left_fine.vue?2c3e:536 linux-image-extra-4.8.0-59-generic_4.8.0-59.64_amd64.deb\nuploader_left_fine.vue?2c3e:537 linux-image-extra-4.8.0-59-generic_4.8.0-59.64_amd64.deb has an invalid extension. Valid extension(s): wmv, avi, divx, 3gp, mov, mpeg, mpg, xvid, flv, asf, rm, dat, mp4, mkv, m4v, f4v, dat, webm, ogv.\nfine-uploader.core.js?b73f:165 [Fine Uploader 5.15.6] Caught exception in 'onTotalProgress' callback - Cannot read property 'length' of null\nqq.log @ fine-uploader.core.js?b73f:165\nlog @ fine-uploader.core.js?b73f:1207\nsafeCallback @ fine-uploader.core.js?b73f:2344\nself._options.callbacks.(anonymous function) @ fine-uploader.core.js?b73f:2353\n_onTotalProgress @ fine-uploader.core.js?b73f:2115\n(anonymous) @ fine-uploader.core.js?b73f:460\ncallbackProxy @ fine-uploader.core.js?b73f:5092\nupdateTotalProgress @ fine-uploader.core.js?b73f:5135\nonCancel @ fine-uploader.core.js?b73f:5106\nonStatusChange @ fine-uploader.core.js?b73f:5141\n(anonymous) @ fine-uploader.core.js?b73f:1472\nsetTimeout (async)\nonStatusChange @ fine-uploader.core.js?b73f:1471\nsetStatus @ fine-uploader.core.js?b73f:959\n_fileOrBlobRejected @ fine-uploader.core.js?b73f:1629\n(anonymous) @ fine-uploader.core.js?b73f:2307\n(anonymous) @ fine-uploader.core.js?b73f:741\nqq.each @ fine-uploader.core.js?b73f:428\nfailure @ fine-uploader.core.js?b73f:740\n_validateFileOrBlobData @ fine-uploader.core.js?b73f:2311\n_onValidateCallbackSuccess @ fine-uploader.core.js?b73f:2165\n(anonymous) @ fine-uploader.core.js?b73f:460\n(anonymous) @ fine-uploader.core.js?b73f:1750\nPromise resolved (async)\n_handleCheckedCallback @ fine-uploader.core.js?b73f:1748\n_onValidateBatchCallbackSuccess @ fine-uploader.core.js?b73f:2142\n(anonymous) @ fine-uploader.core.js?b73f:460\n(anonymous) @ fine-uploader.core.js?b73f:1750\nPromise resolved (async)\n_handleCheckedCallback @ fine-uploader.core.js?b73f:1748\n_prepareItemsForUpload @ fine-uploader.core.js?b73f:2178\naddFiles @ fine-uploader.core.js?b73f:1073\n_onInputChange @ fine-uploader.core.js?b73f:2071\nonChange @ fine-uploader.core.js?b73f:1502\n(anonymous) @ fine-uploader.core.js?b73f:807\n\n```. ",
    "wann2": "Could you show me how to change the config so that I can have success about Gif file?\n(so that EXIF header parsing can accept GIF). How can I add exif header in gif?\nDo you have any guide?. ",
    "ogvolkov": "There is a pull request which fixes it already.\nBut to clarify, if I upload a folder \"data\" which contains a folder \"sub\" which contains a file \"ub\", the resulting payload is\n```\n------WebKitFormBoundaryxwMePIf55gNLuxW1\nContent-Disposition: form-data; name=\"qqpath\"\ndata/s\n------WebKitFormBoundaryxwMePIf55gNLuxW1\nContent-Disposition: form-data; name=\"qquuid\"\n8bbf2d77-7f76-457d-97f4-a327afb673fa\n------WebKitFormBoundaryxwMePIf55gNLuxW1\nContent-Disposition: form-data; name=\"qqfilename\"\nub\n```\netc.\nThe reason is the code tries to remove the file name from the path by finding a first occurrence via indexOf, so \"/data/sub/ub\" without \"ub\" becomes \"/data/s\", which is clearly incorrect. Yes, the functional change is only that.\nHowever to have it tested I've extracted it as a separate function, which is also a bit cleaner imo.. ",
    "Fensterbank": "Sorry, but this is not true. Firefox for Android is a modern browser for mobile devices and supports most features.\nThis line should check if it is an Android stock browser but instead it checks if it is not Chrome for Android.\nThat's a bug since there are more mobile browser out there than Chrome for Android.\nHere is the problem:\nsupportsUploadingBlobs = supportsAjaxFileUploading && !qq.androidStock();\nSince qq.androidStock() returns true on Firefox for Android FineUploader thinks that this browser doesn't support blobs.. The issue you mentioned is about features of old stock browsers. We shouldn't care about them.\nI checked this site and it seems that Firefox for Android is the only browser on Android, which doesn't have \"Chrome\" in it's user agent.\nSo a working solution without messing other things up would be to modify qq.androidStock() and add to check for the \"Firefox\" string.\nI will check and try to confirm the scaling functionability in Firefox for Android. But since it uses Gecko, I'm pretty sure it works as good as in Chrome.\nWhile I validate and prepare a PR you are free to reopen the issue. :). Is there a timeline until when we can expect a merge of the pull request? \ud83d\ude41. ",
    "nicompte": "Hi, it seems they had the same issue on https://github.com/nodeca/pica/issues/130. There is now a reported bug on firefox: https://bugzilla.mozilla.org/show_bug.cgi?id=1450302.. ",
    "vishal-akg": "Okay just simply tell me how to pass parameters in chunking success params i.e when all the chunks has been successfully uploaded.\nas per documentation https://docs.fineuploader.com/branch/master/api/options.html#chunking.success.params\ncan be used.. By doing so i have to send qquuid too, which i am not able to get, in any possible way.. this object inside function callback doesn't have getUuid method.. ok thanks.\nBut the way parameters are passed in request.params options is json object while in chunking.success.params in callback function. \nIn request params i don't have to pass qquuid and other parameters but in case of chunking success params i have to pass each parameters explicitly.. ",
    "sukonzer": "@rnicholus \nReproduce steps:\n1. Click \"select file\" button.\n2. Drag file into dropzone area from the pop-up window.\nPlease repeat several times above operation\nHigh reproduce rate. ",
    "webdevnerdstuff": "The mime type for image/jpeg is in the request payload. The headers are for the most part identical for an image that doesn't have this issue.\nAlso in case it helps or you need it, here is one image that is having this issue.\nGeneral\nRequest URL: https://dev.somedomain.com/ajax/media/upload\nRequest Method: POST\nStatus Code: 200 OK\nRemote Address: ###.###.##.##:###\nReferrer Policy: no-referrer-when-downgrade\nResponse Headers\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nConnection: Keep-Alive\nContent-Encoding: gzip\nContent-Length: 551\nContent-Type: text/html; charset=UTF-8\nDate: Fri, 27 Apr 2018 16:59:08 GMT\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\nKeep-Alive: timeout=5, max=100\nPragma: no-cache\nServer: Apache/2.4.7 (Ubuntu)\nSet-Cookie: ci_session=c7bf0b6d6798267124d09e894a9e28024ab7eeec; expires=Fri, 27-Apr-2018 18:59:08 GMT; Max-Age=7200; path=/; httponly\nVary: Accept-Encoding\nX-Powered-By: PHP/5.5.9-1ubuntu4.24\nRequest Headers\nAccept: application/json\nAccept-Encoding: gzip, deflate, br\nAccept-Language: en-US,en;q=0.9,la;q=0.8,da;q=0.7\nCache-Control: no-cache\nConnection: keep-alive\nContent-Length: 6318639\nContent-Type: multipart/form-data; boundary=----WebKitFormBoundaryeQx97ncMIhhvpQPg\nCookie: ci_session=c7bf0b6d6798267124d09e894a9e28024ab7eeec\nHost: dev.somedomain.com\nOrigin: https://dev.somedomain.com\nReferer: https://dev.somedomain.com/admin/media/add\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36\nX-Requested-With: XMLHttpRequest\nRequest Payload\n------WebKitFormBoundaryeQx97ncMIhhvpQPg\nContent-Disposition: form-data; name=\"qquuid\"\nb67350a8-5407-4cf7-a514-cbfe40eca8a6\n------WebKitFormBoundaryeQx97ncMIhhvpQPg\nContent-Disposition: form-data; name=\"qqfilename\"\nhello-world.jpg\n------WebKitFormBoundaryeQx97ncMIhhvpQPg\nContent-Disposition: form-data; name=\"qqtotalfilesize\"\n6318098\n------WebKitFormBoundaryeQx97ncMIhhvpQPg\nContent-Disposition: form-data; name=\"qqfile\"; filename=\"hello-world.jpg\"\nContent-Type: image/jpeg\n------WebKitFormBoundaryeQx97ncMIhhvpQPg--. I would also note that if I have chunking enabled I don't get this problem, which might wind up being the thing I have to change. As the larger file size could be what's messing things up. I would just need to accommodate for that on the backed as it saves each chunk and doesn't result in a completed image being saved currently. That and it comes in with the mime-type of application/octet-stream instead of image/jpeg.. Wow, just found this page. Going to take a look into using this instead of my code.\nhttps://github.com/FineUploader/php-traditional-server. After integrating the php from that page, it has a similar issue.. After full integration of that PHP from the page I found, I have things working. I guess one thing that would be very helpful and useful for certain things is sending the qqfile data to the chunking.success.endpoint. That alone would have saved me a lot of time.\nSo I guess you can just close this one out. But please consider adding the qqfile data with the chunking.success.endpoint, as getting that information once the chunks are complete is still eluding me. I basically just said screw it and changed some of the other logic involved that was using the mime-type.. ",
    "Markyparky": "Nevermind - my PHP server wasn't configured correctly.. ",
    "JacobEvelyn": "The server's returning JSON that looks like { signature: \"...\" } as I'd expect, and it's definitely using the v4 algorithm to generate it. I've verified that the algorithm the PHP server's producing exactly matches what the example Node.js server produces using v4. I've further confirmed that I can upload files with the v4 signature when chunking is not used, so it appears to only be an issue when chunking is enabled with v4 signatures; since the signature works for non-chunked uploads I suspect there's a bug somewhere in the FineUploader client JS that handles the chunking algorithm.\nI've looked at the V4 test suite but I'm having trouble understanding how the different stages in the test suite interact with the requests FineUploader makes to S3 when chunking is enabled.. I think creating a fix might be a little bit beyond my technical ability. @bagr001 would you be able to?. @bagr001 hmm, the code you pasted above doesn't seem to work for me. Did you have to make any changes to the server signing code as well?. ",
    "davewoodall": "@jedmarasigan Please paste or link us to some code so we can try to help. We don't know if this issue is related to Node, Express, ES or other. In the meantime, press on.. ",
    "logemann": "I can answer question 1 myself via\nhttps://docs.fineuploader.com/branch/master/features/no-server-uploads.html. Question 2: thanks. Have seen some examples here and there with key() function. \nRegarding maintaining the library. Unfortunately i am not good enough on the JS side, coming from a more Java enterprise background. Still fighting with react.\nSpeaking of react. I really searched a lot. It seems there is no good example on how to use client side only S3 upload with integrated singing. The only one i found is quite old (https://github.com/FineUploader/integration-examples/blob/master/src/s3-no-server/fineuploader-glue.js) and not react based. \nIs there a react example somewhere? Also i dont get why i need a signature endpoint when i can already supply credentials via \"credentials\" config key. Thought that the signing can be on the client which by looking at the code from FineUploaderS3 seems to be the case.\nRegarding backing this project. You should consider using https://opencollective.com. Its pretty easy for backers to support projects. I ve done it with mobx recently. Perhaps you might consider this.\n. ",
    "DanielWare": "There are many client side connection issues that can\u2019t be solved from the developers end. What about especially large files on poor connections? Users don\u2019t want to sit and stare at an upload screen for an hour clicking retry every time their connection gets reset. By allowing a Boolean return, devs can check other factors (to see if there is a connection at all, etc) and determine if the current upload should continue or fail. \nAlternatively being able to set the upload status to upload_failed by api would work.. ",
    "bazzacad": "OK, then how can I tell if the delete operation is finished?. Oops sorry, I found the callback events:\nhttps://docs.fineuploader.com/api/events.html\n. ",
    "donbobka": "+1 to enable overriding of any field (not only date)?\n. ",
    "oles-bolotniuk": "+1 Please merge\nThis is pretty much critical, because as finalizing process of some files may take time - onAllComplete gets called twice:\n\nFirst time when all uploads are done\nSecond time when finalizing of the last file is done. \n",
    "jwcharp": "@rnicholus \nYes, I see this however, If I place 100 thumbnails using just img tag on a page, and load it, I can get it to finish loading ~5-10s\nIf I preload 100+ images through the addInitialFiles function with setting timeBetweenThumbs to 0 it takes upto ~25-30s.\nA 3x-5x time jump, is there any way to make the drawing of the images multi-threaded in workers? or asynchronous?\n. ",
    "sagarsolace123": "Hello Guys, I have created a demo with fine uploader latest version but it also not produce image preview when I try to upload an image over the size of 120 MB\nhttp://www.solaceinfotech.com/projects/fineuploaderdemo/fudemo.php\nPlease suggest. . ",
    "CheyenneForbes": "Seriously? you just closed the issue without saying anything?. ",
    "ranuser99": "In our testing, concurrently uploading chunks do not produce a greater aggregate throughput due to the V4 hashing bottleneck.  We found that concurrency of 2 produced no greater total sustained throughput and higher levels of concurrency were actually detrimental.\nAnother issue is that there is slight UI (main thread) freezing with single chunks due to our fast transfer speed (we're always hashing).  Increasing concurrency to 2+ really hurts UI smoothness.  We've also experimented with chunk sizes as well to no avail (we need 5-10MB chunks min to support large file transfers).\nIt's a shame as all of this is due to V4 signing and the apparent need to hash the entire request body.  Do you see any way to further mitigate the V4 performance penalty?  Do you think offloading hashing to web workers will produce a material improvement to both total throughput and UI smoothness?. ",
    "waynebloss": "You guys are looking for maintainers. According to stack overflow developer survey results something like 60% of developers prefer Windows.\nI\u2019m one of them and I\u2019d prefer to not have to install Cygwin just to work on one JS library.\n.  OK, it didn\u2019t look that complicated to me. After a brief glance, I think you can easily take this 500 line makefile and turn it into 10 or so npm script calls in a package.json file.  Maybe I\u2019m wrong.\nI don\u2019t see a lot of large, popular JavaScript projects using makefiles, so I can\u2019t imagine what you\u2019re doing with JavaScript that can\u2019t be done in the same fashion as those other projects. I\u2019ll take a look at it a little closer to find out. Thanks.\nCygwin is a huge install and a pretty high barrier to entry here in my opinion. . Sorry, I forgot about this because I ended up building my own uploader with React.. ",
    "HerringtonDarkholme": "Thank you for taking up the project!. Thanks!. ",
    "Anson-Zhao": "\n\n. ",
    "Chiff": "Yes they are, but there is nothing how to really use them inside component. It's better to see it in working example, like in your repo. Well at least for me it was helpful and I wanted to share that.. ",
    "markskayff": "Hi SinghSukhdeep,\nYeah, maybe it'd be an option. Thanks for your comment, I'll consider it.. Yes, it does matter. \nWe have an web app where we upload images to a remote server. The user will be able to select the images order, these are sent in a specific order to the server, and it's how they are displayed in the remote application.\nSo it does matter.. ",
    "inzanez": "Sure, I'll compose something minimal and will get back to you.. I will need to do some more tests. It seems that enabling concurrent chunking somehow got rid of the problem, maybe you know why that would be.\nI will do some more tests with different systems though.... Well, I can confirm that the error is gone using concurrent chunking,.... ",
    "FernandoFreitasPixelhouse": "Hi @SinghSukhdeep,\nDo you want see my server code? I didn't undesrstand.\nIn relation a \"Please read the issue template.....\" what I did wrong?\nThis problems happens only sometimes and aparently in iOs Devices.\nIt seems that problem happens in line bellow of file \"fine-uploader.js\":\n\"formData.append(spec.inputName, fileOrBlob);\"\n. Follows attached the html's and JS's.\nFiles.zip\n. Hi @rnicholus ,\nI used the debug mode in Mac connected with an iPhone.\nWhen I did this I comprove that content-length of pictures with trouble a so smaller that the pictures that are ok.\nEx.: content-length: 800 ( in post with error) and content-length: about: 4000 (in post ok)\nWhen I change \"maxConnections\" to 1 the problem didn't happen anymore.\n. ",
    "koryp123": "OK, here's the error:\n \"attempting to parse xhr response text\" \"unexpected token < in JSON at position 0\". it's requiring the 4 digit appendage to all zip codes and doesn't like it when there's only a 5 digit zip. error is: \"Error when attempting to parse xhr response text (Unexpected token < in JSON at position 0)\"\n. ",
    "Javarome": "Hi @SinghSukhdeep \nI encountered it many times in my production code when using <img> for preview. I am unable to share it here, but another user has reported here with some sample code : https://github.com/FineUploader/fine-uploader/issues/1882\nA PR was rejected about it because it prevented calling onload when defined, whereas this current PR will avoid calling it only when undefined.\nIn any case such a change can only make the code more robust by avoiding failure when the callback is not defined (but still calling it when it is).. ",
    "inglesuniversal": "Sorry bud if I didn't give you all the details, but the same issue happens with your sample code right at your domain page. I just double checked tonight. . ",
    "gwilson2151": "Ah, thanks for the response @rnicholus.\n@SinghSukhdeep The issue was actually found on the latest version. I was providing detail for the demo page, I'll fix that up in the bug report.. It looks like it's a Chrome bug.\nhttps://crbug.com/843040. ",
    "cgunther": "This breaks the form upload method as the handler doesn't have a reset method. More changes below also assume the XHR method and thus break when using a browser that doesn't support the XHR method.\n. "
}