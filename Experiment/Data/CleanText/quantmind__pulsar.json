{
    "lsbardel": "It is now fixed.\n. They have been removed in 0.4\n. Actually this will be implemented for all workers with a I/O queue.\n. No longer apply\n. This is done by the test suite with the --profile flag\n. Done\n. The --coverage is now available for all applications, not just tests.\n. this is fixed\n. fixed\n. Yes, supporting android apps is the aim.\n. Rejected\n. Which version are you getting this error?\nYou can check by doing\nimport pulsar\npulsar.__version__\n. can you try to download the 0.4 branch (the default branch) and test with that? \n. I can't replicate the issue in ubuntu,\nit looks like an error specific to darwin OS on this file \nhttps://github.com/quantmind/pulsar/blob/0.4/pulsar/apps/rpc/handlers.py\nline 304.\nEither the client sends the request with the wrong method or, more likely, the wsgi parser does not pick up the request method correctly. I'll have to test it on a mac.\n. I've run tests on python 3.3 in a mac and there was an issue which has been fixed in this commit 8d95b886cb2a4e8c654e1c8a570edd354949f4e8.\nAll tests now pass, however I'm not sure the bug was causing your problem.\nIn any case, can you test with the master branch, which should be version \"0.4.5b0\"?\n. Everything is fine on my mac, I've done a couple fixes on master, pull the latest changes and try again.\nYou can pass the --log-level debug flag for more verbose logging, but not sure it will tell you much.\nCan you try to run the tests for the calculator example:\npython runtests.py calculator\n. mmm, tests are passing. Can you try to create the client with a backslash\np = rpc.JsonProxy('http://localhost:8060/')\n. I just pushed to master some changes which should help us find the problem.\nTry to\n- run the server with --log-level debug flag\n- Build the client using the following p = rpc.JsonProxy(\"http://localhost:8060/\", full_response=True)\nThan\n```\n\n\nr = p.ping()\nr.status_code\n...?\nr.request.headers\n...?\nr.request.method\n...?\n```\n\n\nThe server log should give you a more verbose information, with traceback, about the error.\n. mmm,\nrunning out of ideas, Just tested on my mac and everything is fine!!!\nCan you try two things:\n- run the server in python 3.3 and client in python 2.7\n- viceversa\nAlso, have you tried with python 3.2?\nThanks for help.\n. Yes downloaded from PyPI\nMac OS X 64-bit/32-bit Installer (3.3.0) for Mac OS X 10.6 and later\nrunning on OS X 10.8.2\n```\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 01:25:11) \n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nfrom pulsar.apps.rpc import JsonProxy\np = JsonProxy('http://localhost:8060')\np.ping()\n'pong'\np.ping()\n'pong'\n```\n\n\n\nI pushed a minor modification which dumps the environment when errors occur. Can you try tu run that and show me the log result, especially the REQUEST_METHOD value. Thanks\n. I have found the problem, it is caused by the C extensions. Can you try with the master branch?\n. Thanks\n. no need for this\n. This is done.\n. same as issue #66 \n. Removed recursive behaviour\n. I think the issue is a race condition on the pubsub handler.\n. Redis backend needs to be cleaned up before running tests.\n. It is added back to the event loop via call_later once the get_task method returns.\n. No reconnecting clients anymore\n. I don't have much time to work on it at the moment, but if you try I'll be happy to assist you!\nTo get started\n- work on the dev branch which is almost ready to be merged with master and become 0.8\n- there is already an udp module in the async directory, absolutely untested\n- to create a udp endpoint you should use the eventloop.create_datagram_endpoint function (both servers and clients). The function calls the async.udp.create_datagram_endpoint which is, as I said above, absolutely untested\n- setup an example in the examples directory following the same guidelines as the echo example. Include a test module too.\nOnce done that we should have something going relatively fast\n. This is done in 0.8, all part of asyncio integration.\n. Implemented in async.actor\n. No longer an issue\n. done d982455bc4\n. No,\nwill be part of an asynchronous data store package hopefully\n. This is done in version 0.8\n. fixed thanks\n. New release\nhttps://pypi.python.org/pypi/pulsar\ncan you try again? Thanks\n. Yes,\nI'm aware of it, it is fixed in the dev branch already.\nI'll make a new release later on today.\n. Fixed with version 0.7.2\nhttps://pypi.python.org/pypi/pulsar/0.7.2\n. thanks\n. redis won't be moved to a different library.\nInstead, it will part of the new apps.data module together with new pulsar datastore.\nThe app.pubsub module will be removed as consequence.\n. Agree, it shouldn't be too difficult to achieve it.\nThe check could be implemented in the SocketServer.monitor_task callback (which is run at every loop in the arbiter eventloop).\nIf something changes, kill all current workers (they'll auto restart)\n. Thanks, you are welcome to send a patch ;-)\nhttp://pythonhosted.org/pulsar/overview.html#contributing\n. force_sync has been removed in 0.8\n. You are right, missing information in MANIFEST.in\nCan you try the following?\npip install --index-url https://testpypi.python.org/pypi pulsar\n. new_event_loop() is part of asyncio\n. The OneTime class has no documentation because its API is not beta ready yet.\nIt is an event which occurs once only and it is part of the events module\nhttps://github.com/quantmind/pulsar/blob/master/pulsar/async/events.py\nThe Event and EventHandler classes have some docs\nhttp://quantmind.github.io/pulsar/api/async.html#events\n. Same as #77 \n. Thanks,\nclose frame messages need to be implemented, you are right.\n. Didn't need to do that before. Thanks\n. Thanks for the pull request,\nCould you write some docs in client.py about what the client does and what features is showcasing?\nCheck how manage.py is documented for example.\nAlso, a little test is needed in test.py for the client.\nEven if it just tests that the file import correctly.\n. http://quantmind.github.io/pulsar/design.html#monitors\n. Could this be handled at application level?\n. Could this be handled at application level?\n. The WSGI environment is available when that error occurs.\nThe error occurs in the WsgiRequest which a wrapper for the wsgi environment.\nPulsar internals don't call that method apart from the wait_for_body_middleware in the middleware.py module.\nAre you using that middleware function?\nPossibly,  wait_for_body_middleware could be made tolerant of parsing errors.\n. Thanks for flagging this.\nNow, the wait for body middleware doesn't try to decode the HTTP body, it simply reads it.\n. Are you setting the maximum number of requests via the --max-requests flag?\nIn pulsar 0.8 this code has been removed. Maybe I should do the same for 0.7.\n. max-requests is still available, but it will be handled in a different (better) way.\n. I've back-ported the fix from 0.8\nThe max-request flag should work properly with master now\n. what platform are you running your tests? Mac or linux?\n. Maybe, but in the mean time I have found a tricky bug somewhere in the wsgi when connections get closed soon after the response (HTTP 1.0 protocol for example)\n. Would this solve the issue?\n. yup,\nit is a pulsar bug in handling cookie header,\nI'll ship a new version soon with a fix\n. This commit should fix the issue, but it needs testing.\nYou can try with master branch if you like\n. You are right,\nI fixed the issue in the dev branch but forgot to backported to master.\nIt should work now\n. Rejected\n. rejected\n. Thanks,\nI don't have python 3.4 setup on my machine yet. I probably should.\nIn any case pulsar 0.8 will be released after 3.4, so this issue will be fixed by then.\n. Fixed in 0.9\n. Do you know how to do that, or someone who knows?\nI would be happy to assist the process\n. If anyone is interested in adding pulsar to these benchmarks, you could use pulsar-odm as the asynchronous driver of sqlalchemy ORM.\n. we'll have our own benchmark suite #268 . This is fixed on pulsar 0.8.5\n. No longer required.\nPep 8 is run on the command line in the standard way:\npep8 pulsar tests examples\n. thanks\n. Is this a windows issue?\n. You are right!\nNot sure what is going on.\n. Thanks,\nI've got the problem now, I'll release a new version soon\n. Can you try to install using the following command:\npip install pulsar --index-url https://testpypi.python.org/pypi\n. Hi,\nto use pulsar with a sychronous WSGI applications you need to include the wait_for_body_middleware.\nYou can start your server via:\nWSGIServer(callable=WsgiHandler(wait_for_body_middleware, handler)).start()\nProbably, this middleware should be better documented\n. I'm not sure why Server and Date are there! They shouldn't.\n. No longer relevant.\nKnwon_libraries have been removed from pulsar Scripts\n. The http client receives a message it can't properly decode.\nThis could be a pulsar bug or not.\nHow can I replicate it?\nCan I access the url you are requesting?\n. I should be able to replicate the issue,\ncan you tell me pulsar version?\npulsar.__version__\nand your OS?\n. This sounds like a separate issue and should be filed as one. Don't worry about cluttering, there is no issue in closing an issue. ;-)\nIf you file a new one can you be as specific as possible on how to replicate it?\n. This is now fixed\n. Which script is causing this error?\nIt looks like you are running python 3.4 with the asyncio package?!?\nasyncio is part of the python 3.4 standard library, you shouldn't neet to install the package (installation is only required for python 3.3).\n. duplicate of #111 \nplease use that issue\n. same as #114 \n. Tests should be run from the distribution directory, via the runtests.py script. In this case\npython runtests.py pshell\n. Hi,\npreamble.\nIs your twitter_source method using the asynchronous HttpClient shipped with pulsar?\nIf so, you don't need to run it in the executor, instead it is able to process hundreds of different (but asynchronous) connections (such as twitter streams) in the main worker thread.\nThe executor should be used when you are invoking a blocking function, such as a CPU based post-processing operation or blocking socket.\nHaving said that, it looks like the worker (the arbiter in your example) is not able to shut down the executor, which, in turns, is not shutting down because one or more threads don't want to die.\nThe SIGINT signal has been received by the arbiter but it fails to exit because some threads are still alive (signals are received by the mainthread only). This is one of the pitfalls of programming with threads and one reason to choose an asynchronous framework instead.\nIn other words, you need to look into what the code  twitter_source is doing and why is not releasing the thread. Having said that, there may well be a bug in pulsar thread subclass used in the executor.\n. hi,\nwhich python and pulsar versions are you running?\n. OK,\nit looks like it is a silly bug I introduced in 0.8.2 when using python 2.\nThe bug is in the pulsar/apps/wsgi/middleware.py module.\nThe `functools.wraps decorator does not work for instances, only for functions (unlike python 3).\nI've just push the fix in the dev branch.\nhttps://github.com/quantmind/pulsar/commit/b3e2c6ebd996397abcf626fd6d63db1db878ee8f#diff-4\n. What type of logging information do you get from the server?\n. Any reason you are running two servers?\nThe example assume both the web site and the websocket are served from the same ip address as you can see from the home view in\nhttps://github.com/quantmind/pulsar/blob/master/examples/djangoapp/chat/views.py\nYou can run them in separate servers if you need to, but you should to modify that view in that case.\nIn addition, it looks like the pub/sub server has not started.\nYou need to put a config.py file for pulsar, like the one in the example, in the same directory as your manage.py.\nCan you try to run the example using pulsar alone for now?\npython manage.py pulse\n. Unfortunately I haven't tested pulsar on py 3.4 on windows!\nAnd that looks like a bug.\nCan you try to run without multiprocessing?\nTo do that pass\n--concurrency thread\non the command line\n. It looks like the issue is caused by changes in python 3.4 regarding inheritance of file descriptors from pep 446.\nIt affects how file-descriptors are inherited when using the multiprocessing module in windows only.\nI will need to ask the author of the pep how to solve this issue.\n. I found the issue and it is now fixed in the dev branch.\nI'll try to make a new release later on today or tomorrow.\nThanks for flagging this\n. I've checked in some changes in dev branch which should fix this issue\n. How did you test for the 80 MB/s at 100% CPU numbers? Do you have a script I can use?\nYes, it should be debug level, in the mean time you can pass\n--log-level pulsar.wsgi.warning\nto show only warning logs from the pulsar.wsgi logger (only on dev for now)\n. Hi,\nno need for a new Issue, I've modified the title to account for this.\nThe problem is with my fix which needs more attention. It looks like the wsgi server does not exit the iteration even when the socket is closed.\nOne thing to note: multi-threading is not the holy grail, throwing in more threads won't make your application faster but possibly more responsive (more clients at once). Multi-processing is the real thing. In other words, I would not use more than 5~10 threads per process (however, it would be nice to have some benchmarks on these numbers)\nWhat would be a decent download speed on localhost?\n. I've pushed few changes which may or may not fix the various problems you mentioned.\nI've just realised that to do your streaming tests you can use the httpbin site in the examples directory.\nFirst lunch the site and then try to test for speed on the stream url\nFirst your previous example\ncurl http://localhost:9060/stream/4096/1048576 > /dev/null\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 4096M    0 4096M    0     0  87.8M      0 --:--:--  0:00:46 --:--:-- 73.1M\nand then the two numbers flipped, BOOM!\ncurl http://localhost:9060/stream/1048576/4096 > /dev/null\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 4096M    0 4096M    0     0   658M      0 --:--:--  0:00:06 --:--:--  673M\nWhy is the second example much faster?\nBecause the iterator send large chunks to pulsar and the buffering is handled by asyncio rather than the iterator and therefore it is much more efficient. In other words the bigger the chunks the faster the transfer rate and the more responsive (in term of concurrent connections) the server will be.\n. This should not be a problem in dev\n. Both these issues should be fixed now\n. Makes sense,\ndo you know how other libraries handle this (flask or django for example)?\nYou are welcome to send a pull request, I think all you need to modify is the available method.\n. That was quick!\nhttp://quantmind.github.io/pulsar/overview.html#contributing\nan I would add to the list:\n- one fix at the time\n- a test highly welcomed\n. And, one commit only, preferably.\nIf you have done several commits you can use git rebase before pull request\nhttps://help.github.com/articles/about-git-rebase\n. Merged, but need a little test ideally\n. close #122 \n. The js directory is a temporary fix.\nIt is in my plan to move it online so that it can be updated without changing pulsar.\nTherefore I cannot apply this patch\n. Looks like a bug introduced in 0.9\nI'll have a look into it\n. Yeah, it is a bug introduced in 0.9\nThere were no tests for it!\nIt is now fixed in dev branch\n. The response middleware in the WsgiHandler assumes that the response returned by your request middleware is an instance of pulsar WsgiResponse or at least have a similar API.\nIn version 0.8 I was checking if the response was an instance of WsgiResponse and only if that was the case, it was run through the response middlewares.\nPulsar 0.9 does not do that check anymore and therefore if you are planning to return a different type of response object, you should probably not use the response middleware shipped with pulsar (for example the GZipMiddleware).\nThe response you are returning is a Flask response object and therefore not compatible, as it is, with pulsar response middlewares. If you still want to use the GZipMiddleware, you should write one that works with Flask response or alternatively write a response middleware which convert a Flask response into a pulsar WsgiResponse and put it as the first response middleware in your list.\nThis should be better documented.\n. I understand your frustration, but let me clarify few points\n- The response middleware is not part of WSGI, it is a pulsar add-on in the WsgiHandler (django also has a similar feature in its wsgi handler).\n- Setting the headers and status code is the responsibility of the application and not the server. The application must call the start_response function passed as second parameter in the application callable. And this is why the WsgiResponse exists, it does that for you. However if you choose to return a different response, it is your responsability to call that function.\nDoes you application work if you don't add any response middleware?\nI could give you some more help if you setup a little example with the problem.\n. No just yet, lets wait until dev is merged into master.\nCool, the logging middleware works fine because it does touch the response object.\nIn this case you should use the flask compressor since it exists.\nThere is another way you can do the logging in pulsar after every single request (as well as when a  connection is dropped) if you like. It is by using the post_request and connection_lost configuration hooks\nhttp://quantmind.github.io/pulsar/settings.html#application-hooks\nThe benefit of using these two hooks is that you get the full information of the response sent and the connection respectively. No much documentation about it unfortunately, but they can be quite useful in monitoring the server.\n. I've added an example on how to use server hooks\nhttp://quantmind.github.io/pulsar/tutorials/httpbin.html\nYou may want to use that for your logging, the response passed to the hook is the actual server response (rather than the wsgi object which any application framework may use). If no exception occurs, you have the headers_sent property which gives you quite a bit of info\n. Fair enough, thanks for heads up!\nI will make it a soft dependency in 0.9.1\n. Hi, thanks for this.\nI cannot merge it to master, pull requests should be for the dev branch\nhttp://quantmind.github.io/pulsar/overview.html#contributing\nclosing\n. Thanks,\npyflakes did not pick up the Config import missing because of the wild import at L23.\nIdeally a test should be included for the changes in AttributeDictionary, but they are quite trivial.\nOut of curiosity what kind of object is your pulsar_app callable?\n. The WSGIHandler is not guaranteed to be pickable.\nIt depends on what middleware you are adding to it. \nIf you want to be sure to have a wsgi callable which works in multiprocessing you can use the LazyWsgi as in the websocket example.\nhttp://quantmind.github.io/pulsar/apps/wsgi/async.html#lazy-wsgi-handler\n. Can you pull request against the dev branch?\nhttp://quantmind.github.io/pulsar/overview.html#contributing\nthanks\n. Hi Keis,\nthanks for this, can you make the same pull request against the dev branch so I can merge it?\nhttp://quantmind.github.io/pulsar/overview.html#contributing\n. Hi David,\ncan you make the pull request on the dev branch?\nhttp://quantmind.github.io/pulsar/overview.html#contributing\nThanks\n. Thanks, I'll have a look\n. Hi,\ncan you add a minimal example in the examples directory, maybe call it flaskapp and send me a pull request on the dev branch. I will take a look. Thanks\n. When running flask with pulsar, werkzeug server is not used and therefore you need to configure the logger from the command line or the config file. The best way is to do it from the command line.\npython manage.py --log-level routes.info\nCheck the comment in the commit above.\n. what version of pulsar?\n. Can you try installing it via pip and see if it works? Thanks\n. Is it working for you now?\n. This is now fixed in master\n. Fixed in https://github.com/quantmind/pulsar/releases/tag/1.0.1 \n. Does the greater example do?\nhttps://github.com/quantmind/pulsar/blob/master/examples/snippets/greeter.py\npulsar requires asyncio event loop to run.\n. Please contact the mailing list for this type of questions.\n. Yes, python 3.4 and above, it uses the standard library asyncio module only.\nI've updated the release notes https://github.com/quantmind/pulsar/releases/tag/1.0.0\n. Thanks!\n. Where is the code and the test case to reproduce your issue!?\n. The connection_made in the ProtocolConsumer is fired when the Connection (the protocol) creates a new consumer, i.e. when it needs to build the consumer to consume data received from the connection transport.\nTherefore, simply connecting won't fire and connection_made event on the ProtocolConsumer but it will fire a connection_made event on the Connection.\nTry sending a message and you should see the event fired.\nTo have connection_made event on the Connection, you need to add handler to it rather than the ProtocolConsumer.\n. There was a small bug which I've fixed.\nI've updated the example, it should display the message on connection_made event.\nNote, fix is in the dev branch\n. THis won't be merged.\nToo many untested changes in the protocol module.\nMany thanks anyway.\n. Yes, that is a bug. I'll have a look into it, thanks\n. That is expected.\nYou need to add handlers to these events.\nTheir use is needed by applications requiring asynchronous behaviour when new data is received at response level.\nCheck the proxy server example.\n. THe number of sessions in a producer has nothing to do with multi process mode.\nThe number of sessions is relative to a given producer only.\n. No it cannot, and it is not designed to be picklable.\nWhy do you want to pickle a connection?\n. I'm not sure that is something you should do.\nIn any case, the best place to discuss this type of ideas is pulsar mailing list.\n. Expected behavior.\nPulsar is designed to work in multiprocessing mode and therefore all application callables must be picklable.\n. Thanks\n. You are right, I have removed all references to ActorProxyFuture. It is now a simple Future.\n. http://quantmind.github.io/pulsar/search.html?q=ActorProxyFuture&check_keywords=yes&area=default\n. Better docs is not a valid issue, not in this project anyway.\nA valid issue covers a specific area that a person can work on.\nWriting better documentation is very important but it requires a joint effort of several people, especially people that are new and have not been involved in writing pulsar like myself.\nPulsar is opened source, if you need better docs, please feel free to help.\nI have written pulsar because I needed to and I use it everyday to earn my living.\nI didn't write it to prove anything.\n. this has been fixed\n. please, file a different issue.\nI cannot replicate it on mac osx.\n. Hi, not obvious to me, any pull request welcome ;-)\n. I've added an endpoint to the HttpBin router, you can use that for tests if you like\n. Looks good to me, can you pull request? I'll code review there and check test passage. Many thanks\n. merged with master, thanks!\n. @msornay your test fails on mac OS X.\n. On my mac when I do:\n``` python\n\n\n\nserver = socket.getfqdn('::1')\ninfo = socket.getaddrinfo(server, None)\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \".pyenv/versions/3.4.3/lib/python3.4/socket.py\", line 533, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\nsocket.gaierror: [Errno 8] nodename nor servname provided, or not known\n```\n\n\n\nOn a linux box this works fine, therefore it is not a big deal, but it would be nice to have the test working on mac too.\n. That is not great of course, thanks for reporting it.\nI cannot reproduce it on a mac os x.\nWhich OS are you using?\n. Debian of course :-1:  to me\n. This has been replaced by #218 \n. Not sure,\nI understand the rationale but i dislike the implicit behaviour.\nThat dictionary contains values which are lists and therefore the default behaviour should return the actual value in my opinion.\nDo you have a use case where the API you are proposing would be better than the current one?\nAlternatively, what about\n``` python\n\n\n\nrequest.url_data.getfirst('data')\n'hello'\n``\n. Fair enough, they are all very good arguments.\nPlease, go ahead with a patch if you like\n. This has been superseded by #265. Indeed, to be honest that decorator is somehow there for legacy reasons.\n. That is the correct use for now, at least until python 3.4 is supported.\nOnce python 3.4 support is dropped (when python 3.6 is released) the task decorator is not that useful anymore. Theasync/await` pair will do the job nicely.\n\n\n\nThe async wsgi specification will include native coroutine as well as futures as a possible return value from a wsgi middleware.\n. this is now fixed\n. the branch is now master\n. thanks\n. Do you have a use case showing why we need this?\nThe function submitted to the green pool should not return an asynchronous object and the wait function should be use to wait for asynchronous results.\nBut I may be wrong.\n. Right, but how would the exception message cause XSS?\nI'm not an expert, but I'm very curious.\n. Your push method returns a coroutine (generator) and therefore it does not comply with pulsar asynchronous wsgi specification.\nThe server thinks you are returning an iterator an therefore it treats at such, in the same way as standard wsgi does.\nIn python 3.5 we can distinguish between coroutines and generators thanks to the new async keyword. The new syntax will allow for coroutines to be returned (and therefore your example will work), but for now that is not supported.\nFor now, if you want an async application handler you need to return a future, not a coroutine. In your case you could do:\n``` python\n   @route(rule='/push', method='POST')\n    def push(self, request):\n        return asyncio.async(self._push(request))\ndef _push(self, request):\n    body_data = yield from request.body_data\n    return request.response\n\n```\nThe error message is correct. You returned a generator and did not set the headers. Returning the request.response object as result of the future will be set the headers for you.\n. Can you provide the pulsar version you are using?\nThis issue should be fixed in pulsar 1.0.5.\n. The current pypi version 1.0.5 should work for both 3.4.3 and 3.5 and the error above should not occur in either versions. Can you check your version?\npython\nimport pulsar\npulsar.__version__\nThe test suite does not yet fully pass on python 3.5, that is why 3.5 is not yet fully supported. It will be soon enough.\n. Thanks but I cannot merge at this stage.\nSeveral tests are still failing in python 3.5.\nI've updated to sudoless travis.\n. Pulsar will never support gevent in its code base.\nMonkey patching the standard library is not in the philosophy of pulsar.\nThat should not stop you doing that if it fits your needs.\nOn the other hand, If you want to use pulsar in an implicit asynchronous mode you can use pulsar.apps.greenio module.\nThe greenio module can be used to create implicit HttpClients for example or, as pulsar-odm illustrates, implicit asynchronous sqlalchemy dialect for PostgreSql.\nA better place for discussing pulsar usage is the mailing list rather than the issue tracker.\n. Thanks for reporting.\nIt is now fixed in master.\n. replaced by #190 \n. this is resolved\n. new app in 1.0.6\n. This bug is in connection with pep 479.\nIt is an issue with coroutines/generators in python 3.4 or below.\nPython 3.5 should not have such issue.\nMy suggestion is to replace the StopIteration error with a RuntimeError, including the stack trace.\n. thank you, looks good\n. fixed. We should also scan commits between these releases and if a commit has a comment marked as #release-note, that comment should also be included.\n. Moved to https://github.com/quantmind/git-agile/issues/5\n. thanks!\nCan you make the pull requests against dev branch?\nCan we use proxies as a dictionary same API as requests?\n. I have made the changes in the dev branch in this commit https://github.com/quantmind/pulsar/commit/2ad4581dd1f6df780268e4153b340f78977f474e\nThanks for heads up\n. Some of these messages are caused by third party libraries which pulsar uses as soft-dependencies during unit testing.\nTherefore suppressing them may be outside the power of pulsar. Having said that, the Exception ignored.. message is an asyncio message not to worry about until they have finalised the library in py 3.6, i.e. no longer provisional.\nSome other error messages are pulsar related and are there beacuse the test suite stress-test for wanted errors. Those logs need fixing.\n. this is done\n. This has been removed on pulsar 2.0. Sorry to hear your project is behind, however that has nothing to do with the development of pulsar.\nIf you require consultancy services check quantmind.\nIn addition, you would get more help if you can provide an mvce rather than a zip file.\nIn any case, it looks like your app is not returning a WSGI iterable in the response function, infact it is returning nothing, hence the error message.\n. Done and released with ver 1.2\n. https://github.com/quantmind/pulsar/blob/master/examples/helloworld/tests.py#L46\n. thanks for that. All yield from in docs will be soon replaced with await\n. It fails because it requires the unidecode package for testing. It is a soft dependency of pulsar.\nI've added the skip decorator. Thanks for reporting\n. That should not be the case.\nWhat pulsar/python versions are you running?\nCan you try with pulsar from dev branch?\n. thank you\n. thanks\n. You are right, and I would very much welcome some help on that front.\nI didn't give too much attention to the setup.py script over the last few years unfortunately. It was written when pulsar was still working on python 2 and 3 with the same codebase.\n. this is now fixed in the dev branch.\n. This is not what I have in mind.\nIf you want to go down this path you are going to do all the heavy lifting.\nSurely we should be able to modify the current test suite to run via the python setup.py test command!?\n. Let's not over engineer things.\nThe alpha version should not be used in production and therefore no surprises should arise.\nTo have a consistent alpha version one needs to have git in the path.\n. You need to give some more details of your setup and goals for someone to be able to help you. In any case this is not the right channel for such enquires.\nGithub issues are mainly for bug reports and feature requests,\nfor any other query the google mail list is the better place.\n. Thanks, question asked on the maling list\nhttps://groups.google.com/forum/?fromgroups=#!topic/python-pulsar/_QgkzAlKM0o\n. If you pass echo_connection_made it works without your change. When using multiapp, applications other than the first one, must have a prefix and in this example, echo is the prefix.\n. That is a regression introduced in 1.2, thanks for the report.\nI've fixed the issue in the commit above.\nPlease test from master and let me know if it works for you.\n. How can I replicate the issue?\nWhat command are you running?\nIt looks like an issue with the wheel.egg-info.\n. I'm not sure about this to be honest.\nThe current implementation works fine, clients from other languages can decode JSON strings from pulsar endpoints. Do you have a use case I can take a look?\n. OK, can you write a patch with a pull request that fix your issue?\nI will than take a look.\n. thanks\n. Ok, but I cannot consider this pull request.\n61 files changed, 31 commits?\nCan you create a pull request with one commit only please?\n. I trust you on this since I don't have a windows machine at the moment \ud83d\ude31 \nthanks\n. Is this an issue with the JsonProxy class, the HttpClient or the pulsar rpc server middleware?\nCan you show where your use case fails and why?\n. OK, I think the JsonProxy and JsonBatchProxy should not call decode_content but instead the json method.\nThe response should always be JSON serialisable.\nCan you create a pull request with a fix?\n. Looks good \ud83d\udc4d \nthanks for reporting and the fix\n. https://github.com/quantmind/pulsar-django\n. merged\n. That should just work.\nWhat do you bind to? Try the bind to all IP addresses (--bind :8060 for example)\nMaybe the problem is in your docker configuration?\n. I've added some info in the docs, commit above.\nAvailable on the dev documentation http://quantmind.github.io/pulsar/apps/socket.html\n. The actor model in pulsar refers to the parallel side of the asynchronous framework.\nIn pulsar each actor (think of a specialised thread or process) has its own event loop. In this way any actor can run its own asynchronous server for example.\nAn actor has its own event loop and therefore it can run several tasks concurrently. Indeed this is how asyncio works, not just pulsar. If these tasks (coroutines) are IO friendly, a pulsar app can be very fast.\nThrowing lots of actors to your problem is not the correct solution. By default an actor is a process and there are so many processes you can use (usually 4 x number of cores).\nAdding more actors is your last solution, when you need to scale horizontally on a given machine.\nFirst try to get your async app running on one actor\nDepending on what the scrape function does, you can organise your application in different ways:\n- scrape is IO bound (ex: download an html web page). Run one actor only and keep a queue of asynchronous scrapers\n- scrape is CPU bound (ex: parsing a page already downloaded and do some NLP on it). This does not work well in an actor because it does not release the event loop (not IO friendly). You can use pulsar-queue for such configuration.\nIn addition:\npython\nasync def scrape(actor, message):\n    sku = message['sku']\n    actor.logger.info(\"Scraping SKU: \" + sku)\n    time.sleep(3)\nIs not a coroutine. This function blocks in time.sleep(3).\nA better example is to use\npython\nawait asyncio.sleep(3)\nThe line\npython\nresult = await send(worker, 'run', scrape, {'sku': 'SKU1'})\nwaits for results to be ready.\nYour workers are not doing any concurrent work, instead they work one at the time.\n. Closing this ticket as it is not a bug nor a feature request.\nFor general discussion/help/advise the pulsar mailing list is a more suitable location.\n. I've fixed the issue I think, caused by an old implementation of the response.\nWould you mind trying out with the dev branch?\nThanks for reporting\n. Hi, pulsar actors don't need to be overwritten.\nDepending on what you want to do, there are several way of doing message passing between actors.\nCheck out the examples/snippets directory.\nMaybe the actor1.py snippet can give you an idea?\nI'm closing this ticket, because it is not a feature request nor a bug.\nThe best channels for asking these type of questions are the mailing list and stack overflow  python-pulsar tag.\n. I've never used pex before.\nThe Site object is picklable if the Site class is visible in the __main__.\nIt looks like pex has removed that class from the __main__.\nIf you need help, can you provide an mcve? The example above requires modules not available.\n. This is now done.\npython\npython setup.py bench -l\n. done\n. Hi,\nThe test suite documentation needs updating.\nOnly test files with this test patterns are included in the suite\npython\ntest_patterns = [\n    re.compile(r'''test_(?P<name>.*).py'''),\n    re.compile(r'''(?P<name>.*)_test.py'''),\n    re.compile(r'''tests.py''')\n]\n. I've updated the test suite docs:\nhttp://quantmind.github.io/pulsar/apps/test.html#running-tests\n. Hi, thanks for this.\nDo you think you can assemble together a test case?\nYou could use the upload endpoint of the httpbin example like the file upload test case.\n. This has been fixed by the commit above.\nI've used a different approach for the fix, you can control the maximum size of the stream buffer via the stream-buffer config parameter.\nThanks for reporting the issue.\n. thanks\n. It depends what you want to do.\nIf you have a specific question, or would like to discuss possible applications, please ask it in the mailing list.\nIssues are for bug reports and feature requests. \n. Tests are failing which suggests your patch has problems.\n. OK, how can I validate this use case?\nWhat are the full response headers you get back from s3?\n. Thanks for reporting this issue.\nThis is now fixed in master.\nThe fix is different from your patch because the http parser must be compatible with the C http-parser for speed.\n. replaced by #262 . We can't do that.\nThe request is an object while the protocol_class is a class and must work for all requests not just one. The original wsgi request is available as the handshake property in a websocket protocol object.\nCheck\nhttps://github.com/RyanKung/pulsar/blob/master/pulsar/apps/ws/websocket.py#L151\nand\nhttps://github.com/RyanKung/pulsar/blob/master/pulsar/apps/ws/websocket.py#L39. This is fixed in 1.6.2\nhttps://github.com/quantmind/pulsar/releases/tag/1.6.2\nhowever, pulsar in windows does not currently support multi process. Therefore when running servers always pass -w 0. Hi, this should not happen, but there are some issues with uvloop at the moment (see #258).\nYou don't need to pass --concurrency multi, by default pulsar uses subprocess concurrency.\nI'm waiting on python 3.6 release to finalise the fix, many changes have been made in the new python asyncio module.. Issue opened MagicStack/uvloop#65. This has been fixed in the master branch.\nThe fix will be included in the 1.6.4 release. Thanks for reporting.. Answered in the mailing list\nhttps://groups.google.com/forum/?fromgroups#!topic/python-pulsar/Wmxp_qZrX8A. This has been don on dev branch, future 2.0 release. In theory it is possible, do you have a use case for such architecture?\nThanks for the kudos. This is a very interesting topic, Worth discussing on the mailing list if you are interested.\nAt the moment cross-node interaction is not supported out of the box but I don't see why it couldn't in the future.\nBut, is it a useful feature? Will people use it? I'm not so sure.\nThere are many way of achieving cross-node interaction, pulsar-queue is a project that tackle the problem using a distributed task queue. Not the same thing but another cluster/type application.\nI'm closing this ticket for now as it does not fit into our workflow.\nPlease bring the question to the mailing list if you care about it, I'll be happy to bounce ideas.. Created the pulsar-bench repository which runs benchmarks in CI environment and publish results on fluidily platform.. benchmarks run are ready, need a web site. I don't know what you want to do, There is no body in your issue.\nQuestions like this one, with more context, should be asked on the mailing list or on stack overflow. thanks. Time unfortunately \ud83d\ude22 \nI don't have time for pulsar at this precise moment unfortunately and the release script needs testing and love.\nIf you have suggestions/fixes I'll be very happy to guide you in the right direction and review pull requests in needed.. yes, that is already in the pipeline of 2.0, https://github.com/quantmind/pulsar/blob/dev/appveyor.yml\n. This is done\nhttps://github.com/quantmind/pulsar/releases/tag/2.0.1. This seems like a good question, but not an issue with pulsar per se.\nCan you ask the question in the mailing list?\nPerhaps other users can share their experience there.\nMaybe this example can give you some ideas?\nClosing the issue and hopefully see your question in the mailing list\n. You can use the the LazyWsgi in these situations.\n```python\nfrom pulsar.apps import wsgi\nclass Site(wsgi.LazyWsgi):\ndef setup(self, environ=None):\n    from mymodule import app\n    return wsgi.WsgiHandler((wsgi.wait_for_body_middleware,\n                             wsgi.middleware_in_executor(app)))\n\ndef server(kwargs):\n    return wsgi.WSGIServer(Site(), kwargs)\nif name == 'main':  # pragma    nocover\n    server().start()\n```\nFrom pulsar 2.0 this will be done automatically by pulsar.. looks good, thanks \ud83d\udc4d . Hi,\nThis is the correct behaviour.\nA monitor controls a set of workers (actors) andbar_foobar is the name of the monitor of the Bar application. If you send a message to bar_foobar the monitor receives the message.\nWhat the monitor does with the message is up to you. It can send it to one of its workers for example, a random one (workers of a monitor should be interchangeable), or you could pass the worker id in the message so that the monitor pass the message to the worker you are interested in.\nBut why would you want to do this? What about if that worker died? In any case you need the worker id to do such a thing. So you need a method to get the workers ids first.\nThis is an interesting topic of conversation but it is better served by the mailing list.\nI'm closing the issue but you are more than welcome to post in the list.\nhttps://groups.google.com/forum/?fromgroups#!forum/python-pulsar. Interesting method.\nHow is one supposed to use it?\nWhen adding new code the standard practice is to add an example if possible and, importantly, test coverage (without test nothing get merged).\n. Thanks for this.\nCan you make this pull request against the dev branch?\nIt will go into pulsar 2.0. replaced by #279 agains the dev branch. done, in dev branch. thanks for this, pulsar 2.0 will be released sometimes in September/October I hope. we have switch, working on #271 . yes, events cannot be coroutines, the event dispatching mechanism was very slow and it has been changed so that no waiting for asynchronous events is supported.\nIn your case, you need to warp the coroutine in a task with the ensure_future function.\n```python\nasync def some_fn(args, kwargs):\n       foo\nmonitor.spawn(start=lambda: ensure_future(some_fn()))\nDo you have a use case for this?. closing. Ok, my bad, I welcome pull requests for this \ud83d\udc1b . Thanks, looks good.\nCan you create a new pull request against the dev branch (which I have now updated)?\nUnit tests are not run from forked pull requests, therefore I cannot merge into master directly.\nhttps://github.com/quantmind/pulsar/blob/master/README.rst#contributing. Thanks. wow, thanks for this PR.\nLots of changes. I think it is time to switch to pytest. why is this async? maybe you forgot the `async` keyword?python\nasync def async_cast(request):\n     return request.response('async')\n`\nto test async handlers?. this does not look correct, should that beRouter('/')``?. ",
    "Brandl": "Does this mean that there are plans to support websocket fallbacks, like xhr long polling and flashsockets?\nThis would be really awesome, because we are using Pulsar for realtime Django apps and thinking what to do about the lack of websocket support on Android. \n(By the way, we really appreciate the great job you do with Pulsar! Thanks!)\nKind regards\nfrom Austria\n. ",
    "klynton": "0.4.3 -- Also, the Calculator example doesn't actually work it fails with an error about **params not being defined.\n. From the latest install it looks like it is working at first:\nZ0FL:calculator klynton$ python3.3 manage.py \n2013-01-13 23:40:33 [p=5900,t=140735145521536] [INFO] [pulsar.arbiter] arbiter(95aeff93) started at address ('127.0.0.1', 51761)\n2013-01-13 23:40:33 [p=5900,t=140735145521536] [INFO] [pulsar.wsgi] Listening on 127.0.0.1:8060\n2013-01-13 23:40:33 [p=5903,t=140735145521536] [INFO] [pulsar.wsgi-worker] wsgi-worker(4f0d94c6) started at address ('127.0.0.1', 51767)\n2013-01-13 23:40:47 [p=5903,t=140735145521536] [INFO] [pulsar.wsgi] WSGI 405 status code  @ path \n2013-01-13 23:41:24 [p=5903,t=140735145521536] [INFO] [pulsar.wsgi] WSGI 405 status code  @ path \n2013-01-13 23:42:05 [p=5903,t=140735145521536] [INFO] [pulsar.wsgi] WSGI 405 status code  @ path \n2013-01-13 23:42:13 [p=5903,t=140735145521536] [INFO] [pulsar.wsgi] WSGI 405 status code  @ path\nbut I get method not allowed when trying to run any commands:\n```\nZ0FL:~ klynton$ python3\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 01:25:11) \n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nfrom pulsar.apps import rpc\np = rpc.JsonProxy('http://localhost:8060')\np.ping()\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 205, in call\n    return self._end_call(resp, raw)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 213, in _end_call\n    resp.raise_for_status()\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/utils/httpurl.py\", line 1203, in raise_for_status\n    self.content, self.headers, None)\nurllib.error.HTTPError: HTTP Error 405: b'{\"status\": 405, \"message\": \"Method Not Allowed\"}'\np.functions_list()\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 205, in call\n    return self._end_call(resp, raw)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 213, in _end_call\n    resp.raise_for_status()\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/utils/httpurl.py\", line 1203, in raise_for_status\n    self.content, self.headers, None)\nurllib.error.HTTPError: HTTP Error 405: b'{\"status\": 405, \"message\": \"Method Not Allowed\"}'\np.calc.add(3,4)\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 205, in call\n    return self._end_call(resp, raw)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 213, in _end_call\n    resp.raise_for_status()\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/utils/httpurl.py\", line 1203, in raise_for_status\n    self.content, self.headers, None)\nurllib.error.HTTPError: HTTP Error 405: b'{\"status\": 405, \"message\": \"Method Not Allowed\"}'\n```\n. Hi,\n\n\n\nI've just tested the latest '0.4.5b0' and I'm still getting the same errors. Were you able to reproduce the \"method not allowed\" error on the Mac you tested on? Also, is there some option for verbose logging of requests or the data being sent and received and what the headers and such are for further debugging?\n. Ah! I didn't think to do the runtests suite. Here's what it looks like:\n```\nZ0FL:pulsar-master klynton$ python3 runtests.py calculator\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 01:25:11) \n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]\n................................\nRan 32 tests in 1.297s\nOK\nException in thread Mailbox ('127.0.0.1', 49729):\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/threading.py\", line 639, in _bootstrap_inner\n    self.run()\n  File \"/Users/klynton/Downloads/pulsar-master/pulsar/async/access.py\", line 97, in run\n    super(PulsarThread, self).run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/threading.py\", line 596, in run\n    self._target(self._args, *self._kwargs)\n  File \"/Users/klynton/Downloads/pulsar-master/pulsar/async/iostream.py\", line 910, in _run\n    self.ioloop.start()\n  File \"/Users/klynton/Downloads/pulsar-master/pulsar/async/eventloop.py\", line 163, in start\n    self._run()\n  File \"/Users/klynton/Downloads/pulsar-master/pulsar/async/eventloop.py\", line 262, in _run\n    event_pairs = self._impl.poll(poll_timeout)\n  File \"/Users/klynton/Downloads/pulsar-master/pulsar/utils/system/base.py\", line 116, in poll\n    self.read_fds, self.write_fds, self.error_fds, timeout)\nOSError: [Errno 9] Bad file descriptor\n```\n. Still no go on that. I've started with --log-level debug and it doesn't show much more info:\nZ0FL:calculator klynton$ python3 manage.py --log-level debug\n2013-01-16 01:10:11 [p=6337,t=140735175676288] [DEBUG] [pulsar.arbiter] Installing signals\n2013-01-16 01:10:11 [p=6337,t=140735175676288] [INFO] [pulsar.arbiter] arbiter(7c232bb5) started at address ('127.0.0.1', 62001)\n2013-01-16 01:10:11 [p=6337,t=140735175676288] [DEBUG] [pulsar.arbiter] Registering Mailbox ('127.0.0.1', 62001) with event loop.\n2013-01-16 01:10:11 [p=6337,t=140735175676288] [INFO] [pulsar.wsgi] Listening on 127.0.0.1:8060\n2013-01-16 01:10:12 [p=6343,t=140735175676288] [DEBUG] [pulsar.wsgi-worker] Installing signals\n2013-01-16 01:10:12 [p=6343,t=140735175676288] [INFO] [pulsar.wsgi-worker] wsgi-worker(a8f63b70) started at address ('127.0.0.1', 62010)\n2013-01-16 01:10:12 [p=6343,t=140735175676288] [DEBUG] [pulsar.wsgi-worker] Registering Mailbox ('127.0.0.1', 62010) with event loop.\n2013-01-16 01:10:12 [p=6343,t=140735175676288] [DEBUG] [pulsar.wsgi-worker] Registering HttpServer ('127.0.0.1', 8060) with event loop.\n2013-01-16 01:10:12 [p=6337,t=140735175676288] [DEBUG] [pulsar.wsgi] Registering wsgi-worker(a8f63b70) address ('127.0.0.1', 62010)\n2013-01-16 01:10:55 [p=6343,t=140735175676288] [INFO] [pulsar.wsgi] WSGI 405 status code  @ path /\n```\nZ0FL:~ klynton$ python3\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 01:25:11) \n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nfrom pulsar.apps import rpc\np = rpc.JsonProxy(\"http://localhost:8060/\")\np.ping()\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 205, in call\n    return self._end_call(resp, raw)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 213, in _end_call\n    resp.raise_for_status()\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/utils/httpurl.py\", line 1203, in raise_for_status\n    self.content, self.headers, None)\nurllib.error.HTTPError: HTTP Error 405: b'{\"message\": \"Method Not Allowed\", \"status\": 405}'\nprint(p)\nJSONRPCProxy(http://localhost:8060/)\np.type\nJSONRPCProxy(http://localhost:8060/ - ab55f0c4-fb17-48d7-85e4-eb6dda17cf13)\n```\n. I've taken some time to test this whole thing on Python 2.7 and everything works fine on the same machine:\n\n\n\nhttps://gist.github.com/bac8e60eea7ffbb0ae17\nSo it has to be a 3.x problem, but I'm not sure where or what.\n. OK, I think we've got it now. The errors below show \"pulsar.utils.exceptions.HttpException: Method \"b'post'\" not allowed\" is the b a byte string instead of a unicode string and that's what's causing the issue?\nZ0FL:calculator klynton$ python3.3 manage.py --log-level debug\n2013-01-24 09:11:24 [p=59883,t=140735175676288] [DEBUG] [pulsar.arbiter] Installing signals\n2013-01-24 09:11:24 [p=59883,t=140735175676288] [INFO] [pulsar.arbiter] arbiter(ec11e5d0) started at address ('127.0.0.1', 53206)\n2013-01-24 09:11:24 [p=59883,t=140735175676288] [DEBUG] [pulsar.arbiter] Registering Mailbox ('127.0.0.1', 53206) with event loop.\n2013-01-24 09:11:24 [p=59883,t=140735175676288] [INFO] [pulsar.wsgi] Listening on 127.0.0.1:8060\n2013-01-24 09:11:24 [p=59887,t=140735175676288] [DEBUG] [pulsar.wsgi-worker] Installing signals\n2013-01-24 09:11:24 [p=59887,t=140735175676288] [INFO] [pulsar.wsgi-worker] wsgi-worker(fc52b84b) started at address ('127.0.0.1', 53208)\n2013-01-24 09:11:24 [p=59887,t=140735175676288] [DEBUG] [pulsar.wsgi-worker] Registering Mailbox ('127.0.0.1', 53208) with event loop.\n2013-01-24 09:11:24 [p=59887,t=140735175676288] [DEBUG] [pulsar.wsgi-worker] Registering HttpServer ('127.0.0.1', 8060) with event loop.\n2013-01-24 09:11:25 [p=59883,t=140735175676288] [DEBUG] [pulsar.wsgi] Registering wsgi-worker(fc52b84b) address ('127.0.0.1', 53208)\n2013-01-24 09:11:51 [p=59887,t=140735175676288] [INFO] [pulsar.wsgi] WSGI 405 status code  @ path \"/\"\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/wsgi/server.py\", line 238, in __iter__\n    resp = conn.server.app_handler(self.environ, self.start_response)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/wsgi/wsgi.py\", line 327, in __call__\n    response = middleware(environ, start_response)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/handlers.py\", line 285, in __call__\n    method)\npulsar.utils.exceptions.HttpException: Method \"b'post'\" not allowed\n2013-01-24 09:12:37 [p=59887,t=140735175676288] [INFO] [pulsar.wsgi] WSGI 405 status code  @ path \"/\"\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/wsgi/server.py\", line 238, in __iter__\n    resp = conn.server.app_handler(self.environ, self.start_response)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/wsgi/wsgi.py\", line 327, in __call__\n    response = middleware(environ, start_response)\n  File \"/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/pulsar/apps/rpc/handlers.py\", line 285, in __call__\n    method)\npulsar.utils.exceptions.HttpException: Method \"b'post'\" not allowed\n```\nZ0FL:~ klynton$ python3.3\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 01:25:11) \n[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nfrom pulsar.apps import rpc\np = rpc.JsonProxy(\"http://localhost:8060/\", full_response=True)\nr = p.ping()\nr.status_code\n405\nr.request.headers\nclient {'Content-Type': ['application/json'], 'Connection': ['Keep-Alive'], 'User-Agent': ['python-Pulsar/0.4.5b3'], 'Accept-Encoding': ['gzip']}\nr.request.method\n'POST'\np.ping\nping\np.ping()\nHttpResponse(405 Method Not Allowed)\n```\n. I've tried the server in 3.3 and the client in 2.7 and this is the result:\n\n\n\n{{{\n\n\n\np = rpc.JsonProxy(\"http://localhost:8060/\")\np.ping\nJSONRPCProxy(http://localhost:8060/ - 7fd7fedf-8bf1-491f-aab4-de6a9c66988e)\np.ping()\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/Library/Python/2.7/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 205, in call\n    usage is simple::\n  File \"/Library/Python/2.7/site-packages/pulsar/apps/rpc/jsonrpc.py\", line 213, in _end_call\n    r = range(times)\n  File \"/Library/Python/2.7/site-packages/pulsar/utils/httpurl.py\", line 1203, in raise_for_status\n    self.content, self.headers, None)\nurllib2.HTTPError: HTTP Error 405: {\"status\": 405, \"message\": \"Method Not Allowed\"}\n\n\n\n}}}\nAnd running the server in 2.7 and the client in 3.3 which works correctly! How did you install 3.3 on your Mac? I'm on 10.8 and I've used the Python 3.3 Mac installer from the Python.org page.\n. Works perfectly now!!!\n. ",
    "quantmind": "Thanks\n. You are right!\nI'll fix it and re-release, thanks\n. ",
    "rferreira": "Bump (or I'll take some direction on where to get started on this). I would like to port sentry https://github.com/rferreira/sentry to pulsar and UDP is a must. \n. not really fixed, I'm still getting the same error on 0.7.2: \nInternal Server Error: /v2/scan/\nTraceback (most recent call last):\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/core/handlers/base.py\", line 115, in get_response\n    response = callback(request, _callback_args, _callback_kwargs)\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 77, in wrapped_view\n    return view_func(_args, _kwargs)\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/papaya/decorators.py\", line 26, in decorator\n    resp = func(request, _args, _kwargs)\n  File \"/Users/rafael/dev/jackfruit/jackfruit/api/decorators.py\", line 104, in decorator\n    if request.REQUEST.get('indent',None) != None:\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/core/handlers/wsgi.py\", line 184, in _get_request\n    self._request = datastructures.MergeDict(self.POST, self.GET)\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/core/handlers/wsgi.py\", line 198, in _get_post\n    self._load_post_and_files()\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/http/request.py\", line 229, in _load_post_and_files\n    self._post, self._files = QueryDict(self.body, encoding=self._encoding), MultiValueDict()\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/http/request.py\", line 185, in body\n    self._body = self.read()\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/http/request.py\", line 243, in read\n    return self._stream.read(_args, _kwargs)\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/core/handlers/wsgi.py\", line 98, in read\n    result = self.buffer + self._read_limited()\n  File \"/Users/rafael/dev/venvs/jackfruit/lib/python2.7/site-packages/django/core/handlers/wsgi.py\", line 93, in _read_limited\n    self.remaining -= len(result)\nTypeError: object of type 'Deferred' has no len()\n$ pip freeze\nDjango==1.5.4\nPyYAML==3.10\namqp==1.0.11\nanyjson==0.3.3\nbilliard==2.7.3.28\nboto==2.6.0\ncelery==3.0.19\ncertifi==0.0.7\nchardet==1.0.1\ndistribute==0.6.34\ndjango-celery==3.0.17\nfutures==2.1.3\nkombu==2.5.10\nmeld3==0.6.10\npapaya==80e3da9\npulsar==0.7.2\npy==1.4.12\npyflakes==0.5.0\npytest==2.3.4\npytest-django==2.2.0\npython-dateutil==2.1\npython-magic==0.4.3\npytz==2012d\nredis==2.7.4\nrequests==0.14.2\nsh==1.08\nsix==1.3.0\nsupervisor==3.0b1\nwsgiref==0.1.2\n. never mind, it looks to be a behavior thing with the async wsgi and django. I fixed it by wrapping  wsgi.middleware.wait_for_body_middleware, around my app \n. Patch proposed:\nhttps://github.com/quantmind/pulsar/pull/80\n. Not without this patch, without it, pulsar was just throwing a 500 error back before even having the WSGI environment built (since the exception was happening while attempting to parse the arguments). \n. I'll look into moving the patch to the wait_for_body_middleware.\n. Any idea when you plan on rolling out a release with this fix?\n. Yup, I'm setting max-requests to 500, has that feature been deprecated altogether?  The automatic restarts are a good way to avoid dealing with potential memory leaks \n. That's excellent, any documentation on how to handle it properly? \n. That's awesome Luca, much appreciated. \n. Looks to be working albeit there's some noisy logging going on: \n```\n2013-12-13 06:41:12 [p=2222,t=140735140303632] [INFO] [pulsar.jackfruit-worker] TcpServer None closing 2 connections\n2013-12-13 06:41:12 [p=2222,t=140735140303632] [WARNING] [pulsar.jackfruit-worker] Event \"post_request\" already fired for \n2013-12-13 06:41:12 [p=2222,t=140735140303632] [WARNING] [pulsar.jackfruit-worker] Event \"post_request\" already fired for \n2013-12-13 06:41:12 [p=2222,t=140735140303632] [INFO] [pulsar.jackfruit-worker] TcpServer None closing 1 connections\n2013-12-13 06:41:12 [p=2222,t=140735140303632] [INFO] [pulsar.jackfruit-worker] ('127.0.0.1', 55420) closing 1 connections\n2013-12-13 06:41:12 [p=2222,t=140735140303632] [WARNING] [pulsar.jackfruit-worker] Event \"post_request\" already fired for \n2013-12-13 06:41:12 [p=2222,t=140735140303632] [INFO] [pulsar.jackfruit-worker] Exiting MainThread pulsar.jackfruit-worker\n2013-12-13 06:41:12 [p=2222,t=140735140303632] [INFO] [pulsar.jackfruit-worker] Bye from \"jackfruit-worker(7ee8bda2)\"\n2013-12-13 06:41:12 [p=2221,t=140735140303632] [INFO] [pulsar.jackfruit-worker] Reached maximum number of connections 500. Stop serving.\n2013-12-13 06:41:12 [p=2221,t=140735140303632] [ERROR] [pulsar.jackfruit-worker] Could not accept new connection\nTraceback (most recent call last):\n  File \"/Users/rafael/dev/venvs/jackfruit/src/pulsar/pulsar/async/stream.py\", line 542, in sock_accept_connection\n    conn, address = sock.accept()\n  File \"/usr/local/Cellar/python/2.7.5/Frameworks/Python.framework/Versions/2.7/lib/python2.7/socket.py\", line 202, in accept\n    sock, addr = self._sock.accept()\n  File \"/usr/local/Cellar/python/2.7.5/Frameworks/Python.framework/Versions/2.7/lib/python2.7/socket.py\", line 170, in _dummy\n    raise error(EBADF, 'Bad file descriptor')\nerror: [Errno 9] Bad file descriptor\n2013-12-13 06:41:12 [p=2221,t=140735140303632] [INFO] [pulsar.jackfruit-worker] TcpServer None closing 6 connections\n2013-12-13 06:41:12 [p=2221,t=140735140303632] [ERROR] [pulsar.jackfruit-worker] Unhadled exception in event loop callback.\nTraceback (most recent call last):\n  File \"/Users/rafael/dev/venvs/jackfruit/src/pulsar/pulsar/async/eventloop.py\", line 679, in _run_once\n    value = callback()\n  File \"/Users/rafael/dev/venvs/jackfruit/src/pulsar/pulsar/async/pollers.py\", line 147, in handle_events\n    'descriptor %s' % fd)\nKeyError: 'Received an event on unregistered file descriptor 16'\n2013-12-13 06:41:12 [p=2221,t=140735140303632] [ERROR] [pulsar.jackfruit-worker] Unhadled exception in event loop callback.\nTraceback (most recent call last):\n  File \"/Users/rafael/dev/venvs/jackfruit/src/pulsar/pulsar/async/eventloop.py\", line 679, in _run_once\n    value = callback()\n  File \"/Users/rafael/dev/venvs/jackfruit/src/pulsar/pulsar/async/pollers.py\", line 147, in handle_events\n    'descriptor %s' % fd)\nKeyError: 'Received an event on unregistered file descriptor 17'\n```\n. Never mind, after this error, all subsequent requests return a 500:\n2013-12-13 06:48:49 [p=2402,t=140735140303632] [ERROR] [pulsar.jackfruit-worker] Could not accept new connection\nTraceback (most recent call last):\n  File \"/Users/rafael/dev/venvs/jackfruit/src/pulsar/pulsar/async/stream.py\", line 542, in sock_accept_connection\n    conn, address = sock.accept()\n  File \"/usr/local/Cellar/python/2.7.5/Frameworks/Python.framework/Versions/2.7/lib/python2.7/socket.py\", line 202, in accept\n    sock, addr = self._sock.accept()\n  File \"/usr/local/Cellar/python/2.7.5/Frameworks/Python.framework/Versions/2.7/lib/python2.7/socket.py\", line 170, in _dummy\n    raise error(EBADF, 'Bad file descriptor')\nerror: [Errno 9] Bad file descriptor\n. osx:\n$ uname -a\nDarwin rafael-imac.local 13.0.0 Darwin Kernel Version 13.0.0: Thu Sep 19 22:22:27 PDT 2013; root:xnu-2422.1.72~6/RELEASE_X86_64 x86_64\n. All right, ran some more tests and the problem is on my side, not sure exactly why but your back port seems to be working just fine, thanks again!\n. ",
    "coveralls": "\nCoverage remained the same when pulling 865342dd35022b5b35c6a58f5ff4d49ad93e4551 on elimisteve:patch-1 into 82288be718f9f30bf127b67272404e4de1f499aa on quantmind:master.\n. \nCoverage remained the same when pulling 3dd9f5727daebd4d2a787f568c0e8bacc08be37c on dhutty:patch-1 into 8018c252292fb5de81ff862a40735d1a66ca35b8 on quantmind:master.\n. \nChanges Unknown when pulling a85edba7b9b9d20ab08cb7794cf89205688d871f on axisofentropy:dev into * on quantmind:dev*.\n. \nCoverage decreased (-0.02%) when pulling 21ab29df1905791c3524b9fc75479326ca7bbd2b on wieden-kennedy:master into 8e682b6d7c5a3d9e502979760b55d7ded84e2633 on quantmind:master.\n. \nChanges Unknown when pulling b51e2d9f256db78a3acf7724c5d71e085ac82d62 on keis:wsgi-asyncio-futures into * on quantmind:dev*.\n. \nCoverage increased (+0.01%) when pulling 5a22096465f8ab9ea159dd6c2b8e04aabd92313e on DavidJFelix:patch-1 into 4b6f0a52a2b94fe563f1a660b446a35c195d652a on quantmind:master.\n. \nCoverage increased (+0.01%) to 81.59% when pulling f37336825658853f94bc6e4786e25db4818cfe5a on robgil:dev into 8663fcdb0fa01288ae735db5d585cb178c964546 on quantmind:dev.\n. \nCoverage increased (+0.2%) to 86.566% when pulling c69056ea49a8899be185d457fa4dda3dd73bb711 on bright-pan:patch-2 into 168923d47643507b0cbccb1806dcf33df78744cd on quantmind:master.\n. \nCoverage increased (+0.0008%) to 86.93% when pulling 15240cae9ce6ea731a3511d507a12d3fda7e312e on wilddom:encoding into 931e63a3ecbfacf290acbdc5f6e39eaf4f19c56b on quantmind:master.\n. \nCoverage decreased (-0.03%) to 86.9% when pulling 8e637cb86602636b80913591f925b6af32f5d04f on wilddom:encoding into 931e63a3ecbfacf290acbdc5f6e39eaf4f19c56b on quantmind:master.\n. \nCoverage decreased (-0.02%) to 86.912% when pulling 8e637cb86602636b80913591f925b6af32f5d04f on wilddom:encoding into 931e63a3ecbfacf290acbdc5f6e39eaf4f19c56b on quantmind:master.\n. \nCoverage increased (+0.3%) to 87.008% when pulling 5733fae0eb52c4bb7c36ba09deeaa22dd3b59ec9 on mbikovitsky:pyreadline_compatibility into d66ddb80fed4a620fb768526c445203dee8f02ce on quantmind:dev.\n. \nCoverage increased (+0.2%) to 86.913% when pulling f032457aa3a8f108759cbbc238ef0a88eb6712a3 on mbikovitsky:pyreadline_compatibility into d66ddb80fed4a620fb768526c445203dee8f02ce on quantmind:dev.\n. \nCoverage increased (+0.2%) to 87.236% when pulling ff809e7e816c4910e35b9f505bc5ca06e869d0ca on dev into 0839757c5f924f4c4759ac56d9cb54208d7e1925 on master.\n. \nCoverage decreased (-0.09%) to 87.094% when pulling 708acaaeb117a2fce58b33faa993bfd21ea4280c on s-sokolko:master into 3fd9f0ebaa88667a9bc89df685a9188cb8f774d9 on quantmind:master.\n. \nCoverage decreased (-0.3%) to 86.937% when pulling 2036963c4031a9bb76450c72dbc26f5859cb74b8 on s-sokolko:master into 3fd9f0ebaa88667a9bc89df685a9188cb8f774d9 on quantmind:master.\n. \nCoverage decreased (-0.06%) to 87.132% when pulling 599291311edd390b67ab7dc63ab76495bf9b76d5 on s-sokolko:master into 3fd9f0ebaa88667a9bc89df685a9188cb8f774d9 on quantmind:master.\n. \nCoverage remained the same at 87.188% when pulling c9226e06e1d5d878955bec1b11b3cb319aa54beb on RyanKung:patch-1 into 3fd9f0ebaa88667a9bc89df685a9188cb8f774d9 on quantmind:master.\n. \nCoverage increased (+0.04%) to 87.654% when pulling eeafeab596fa867bcaafdd587b5615f136e980a4 on s-sokolko:fix-head-error-requests into bab9f030234f7675ab1fb658196933f58e3c42bc on quantmind:master.\n. \nCoverage increased (+0.008%) to 87.622% when pulling a57837cf9330d2e247356d07d77d7701659bfd15 on s-sokolko:fix-head-error-requests into bab9f030234f7675ab1fb658196933f58e3c42bc on quantmind:master.\n. \nCoverage increased (+0.01%) to 87.628% when pulling c2e131b1c09e0dc7d016c8dc8a1b187c12fa9162 on s-sokolko:fix-head-error-requests into bab9f030234f7675ab1fb658196933f58e3c42bc on quantmind:master.\n. \n\nCoverage decreased (-0.6%) to 86.78% when pulling e00725e74ef8bbb160fdf67f30c2789d0031da34 on RyanKung:master into db43f74d9e8fc8f0216ff3e545a7b31b2e592b8e on quantmind:master.\n. \n\nCoverage increased (+0.04%) to 87.457% when pulling 519a2dbd327727cf6eed7bc693a148b48084a79e on s-sokolko:quantmind_master into f607398aecf41bc6125d7ae79b3e64b4ce0e604d on quantmind:master.\n. \n\nChanges Unknown when pulling 73c2322fd8a41e20a6ca2b37eb8453b71705bd2f on RyanKung:master into  on quantmind:master.\n. \n\nChanges Unknown when pulling cc332997f2cfa7498d20d6442efb6b863f9c5ff2 on RyanKung:master into  on quantmind:master.\n. ",
    "mborho": "Yes, works without any problems now. \nVery responsive, appreciated! :)\n. ",
    "PAStheLoD": "pip install --index-url https://testpypi.python.org/pypi pulsar --pre works great, only some g++ warnings.\n. ",
    "etataurov": "sorry about creating new pull request instead of pull-requesting in original issue\n. Have not found any info in travis blog, but help says that redis is turned off by default. Don't know when this happened\n. ",
    "guettli": "I am going a different road now. I use tornado now. See https://github.com/guettli/websocketrpc\n. ",
    "kwquick": "This solves the issue for my python2.6 virtualenv.  Thank you very much for the fast fix, and I'm looking forward to seeing 0.8.0 on PyPi soon!\n. ",
    "giginet": "@lsbardel Thanks for your quick response.\nI've try it. Then I can login. This issue seems to be fixed.\nThank you.\n. @lsbardel Thanks to your commit, this issue seemed to be fixed.\nHowever it still not works on some browsers such as Google Chrome.\nWe can login via admin page, but login sessions are not stored on chat view.\nIt seems to be fixed on Safari.\nPlease check it again.\n. ",
    "derekchiang": "They have a pretty detailed guide for adding a benchmark: http://www.techempower.com/benchmarks/#section=code&hw=i7&test=json\nNot sure if I will have time to do this though.  If others are interested that'd be great.\n. ",
    "CMGS": "no\uff0cI use mac \n. ",
    "sekrause": "The problem is in the file pulsar.egg-info/SOURCES.txt from pulsar-0.8.0.tar.gz. It contains an absolute path in line 7:\n.gitignore\nLICENSE\nMANIFEST.in\nREADME.rst\nsetup.cfg\nsetup.py\n/Users/lsbardel/workspace/pulsar/extensions/lib/lib.c\ndocs/Makefile\ndocs/make.bat\ndocs/source/.DS_Store\ndocs/source/advantage.rst\ndocs/source/changelog.rst\n. Looks good now:\n```\nDownloading/unpacking pulsar\n  Downloading pulsar-0.8.1.tar.gz (684kB): 684kB downloaded\n  Running setup.py egg_info for package pulsar\n    ***********\n    WARNING: C extensions could not be compiled, Maybe Cython is not installed.\n    *************\n***************************************************************************\nPlain-Python build succeeded.\n***************************************************************************\n\nInstalling collected packages: pulsar\n  Running setup.py install for pulsar\n    ***********\n    WARNING: C extensions could not be compiled, Maybe Cython is not installed.\n    *************\n***************************************************************************\nPlain-Python build succeeded.\n***************************************************************************\n\nSuccessfully installed pulsar\nCleaning up...\n```\n. Thanks for the clarification, it does indeed work like that. I'm closing this bug.\n. Unfortunately I won't be able to test it before Monday. However, the main reason I would like to use Pulsar is because it really seems to be the only good solution to run a multiprocessing WSGI server on Windows, so turning off multiprocessing doesn't look like a good option except for testing. But I'll still test it if it helps hunting down the bug.\n. Thanks for the quick fix. I've just tested it with the dev branch and can confirm that it's now working there.\n. The MemoryError is gone now and even very large transfers finish completely, though they max out (with 100% CPU load) at around 80 MB/s (over localhost) per process on my machine, which I think should be higher (both through generating content on demand or sending a large file from an SSD).\nOne remaining problem is that when I either rate limit the transfer (wget -O /dev/null --limit-rate=1M http://localhost:8080/) or download content from a remote machine, I get a lot of those log statements:\n16:35:35 [p=6756, t=4368, INFO, pulsar.wsgi.worker] server 192.168.100.210:47921 session 2 wait for transport to drain\n16:35:35 [p=6756, t=4368, INFO, pulsar.wsgi.worker] server 192.168.100.210:47921 session 2 wait for transport to drain\n16:35:35 [p=6756, t=4368, INFO, pulsar.wsgi.worker] server 192.168.100.210:47921 session 2 wait for transport to drain\n[...]\nRate limiting on localhost it's only a few logs per second, but a transfer over a LAN connection creates thousands of logs per second. Maybe the log should be DEBUG level?\n. Here is a modified verion of the program above which I have used for testing (basically the same with a faster generator):\n``` python\nfrom itertools import repeat\nfrom flask import Flask\nfrom pulsar.apps import wsgi\nfrom pulsar.apps.wsgi.middleware import middleware_in_executor, wait_for_body_middleware\nfrom werkzeug.wrappers import Response\nclass Site(wsgi.LazyWsgi):\n    def setup(self, environ=None):\n        app = Flask(name)\n    @app.route(\"/\")\n    def test():\n        return Response(repeat('a' * 4096, 1048576), mimetype='text/plain')\n\n    return wsgi.WsgiHandler([wait_for_body_middleware, middleware_in_executor(app)])\n\nif name == 'main':\n    wsgi.WSGIServer(callable=Site(),\n               workers=0, thread_workers=20,\n               bind='0.0.0.0:8080').start()\n```\nNow that I'm at home I can try to reproduce the performance problem on OS X (I'm using Windows at work and a MacBook at home). So this time my setup is a 64-bit Python 3.4.1 on OS X.\nFirst we need to make sure that the generator function is not the bottleneck:\n``` python\ntest_generator.py\nimport itertools\nfor j in itertools.repeat('a' * 4096, 1048576):\n    print(j)\n```\n$ python test_generator.py | pv -a > /dev/null\n[1.96GiB/s]\nSo 1.96GiB/s should be fast enough (throughput measured by http://www.ivarch.com/programs/pv.shtml). Now let's download the generated data with curl:\n$ curl http://localhost:8080/ > /dev/null     \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 4096M    0 4096M    0     0  91.4M      0 --:--:--  0:00:44 --:--:-- 89.6M\nJust an average download speed of 91.4 MB/s. wget shows almost exactly the same speed.\nI've also discovered another critical problem on OS X which I didn't have on Windows: When I exit (Ctrl-C) curl while the transfer is still running, Pulsar stops responding completely and starts thrashing the console with endless repetitions of the following message:\n19:12:18 [p=18078, t=140735165104912, WARNING, asyncio] socket.send() raised exception.\n19:12:18 [p=18078, t=140735165104912, WARNING, asyncio] socket.send() raised exception.\n19:12:18 [p=18078, t=140735165104912, WARNING, asyncio] socket.send() raised exception.\n[...]\nThe only way to stop it from doing that is to kill -9 the process. Not even Ctrl-C works.\nAnd when I start a second curl download while one is already running, it won't receive any data until the first is finished even though I have 20 thread workers and the middleware_in_executor. Should I maybe file separate bug reports for this?\n. The goal should be to be able to download data almost as quickly as they can be generated, e.g. file downloads should be limited by the hard disk speed. However this is not a major problem for me right now since Pulsar is almost able to saturage a gigabit connection anyway.\nI actually did some benchmarks with Apache JMeter yesterday and I think I found more problems. When number_of_threads_in_jmeter > workers * thread_workers I actually get a lot of Connection refused errors for new requests. Shouldn't those requests have to wait until a thread is released instead of just being denied?\n. You're right, increasing the chunk size in the generator does indeed improve performance a lot. That also explains why sending files was so slow: Flask's send_file uses http://werkzeug.pocoo.org/docs/wsgi/#werkzeug.wsgi.wrap_file which has a default buffer size of only 8192 bytes. So if I ever run into actual performance problems, I'll just call wrap_file myself with a greater buffer size.\nThe two problems on OS X (failing after Ctrl-C in curl and no parallel transfers) indeed seem to be fixed now.\nHave you also done something about the Connection refused problem with many threads in JMeter? If yes, I'll do another load test tomorrow at work.\n. I hope I've done it correctly: https://github.com/quantmind/pulsar/pull/123\nAt least Flask and Werkzeug don't do any compression, they rely on the WSGI server or a reverse proxy server in front of it.\n. Do you know what the best workflow for pull requests is? Should I create a different branch for each issue? Looks like my second commit also went into the first pull request.\n. OK, I've removed the second commit.\n. Not sure if I'm doing something wrong. So my plan was to log all the requests in the response middleware so that I can log the response status code as well. Apart from the behavior above it looks that no reponse middleware at all is called unless the reponse was something served by the MediaRouter. Here is the code I use for running my application:\n``` python\ndef log_request(environ, response):\n    # Test function for now, doesn't actually do anything.\n    print(environ)\n    return response\nclass Site(wsgi.LazyWsgi):\n    def setup(self, environ=None):\n        from myapp.app import create_app\n        from myapp.config import default_ui_path\n    app = create_app()\n\n    middleware = [\n        wsgi.MediaRouter('ui/', default_ui_path(), show_indexes=False),\n        wait_for_body_middleware,\n        middleware_in_executor(app)\n    ]\n\n    response_middleware = [\n        log_request,\n        GZipMiddleware(),\n    ]\n\n    return wsgi.WsgiHandler(middleware=middleware, response_middleware=response_middleware)\n\n```\nIn all requests which go through the middleware_in_executor(app) neither the log_request nor GZipMiddleware is called.\n. It does work again with the wsgi.MediaRouter. When using the GZipMiddleware all responses which go through my Flask application fail with the following exception:\nFile \"D:\\virtualenv\\lib\\site-packages\\pulsar\\apps\\wsgi\\response.py\", line 107, in available\n    if response.status_code == 200 and not response.is_streamed:\nAttributeError: 'ClosingIterator' object has no attribute 'status_code'\nAt the time when the reponse middleware is called the response parameter is of the type werkzeug.wsgi.ClosingIterator  and I'm not sure what it's doing. Are the reponse middlewares maybe called a bit too early, before the reponse is fully ready? I tried to debug the problem, but couldn't find out where the ClosingIterator is converted into an actual reponse. \n. Thanks for the clarification. I guess I just don't understand WSGI well enough, but the way I see it ClosingIterator is just a simple iterator. I can call next() on it and get the response body, but I see no way to actually get or edit the response headers and status code.\nMy assumption was that since at some point (which I can't find) Pulsar must extract the actual result headers, status code etc. from Flask (it's sending them to the browser after all), I would get a chance to view and edit this result in a normalized form in the response middlewares.\nUnfortunately the async nature of Pulsar makes it really difficult for me to understand the internal workflow through a debugger, so I'm kind of lost there.\n. Yes, the application works fine as long as I don't add the GZipMiddleware. So it's not really a bug, just my own confusion. Here is what I was trying to achieve:\n- Log all requests, both the ones from Flask and the MediaRouter. And since Flask never sees static requests already handled by Pulsar, I thought there might be a place in Pulsar itself where I can see both the original request and the generated response and add my log statements there.\n- I wanted the GZipMiddleware to compress my Flask responses as well.\nConverted to an example program my application looks a bit like this:\n``` python\nfrom flask import Flask\nfrom pulsar.apps import wsgi\nfrom pulsar.apps.wsgi.middleware import middleware_in_executor, wait_for_body_middleware\ndef log_request(environ, response):\n    print(environ)\n    return response\nclass Site(wsgi.LazyWsgi):\n    def setup(self, environ=None):\n        app = Flask(name)\n    @app.route(\"/\")\n    def hello():\n        return \"Hello World!\"\n\n    middleware = [\n        wait_for_body_middleware,\n        middleware_in_executor(app)\n    ]\n\n    response_middleware = [\n        log_request,\n        #GZipMiddleware(),\n    ]\n\n    return wsgi.WsgiHandler(middleware=middleware, response_middleware=response_middleware)\n\nif name == 'main':\n    wsgi.WSGIServer(Site()).start()\n```\nIn the end I guess the best solution is to simply do everything in Flask. I can log the request in Flask's after_request() hook and compress my responses with Flask-Compress. And if still want to log requests for static files, I'll just subclass the MediaRouter and add my log statements there was well. In hindsight this probably sounds more elegant than fiddling around with raw response objects anyway.\n. And by the way, since the bug (chaining response middlewares) is indeed fixed, I guess this issue can be closed.\n. ",
    "impliers": "This is a call to the Twitter API endpoint documented here:\nhttps://dev.twitter.com/docs/api/1.1/get/user\nBecause it's Twitter, running the code requires that you register as a\ndeveloper and register an app to get the appropriate OAuth tokens, so I\ncan't share the code unless you want to register at Twitter.\nI use Pulsar's http client to make the https requests to log in prior to\ncalling this endpoint with no side effects.\nI am happy to add logging if you can think of any thing that might be\nhelpful.\nThe line of code which issues the request is\nr = client.request(method, url, headers=headers,\ndata_received=data_received)\nAny ideas?\nOn Tue, May 6, 2014 at 1:51 PM, Luca Sbardella notifications@github.comwrote:\n\nThe http client receives a message it can't properly decode.\nThis could be a pulsar bug or not.\nHow can I replicate it?\nCan I access the url you are requesting?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/quantmind/pulsar/issues/110#issuecomment-42357089\n.\n. As requested:\n\n```\n$ python\nPython 2.7.5 (default, Feb 19 2014, 13:47:28)\n[GCC 4.8.2 20131212 (Red Hat 4.8.2-7)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nimport pulsar\npulsar.version\n'0.8.1'\n$ uname -a\nLinux xxx.xxx.com 3.14.2-200.fc20.x86_64 #1 SMP Mon Apr 28 14:40:57 UTC\n2014 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n\n\nI'm happy to help any way I can.\nThanks.\nOn Tue, May 6, 2014 at 11:12 PM, Luca Sbardella notifications@github.comwrote:\n\nI should be able to replicate the issue,\ncan you tell me pulsar version?\npulsar.version\nand your OS?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/quantmind/pulsar/issues/110#issuecomment-42392938\n.\n. Related: in-progress chunked transfers inside workers don't respond to SIGINT.\n\nI decided not to clutter the issues list by filing this separately, perhaps incorrectly. \n. ",
    "an-dev": "python 2.7.3\npulsar 0.8.2\nDoes it have something to do with trollius and asyncio maybe?\n. btw my configuration is:\npip freeze >\namqp (1.4.5)\nanyjson (0.3.3)\nargparse (1.2.1)\nbilliard (3.3.0.17)\ncelery (3.1.12)\nDjango (1.6.5)\ndjango-celery (3.1.10)\nfutures (2.1.6)\nkombu (3.0.19)\npip (1.4.1)\npulsar (0.8.2)\npytz (2014.4)\nsetuptools (0.9.8)\nSouth (0.8.4)\ntrollius (0.3)\nwsgiref (0.1.2)\nrunning in a virtualenv on:\nLinux 3.8.0-33-generic #48~precise1-Ubuntu 32bit\nalso, my project looks like so:\n\n(I did change some names though)\n. mmm I've changed the listed files, but the problem seems to still be there\n. \nis this the right way to start the pulse/wsgi server?\n. There it is, it was certainly the config file. Totally missed that, wasn't in the tutorials/examples...Thanks!!\n. ",
    "axisofentropy": "Sorry all that got clobbered so I'm not sure what it was.  Probably a WSGIHandler.  It was very similar to the Websocket example.\n. Yes, I did use the LasyWsgi example.  My application is well on its way now, thanks!\n. ",
    "gthomas": "PyPy build failed (which is weird)\n. Actually looks like it's already fixed in dev.\n. ",
    "keis": "sure, reopened as #133 \n. ",
    "DavidJFelix": "Well this is awkward. Sorry @coveralls, I'm replacing your PNG. Yes that one.\n. Closing. #135 covers this per @lsbardel request to have changes be made to dev.\n. For what it's worth, I didn't break a build with this, that was just travis's fault. This is just a markdown change.\n. ",
    "robgil": "Thanks @lsbardel.\nPR: https://github.com/quantmind/pulsar/pull/138\n. Thank you so much @lsbardel. I will try to get to this in the next couple of days. \n. Yup. I'll work this up. \n. Here it is. Pex is pretty neat, but I would be open to other suggestions for deploying python apps. I'm trying to avoid either baking images or dealing with docker nonsense.\nhttps://github.com/robgil/pulsar-pex\n. I moved away from Pex to using newer versions of pip. New versions of pip allow you to store your compiled wheel files. It makes for an easier deploy.\nThe following is the relevant bits in the .travis.yml\n```\ninstall:\n   - pip install virtualenv\n   - virtualenv --always-copy ../mono-events\n   - mkdir .cache/\n   - . bin/activate && pip download -d .cache/ -r requirements.txt && pip install --find-links .cache/ -r requirements.txt\nbefore_deploy:\n  - rm -rf bin/ include/ lib/\n  - zip -r latest * .cache\n  - mkdir -p upload_dir/$TRAVIS_REPO_SLUG/$TRAVIS_BRANCH/\n  - mv latest.zip upload_dir/$TRAVIS_REPO_SLUG/$TRAVIS_BRANCH/$TRAVIS_BUILD_NUMBER.zip\n```\nOnce deployed to the server, the following will set up the virtualenv without needing internet, and without building.\ncd /<virtualenv path>\nvirtualenv -p /<path to python>/bin/python3.5 /<virtualenv path>/\n. bin/activate\npip install --find-links .cache/ -r requirements.txt\nThanks again for looking at this and lending an ear while I learn :)\n. ",
    "Arttii": "I tried the one from pip and github.  The only conflict I am thinking might occur is that I have python 3 installed as a conda environment, and during the cython compile its using the MinGw bundled with Anaconda for 2.7, but I don't see why that would not work for Python 3.\n. I did try that. The repl just crashes. I tried using Conda to create a virtual env with Python 3.3 so  the paths do not collide. Now I get :\nctypes.ArgumentError: argument 2: <class 'TypeError'>: expected      LP_CONSOLE_SCREEN_BUFFER_INFO instance instead of pointer to CONSOLE_SCREEN_BUFFER_INFO\nReadline internal error\nThis is really confusing me. This looks like a colorama issue, but I even tried uninstalling it. No effect.\n. The error seems to be in colorama or pyreadline. Uninstalling pyreadline alleviated the issue. This is discussed in pyreadline/pyreadline#21 and there's a PR to solve it. Uninstalling just seems easier though.\n. Yes. So Anaconda users should patch pyreqdline as per the PR or uninstall it.\n\nFrom: Luca Sbardellamailto:notifications@github.com\nSent: \u200e26.\u200e03.\u200e2015 21:49\nTo: quantmind/pulsarmailto:pulsar@noreply.github.com\nCc: Arttiimailto:artyom.topchyan@live.com\nSubject: Re: [pulsar] Compiled C extension import crashing Python, Windows (#139)\nIs it working for you now?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/quantmind/pulsar/issues/139#issuecomment-86708939\n. ",
    "Jiehong": "The greeter example shows a class calling a method outside itself, and it also calls the global variable names just like that.\nI don't get it\u2026\n. ",
    "artemmus": "Thanks, for an interesting framework\n. ",
    "nmg1986": "the code from the echo server examples:\nhttps://github.com/quantmind/pulsar/blob/master/examples/echo/manage.py\nand i add the connection_made method for class EchoProtocol as follows:\nclass EchoProtocol(pulsar.ProtocolConsumer):\n    '''An echo :class:~.ProtocolConsumer for client and servers.\n``\nThe only difference between client and server is the implementation\nof the :meth:response` method.\n'''\nseparator = b'\\r\\n\\r\\n'\n'''A separator for messages.'''\nbuffer = b''\n'''The buffer for long messages'''\ndef connection_made(self, connection):\n    self.logger.info('connected')\n```\nwhen i run the server and telnet from another terminal, when connected, the connection_made method do noting!\n. you mean class EchoProtocol(pulsar.async.events.EventHandler): ?\n. when i use class EchoProtocol(asyncio.Protocol): , it still does not work:(, can you give some examples for this ? \n. Yes, the updated example works well, but how can i do connection_made and connection_lost in ProtocolConsumer not outside?\n. Add also, in\npython\n def _data_received(self, data):\n        # Called by Connection, it updates the counters and invoke\n        # the high level data_received method which must be implemented\n        # by subclasses\n        if not hasattr(self, '_request'):\n            self.start()\n        self._data_received_count = self._data_received_count + 1\n        self.fire_event('data_received', data=data)\n        result = self.data_received(data)\n        self.fire_event('data_processed', data=data)\n        return result\nthe self.fire_event('data_received', data=data) and self.fire_event('data_processed', data=data) seems do noting , when i print out the event, i found the handler is None, does it necessary to do this here?\n. Ok, i known.\nBtw, i am writing a socket chat server these days, and I'm looking forward very much you can give me some project examples writing with pulsar, any suggestions will be very very appreciated.thank you:)\n. I wanna save it in redis for multiprocess access.\nIf i use a dict to store client-connection pair, the dict cannot be shared between processes when i used pulsar with multiprocess mode. \n. ",
    "mtpc": ":+1: \nI'd particularly love a comparison with Twisted and Tornado, both using the Reactor pattern\n. ",
    "msornay": "(I can open a new issue if you prefer)\nI'm using Python 3.4 on a Debian Jessie\n- Run python -m runtests --coverage\n- Stop it with ctrl+C\n- Run python -m runtests --coverage again. It fails with the following output :\n```\n$ python -m runtests --coverage                                               [15-10-02 14:56]\n3.4.3 (default, Sep 17 2015, 15:46:34) \n[GCC 4.9.2]\nCoverage file available. Type \"coverage html\" for a report\nBye (exit code = 2)\n```\nMy solution right now is to use git clean -fdx between test executions.\n. Thanks! I'm looking into it.\n. Could you please have a look at https://github.com/msornay/pulsar/commit/633b8622cf48b9d1b676977d8d949afaf01a656e  and give me advices ?\nIt provides what I think is the correct behavior, i.e. the result of socket.getfqdn() on the address returned by socket.getsockname(). This is what happens here.\nHowever : \n- It might not be necessary to do socket.getfqdn() on each requests ;\n- It might change the way \"host errors\" are handled in HTTPServerResponse._response ;\n- The test I wrote might be incorrect. The bug is only really clear when the remote server running pulsar cannot resolve the HTTP_HOST itself, which is hard to reproduce when the client and the server are on the same machine.\nThanks !\n. I have unfortunately no way of testing that myself. Could you give me the output ? Thanks.\n. > I understand the rationale but i dislike the implicit behaviour.\nI agree with you, but the implicit behavior is already there since access on a single value list returns the item, not the list. An alternative would be to always return lists.\n\nDo you have a use case where the API you are proposing would be better than the current one?\n\nDevelopers are used to the alternative implemented by Werkzeug (Flask is based on it). Moreover, using the several argument with the same name in the URL is not something that you consider often.\nIt is not so much about functionnality as it is about security. I'm sure that 9 times out of 10, making a request on an url with the same arguments will make a Pulsar-based app throw a 500 because the developper will not have taken the time to handle it properly (and I think he shoudn't anyway)\n. > Indeed, to be honest that decorator is somehow there for legacy reasons.\nInteresting. I have been using it on my Routers method to construct the reply in an asynchronous fashion. Am I missing something ? \n. If the developer re-use user input in an exception message, Pulsar will create HTML from it. If the user input happens to be javascript, it will be executed in the client browser when the error page is displayed.\n. ",
    "steveholden": "I'm seeing the same issue on Mac OS 10.10.5 with a simple python runtests.py - many thanks to @msornay for the workaround\n. The arbiter appears to be calling stop with an exception because the pid file is stale. The exception I see is:\nHaltServer(\"ERROR. Already running on PID 16308 (or pid file 'test.pid' is stale)\",)\n. Apologies: the exceptions concerned don't appear to be related to the line in question, as they occur even when 'OK'+4 is changed to 'OK'.\n. I also see two messages that read \"Not Found: /bsjdhcbjsdh\" in the testing output.\n. Additionally, please note that the \"Exception ignored\" message only occurs on Mac OS (Yosemite), while the \"Not found\" message occurs on both Mac OS and Ubuntu\n. ",
    "ssbarnea": "Yep, it seems that I raised a duplicate of this at #216 \n. ",
    "pvanderlinden": "This is a bug in lux, not in pulsar: https://github.com/quantmind/lux/issues/229\n. This doesn't make sense indeed, it should just run as asyncio in this case instead of as a green thread.\n. This solution seems to closely match PEP 479 for python < 3.5\n. ",
    "thedrow": "I don't see it documented anywhere. Also async is deprecated. It's called ensure_future in 3.5.\n. It seems that SSL support is broken on 3.5. See #176 \n. I was using the latest from pip.\nWhen I installed the version from the py35 branch the exception did not occur. \nWill these fixes be backported to 1.0.x as well or do I have to wait for a version that supports python 3.5?\n. That's exactly what I have and it's not working properly.\n. ",
    "bright-pan": "cool. sorry\uff0c i make a mistake for it,  i am not review pulsar test regulation in pulsar.apps.test.init.py\nIntroduction\n====================\nTo get started with pulsar asynchronous test suite is easy. The first thing to\ndo is to create a python ``script`` on the top level directory of your library,\nlet's call it ``runtests.py``::\n    from pulsar.apps import TestSuite\n    if __name__ == '__main__':\n        TestSuite(description='Test suite for my library',\n                  modules=('regression',\n                           ('examples', 'tests'))).start()\n. ",
    "akatrevorjay": "\nCan do.\nYeah, I was considering doing that, it will require some restructuring of how proxies are applied, but honestly I think it will be worth it.\n. \n",
    "dejlek": "Why would it behave any different? \"hello asdfsfworld!\" is just yet another string. Have you seen what the test actually does?\n. ",
    "davebshow": "Everything seems to be working as expected now. Thanks @lsbardel! \n. ",
    "hoefling": "Unfortunately, I don't see a possibility to reproduce the issue without installing Gentoo (at least a minimal installation on a VM) and integrating the custom ebuild via layman. At least I did a bisect and found out that the issue was first introduced in 83ce3e3.\n. After looking further into the diff of the mentioned commit, I found the issue source. I simply forgot to declare a dependency on the wheel package, thus the problem was entirely on my side. Sorry! Closing this issue as nothing to fix.\n. ",
    "wilddom": "Well, the endpoint I use unfortunately does not support unicode escape sequences (\\uXXXX), which actually breaks the JSON specification. But anyway, it would be nice to be able to choose the encoding.\n. breaks style convention.\n. In my case I'm using the JsonProxy but it's actually the underlying HttpClient (the decode_content method) which is parsing json. In the end I get back a string instead of a dict after calling one of the JsonProxy's rpc method. And that's because the server sends the content type application/json-rpc.\n. ",
    "mbikovitsky": "Yeah, sorry about that. Note to self: don't commit when tired.\n. ",
    "IwanLD": "TLDR\nHey, I'm having the same issue, but found a hacky workaround - see SOLUTION beneath if your tldr ;) \nANALYSIS\nTo dive into it I have the simple test server\n```\ndef hello(environ, start_response):\n    data = b\"Hello World!\"\n    response_headers = [('Content-type','text/plain'),\n                        ('Content-Length', str(len(data)))]\n    start_response(\"200 OK\", response_headers)\n    return [data]\nif name == 'main':\n    wsgi.WSGIServer(hello).start()\n```\nwhen it starts via python3 app.py , I get\n16:40:21 [p=383, t=139677125908224, INFO, pulsar.arbiter] mailbox serving on 127.0.0.1:42675\n16:40:21 [p=383, t=139677125908224, INFO, pulsar.arbiter] started\n16:40:21 [p=383, t=139677125908224, INFO, pulsar.wsgi] started\n16:40:21 [p=385, t=139677125908224, INFO, pulsar.wsgi.worker] wsgi serving on 127.0.0.1:8060\n16:40:21 [p=385, t=139677125908224, INFO, pulsar.wsgi.worker] started\nMy docker is basically run with docker -p 8060:8060 -p 5000:5000 -it myimage.  So the port 8060 is open. (5000 is just to show that flask works later)\nInside the docker\n$ curl localhost:8060\nHello World!\nOutside the docker\n$ curl localhost:8060\ncurl: (52) Empty reply from server\n$ curl localhost:5000\ncurl: (52) Empty reply from server\n$ curl localhost:5001\ncurl: (7) Failed to connect to localhost port 5001: Connection refused\nWhen I then run a hello world in flask on 5000 everithing works fine.\nOutside the docker\n$ curl localhost:5000\nHello world\nSo it seems that somehow to the outsite world it is if there were no one listening to the 8060 port.\nNow when I run it with python3 app.py --bind localhost:8060 the output is a bit different...\n17:27:46 [p=1056, t=140084304557824, INFO, pulsar.arbiter] mailbox serving on 127.0.0.1:43803\n17:27:46 [p=1056, t=140084304557824, INFO, pulsar.arbiter] started\n17:27:46 [p=1056, t=140084304557824, INFO, pulsar.wsgi] started\n17:27:46 [p=1059, t=140084304557824, INFO, pulsar.wsgi.worker] wsgi serving on [::1]:8060\n17:27:46 [p=1059, t=140084304557824, INFO, pulsar.wsgi.worker] wsgi serving on 127.0.0.1:8060\n17:27:46 [p=1059, t=140084304557824, INFO, pulsar.wsgi.worker] started\n... but the result stays the same.\nSOLUTION\nNow when inside the docker I run \n$ ip route show\ndefault via 172.17.0.1 dev eth0\n172.17.0.0/16 dev eth0  proto kernel  scope link  src 172.17.0.2\nand then start the app with python3 app.py --bind 172.17.0.2:8060 there comes remedy.\nOn the outside I get\n$ curl localhost:8060\nHello World!\nYeay!\nOn the inside of the container I get\n$ curl localhost:8060\ncurl: (7) Failed to connect to localhost port 8060: Connection refused\nand even\n$ curl 172.17.0.2:8060\ncurl: (7) Failed to connect to 172.17.0.2 port 8060: Connection refused\nbut luckily\n$ curl 172.17.0.1:8060\nHello World!\nANALYSIS\nI'm no expert on networks but so far my interpretation is this: Docker seems to set up some sort of extra routes layer between the containers localhost and the outer world.\nEvery other web framework I've used so far with docker (flask, node) binds both localhost and this extra layer by default and works with docker out of the box.\nPulsar so far binds only either or. Imho, this should be either changed (to always binding both) or added as an extra option.\nFURTHER READING\nI got the idea from this SO post\n. I'm a bit confused, that this got closed without a comment. I consider this a major gotcha, since docker is gaining popularity quickly and this behavior is unexpected. Especially since a lot of the pulsar documentaion (well the docstrings actually) contains examples with \"bind 127.0.0.1\". It should be at least noted somewhere (preferably somewhere besides this post).\n. ",
    "MrLoh": "It seems like simply doing the --bind :8060 also does the trick. I can then connect inside the docker to localhost:8060 and outside the docker to docker_ip:mapped_port, just as expected.\n. ",
    "JordanP": "Yes, I tested it, it's fixed in the dev branch.\nThanks.\n. ",
    "scailer": "```\n$ python3 runtests.py --test-modules myapp \n3.5.2 (default, Jun 28 2016, 08:46:01) \n[GCC 6.1.1 20160602]\nRan 0 tests in 0.000s\nOK\nBye (exit code = 0)\n```\n```\n$ python3 runtests.py --test-modules myapp.test\n3.5.2 (default, Jun 28 2016, 08:46:01) \n[GCC 6.1.1 20160602]\n\n.\n$ py.test myapp/test.py                       \n===================== test session starts =====================\nplatform linux -- Python 3.5.2, pytest-3.0.3, py-1.4.31, pluggy-0.4.0\nrootdir: /home/scailer/projects/tamtam/message, inifile: \nplugins: asyncio-0.5.0, cov-2.4.0\ncollected 1 items \nmyapp/test.py .\n=================== 1 passed in 0.10 seconds ===================\n```\n. Move text file to another dir and tests successfuly run\n```\n$ mkdir tests\n$ mv myapp/test.py tests/myapp_test.py\n$ python3 runtests.py --test-modules tests                                       \n3.5.2 (default, Jun 28 2016, 08:46:01) \n[GCC 6.1.1 20160602]\nCALL\n.\nRan 1 test in 0.002s\nOK\nBye (exit code = 0)\n```\n. Sometimes (~10%) get error in tests. Can't understand reasons.\n```\nERROR: http.client.test_raw_stream_large (home.scailer.tmp.pulsar.tests.http.test.client.TestHttpClient)\n\nTraceback (most recent call last):\nFile \"/home/scailer/tmp/pulsar/pulsar/apps/test/runner.py\", line 234, in store_trace\n    await coro\nFile \"/home/scailer/tmp/pulsar/tests/http/base.py\", line 848, in test_raw_stream_large\n    data = await raw.read()\nFile \"/home/scailer/tmp/pulsar/pulsar/apps/http/stream.py\", line 33, in read\n    async for body in self:\nFile \"/home/scailer/tmp/pulsar/pulsar/apps/http/stream.py\", line 62, in anext\n    return await self._queue.get()\nFile \"/usr/lib64/python3.7/asyncio/queues.py\", line 159, in get\n    await getter\nconcurrent.futures._base.CancelledError\n```. ",
    "s-sokolko": "@lsbardel yes, I'll do the tests, just need some time to learn how to write tests for pulsar. Thanks for the link, I will study the example and make the test case for my code basing on your example\n. @lsbardel  Done, tests are working now\n. @lsbardel  This happens when I run obj_head method on non-existent object resulting in HEAD HTTP request returning empty HTTP response with the status of 404 error. The response also has a header of chunked content. Maybe this is incorrect, but S3 does this, so this patch allows handle S3 response correctly.\n. ",
    "RyanKung": "'WsgiRequest' object has no attribute 'version'\n???. @lsbardel ok & thanks. @lsbardel Here is the unit test and examples. . Hi @lsbardel , plz check https://github.com/quantmind/pulsar/pull/280 and https://github.com/quantmind/pulsar/pull/279 which is for dev branch. Fixed, sorry for that mistakes, all OK now. \nThanks for the reviewing @lsbardel \n```\npython setup.py test -a pulsarapp\npython setup.py test -a wsgi.router\n``\n. Thanks,ensure_future` is exactly what I need, I'm just switching to pulsar 2.0.  \ud83e\udd42 . ",
    "carn1x": "Would this describe the ability to list and specify specific test functions as per this example?:\nFor instance in a current project I run -m runtests -l and get:\n```\nAll test labels:\nmyapp.tasks\n```\nWhen actually what I'd hope to do is emulate the level of drill-down which -m unittest provides so I could list the following (and individually run any of):\n```\nAll test labels:\nmyapp.tasks\nmyapp.tasks.SetQuantityTest\nmyapp.tasks.SetQuantityTest.test_gets_actor_quantity\nmyapp.tasks.SetQuantityTest.test_sets_actor_quantity\n```\nCurrently at the moment only the following work:\n-m runtests myapp\n-m runtests myapp.tasks\n-m runtests myapp.tasks.test_gets_actor_quantity\nBut not:\n-m runtests myapp.tasks.SetQuantityTest\n-m runtests myapp.tasks.SetQuantityTest.test_gets_actor_quantity\nwhich seems kinda odd, and I suppose requires that all my test methods need to have unique  names even across multiple classes? Is this a general assumption for all test suites or just pulsar's assumption? I've not encountered it before though.\n. Closing, will post on https://groups.google.com/forum/?fromgroups#!forum/python-pulsar instead. ",
    "erikash": "Thanks for the quick response!\nThe simplest use case is batch processing (multiple machines needed for performance), in which a Monitor which needs to coordinate actors across machines.\nAnother use case is consistent hashing or another sharding scheme in which an actor is assigned a chunk of data to process commands, this requires the monitor to intelligently route commands to the matching actors.\nDoes this make sense?\nThanks,\nErik.. ",
    "sideffect0": "is release script private(not in public code) ?. what is blocking it from running the script in CI ?. I was checking what is blocking pulsar 2.0 release; Am happy to contribute/help :)\n. @lsbardel  we can use https://www.appveyor.com/ for windows builds. ",
    "wellls": "@sideffect0 I think release script is public, it's in this folder.. ",
    "Triquetra": "This seems to be an issue with weppy App objects not being pickleable (see weppy issue linked above).  Is there a way to run Pulsar in non-blocking mode or with greenlets that does not pickle the callable?. Thanks.  That worked.. ",
    "codecov-io": "Codecov Report\n\nMerging #292 into deploy will increase coverage by 0.02%.\nThe diff coverage is 66.66%.\n\n\n```diff\n@@            Coverage Diff             @@\ndeploy     #292      +/-\n==========================================\n+ Coverage   84.89%   84.91%   +0.02%   \n==========================================\n  Files         139      139            \n  Lines       15692    15693       +1   \n==========================================\n+ Hits        13322    13326       +4   \n+ Misses       2370     2367       -3\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/cmds/linux_wheels.py | 0% <0%> (\u00f8) | :arrow_up: |\n| pulsar/utils/config.py | 96.35% <100%> (\u00f8) | :arrow_up: |\n| pulsar/apps/data/pulsards/__init__.py | 0% <0%> (\u00f8) | :arrow_up: |\n| pulsar/async/concurrency.py | 81.43% <0%> (+0.75%) | :arrow_up: |\n| pulsar/utils/pylib/events.py | 95.32% <0%> (+1.86%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 27fa136...be00ac6. Read the comment docs.\n. # Codecov Report\nMerging #293 into release will decrease coverage by 0.02%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff             @@\nrelease     #293      +/-\n===========================================\n- Coverage     84.9%   84.88%   -0.03%   \n===========================================\n  Files          139      139            \n  Lines        15692    15696       +4   \n===========================================\n  Hits         13323    13323            \n- Misses        2369     2373       +4\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/cmds/linux_wheels.py | 0% <0%> (\u00f8) | :arrow_up: |\n| pulsar/async/concurrency.py | 80.68% <0%> (-0.76%) | :arrow_down: |\n| pulsar/utils/pylib/events.py | 95.32% <0%> (+1.86%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4ecb2d4...3205865. Read the comment docs.\n. # Codecov Report\nMerging #294 into deploy will decrease coverage by 0.02%.\nThe diff coverage is 28.57%.\n\n\n```diff\n@@            Coverage Diff             @@\ndeploy     #294      +/-\n==========================================\n- Coverage   84.89%   84.87%   -0.03%   \n==========================================\n  Files         139      139            \n  Lines       15692    15696       +4   \n==========================================\n  Hits        13322    13322            \n- Misses       2370     2374       +4\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/async/mailbox.py | 85.8% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/apps/wsgi/__init__.py | 100% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/apps/wsgi/routers.py | 93.08% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/async/consts.py | 100% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/async/proxy.py | 96.87% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/apps/wsgi/route.py | 89.72% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/cmds/linux_wheels.py | 0% <0%> (\u00f8) | :arrow_up: |\n| pulsar/utils/config.py | 96.34% <100%> (-0.01%) | :arrow_down: |\n| pulsar/utils/http/parser.py | 91.28% <0%> (-0.42%) | :arrow_down: |\n| pulsar/apps/data/pulsards/__init__.py | 0% <0%> (\u00f8) | :arrow_up: |\n| ... and 1 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 27fa136...e9cb1bf. Read the comment docs.\n. # Codecov Report\nMerging #295 into deploy will decrease coverage by 1.15%.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff             @@\ndeploy     #295      +/-\n==========================================\n- Coverage   86.01%   84.85%   -1.16%   \n==========================================\n  Files         134      139       +5   \n  Lines       15485    15696     +211   \n==========================================\n  Hits        13319    13319            \n- Misses       2166     2377     +211\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/apps/http/stream.py | 76.59% <0%> (-2.13%) | :arrow_down: |\n| pulsar/utils/http/parser.py | 91.28% <0%> (-0.42%) | :arrow_down: |\n| pulsar/utils/config.py | 96.34% <0%> (-0.01%) | :arrow_down: |\n| pulsar/apps/wsgi/content.py | 88.13% <0%> (\u00f8) | :arrow_up: |\n| pulsar/apps/wsgi/routers.py | 93.08% <0%> (\u00f8) | :arrow_up: |\n| pulsar/async/mailbox.py | 85.8% <0%> (\u00f8) | :arrow_up: |\n| pulsar/apps/test/wsgi.py | 100% <0%> (\u00f8) | :arrow_up: |\n| pulsar/apps/data/pulsards/__init__.py | 0% <0%> (\u00f8) | :arrow_up: |\n| pulsar/apps/wsgi/__init__.py | 100% <0%> (\u00f8) | :arrow_up: |\n| pulsar/apps/wsgi/route.py | 89.72% <0%> (\u00f8) | :arrow_up: |\n| ... and 5 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ddd4a21...fc84f0f. Read the comment docs.\n. # Codecov Report\nMerging #298 into release will increase coverage by 1.25%.\nThe diff coverage is 91.48%.\n\n\n```diff\n@@            Coverage Diff             @@\nrelease    #298      +/-\n==========================================\n+ Coverage    84.85%   86.1%   +1.25%   \n==========================================\n  Files          139     132       -7   \n  Lines        15696   15074     -622   \n==========================================\n- Hits         13319   12980     -339   \n+ Misses        2377    2094     -283\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/apps/greenio/__init__.py | 100% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/async/futures.py | 81.05% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/apps/http/client.py | 90% <\u00f8> (+0.6%) | :arrow_up: |\n| pulsar/apps/wsgi/wrappers.py | 76.38% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/utils/lib.py | 66.66% <0%> (-3.93%) | :arrow_down: |\n| pulsar/utils/pylib/events.py | 97.08% <100%> (+3.62%) | :arrow_up: |\n| pulsar/apps/wsgi/content.py | 89.66% <100%> (+1.53%) | :arrow_up: |\n| pulsar/api.py | 100% <100%> (\u00f8) | :arrow_up: |\n| pulsar/apps/greenio/utils.py | 84% <25%> (-2.96%) | :arrow_down: |\n| pulsar/utils/context.py | 95.18% <95.18%> (\u00f8) | |\n| ... and 13 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update fc84f0f...f89acb4. Read the comment docs.\n. # Codecov Report\nMerging #301 into release will increase coverage by 0.01%.\nThe diff coverage is 80.95%.\n\n\n```diff\n@@             Coverage Diff             @@\nrelease     #301      +/-\n===========================================\n+ Coverage    86.09%   86.11%   +0.01%   \n===========================================\n  Files          132      132            \n  Lines        15074    15081       +7   \n===========================================\n+ Hits         12978    12987       +9   \n+ Misses        2096     2094       -2\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/apps/test/__init__.py | 93.75% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/apps/greenio/utils.py | 84% <\u00f8> (\u00f8) | :arrow_up: |\n| pulsar/apps/wsgi/wrappers.py | 74.87% <0%> (-1.51%) | :arrow_down: |\n| pulsar/apps/http/client.py | 90.29% <100%> (+0.29%) | :arrow_up: |\n| pulsar/apps/test/utils.py | 94.23% <100%> (+0.29%) | :arrow_up: |\n| pulsar/apps/test/runner.py | 80.23% <100%> (+0.11%) | :arrow_up: |\n| pulsar/async/concurrency.py | 81.43% <0%> (+0.75%) | :arrow_up: |\n| pulsar/utils/pylib/events.py | 99.02% <0%> (+1.94%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update f10c3ea...01183d7. Read the comment docs.\n. # Codecov Report\nMerging #302 into release will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff             @@\nrelease    #302      +/-\n==========================================\n+ Coverage     86.1%   86.1%   +<.01%   \n==========================================\n  Files          132     132            \n  Lines        15081   15081            \n==========================================\n+ Hits         12985   12986       +1   \n+ Misses        2096    2095       -1\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/apps/http/stream.py | 76.59% <0%> (-2.13%) | :arrow_down: |\n| pulsar/utils/pylib/events.py | 99.02% <0%> (+1.94%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d8d9082...0f3d798. Read the comment docs.\n. # Codecov Report\nMerging #304 into release will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff             @@\nrelease    #304      +/-\n==========================================\n+ Coverage    86.09%   86.1%   +<.01%   \n==========================================\n  Files          132     132            \n  Lines        15081   15081            \n==========================================\n+ Hits         12984   12985       +1   \n+ Misses        2097    2096       -1\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/utils/http/parser.py | 91.7% <0%> (+0.41%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 0e47274...a9bfdfd. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (deploy@ca32ea3). Click here to learn what that means.\nThe diff coverage is 89.56%.\n\n\n```diff\n@@            Coverage Diff            @@\ndeploy     #305   +/-\n=========================================\n  Coverage          ?   86.08%         \n=========================================\n  Files             ?      132         \n  Lines             ?    15081         \n  Branches          ?        0         \n=========================================\n  Hits              ?    12983         \n  Misses            ?     2098         \n  Partials          ?        0\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| pulsar/async/futures.py | 81.05% <\u00f8> (\u00f8) | |\n| pulsar/apps/test/__init__.py | 93.75% <\u00f8> (\u00f8) | |\n| pulsar/apps/greenio/__init__.py | 100% <\u00f8> (\u00f8) | |\n| pulsar/apps/wsgi/wrappers.py | 74.87% <0%> (\u00f8) | |\n| pulsar/utils/lib.py | 66.66% <0%> (\u00f8) | |\n| pulsar/apps/test/utils.py | 94.23% <100%> (\u00f8) | |\n| pulsar/apps/test/runner.py | 80.23% <100%> (\u00f8) | |\n| pulsar/api.py | 100% <100%> (\u00f8) | |\n| pulsar/apps/http/client.py | 90.29% <100%> (\u00f8) | |\n| pulsar/utils/pylib/events.py | 97.08% <100%> (\u00f8) | |\n| ... and 3 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ca32ea3...4907faf. Read the comment docs.\n. \n",
    "fabiocerqueira": "Ok, I can take this issue :D . I just switched the base branch to dev. ",
    "ldanilov": "+2. ",
    "ringods": "@lsbardel would you have time to look into the Cloudflare setup? The docs accessible so far are the 1.6 ones here: http://quantmind.github.io/pulsar/index.html. ",
    "TTimo": "Oh I didn't see pull request #313 I will have to try. "
}